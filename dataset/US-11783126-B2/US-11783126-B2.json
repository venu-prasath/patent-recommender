{
    "patent_id": "US-11783126-B2",
    "title": "Enabling chatbots by detecting and supporting affective argumentation ",
    "assignee": "Oracle International Corporation",
    "publication_date": "2023-10-10",
    "patent_link": "https://patents.google.com/patent/US11783126B2/en",
    "inventors": [
        "Boris Galitsky"
    ],
    "classifications": [
        "G06F40/253",
        "G06F40/205",
        "G06F40/216",
        "G06F40/289",
        "G06F40/30",
        "G06F40/35",
        "G06N20/10",
        "G06N3/006",
        "G06N5/01",
        "G06N5/02",
        "G06N5/041"
    ],
    "abstract": "Systems, devices, and methods of the present invention detect affective argumentation in text. In an example, an application executing on a computing device accesses text comprising fragments. The application creates a discourse tree from the text. The discourse tree includes nodes, each nonterminal node representing a rhetorical relationship between two of the fragments and each terminal node of the nodes of the discourse tree is associated with one of the fragments. The application matches each fragment that has a verb to a verb signature, thereby creating a communicative discourse tree. The application determines whether the communicative discourse tree represents text that includes affective argumentation by applying a classification model trained to detect affective argumentation to the communicative discourse tree.",
    "claims": "\n1. A method for determining argumentation in text, the method comprising:\ncreating, from fragments of text, a communicative discourse tree, wherein a communicative discourse tree comprises a discourse tree having a plurality of nodes, each nonterminal node representing a rhetorical relationship between at least two fragments of the fragments of text and each terminal node of the nodes of the discourse tree is associated with one of the fragments, and wherein each fragment that has a verb is matched to a verb signature, wherein a verb signature comprises the verb and a respective thematic role that describes a relationship between the verb and other words in the fragment;\ndetermining whether text comprises affective argumentation by applying, to the communicative discourse tree, a classification model trained to detect a presence of affective argumentation, wherein applying the classification model to the communicative discourse tree comprises:\nidentifying an additional communicative discourse tree from a positive set or a negative training set, wherein the positive set is associated with text containing affective argumentation and the negative set is associated with text without affective argumentation;\ndetermining one or more common verb signatures present in both the communicative discourse tree and the additional communicative discourse tree; and\ndetermining, based on the identifying, whether the text contains affective argumentation or no affective argumentation; and\nresponsive to determining that the text comprises affective argumentation, accessing a response that corresponds to the text and outputting the response.\n2. The method of claim 1, wherein the classification model is trained by iteratively:\nproviding one of a set of training pairs to the classification model, wherein each training pair comprises a training communicative discourse tree and an expected level of affective argumentation;\nreceiving, from the classification model, a determined level of affective argumentation;\ncalculating a loss function by calculating a difference between the determined level of affective argumentation and the expected level of affective argumentation; and\nadjusting internal parameters of the classification model to minimize the loss function.\n3. The method of claim 1, wherein each verb signature comprises one of (i) an adverb, (ii) a noun phrase, or (iii) a noun.\n4. The method of claim 1, wherein applying the classification model to the communicative discourse tree further comprises identifying one or more common rhetoric relations or common communicative action labels between the communicative discourse tree and the additional communicative discourse tree.\n5. The method of claim 1, wherein applying the classification model to the communicative discourse tree further comprises identifying one or more common structures of nonterminal nodes and terminal nodes between the communicative discourse tree and the additional communicative discourses tree.\n6. The method of claim 1, wherein the classification model is a support vector machine with tree kernel learning or uses nearest neighbor learning of maximal common sub-trees of communicative discourse trees.\n7. The method of claim 1, wherein the one or more common verb signatures comprise a common thematic role between the communicative discourse tree and the additional communicative discourse tree.\n8. A system comprising:\na non-transitory computer-readable medium storing computer-executable program instructions; and\na processing device communicatively coupled to the non-transitory computer-readable medium for executing the computer-executable program instructions, wherein executing the computer-executable program instructions configures the processing device to perform operations comprising:\ncreating a communicative discourse tree from fragments of text, wherein a communicative discourse tree comprises a discourse tree having a plurality of nodes, each nonterminal node representing a rhetorical relationship between at least two fragments of the fragments of text and each terminal node of the nodes of the discourse tree is associated with one of the fragments, and wherein each fragment that has a verb is matched to a verb signature wherein a verb signature comprises the verb and a respective thematic role that describes a relationship between the verb and other words in the fragment;\ndetermining whether text comprises affective argumentation by applying, to the communicative discourse tree, a classification model trained to detect a presence of affective argumentation, wherein applying the classification model to the communicative discourse tree comprises:\nidentifying an additional communicative discourse tree from a positive set or a negative training set, wherein the positive set is associated with text containing affective argumentation and the negative set is associated with text without affective argumentation;\ndetermining one or more common verb signatures present in both the communicative discourse tree and the additional communicative discourse tree; and\ndetermining, based on the identifying, whether the text contains affective argumentation or no affective argumentation; and\nresponsive to determining that the text comprises affective argumentation, accessing a response that corresponds to the text and outputting the response.\n9. The system of claim 8, wherein the classification model is trained by iteratively:\nproviding one of a set of training pairs to the classification model, wherein each training pair comprises a training communicative discourse tree and an expected level of affective argumentation;\nreceiving, from the classification model, a determined level of affective argumentation;\ncalculating a loss function by calculating a difference between the determined level of affective argumentation and the expected level of affective argumentation; and\nadjusting internal parameters of the classification model to minimize the loss function.\n10. The system of claim 8, wherein applying the classification model to the communicative discourse tree further comprises identifying common structures of nonterminal nodes and terminal nodes between the communicative discourse tree and the additional communicative discourses tree.\n11. The system of claim 8, wherein the classification model is a support vector machine with tree kernel learning or uses nearest neighbor learning of maximal common sub-trees of communicative discourse trees.\n12. The system of claim 8, wherein the one or more common verb signatures comprise a common thematic role between the communicative discourse tree and the additional communicative discourse tree.\n13. The system of claim 8, wherein applying the classification model to the communicative discourse tree further comprises identifying on one or more common structures of nonterminal nodes and terminal nodes between the communicative discourse tree and the additional communicative discourses tree.\n14. A non-transitory computer-readable medium storing computer-executable program instructions that when executed by a processor, perform operations comprising:\ncreating a communicative discourse tree from fragments of text, wherein a communicative discourse tree comprises a discourse tree having a plurality of nodes, each nonterminal node representing a rhetorical relationship between at least two fragments of the fragments of text and each terminal node of the nodes of the discourse tree is associated with one of the fragments, and wherein each fragment that has a verb is matched to a verb signature, wherein a verb signature comprises the verb and a respective thematic role that describes a relationship between the verb and other words in the fragment;\ndetermining whether text comprises affective argumentation by applying, to the communicative discourse tree, a classification model trained to detect a presence of affective argumentation, wherein applying the classification model to the communicative discourse tree comprises:\nidentifying an additional communicative discourse tree from a positive set or a negative training set, wherein the positive set is associated with text containing affective argumentation and the negative set is associated with text without affective argumentation;\ndetermining one or more common verb signatures present in both the communicative discourse tree and the additional communicative discourse tree; and\ndetermining, based on the identifying, whether the text contains affective argumentation or no affective argumentation; and\nresponsive to determining that the text comprises affective argumentation, accessing a response that corresponds to the text and outputting the response.\n15. The non-transitory computer-readable medium of claim 14, wherein the classification model is trained by iteratively:\nproviding one of a set of training pairs to the classification model, wherein each training pair comprises a training communicative discourse tree and an expected level of affective argumentation;\nreceiving, from the classification model, a determined level of affective argumentation;\ncalculating a loss function by calculating a difference between the determined level of affective argumentation and the expected level of affective argumentation; and\nadjusting internal parameters of the classification model to minimize the loss function.\n16. The non-transitory computer-readable medium of claim 14, wherein a thematic role of the verb signature corresponds to one or more roles of words in the fragment and describes a relationship between a verb of the fragment and one or more words in the fragment.\n17. The non-transitory computer-readable medium of claim 14, wherein each verb signature comprises one of (i) an adverb, (ii) a noun phrase, or (iii) a noun.\n18. The non-transitory computer-readable medium of claim 14, wherein applying the classification model to the communicative discourse tree further comprises identifying common rhetoric relations or common communicative action labels between the communicative discourse tree and the additional communicative discourse tree.\n19. The non-transitory computer-readable medium of claim 14, wherein the one or more common verb signatures comprise a common thematic role between the communicative discourse tree and the additional communicative discourse tree.\n20. The non-transitory computer-readable medium of claim 14, wherein applying the classification model to the communicative discourse tree further comprises identifying on one or more common structures of nonterminal nodes and terminal nodes between the communicative discourse tree and the additional communicative discourses tree.",
    "status": "Active",
    "citations_own": [
        "US5495605A",
        "US5930392A",
        "US6112168A",
        "US6181909B1",
        "US20010007987A1",
        "US20010053968A1",
        "US20020040292A1",
        "US20030138758A1",
        "US20040044519A1",
        "US6731307B1",
        "US20040133579A1",
        "US20040148170A1",
        "US20040267770A1",
        "US20050049867A1",
        "US20050086592A1",
        "US6961692B1",
        "US7152031B1",
        "US20070073533A1",
        "US20070136284A1",
        "US20070192306A1",
        "US20070239423A1",
        "US20070294229A1",
        "US7359860B1",
        "US20080172409A1",
        "US20080228467A1",
        "US20090089252A1",
        "US7519529B1",
        "US20090100053A1",
        "US7551552B2",
        "US20090248399A1",
        "US20090282019A1",
        "US20100169359A1",
        "US7840556B1",
        "US20100299136A1",
        "US20110119049A1",
        "CN102165518A",
        "US20120041950A1",
        "US20120078902A1",
        "US20120173500A1",
        "US20120246578A1",
        "US20130046757A1",
        "US20130151347A1",
        "US20130204611A1",
        "US20130268532A1",
        "US20130311485A1",
        "US20140040288A1",
        "US20140090054A1",
        "US8694303B2",
        "US20140122083A1",
        "US20140136188A1",
        "US8756617B1",
        "US20150039295A1",
        "US20150046492A1",
        "US20150051900A1",
        "US20150134325A1",
        "US9037464B1",
        "US20150149461A1",
        "US20150161512A1",
        "US20160026608A1",
        "US20160034457A1",
        "US20160055240A1",
        "US20160071517A1",
        "US20160085743A1",
        "US20160086601A1",
        "US20160099892A1",
        "US20160232152A1",
        "US20160245779A1",
        "US20160246779A1",
        "US20160247068A1",
        "US9449080B1",
        "CN105955956A",
        "US20160283491A1",
        "US20160292153A1",
        "US20160328667A1",
        "US9514098B1",
        "US20170032053A1",
        "US9582501B1",
        "CN106502981A",
        "US20170104829A1",
        "US20170116982A1",
        "US20170177675A1",
        "US20170228368A1",
        "US20170277993A1",
        "US20170286390A1",
        "US9817721B1",
        "US20180181648A1",
        "US20180189385A1",
        "US10019716B1",
        "US20180260472A1",
        "US20180314689A1",
        "US20180365228A1",
        "US20180365593A1",
        "US20180373701A1",
        "US20190005027A1",
        "US20190033957A1",
        "US20190057157A1",
        "US20190103111A1",
        "US10289974B1",
        "US20190163756A1",
        "US20190354544A1",
        "US20190377605A1",
        "US10599885B2",
        "US20200099790A1",
        "US20200117858A1",
        "US10679011B2",
        "US20200279075A1",
        "US20200301589A1",
        "US10839154B2",
        "US20210020165A1",
        "US20210027799A1",
        "US20210029248A1",
        "US11023684B1",
        "US11373632B2",
        "US11386274B2",
        "US11410072B2",
        "US11455469B2",
        "US11586827B2"
    ],
    "citations_ftf": [
        "WO2015089822A1"
    ],
    "citedby_own": [],
    "citedby_ftf": [
        "US10839154B2",
        "US11386274B2",
        "US11615145B2",
        "US10796099B2",
        "US10733538B2",
        "US10635521B2",
        "US11537645B2",
        "US11301640B2",
        "US10977443B2",
        "US11182557B2",
        "US11080490B2",
        "US11106874B2",
        "US11270077B2",
        "US11501233B2",
        "CN110263159B",
        "CN110321554A",
        "US20200409982A1",
        "US20210065019A1",
        "US10691897B1",
        "US11741305B2",
        "US11157916B2",
        "US20210182663A1",
        "CN111079665A",
        "US11200883B2",
        "US10841251B1",
        "US11651161B2",
        "US20210264112A1",
        "US11741308B2",
        "CN111813828A",
        "US20220035998A1",
        "US11206190B1",
        "US11709812B2",
        "US20230106590A1",
        "CN114756677B",
        "CN116562305B"
    ]
}