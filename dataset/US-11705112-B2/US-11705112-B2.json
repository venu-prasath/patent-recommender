{
    "patent_id": "US-11705112-B2",
    "title": "Adversarial, learning framework for persona-based dialogue modeling ",
    "assignee": "Capital One Services, Llc",
    "publication_date": "2023-07-18",
    "patent_link": "https://patents.google.com/patent/US11705112B2/en",
    "inventors": [
        "Oluwatobi Olabiyi",
        "Alan SALIMOV",
        "Anish KHAZANE",
        "Erik Mueller"
    ],
    "classifications": [
        "G06F40/30",
        "G10L15/16",
        "G06F40/216",
        "G06F40/35",
        "G06N3/044",
        "G06N3/045",
        "G06N3/047",
        "G06N3/08",
        "G06N3/084",
        "G06N5/041",
        "G10L15/183",
        "G10L15/22"
    ],
    "abstract": "Various embodiments may be generally directed to the use of an adversarial learning framework for persona-based dialogue modeling. In some embodiments, automated multi-turn dialogue response generation may be performed using a persona-based hierarchical recurrent encoder-decoder-based generative adversarial network (phredGAN). Such a phredGAN may feature a persona-based hierarchical recurrent encoder-decoder (PHRED) generator and a conditional discriminator. In some embodiments, the conditional discriminator may include an adversarial discriminator that is provided with attribute representations as inputs. In some other embodiments, the conditional discriminator may include an attribute discriminator, and attribute representations may be handled as targets of the attribute discriminator. The embodiments are not limited in this context.",
    "claims": "\n1. A system, comprising:\na generative adversarial network having\ngenerator logic, the generator logic including:\na context recurrent neural network (cRNN),\nan encoder recurrent neural network (eRNN),\nan attention recurrent neural network (aRNN), and\nand a decoder recurrent neural network (dRNN); and\ndiscriminator logic coupled to the generator logic;\na network interface coupled to the generative adversarial network, wherein the network interface is configured to receive a dialogue utterance from a device external to the system; and\nprocessing circuitry configured to implement the generator logic and the discriminator logic and coupled to the network interface, wherein the generator logic and the discriminator logic that when executed cause the processing circuitry to:\nreceive, via the network interface, the dialogue utterance;\ngenerate, using the generator logic, response candidates responsive to the dialogue utterance, wherein:\nthe cRNN is applied to concatenate a source attribute with an output of the eRNN to generate an initial state for the dRNN, and\nthe dRNN generates the response candidates based on the initial state;\ndetermine, using the discriminator logic, a response to the dialogue utterance from the response candidates; and\noutput, via the network interface, the response to the dialogue utterance to a user device.\n2. The system of claim 1, wherein the generator logic when executed by the processing circuitry is further configured to:\nreceive training samples and injected noise;\nprovide feedback related to one or more response generation parameters;\nupdate the one or more response generation parameters in the generator logic;\ngenerate, based on the updated one or more response generation parameters, the response candidates based on the dialogue utterances; and\nprovide the generated response candidates to the discriminator logic.\n3. The system of claim 1, wherein an output of the aRNN is coupled to the dRNN using an additive attention mechanism.\n4. The system of claim 1, wherein the eRNN is a bidirectional recurrent neural network (RNN) and the cRNN is a unidirectional RNN, and each of the eRNN and THE cRNN includes a three-layer gate recurrent unit (GRU) with a hidden state size of 512.\n5. The system of claim 1, wherein the discriminator logic further comprises:\na word-level adversarial discriminator that is configured to determine the response to a word in the dialogue utterance.\n6. The system of claim 5, wherein the word-level adversarial discriminator is a bidirectional RNN having a gate recurrent unit (GRU).\n7. The system of claim 5, wherein when determining a response by the discriminator logic, the discriminator logic includes:\nobtain outputs of a forward cell and a backward cell of the word-level adversarial for each word;\nconcatenate the outputs of the forward cell and the backward cell; and\npass the concatenated outputs to a fully-connected layer having binary output, wherein the binary output is a probability that the word is from a ground truth given a past word and a future word of a sequence of words.\n8. The system of claim 1, wherein the network interface is configured to:\nreceive dialogue utterances via a wired or a wireless communication with a client device.\n9. A non-transitory, computer-readable medium storing instructions that, when executed, cause one or more processors of one or more servers to implement generator logic and discriminator logic of a generative adversarial network:\ngenerate, using the generator logic of the generative adversarial network, response candidates responsive to a dialogue utterance, wherein the generator logic of the generative adversarial network includes a context recurrent neural network (cRNN), an encoder recurrent neural network (eRNN), an attention recurrent neural network (aRNN), and a decoder recurrent neural network (dRNN), the cRNN utilizes an output of the eRNN to generate an initial state for the dRNN, and the dRNN is applied to generate the response candidates based on the initial state;\ndetermine, via the discriminator logic, a response to the dialogue utterance from the response candidates; and\noutput, via a network interface, the response to the dialogue utterance to a user device.\n10. The non-transitory, computer-readable medium of claim 9, wherein the instructions that, when executed, further cause the one or more processors of the one or more servers to:\nreceive training samples and injected noise;\nprovide feedback related to one or more response generation parameters;\nupdate the one or more response generation parameters in the generator logic;\ngenerate, based on the updated one or more response generation parameters, the response candidates based on the dialogue utterance; and\nprovide the generated response candidates to the discriminator logic.\n11. The non-transitory, computer-readable medium of claim 9, wherein logic of the eRNN is a bidirectional RNN and logic of the cRNN is a unidirectional RNN, wherein each of the logic of the eRNN and the logic of the cRNN include a three-layer gate recurrent unit (GRU) with a hidden state size of 512.\n12. The non-transitory, computer-readable medium of claim 9, wherein the instructions that, when executed, further cause the one or more processors of the one or more servers to:\nexecute the generator logic to determine utterance attributes from the dialogue utterance, wherein the utterance attributes include:\none or more of a speaker identity, a speaker background, a speaker location, a speaker preference, a speaker sentiment, or a combination thereof.\n13. The non-transitory, computer-readable medium of claim 9, wherein the discriminator logic that, when executed, further cause the one or more processors of the one or more servers to:\nutilize a word-level adversarial discriminator to determine the response, wherein the word-level adversarial discriminator is a bidirectional recurrent neural network including a gate recurrent unit.\n14. The non-transitory, computer-readable medium of claim 13, wherein the discriminator logic that, when executed, further cause the one or more processors of the one or more servers to:\nobtain outputs of a forward cell and a backward cell of the bidirectional recurrent neural network for each word of the dialogue utterance;\nconcatenate the outputs of the forward cell and the backward cell; and\npass the concatenated outputs to a fully-connected layer having binary output, wherein the binary output is a probability that the word is from a ground truth given a past word and a future word of a sequence of words.\n15. The non-transitory, computer-readable medium of claim 9, wherein the instructions that, when executed, further cause the one or more processors of the one or more servers to:\nreceive dialogue utterances via the network interface.\n16. A computer-implemented method utilizing a generative adversarial network, the method comprising:\nreceiving, via a network interface, a dialogue utterance;\ngenerating, using generator logic of the generative adversarial network, response candidates responsive to the dialogue utterance, wherein the generator logic of the generative adversarial network includes a context recurrent neural network (cRNN), an encoder recurrent neural network (eRNN), an attention recurrent neural network (aRNN), and a decoder recurrent neural network (dRNN), the cRNN is configured to concatenate a source attribute with an output of the eRNN to generate an initial state for the dRNN, and the dRNN is configured to use an output of the aRNN to generate the response candidates based on the initial state;\ndetermining, by using discriminator logic, a response to the dialogue utterance from the response candidates; and\noutputting, via the network interface, the response to the dialogue utterance to a user device.\n17. The computer-implemented method of claim 16, further comprising:\nreceiving training samples and injected noise;\nproviding feedback related to one or more response generation parameters;\nupdating the one or more response generation parameters in the generator logic;\ngenerating, based on the updated one or more response generation parameters, the response candidates based on the dialogue utterances; and\nproviding the generated response candidates to the discriminator logic.\n18. The computer-implemented method of claim 16, further comprising:\ndetermining, by the generator logic, utterance attributes from the dialogue utterance, wherein the utterance attributes include:\none or more of a speaker identity, a speaker background, a speaker location, a speaker preference, a speaker sentiment, or a combination thereof.\n19. The computer-implemented method of claim 16, further comprising:\ndetermining the response, by the discriminator logic, using a word-level adversarial discriminator, wherein the word-level adversarial discriminator is a bidirectional recurrent neural network with a number of units, and each unit of the number of units of the bidirectional recurrent neural network includes a gate recurrent unit.\n20. The computer-implemented method of claim 19, further comprising:\nobtaining outputs of a forward cell and a backward cell of the bidirectional recurrent neural network for each word of the dialogue utterance;\nconcatenating the outputs of the forward cell and the backward cell; and\npassing the concatenated outputs to a fully-connected layer having binary output, wherein the binary output is a probability that the word is from a ground truth given a past word and a future word of a sequence of words."
}