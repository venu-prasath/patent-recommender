{
    "patent_id": "US-11016729-B2",
    "title": "Sensor fusion service to enhance human computer interactions ",
    "assignee": "International Business Machines Corporation",
    "publication_date": "2021-05-25",
    "patent_link": "https://patents.google.com/patent/US11016729B2/en",
    "inventors": [
        "John J. Andersen",
        "Dogukan Erenel",
        "Richard O. Lyle",
        "Connie Yee"
    ],
    "classifications": [
        "G10L15/26",
        "G06F16/90332",
        "G06F3/167",
        "G06N3/08",
        "G06N7/005",
        "G06N7/01",
        "G10L15/22",
        "G06F40/35",
        "G06N3/006",
        "G06N5/041",
        "G10L2015/227",
        "G10L25/21",
        "G10L25/48"
    ],
    "abstract": "Mechanisms are provided, in a data processing system comprising a fusion sensor service and a human computer interaction (HCI) device, for responding to a user input. The HCI device receives a user input from a first sensor monitoring a monitored environment. The fusion sensor service captures, via one or more second sensors different from the first sensor, sensor data representing characteristics of one or more entities within the monitored environment indicative of a condition within the monitored environment. The fusion sensor service determines whether the user input is specifically directed to the HCI device based on the captured sensor data. The HCI device performs an operation in response to the data processing system determining that the user input is specifically directed to the HCI device based on the capture sensor data.",
    "claims": "\n1. A method, in a data processing system comprising a fusion sensor service and a human computer interaction (HCI) device, for responding to a user input, the method comprising:\nreceiving, by the HCI device, a user input from a first sensor monitoring a monitored environment, wherein the user input comprises a speech input;\ncapturing, by the fusion sensor service, via one or more second sensors different from the first sensor, sensor data representing characteristics of one or more entities within the monitored environment indicative of a condition within the monitored environment;\ndetermining, by the fusion sensor service, whether the user input is specifically directed to the HCI device based on the captured sensor data; and\nperforming, by the HCI device, an operation in response to the data processing system determining that the user input is specifically directed to the HCI device based on the capture sensor data, wherein the captured sensor data comprises a plurality of different non-verbal attention indicators having a plurality of different non-verbal attention indicator types, and wherein: the fusion sensor service comprises a feed forward neural network, and wherein the characteristics of the entities obtained from the sensor data captured by the one or more sensors are input to the feed forward neural network and the feed forward neural network outputs an indication of whether or not characteristics indicate that the user input is directed to the HCI device,\ndetermining whether the user input is specifically directed to the HCI device based on the captured sensor data comprises inputting, to the neural network, the plurality of different non-verbal attention indicators,\nthe neural network collectively processes the plurality of different non-verbal attention indicators to generate an output indicating whether or not the speech input is directed to the HCI device,\nthe neural network comprises a layer of output nodes having a separate output node for each non-verbal attention indicator in the plurality of different non-verbal attention indicators that are input to the neural network,\nthe output nodes generate outputs indicative of whether a corresponding non-verbal attention indicator indicates that the speech input is directed to the HCI device, and\nthe outputs from the output nodes are combined by a merge node of the neural network to generate a single output indicating whether or not the speech input of the audio sample is directed to the HCI device.\n2. The method of claim 1, wherein the first sensor is an audio capture device that captures the speech input from the user, wherein the method further comprises:\nconverting, by a speech to text transcription service, the speech input to a text representation of the speech input;\nperforming, by a natural language classification service, natural language processing on the text representation of the speech input to extract features of the speech input;\ndetermining, by the fusion sensor service, based on results of determining whether the user input is specifically directed to the HCI device based on the captured sensor data, whether or not the HCI device is to respond to the speech input; and\nin response to determining that the HCI device is to respond to the speech input, performing the operation.\n3. The method of claim 1, wherein the one or more sensors comprise a plurality of sensors capturing different types of sensor data, and wherein determining, by the fusion sensor service, whether the user input is specifically directed to the HCI device based on the captured sensor data comprises:\nperforming deep learning on the sensor data captured by the one or more sensors to consolidate features from the sensor data captured by the plurality of sensors of different types to determine whether or not the user input is directed to the HCI device.\n4. The method of claim 3, wherein performing deep learning comprises at least one of:\nperforming proximity analysis based on at least one of proximity sensor data or location sensor data indicating a relative location of the source of the user input relative to the HCI device, wherein, in response to the source of the user input being within a threshold distance of the HCI device, the deep learning indicates a higher probability that the user input is directed to the HCI device; or\nperforming a speech to text transcription confidence evaluation based on a transcription of the user input into a text representation, wherein in response to the speech to text transcription confidence being equal to or higher than a threshold confidence, the deep learning indicates a higher probability that the user input is directed to the HCI device.\n5. The method of claim 1, wherein performing the operation in response to the data processing system determining that the user input is specifically directed to the HCI device based on the captured sensor data comprises:\nproviding a text representation of the user input to natural language processing system comprising at least one pipeline, wherein the natural language processing system processes the text representation to generate a response at least by performing a search of a corpus of electronic documents to generate candidate responses, and selecting a candidate response to be a final response that is output to a source of the user input.\n6. The method of claim 1, determining, by the fusion sensor service, whether the user input is specifically directed to the HCI device based on the captured sensor data comprises tracking at least one of a location or movement of a source of the user input to determine a relative proximity of the source to the HCI device.\n7. The method of claim 1, wherein the plurality of different non-verbal attention indicator types comprises a normalized sound energy level of the speech input and at least one of an intent classification confidence of natural language processing of the speech input or a confidence measure associated with conversion of the speech input to a text representation.\n8. The method of claim 1, wherein the plurality of different non-verbal attention indicator types comprises a normalized sound energy level of the speech input and at least one of a gaze direction of the source of the speech input relative to the HCI device location, a proximity of the source of the speech input to the HCI device, an intent classification confidence of natural language processing of the speech input, and a confidence measure associated with conversion of the speech input to a text representation.\n9. The method of claim 1, wherein determining whether the user input is specifically directed to the HCI device based on the captured sensor data comprises:\nperforming proximity analysis based on at least one of proximity sensor data or location sensor data indicating a relative location of the source of the speech input relative to the HCI device, wherein, in response to the source of the speech input being within a threshold distance of the HCI device, the deep learning indicates a higher probability that the speech input is directed to the HCI device;\nperforming a speech to text transcription confidence evaluation based on a transcription of the speech input into a text representation, wherein in response to the speech to text transcription confidence being equal to or higher than a threshold confidence, the deep learning indicates a higher probability that the speech input is directed to the HCI device.\n10. The method of claim 1, wherein the plurality of different non-verbal attention indicator types comprise at least two different types of non-verbal attention indicators selected from the following set of non-verbal attention indicator types: normalized sound energy level of the speech input, results of gaze detection analysis of a source of the speech input, proximity of the source of the speech input to the HCI device, intent classification confidence of natural language processing of the speech input, or a confidence measure associated with conversion of the speech input to a text representation.\n11. A computer program product comprising a computer readable storage medium having a computer readable program stored therein, wherein the computer readable program, when executed on a data processing system, causes the data processing system to:\nreceive a user input from a first sensor monitoring a monitored environment, wherein the user input comprises a speech input;\ncapture, by a fusion sensor service executing in the data processing system, via one or more second sensors different from the first sensor, sensor data representing characteristics of one or more entities within the monitored environment indicative of a condition within the monitored environment;\ndetermine, by the fusion sensor service, whether the user input is specifically directed to a human computer interaction (HCI) device present within the monitored environment, based on the captured sensor data; and\nperform an operation in response to the data processing system determining that the user input is specifically directed to the HCI device based on the capture sensor data, wherein the captured sensor data comprises a plurality of different non-verbal attention indicators having a plurality of different non-verbal attention indicator types, and wherein the fusion sensor service comprises a feed forward neural network, and wherein the characteristics of the entities obtained from the sensor data captured by the one or more sensors are input to the feed forward neural network and the feed forward neural network outputs an indication of whether or not characteristics indicate that the user input is directed to the HCI device:\ndetermining whether the user input is specifically directed to the HCI device based on the captured sensor data comprises inputting, to the neural network, the plurality of different non-verbal attention indicators,\nthe neural network collectively processes the plurality of different non-verbal attention indicators to generate an output indicating whether or not the speech input is directed to the HCI device,\nthe neural network comprises a layer of output nodes having a separate output node for each non-verbal attention indicator in the plurality of different non-verbal attention indicators that are input to the neural network,\nthe output nodes generate outputs indicative of whether a corresponding non-verbal attention indicator indicates that the speech input is directed to the HCI device, and\nthe outputs from the output nodes are combined by a merge node of the neural network to generate a single output indicating whether or not the speech input of the audio sample is directed to the HCI device.\n12. The computer program product of claim 11, wherein the first sensor is an audio capture device that captures the speech input from the user, wherein the computer readable program further causes the data processing system to:\nconvert, by a speech to text transcription service executing in the data processing system, the speech input to a text representation of the speech input;\nperform, by a natural language classification service executing in the data processing system, natural language processing on the text representation of the speech input to extract features of the speech input;\ndetermine, by the fusion sensor service, based on results of determining whether the user input is specifically directed to the HCI device based on the captured sensor data, whether or not the HCI device is to respond to the speech input; and\nin response to determining that the HCI device is to respond to the speech input, perform the operation.\n13. The computer program product of claim 11, wherein the one or more sensors comprise a plurality of sensors capturing different types of sensor data, and wherein the fusion sensor service determines whether the user input is specifically directed to the HCI device based on the captured sensor data at least by:\nperforming deep learning on the sensor data captured by the one or more sensors to consolidate features from the sensor data captured by the plurality of sensors of different types to determine whether or not the user input is directed to the HCI device.\n14. The computer program product of claim 13, wherein performing deep learning comprises at least one of:\nperforming proximity analysis based on at least one of proximity sensor data or location sensor data indicating a relative location of the source of the user input relative to the HCI device, wherein, in response to the source of the user input being within a threshold distance of the HCI device, the deep learning indicates a higher probability that the user input is directed to the HCI device; or\nperforming a speech to text transcription confidence evaluation based on a transcription of the user input into a text representation, wherein in response to the speech to text transcription confidence being equal to or higher than a threshold confidence, the deep learning indicates a higher probability that the user input is directed to the HCI device.\n15. The computer program product of claim 11, wherein the computer readable program causes the data processing system to perform the operation in response to the data processing system determining that the user input is specifically directed to the HCI device based on the capture sensor data at least by:\nproviding a text representation of the user input to natural language processing system comprising at least one pipeline, wherein the natural language processing system processes the text representation to generate a response at least by performing a search of a corpus of electronic documents to generate candidate responses, and selecting a candidate response to be a final response that is output to a source of the user input.\n16. The computer program product of claim 11, wherein the plurality of different non-verbal attention indicator types comprise at least two different types of non-verbal attention indicators selected from the following set of non-verbal attention indicator types: normalized sound energy level of the speech input, results of gaze detection analysis of a source of the speech input, proximity of the source of the speech input to the HCI device, intent classification confidence of natural language processing of the speech input, or a confidence measure associated with conversion of the speech input to a text representation.\n17. An apparatus comprising:\nat least one processor; and\nat least one memory coupled to the at least one processor, wherein the at least one memory comprises instructions which, when executed by the at least one processor, cause the at least one processor to:\nreceive a user input from a first sensor monitoring a monitored environment, wherein the user input comprises a speech input;\ncapture, by a fusion sensor service executing on the at least one processor, via one or more second sensors different from the first sensor, sensor data representing characteristics of one or more entities within the monitored environment indicative of a condition within the monitored environment;\ndetermine, by the fusion sensor service, whether the user input is specifically directed to a human computer interaction (HCI) device present within the monitored environment, based on the captured sensor data; and\nperform an operation in response to the data processing system determining that the user input is specifically directed to the HCI device based on the capture sensor data, wherein the captured sensor data comprises a plurality of different non-verbal attention indicators having a plurality of different non-verbal attention indicator types, and wherein the fusion sensor service comprises a feed forward neural network, and wherein the characteristics of the entities obtained from the sensor data captured by the one or more sensors are input to the feed forward neural network and the feed forward neural network outputs an indication of whether or not characteristics indicate that the user input is directed to the HCI device:\ndetermining whether the user input is specifically directed to the HCI device based on the captured sensor data comprises inputting, to the neural network, the plurality of different non-verbal attention indicators,\nthe neural network collectively processes the plurality of different non-verbal attention indicators to generate an output indicating whether or not the speech input is directed to the HCI device,\nthe neural network comprises a layer of output nodes having a separate output node for each non-verbal attention indicator in the plurality of different non-verbal attention indicators that are input to the neural network,\nthe output nodes generate outputs indicative of whether a corresponding non-verbal attention indicator indicates that the speech input is directed to the HCI device, and\nthe outputs from the output nodes are combined by a merge node of the neural network to generate a single output indicating whether or not the speech input of the audio sample is directed to the HCI device.\n18. The apparatus of claim 17, wherein the plurality of different non-verbal attention indicator types comprise at least two different types of non-verbal attention indicators selected from the following set of non-verbal attention indicator types:\nnormalized sound energy level of the speech input, results of gaze detection analysis of a source of the speech input, proximity of the source of the speech input to the HCI device, intent classification confidence of natural language processing of the speech input, or a confidence measure associated with conversion of the speech input to a text representation."
}