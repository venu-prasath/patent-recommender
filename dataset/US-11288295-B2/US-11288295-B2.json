{
    "patent_id": "US-11288295-B2",
    "title": "Utilizing word embeddings for term matching in question answering systems ",
    "assignee": "Green Market Square Limited",
    "publication_date": "2022-03-29",
    "patent_link": "https://patents.google.com/patent/US11288295B2/en",
    "inventors": [
        "James J. Fan",
        "Chang Wang",
        "Bing Xiang",
        "Bowen Zhou"
    ],
    "classifications": [
        "G06F16/3344",
        "G06F16/24578",
        "G06F16/313",
        "G06F16/3329",
        "G06F40/30",
        "G06N20/00",
        "G06N3/04",
        "G06N3/084",
        "G06N7/005",
        "G06N7/01"
    ],
    "abstract": "Software that generates an answer to an input question using a source document by performing the following operations: (i) receiving a question; (ii) generating a plurality of vectors including a first vector representation of a term in the question and a second vector representation of a term in a source document; (iii) providing each dimension of each of the first vector representation and the second vector representation into a respective input node of an artificial neural network; (iv) determining whether the source document is relevant to answering the question based, at least in part, on an output generated by the artificial neural network; and (v) in response to determining that the source document is relevant, generating an answer to the question utilizing the source document.",
    "claims": "\n1. A computer-implemented method comprising:\nreceiving, by a question answering (QA) system, an input question asked by a user, wherein the QA system is a computer system configured to answer input questions utilizing a plurality of source documents;\ngenerating, by the QA system, a plurality of vectors including a first vector representation of an input question term of a set of ordered input question terms in the input question and a second vector representation of a source document term of a set of ordered source document terms in a source document of the plurality of source documents, wherein the first vector representation and the second vector representation are generated by combining respective pluralities of dimensions for the first vector representation and the second vector representation to form multi-dimension vectors, wherein the first vector representation is based at least in part on the set of ordered input question terms and the second vector representation is based at least in part on the set of ordered source document terms;\ndetermining, by the QA system, a similarity score for the input question term and the source document term based at least in part on each dimension of each of the first vector representation and the second vector representation as input into a respective input node of an artificial neural network;\ndetermining, by the QA system, whether the source document is relevant to answering the input question based, at least in part, on: (i) an output generated by the artificial neural network based on the input question, wherein the output comprises the similarity score, and (ii) additional outputs generated by the artificial neural network based on additional inputs, the additional inputs including respective dimensions of respective vector representations for respective input question terms and source document terms, wherein the output and the additional outputs comprise similarity scores for every combination of input question terms in the ordered set of input question terms and source document terms in the ordered set of source document terms; and\nin response to determining that the source document is relevant to answering the input question, generating, by the QA system, an answer to the input question utilizing the source document.\n2. The method of claim 1, further comprising training, by the QA system, the artificial neural network, wherein training the artificial neural network comprises: (i) providing, at respective input nodes of an input layer of the artificial neural network, vector dimensions of a set of ground truth vector representations corresponding to ground truth question/answer pairs, (ii) providing, at a first output node of an output layer of the artificial neural network, first pairs of vector dimensions of the set of ground truth vector representations that are similar, (iii) providing, at a second output node of the output layer of the artificial neural network, second pairs of vector dimensions of the set of ground truth vector representations that are not similar, and (iv) training the artificial neural network using backpropagation.\n3. The method of claim 1, wherein the determining of whether the source document is relevant to answering the input question is further based, in part, on one or more unsupervised learning methods.\n4. The method of claim 3, wherein the one or more unsupervised learning methods include comparing the first vector representation and the second vector representation using a similarity function.\n5. The method of claim 4, wherein the similarity function is at least one of a cosine similarity function and a Euclidean distance function.\n6. The method of claim 1, wherein the respective pluralities of dimensions for the first vector representation and the second vector representation are determined using dimensionality reduction on a word co-occurrence matrix.\n7. The method of claim 1, further comprising providing, by the QA system, the answer to the user.\n8. The method of claim 1, wherein the artificial neural network is trained to determine probabilities that pairs of vector dimensions are similar and probabilities that pairs of vector dimensions are not similar.\n9. A computer program product comprising a computer readable storage medium having stored thereon:\nprogram instructions to receive, by a question answering (QA) system, an input question asked by a user, wherein the QA system is a computer system configured to answer input questions utilizing a plurality of source documents;\nprogram instructions to generate, by the QA system, a plurality of vectors including a first vector representation of an input question term of a set of ordered input question terms in the input question and a second vector representation of a source document term of a set of ordered source document terms in a source document of the plurality of source documents, wherein the first vector representation and the second vector representation are generated by combining respective pluralities of dimensions for the first vector representation and the second vector representation to form multi-dimension vectors, wherein the first vector representation is based at least in part on the ordered input question terms and the second vector representation is based at least in part on the ordered source document terms;\nprogram instructions to determine, by the QA system, a similarity score for the input question term and the source document term based at least in part on each dimension of each of the first vector representation and the second vector representation as input into a respective input node of an artificial neural network;\nprogram instructions to determine, by the QA system, whether the source document is relevant to answering the input question based, at least in part, on: (i) an output generated by the artificial neural network based on the input question, wherein the output comprises the similarity score, and (ii) additional outputs generated by the artificial neural network based on additional inputs, the additional inputs including respective dimensions of respective vector representations for respective input question terms and source document terms, wherein the output and the additional outputs comprise similarity scores for every combination of input question terms in the ordered set of input question terms and source document terms in the ordered set of source document terms; and\nprogram instructions to, in response to determining that the source document is relevant to answering the input question, generate, by the QA system, an answer to the input question utilizing the source document.\n10. The computer program product of claim 9, the computer readable storage medium having further stored thereon program instructions to train, by the QA system, the artificial neural network, wherein training the artificial neural network comprises: (i) providing, at respective input nodes of an input layer of the artificial neural network, vector dimensions of a set of ground truth vector representations corresponding to ground truth question/answer pairs, (ii) providing, at a first output node of an output layer of the artificial neural network, first pairs of vector dimensions of the set of ground truth vector representations that are similar, (iii) providing, at a second output node of the output layer of the artificial neural network, second pairs of vector dimensions of the set of ground truth vector representations that are not similar, and (iv) training the artificial neural network using backpropagation.\n11. The computer program product of claim 9, wherein the determining of whether the source document is relevant to answering the input question is further based, in part, on one or more unsupervised learning methods.\n12. The computer program product of claim 11, wherein the one or more unsupervised learning methods include comparing the first vector representation and the second vector representation using a similarity function.\n13. The computer program product of claim 12, wherein the similarity function is at least one of a cosine similarity function and a Euclidean distance function.\n14. The computer program product of claim 9, wherein the respective pluralities of dimensions for the first vector representation and the second vector representation are determined using dimensionality reduction on a word co-occurrence matrix.\n15. The computer program product of claim 9, the computer readable storage medium having further stored thereon program instructions to provide, by the QA system, the answer to the user.\n16. A question answering (QA) system configured to answer input questions utilizing a plurality of source documents, the QA system comprising:\none or more processors; and\na computer readable storage medium;\nwherein:\nthe one or more processors are structured, located, connected and/or programmed to run program instructions stored on the computer readable storage medium; and\nthe program instructions include:\nfirst program instructions to receive, by the QA system, an input question asked by a user;\nsecond program instructions to generate, by the QA system, a plurality of vectors including a first vector representation of an input question term of a set of ordered input question terms in the input question and a second vector representation of a source document term of a set of ordered source document terms in a source document of the plurality of source documents, wherein the first vector representation and the second vector representation are generated by combining respective pluralities of dimensions for the first vector representation and the second vector representation to form multi-dimension vectors, wherein the first vector representation is based at least in part on the ordered input question terms and the second vector representation is based at least in part on the ordered source document terms;\nthird program instructions to determine, by the QA system, a similarity score for the input question term and the source document term based at least in part on each dimension of each of the first vector representation and the second vector representation as input into a respective input node of an artificial neural network;\nfourth program instructions to determine, by the QA system, whether the source document is relevant to answering the input question based, at least in part, on: (i) an output generated by the artificial neural network based on the input question, wherein the output comprises the similarity score, and (ii) additional outputs generated by the artificial neural network based on additional inputs, the additional inputs including respective dimensions of respective vector representations for respective input question terms and source document terms, wherein the output and the additional outputs comprise similarity scores for every combination of input question terms in the ordered set of input question terms and source document terms in the ordered set of source document terms; and\nfifth program instructions to, in response to determining that the source document is relevant to answering the input question, generate, by the QA system, an answer to the input question utilizing the source document.\n17. The QA system of claim 16, the stored program instructions further including sixth program instructions to train, by the QA system, the artificial neural network, wherein training the artificial neural network comprises: (i) providing, at respective input nodes of an input layer of the artificial neural network, vector dimensions of a set of ground truth vector representations corresponding to ground truth question/answer pairs, (ii) providing, at a first output node of an output layer of the artificial neural network, first pairs of vector dimensions of the set of ground truth vector representations that are similar, (iii) providing, at a second output node of the output layer of the artificial neural network, second pairs of vector dimensions of the set of ground truth vector representations that are not similar, and (iv) training the artificial neural network using backpropagation.\n18. The QA system of claim 16, wherein the determining of whether the source document is relevant to answering the input question is further based, in part, on one or more unsupervised learning methods.\n19. The QA system of claim 18, wherein the one or more unsupervised learning methods include comparing the first vector representation and the second vector representation using a similarity function.\n20. The QA system of claim 16, wherein the respective pluralities of dimensions for the first vector representation and the second vector representation are determined using dimensionality reduction on a word co-occurrence matrix.\n21. The QA system of claim 16, the program instructions further including seventh program instructions to provide, by the QA system, the answer to the user.",
    "status": "Active",
    "citations_own": [
        "US6533131B2",
        "US6553131B1",
        "US20050143971A1",
        "US20060235689A1",
        "US20100063797A1",
        "US20100063948A1",
        "US20110270604A1",
        "US20120078636A1",
        "US8538955B2",
        "US20140156567A1",
        "US20140163962A1",
        "US20140172883A1",
        "US20140172880A1",
        "US20140236578A1",
        "US20150095017A1",
        "US20160358094A1"
    ],
    "citations_ftf": [],
    "citedby_own": [
        "US11449559B2",
        "US20230096857A1"
    ],
    "citedby_ftf": [
        "US10467268B2",
        "US10606846B2",
        "CN106844368B",
        "US10063702B2",
        "US10489712B2",
        "US9984772B2",
        "US11550751B2",
        "US10459928B2",
        "CN106815310B",
        "CN106599317B",
        "WO2018147543A1",
        "US11509794B2",
        "US10311454B2",
        "US10162844B1",
        "CN107590192B",
        "CA3015240A1",
        "CN107454436A",
        "KR102055899B1",
        "WO2019081776A1",
        "US11409749B2",
        "EP3499432A1",
        "US11475291B2",
        "US11017317B2",
        "US10730181B1",
        "CN108182275A",
        "CN110555093A",
        "CN108595629B",
        "US10831752B2",
        "GB2573998A",
        "US11386304B2",
        "US11227248B2",
        "US10884893B2",
        "EP3617970A1",
        "US10459962B1",
        "US11263223B2",
        "US20200142962A1",
        "EP3654258A1",
        "KR102138130B1",
        "US11410031B2",
        "CN110059155A",
        "CN109766423A",
        "CN109783626B",
        "US10586532B1",
        "CN109992659B",
        "WO2020198855A1",
        "CN110162596B",
        "CN111800671B",
        "CN110033236A",
        "CN110059318B",
        "CN110134798B",
        "CN110362665B",
        "CN110390002A",
        "US11720757B2",
        "CN110609886A",
        "CN110825851A",
        "CN110929015A",
        "US11481418B2",
        "CN111597319B",
        "US11526756B1",
        "CN111935555B",
        "KR102526501B1",
        "CN112288145B",
        "CN113641809A"
    ]
}