{
    "patent_id": "US-11144725-B2",
    "title": "Predictive natural language rule generation ",
    "assignee": "International Business Machines Corporation",
    "publication_date": "2021-10-12",
    "patent_link": "https://patents.google.com/patent/US11144725B2/en",
    "inventors": [
        "Yan Luo"
    ],
    "classifications": [
        "G06F8/73",
        "G06F40/30",
        "G06N3/044",
        "G06N3/0445",
        "G06N3/08",
        "G06N3/084",
        "G06N5/025",
        "G06F40/16",
        "G06F8/75",
        "G06N20/10",
        "G06N3/042",
        "G06N3/045",
        "G06N3/047",
        "G06N7/01"
    ],
    "abstract": "In an approach to generating natural language rules based on detected code snippets, one or more computer processors detect a code snippet. The one or more computer processors extract code information from the detected code snippet. The one or more computer processors feed the extracted code information into a cognitive model, wherein the cognitive model utilizes one or more historical code snippets based on the extracted code information and one or more natural language rules based on the extracted code information. The one or more computer processors generate, based on one or more calculations by the cognitive model, a natural language rule for the code snippet.",
    "claims": "\n1. A method comprising:\nresponsive to a user inputting a code snippet into an integrated development environment, extracting, by one or more computer processors, code information from the code snippet;\ndetermining, by one or more computer processors, a programing language associated with the code snippet based on the extracted code information, wherein determining the programming language comprises generating a relevancy score based on the code snippet and one or more programming languages each associated with one or more conventions;\nretrieving, by one or more computer processors, a code corpus specific to the determined programing language;\ntraining, by one or more computer processors, a cognitive model utilizing the retrieved code corpus;\nfeeding, by one or more computer processors, the extracted code information into the cognitive model, wherein the cognitive model utilizes one or more historical code snippets based on the extracted code information and one or more natural language rules based on the extracted code information; and\ngenerating, by one or more computer processors, based on one or more calculations by the cognitive model, a natural language rule for the code snippet, wherein generating the natural language rule comprises:\nresponsive to a generated natural language word not exceeding a predetermined probability threshold, prompting, by one or more computer processors, a user for a selection from a list of predicted words with respective calculated probabilities; and\nresponsive to a user selection from the list of predicted words, appending, by one or more computer processors, the selection to the natural language rule.\n2. The method of claim 1, further comprises:\ncreating, by one or more computer processors, one or more training sets based on the retrieved historical code snippets and associated natural language rules;\ncreating, by one or more computer processors, one or more testing sets based on the retrieved historical code snippets and associated natural language rules; and\ntraining, by one or more computer processors, the cognitive model utilizing one or more supervised training methods, wherein the supervised training methods utilize the one or more created training sets and testing sets.\n3. The method of claim 2, wherein training of the cognitive model utilizing the one or more supervised training methods, wherein the supervised training methods utilize the one or more created training sets and testing sets, further comprises:\nretrieving, by one or more computer processors, one or more programmatic comments associated with the one or more retrieved historical code snippets; and\ntraining, by one or more compute processors, the cognitive model utilizing one or more supervised training methods utilizing the retrieved historical code snippets, associated natural language rules, and associated programmatic comments.\n4. The method of claim 1, wherein the code information is selected from the group consisting of: natural language rule complexity, code complexity, code length, natural language rule length, intermediate representation objects, abstract syntax trees, word embedded code snippet vectors, and word embedded natural language rule vectors.\n5. The method of claim 1, further comprises:\nidentifying, by one or more computer processors, a user selected portion of code; and\nextracting, by one or more computer processors, the code contained with the selected portion.\n6. The method of claim 1, further comprises:\nretraining, by one or more computer processors, the cognitive model based on the detected code snippet and the generated natural language rule;\ndetermining, by one or more computer processors, a precision of the cognitive model; and\nresponsive to determining that the precision of the cognitive model increased, storing, by one or more computer processors, the detected code snippet and the generated natural language rule.\n7. The method of claim 1, further comprises:\nretraining, by one or more computer processors, the cognitive model based on the detected code snippet and the generated natural language rule;\ndetermining, by one or more computer processors, a precision of the cognitive model; and\nresponsive to determining that the precision of the cognitive model decreased, adjusting, by one or more computer processors, one or more weights of the cognitive model.\n8. The method of claim 1, wherein the cognitive model is a recurrent neural network.\n9. The method of claim 8, wherein the recurrent neural network includes long short term memory.\n10. The method of claim 8, wherein the recurrent neural network includes gated recurrent units.\n11. The method of claim 1, wherein the natural language rule is selected from the group consisting of: business rules and business logic.\n12. A computer program product comprising:\none or more computer readable storage media and program instructions stored on the one or more computer readable storage media, the program instructions comprising:\nprogram instructions to detect a code snippet;\nprogram instructions to extract code information from the detected code snippet;\nprogram instructions to feed the extracted code information into a cognitive model, wherein the cognitive model utilizes one or more historical code snippets based on the extracted code information and one or more natural language rules based on the extracted code information; and\nprogram instructions to generate, based on one or more calculations by the cognitive model, a natural language rule for the code snippet, wherein program instructions to generate the natural language rule comprise:\nprogram instructions to responsive to a generated natural language word not exceeding a predetermined probability threshold, prompt a user for a selection from a list of predicted words with respective calculated probabilities; and\nprogram instructions to responsive to a user selection from the list of predicted words, append the selection to the natural language rule.\n13. The computer program product of claim 12, further comprises:\nprogram instructions to create one or more training sets based on the retrieved historical code snippets and associated natural language rules;\nprogram instructions to create one or more testing sets based on the retrieved historical code snippets and associated natural language rules; and\nprogram instructions to train the cognitive model utilizing one or more supervised training methods, wherein the supervised training methods utilize the one or more created training sets and testing sets.\n14. The computer program product of claim 13, wherein training of the cognitive model utilizing the one or more supervised training methods, wherein the supervised training methods utilize the one or more created training sets and testing sets, further comprises:\nprogram instructions to retrieve one or more programmatic comments associated with the one or more retrieved historical code snippets; and\nprogram instructions to train the cognitive model utilizing one or more supervised training methods utilizing the retrieved historical code snippets, associated natural language rules, and associated programmatic comments.\n15. The computer program product of claim 12, wherein the code information is selected from the group consisting of: natural language rule complexity, code complexity, code length, natural language rule length, intermediate representation objects, abstract syntax trees, word embedded code snippet vectors, and word embedded natural language rule vectors.\n16. The computer program product of claim 12, wherein the cognitive model is a recurrent neural network.\n17. A computer system comprising:\none or more computer processors;\none or more computer readable storage media; and\nprogram instructions stored on the computer readable storage media for execution by at least one of the one or more processors, the program instructions comprising:\nprogram instructions to detect a code snippet;\nprogram instructions to extract code information from the detected code snippet;\nprogram instructions to feed the extracted code information into a cognitive model, wherein the cognitive model utilizes one or more historical code snippets based on the extracted code information and one or more natural language rules based on the extracted code information; and\nprogram instructions to generate, based on one or more calculations by the cognitive model, a natural language rule for the code snippet, wherein program instructions to generate the natural language rule comprise:\nprogram instructions to responsive to a generated natural language word not exceeding a predetermined probability threshold, prompt a user for a selection from a list of predicted words with respective calculated probabilities; and\nprogram instructions to responsive to a user selection from the list of predicted words, append the selection to the natural language rule.\n18. The computer system of claim 17, further comprises:\nprogram instructions to create one or more training sets based on the retrieved historical code snippets and associated natural language rules;\nprogram instructions to create one or more testing sets based on the retrieved historical code snippets and associated natural language rules; and\nprogram instructions to train the cognitive model utilizing one or more supervised training methods, wherein the supervised training methods utilize the one or more created training sets and testing sets.\n19. The computer system of claim 18, wherein training of the cognitive model utilizing the one or more supervised training methods, wherein the supervised training methods utilize the one or more created training sets and testing sets, further comprises:\nprogram instructions to retrieve one or more programmatic comments associated with the one or more retrieved historical code snippets; and\nprogram instructions to train the cognitive model utilizing one or more supervised training methods utilizing the retrieved historical code snippets, associated natural language rules, and associated programmatic comments.\n20. The computer system of claim 17, wherein the code information is selected from the group consisting of: natural language rule complexity, code complexity, code length, natural language rule length, intermediate representation objects, abstract syntax trees, word embedded code snippet vectors, and word embedded natural language rule vectors."
}