{
    "patent_id": "US-11741484-B2",
    "title": "Customer interaction and experience system using emotional-semantic computing ",
    "assignee": "Vonage Business Limited",
    "publication_date": "2023-08-29",
    "patent_link": "https://patents.google.com/patent/US11741484B2/en",
    "inventors": [
        "Alan McCord"
    ],
    "classifications": [
        "G06Q30/0201",
        "G06F16/24578",
        "G06F16/248",
        "G06F16/9535",
        "G06F40/237",
        "G06F40/242",
        "G06F40/30",
        "G06N20/00",
        "G10L15/1815",
        "G10L15/22",
        "G10L15/26",
        "G10L25/63",
        "G06F18/23",
        "G06N3/006",
        "G06N3/045",
        "G06N7/01"
    ],
    "abstract": "A system and method for customer interaction and experience enhancement which automatically gathers direct and indirect customer communications about products and services, converts them to text where necessary, and analyzes the communications for sentiment and emotional content, and scores and displays the information in a manner conducive to making business decisions based on the customer sentiment and emotion, such as making changes to products or services, troubleshooting customer service interactions, and better marketing.",
    "claims": "\n1. A system for enhancing customer relations through automated analysis of the conversational distance in direct and indirect customer communications, comprising:\na web search engine for gathering indirect customer communications about products and services from online sources;\nan automated speech recognition engine for converting audio to text transcriptions;\na sentiment and emotion analyzer for:\nreceiving direct and indirect customer communications, each communication being associated with a product or service and each communication comprising either text content or audio content, the text content and audio content comprising an expression of an emotion or a sentiment;\nconverting any audio content to text content using the automated speech recognition engine;\nreceiving text content from each of the direct and indirect customer communications;\nanalyzing the received text content using a machine learning algorithm to determine a conversational distance between an agent and a customer for each of the direct and indirect customer communications, wherein:\nthe conversational distance is determined at least in part by the emotion or the sentiment;\nthe conversational distance for the direct customer communications is determined using the agent's interactions with the customer, and\nthe conversational distance for the indirect customer communications is determined using the agent's history of interactions with other customers;\ncumulatively assigning similarity scores to the products or services associated with the direct or indirect customer communications based on the determined conversational distance; and\ngenerating a recommended response for the agent to each direct or indirect communication based on the assigned similarity score for that direct or indirect communication.\n2. The system of claim 1 wherein the sentiment and emotion analyzer uses vector clustering to segment similar content.\n3. The system of claim 1 wherein the sentiment and emotion analyzer uses linear transformation to translate between the language of product-specific or service-specific domains.\n4. The system of claim 1 wherein the sentiment and emotion analyzer uses vector algebra to determine sentiment.\n5. The system of claim 1 wherein the sentiment and emotion analyzer uses vector calculus to understand and predict time evolution in sentiment by calculating rates of change of vectors and time dynamics, and the predictions are applied to the cumulatively assigned similarity scores.\n6. A method for enhancing customer relations through automated analysis of conversational distance in direct and indirect customer communications, comprising:\ngathering indirect customer communications from online sources using a web search engine operating on a computing device;\nreceiving direct and indirect customer communications at a sentiment and emotion analyzer operating on the computing device, each communication being associated with a product or service and each communication comprising either text content or audio content the text content and audio content comprising an expression of an emotion or a sentiment;\nconverting any audio content to text content using an automated speech recognition engine operating on the computing device;\nanalyzing text content from each of the direct and indirect customer communications using a machine learning algorithm to determine a conversational distance between an agent and a customer for each of the direct and indirect customer communications, wherein:\nthe conversational distance is determined at least in part by the emotion or the sentiment;\nthe conversational distance for the direct customer communications is determined using the agent's interactions with the customer, and\nthe conversational distance for the indirect customer communications is determined using the agent's history of interactions with other customers;\ncumulatively assigning similarity scores to the products or services associated with the direct or indirect customer communications based on the determined conversational distance; and\ngenerating a recommended response for the agent to each direct or indirect communication based on the assigned similarity score for that direct or indirect communication.\n7. The method of claim 6 comprising the additional step of using vector clustering to segment similar content.\n8. The method of claim 6 comprising the additional step of using linear transformation to translate between the language of product-specific or service-specific domains.\n9. The method of claim 6 comprising the additional step of using vector algebra to determine sentiment.\n10. The method of claim 6 comprising the additional step of using vector calculus to understand and predict time evolution in emotion and meaning by calculating rates of change of vectors and time dynamics, and applying the predictions to the cumulatively assigned similarity scores.",
    "status": "Active",
    "citations_own": [
        "US9652113B1",
        "US20170250931A1",
        "US10275522B1",
        "US20190347571A1"
    ],
    "citations_ftf": [
        "US9411860B2",
        "US9799035B2",
        "US10038786B2",
        "US20150339327A1",
        "US10586175B2",
        "US9483768B2",
        "US10467268B2",
        "US10740678B2"
    ],
    "citedby_own": [
        "US20230109021A1"
    ],
    "citedby_ftf": [
        "JP6465077B2",
        "US11544719B1",
        "CN107464554B",
        "WO2019200584A1",
        "US11094316B2",
        "KR20190131163A",
        "US10810436B2",
        "CN109308892B",
        "CN110032639B",
        "US11132511B2",
        "US11089157B1",
        "CN109918376A",
        "US10482185B1",
        "CN110046223B",
        "CN109949827A",
        "US11455999B1",
        "US11176333B2",
        "US11132513B2",
        "US11416539B2",
        "AU2020290434B2",
        "WO2020251580A1",
        "CN110322899B",
        "CN110335596A",
        "US20210012065A1",
        "US11151328B2",
        "EP4018438A4",
        "CN110705309B",
        "US10735585B1",
        "US11256872B2",
        "US11341959B2",
        "US11664044B2",
        "JP2021096711A",
        "CN111191428B",
        "CN111240478B",
        "CN111223498A",
        "CN111343398B",
        "US11636850B2",
        "US10999434B1",
        "US20220012667A1",
        "US11410677B2",
        "US20220172219A1",
        "CN112507115B",
        "CN112686327A",
        "CN113220964A",
        "US11442976B1",
        "US20220414694A1",
        "US20230009317A1",
        "US20230206255A1",
        "US11748248B1"
    ]
}