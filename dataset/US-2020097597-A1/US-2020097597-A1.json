{
    "patent_id": "US-2020097597-A1",
    "title": "On-demand relation extraction from text ",
    "assignee": "International Business Machines Corporation",
    "publication_date": "2020-03-26",
    "patent_link": "https://patents.google.com/patent/US20200097597A1/en",
    "inventors": [
        "Ismini Lourentzou",
        "Anna Lisa Gentile",
        "Daniel Gruhl",
        "Alfredo Alba",
        "Chris Kau",
        "Chad DeLuca",
        "Linda Kato",
        "Petar Ristoski",
        "Steven R. Welch"
    ],
    "classifications": [
        "G06F16/35",
        "G06F17/30616",
        "G06F16/313",
        "G06F16/3347",
        "G06F17/271",
        "G06F17/3069",
        "G06F40/211",
        "G06F40/295",
        "G06F40/30",
        "G06N20/10",
        "G06N3/044",
        "G06N3/045",
        "G06N3/048",
        "G06N3/0481",
        "G06N3/08",
        "G06N5/022",
        "G06N7/01",
        "G06N5/041"
    ],
    "abstract": "One embodiment provides a method for on-demand relation extraction from unstructured text that includes obtaining a text corpus of domain related unstructured text. Representations of the unstructured text that capture entity-specific syntactic knowledge are created. Initial user seeds of informative examples containing relations are received. Extraction models in a neural network are trained using the initial user seeds. Performance information and a confidence score are provided for each prediction for each extraction model. A next batch of informative examples are identified for annotation from the text corpus based on training a neural network classifier on a pool of labeled informative examples. Stopping criteria is determined based on differences of the performance information and the confidence score in relation to parameters for each extraction model. Based on the stopping criteria, it is determined whether to retrain a particular extraction model after the informative examples have been labeled.",
    "claims": "\n1. A method for on-demand relation extraction from unstructured text, the method comprising:\nobtaining a text corpus of domain related unstructured text;\ncreating representations of the unstructured text that capture entity-specific syntactic knowledge;\nreceiving initial user seeds of informative examples containing relations;\ntraining extraction models in a neural network using the initial user seeds;\nproviding performance information and a confidence score for each prediction for each extraction model;\nidentifying a next batch of informative examples for annotation from the text corpus based on training a neural network classifier on a pool of labeled informative examples;\ndetermining stopping criteria based on differences of the performance information and the confidence score in relation to parameters for each extraction model; and\ndetermining, based on the stopping criteria, whether to retrain a particular extraction model after the informative examples have been labeled.\n2. The method of claim 1, wherein the representations of the unstructured text that capture entity-specific syntactic knowledge are created without relying on additional lexical or linguistic resources.\n3. The method of claim 2, wherein creating the representations of the unstructured text that capture entity-specific syntactic knowledge comprises representing distance of each word from each entity in a continuous vector format.\n4. The method of claim 3, wherein creating the representations of the unstructured text that capture entity-specific syntactic knowledge further comprises splitting the unstructured text into three parts based on position of entities.\n5. The method of claim 3, wherein creating the representations of the unstructured text that capture entity-specific syntactic knowledge further comprises distinguishing between an entity representation and an averaged vector representation for the words in the unstructured text.\n6. The method of claim 2, wherein identifying the next batch of informative examples for annotation from the text corpus further comprises:\npassing each unlabeled example from the neural network classifier to produce a prediction and a continuous representation for each informative example, the representation comprises weights of a final hidden layer; and\nusing a clustering-based active learning process to output informative examples that are both representative of each cluster and for which the neural network classifier has a confidence score below a threshold for its prediction.\n7. The method of claim 1, wherein the performance information and the confidence score of each extraction model comprises k-fold cross validation on the initial user seeds, and user selection is provided for selecting an extraction model and selecting a threshold for producing the next batch of informative examples.\n8. The method of claim 1, wherein user control is provided for determining parameters to trade-off between performance information and annotation processing.\n9. A computer program product for on-demand relation extraction from unstructured text, the computer program product comprising a computer readable storage medium having program instructions embodied therewith, the program instructions executable by a processor to cause the processor to:\nobtain, by the processor, a text corpus of domain related unstructured text;\ncreate, by the processor, representations of the unstructured text that capture entity-specific syntactic knowledge;\nreceive, by the processor, initial user seeds of informative examples containing relations;\ntrain, by the processor, extraction models in a neural network using the initial user seeds;\nprovide, by the processor, performance information and a confidence score for each prediction for each extraction model;\nidentify, by the processor, a next batch of informative examples for annotation from the text corpus based on training a neural network classifier on a pool of labeled informative examples;\ndetermine, by the processor, stopping criteria based on differences of the performance information and the confidence score in relation to parameters for each extraction model; and\ndetermine, by the processor, based on the stopping criteria, whether to retrain a particular extraction model after the informative examples have been labeled.\n10. The computer program product of claim 9, wherein the representations of the unstructured text that capture entity-specific syntactic knowledge are created without relying on additional lexical or linguistic resources.\n11. The computer program product of claim 10, wherein creating the representations of the unstructured text that capture entity-specific syntactic knowledge comprises representing distance of each word from each entity in a continuous vector format.\n12. The computer program product of claim 11, wherein creating the representations of the unstructured text that capture entity-specific syntactic knowledge further comprises splitting the unstructured text into three parts based on position of entities.\n13. The computer program product of claim 11, wherein creating the representations of the unstructured text that capture entity-specific syntactic knowledge further comprises distinguishing between an entity representation and an averaged vector representation for the words in the unstructured text.\n14. The computer program product of claim 10, wherein identifying the next batch of informative examples for annotation from the text corpus further comprises:\npassing each unlabeled example from the neural network classifier to produce a prediction and a continuous representation for each informative example, the representation comprises weights of a final hidden layer; and\nusing a clustering-based active learning process to output informative examples that are both representative of each cluster and for which the neural network classifier has a confidence score below a threshold for its prediction.\n15. The computer program product of claim 9, wherein:\nthe performance information and the confidence score of each extraction model comprises k-fold cross validation on the initial user seeds;\nuser selection is provided for selecting an extraction model and selecting a threshold for producing the next batch of informative examples; and\nuser control is provided for determining parameters to trade-off between performance information and annotation processing.\n16. An apparatus comprising:\na memory configured to store instructions; and\na processor configured to execute the instructions to:\nobtain a text corpus of domain related unstructured text;\ncreate representations of the unstructured text that capture entity-specific syntactic knowledge;\nreceive initial user seeds of informative examples containing relations;\ntrain extraction models in a neural network using the initial user seeds;\nprovide performance information and a confidence score for each prediction for each extraction model;\nidentify a next batch of informative examples for annotation from the text corpus based on training a neural network classifier on a pool of labeled informative examples;\ndetermine stopping criteria based on differences of the performance information and the confidence score in relation to parameters for each extraction model; and\ndetermine based on the stopping criteria, whether to retrain a particular extraction model after the informative examples have been labeled.\n17. The apparatus of claim 16, wherein:\nthe representations of the unstructured text that capture entity-specific syntactic knowledge are created without relying on additional lexical or linguistic resources; and\ncreating the representations of the unstructured text that capture entity-specific syntactic knowledge comprises:\nrepresenting distance of each word from each entity in a continuous vector format; and\nsplitting the unstructured text into three parts based on position of entities.\n18. The apparatus of claim 17, wherein creating the representations of the unstructured text that capture entity-specific syntactic knowledge further comprises distinguishing between an entity representation and an averaged vector representation for the words in the unstructured text.\n19. The apparatus of claim 17, wherein identifying the next batch of informative examples for annotation from the text corpus further comprises:\npassing each unlabeled example from the neural network classifier to produce a prediction and a continuous representation for each informative example, the representation comprises weights of a final hidden layer; and\nusing a clustering-based active learning process to output informative examples that are both representative of each cluster and for which the neural network classifier has a confidence score below a threshold for its prediction.\n20. The apparatus of claim 16, wherein:\nthe performance information and the confidence score of each extraction model comprises k-fold cross validation on the initial user seeds;\nuser selection is provided for selecting an extraction model and selecting a threshold for producing the next batch of informative examples; and\nuser control is provided for determining parameters to trade-off between performance information and annotation processing."
}