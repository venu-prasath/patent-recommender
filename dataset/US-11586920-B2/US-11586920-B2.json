{
    "patent_id": "US-11586920-B2",
    "title": "Neural network processor ",
    "assignee": "Google Llc",
    "publication_date": "2023-02-21",
    "patent_link": "https://patents.google.com/patent/US11586920B2/en",
    "inventors": [
        "Jonathan Ross",
        "Norman Paul Jouppi",
        "Andrew Everett Phelps",
        "Reginald Clifford Young",
        "Thomas Norrie",
        "Gregory Michael Thorson",
        "Dan Luu"
    ],
    "classifications": [
        "G06N3/08",
        "G06N3/063",
        "G06F15/8046",
        "G06N5/04"
    ],
    "abstract": "A circuit for performing neural network computations for a neural network comprising a plurality of neural network layers, the circuit comprising: a matrix computation unit configured to, for each of the plurality of neural network layers: receive a plurality of weight inputs and a plurality of activation inputs for the neural network layer, and generate a plurality of accumulated values based on the plurality of weight inputs and the plurality of activation inputs; and a vector computation unit communicatively coupled to the matrix computation unit and configured to, for each of the plurality of neural network layers: apply an activation function to each accumulated value generated by the matrix computation unit to generate a plurality of activated values for the neural network layer.",
    "claims": "\n1. A system for performing neural network computations for a neural network the system comprising:\na memory device configured to store respective sets of weight inputs and activation inputs;\na matrix computation unit comprising a plurality of cells arranged as a multi-dimensional array, wherein each cell of the plurality of cells:\nis configured to receive weight inputs for a neural network layer of the neural network and activation inputs for the neural network layer; and\nincludes circuitry for performing neural network computations for the neural network layer using at least the weight inputs and the activation inputs received at the cell; and. a vector computation unit configured to:\nreceive a vector of accumulated values for the neural network layer;\napply an activation function to the vector of accumulated values; and\ngenerate an output based on the applied activation function and the accumulated values.\n2. The system of claim 1, wherein the memory device is a direct memory access engine configured to:\nsend the respective sets of activation inputs to a memory buffer of the system, wherein the memory buffer provides the respective sets of activation inputs to the matrix computation unit; and\nread outputs of the matrix computation unit that are stored in the memory buffer.\n3. The system of claim 1, wherein:\nthe neural network layer is a first neural network layer; and\nthe memory device is a unified buffer configured to:\nsend the respective sets of activation inputs to the matrix computation unit;\nreceive and store outputs of the matrix computation unit that are provided by the vector computation unit, wherein the vector computation unit is further configured to communicate with the matrix computation unit; and\nprovide outputs received from the vector computation unit as activation inputs to the matrix computation unit for performing neural network computations for a second neural network layer of the neural network different from the first neural network layer.\n4. The system of claim 1, wherein the matrix computation unit is configured to process a plurality of weight inputs and a plurality of activation inputs to generate activation values for the neural network layer using respective circuitry in at least two distinct cells of the plurality of cells of the matrix computation unit.\n5. The system of claim 1, further comprising circuitry configured to:\ndetermine whether there are more sets of activation inputs for the neural network layer than there are rows for a first dimension of the multi-dimensional array;\ndivide the sets of activation inputs into respective portions that are each sized to be less than or equal to an amount of rows for the first dimension of the multi-dimensional array; and\ngenerate, for each respective portion of activation inputs, a portion of accumulated values.\n6. The system of claim 5, wherein each portion of accumulated values is stored in a memory buffer of the system until all respective portions of activation inputs have been processed by the matrix computation unit for performing at least a subset of the neural network computations for the neural network layer.\n7. The system of claim 5, further comprising circuitry configured to:\ndetermine whether there are more sets of weight inputs for the neural network layer than there are columns for a second dimension of the multi-dimensional array;\ndivide the sets of weight inputs into respective portions that are each sized to be less than or equal to an amount of columns for the second dimension of the multi-dimensional array; and\ngenerate, for each respective portion of weight inputs, a portion of accumulated values.\n8. The system of claim 7, further comprising circuitry configured to:\ncompute products using the respective portions of activation inputs and the respective portions of weight inputs;\ncompute sums of the products that are computed using the respective portions of activation inputs and the respective portions of weight inputs; and\ncompute dot products using the computed sums of the products.\n9. A method for performing neural network computations for a neural network, comprising:\nreceiving, by a matrix computation unit, weight inputs and activation inputs, wherein the matrix computation unit includes a plurality of cells arranged as a multi-dimensional array;\nperforming, by the matrix computation unit, a portion of the neural network computations for the neural network using at least the weight inputs and the activation inputs received at the cell;\nreceiving, by a vector computation unit, a vector of accumulated values for the neural network layer;\napplying an activation function to the vector of accumulated values; and\ngenerating an output based on the applied activation function and the accumulated values.\n10. The method of claim 9, wherein the matrix computation unit and the vector computation unit are part of a system configured to perform neural network computations.\n11. The method of claim 10, wherein each cell of the plurality of cells of the matrix computation unit includes one or more registers, and wherein the method further comprises:\nstoring, in the one or more registers of the cell, the weight inputs or the activation inputs; and\nshifting, to an adjacent cell of the matrix computation unit, the weight inputs or the activation inputs based on a control signal stored in the cell.\n12. The method of claim 10, wherein the weight inputs and activation inputs are stored in a direct memory access engine, and wherein the method further comprises:\nsending, by the direct memory access engine, the respective sets of activation inputs to a memory buffer of the system; and\nproviding, by the memory buffer of the system and to the matrix computation unit, the respective sets of activation inputs; and\nreading, by the direct memory access engine, outputs of the matrix computation unit that are stored in the memory buffer of the system, the outputs being generated in response to the matrix computation unit being used to perform the neural network computations.\n13. The method of claim 10, wherein the weight inputs and the activation inputs are stored in a unified buffer, and wherein the method further comprises:\nsending, by the unified buffer, the respective sets of activation inputs to the matrix computation unit; and\nstoring, at the unified buffer, outputs of the matrix computation unit that are generated in response to performing the neural network computations;\nwherein the outputs are provided to the unified buffer by the vector computation unit.\n14. The method of claim 10, further comprising:\nprocessing, by the matrix computation unit, a plurality of weight inputs and a plurality of activation inputs for the neural network layer; and\nin response to processing, generating, by the matrix computation unit, accumulated values for the neural network layer using respective circuitry in at least two distinct cells of the plurality of cells of the matrix computation unit.\n15. The method of claim 10, further comprising:\ndetermining, by the system, whether there are more sets of activation inputs for the neural network layer than there are rows for a first dimension of the multi-dimensional array;\nin response to determining that there are more sets of activation inputs for the neural network layer than there are rows for the first dimension of the multi-dimensional array, dividing, by the system, the sets of activation inputs into respective portions that are each sized to be less than or equal to an amount of rows for the first dimension of the multi-dimensional array; and\ngenerating, by the system and for each respective portion of activation inputs, a portion of accumulated values.\n16. The method of claim 10, further comprising:\ndetermining, by the system, whether there are more sets of weight inputs for the neural network layer than there are columns for a second dimension of the multi-dimensional array;\nin response to determining that there are more sets of weight inputs for the neural network layer than there are columns for the second dimension of the multi-dimensional array, dividing, by the system, the sets of weight inputs into respective portions that are each sized to be less than or equal to an amount of columns for the second dimension of the multi-dimensional array; and\ngenerating, by the system and for each respective portion of weight inputs, a portion of accumulated values.\n17. One or more non-transitory machine-readable storage devices for storing instructions for performing neural network computations for a neural network, wherein the instructions are executable by one or more processing devices to cause the one or more processing devices to perform operations comprising:\nreceiving, by a matrix computation unit, weight inputs and activation inputs, wherein the matrix computation unit includes a plurality of cells arranged as a multi-dimensional array;\nperforming, by the matrix computation unit, a portion of the neural network computations for the neural network using at least the weight inputs and the activation inputs received at the cell;\nreceiving, by a vector computation unit, a vector of accumulated values for the neural network layer;\napplying an activation function to the vector of accumulated values; and\ngenerating an output based on the applied activation function and the accumulated values.\n18. The one or more machine-readable storage devices of claim 17, wherein the matrix computation unit and the vector computation unit are part of a system configured to perform neural network computations.\n19. The one or more machine-readable storage devices of claim 18, wherein the weight inputs and activation inputs are stored in a direct memory access engine, and wherein the operations further comprises:\nsending, by the direct memory access engine, the respective sets of activation inputs to a memory buffer of the system; and\nproviding, by the memory buffer of the system and to the matrix computation unit, the respective sets of activation inputs; and\nreading, by the direct memory access engine, outputs of the matrix computation unit that are stored in the memory buffer of the system, the outputs being generated in response to the matrix computation unit being used to perform the neural network computations.\n20. The one or more machine-readable storage devices of claim 18, wherein the weight inputs and the activation inputs are stored in a unified buffer, and wherein the operations further comprise:\nsending, by the unified buffer, the respective sets of activation inputs to the matrix computation unit; and\nstoring, at the unified buffer, outputs of the matrix computation unit that are generated in response to performing the neural network computations, wherein the outputs are provided to the unified buffer by the vector computation unit.",
    "status": "Active",
    "citations_own": [
        "EP0422348A2",
        "US5014235A",
        "US5136717A",
        "US5146543A",
        "US5337395A",
        "US5509106A",
        "US5544336A",
        "US5799134A",
        "US5812993A",
        "US5892962A",
        "US6038337A",
        "US6184753B1",
        "CN1333518A",
        "US20020168100A1",
        "US20050044053A1",
        "US7082419B1",
        "US7136710B1",
        "US20070086655A1",
        "US20080319933A1",
        "CN101681450A",
        "US20110029471A1",
        "TW201128542A",
        "US8184696B1",
        "TW201232429A",
        "US8417758B1",
        "TW201331855A",
        "US20140142929A1",
        "TW201421381A",
        "US20140180984A1",
        "US20140180989A1",
        "CN104035751A",
        "TW201435757A",
        "US20140288928A1",
        "US20140337262A1",
        "CN104238993A",
        "US8924455B1",
        "EP3064130A1",
        "US20160267111A1",
        "US10699188B2"
    ],
    "citations_ftf": [],
    "citedby_own": [],
    "citedby_ftf": [
        "US11797641B2",
        "CA2881033C",
        "US9747546B2",
        "US10509765B2",
        "US10616314B1",
        "US10482380B2",
        "GB201607713D0",
        "US10175980B2",
        "US10417560B2",
        "US10037490B2",
        "CN108241484B",
        "US10521488B1",
        "US10824934B2",
        "US10062378B1",
        "US10896367B2",
        "US9691019B1",
        "US10909447B2",
        "US10241972B2",
        "US11544545B2",
        "US10387298B2",
        "US11551028B2",
        "US11238334B2",
        "US11615297B2",
        "CN116661732A",
        "KR102481428B1",
        "US10019668B1",
        "WO2018231204A1",
        "CN107146616B",
        "CN112214727A",
        "US11328037B2",
        "US11157441B2",
        "US10671349B2",
        "US11409692B2",
        "US11157287B2",
        "US11507429B2",
        "US11360934B1",
        "US11114138B2",
        "US11243880B1",
        "US11170307B1",
        "US20190114548A1",
        "CN111194451A",
        "KR102586173B1",
        "US10902318B2",
        "KR20190051697A",
        "KR102561261B1",
        "KR102424962B1",
        "US20190156214A1",
        "KR20190065144A",
        "WO2019118363A1",
        "WO2019126030A1",
        "US11360930B2",
        "CN109977071A",
        "US11561791B2",
        "US11164074B2",
        "US11769042B2",
        "US10416899B2",
        "TWI659324B",
        "TWI673614B",
        "US10452871B2",
        "US10509698B2",
        "US10509600B2",
        "US20190266111A1",
        "CN110222833A",
        "KR20190106010A",
        "CN110210610B",
        "US10621489B2",
        "US11188814B2",
        "US20210018742A1",
        "CN112005230A",
        "CN112041838A",
        "US10387122B1",
        "US10963787B2",
        "US11216732B2",
        "US10832133B2",
        "US11449363B2",
        "US20190392287A1",
        "US10839894B2",
        "CN112771498A",
        "US20200082242A1",
        "WO2020072274A1",
        "US11443185B2",
        "TWI714003B",
        "KR20200049366A",
        "JP7315317B2",
        "US11341369B2",
        "KR20200064264A",
        "US10867399B2",
        "KR20200066953A",
        "TWI694413B",
        "TWI696961B",
        "CN109657788A",
        "CN109670581B",
        "US11544559B2",
        "US11550971B1",
        "US10992314B2",
        "CN110163338A",
        "CN109933371A",
        "KR20200107295A",
        "US10929058B2",
        "US11783176B2",
        "US11169957B2",
        "US20200320373A1",
        "US11671111B2",
        "WO2021026225A1",
        "US20230023859A1",
        "US20210089873A1",
        "US11443163B2",
        "KR20210060024A",
        "CN114930351A",
        "US20210166110A1",
        "CN111325332B",
        "US11507817B2",
        "JP6834097B1",
        "CA3179781A1",
        "US11120805B1",
        "JP7358312B2",
        "US11263077B1",
        "US11221929B1",
        "US11237894B1",
        "CN116457787A",
        "US11417373B2",
        "US11556757B1",
        "RU2754605C1",
        "US11144822B1",
        "CN112949834B",
        "US11669331B2",
        "US11734013B2",
        "US11269632B1",
        "US11797270B2",
        "US11693692B2",
        "US11675592B2",
        "CN113705773B",
        "US11714556B2",
        "US11657864B1"
    ]
}