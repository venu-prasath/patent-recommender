{
    "patent_id": "US-11763668-B2",
    "title": "Detecting blocking objects ",
    "assignee": "Zoox, Inc.",
    "publication_date": "2023-09-19",
    "patent_link": "https://patents.google.com/patent/US11763668B2/en",
    "inventors": [
        "Mahsa Ghafarianzadeh",
        "Benjamin John Sapp"
    ],
    "classifications": [
        "G08G1/0145",
        "B60K31/0008",
        "G05D1/0221",
        "G06F18/24323",
        "G06N20/00",
        "G06N7/01",
        "G06V10/764",
        "G06V20/58",
        "G08G1/0112",
        "G08G1/0133",
        "G08G1/165"
    ],
    "abstract": "A method and system of determining whether a stationary vehicle is a blocking vehicle to improve control of an autonomous vehicle. A perception engine may detect a stationary vehicle in an environment of the autonomous vehicle from sensor data received by the autonomous vehicle. Responsive to this detection, the perception engine may determine feature values of the environment of the vehicle from sensor data (e.g., features of the stationary vehicle, other object(s), the environment itself). The autonomous vehicle may input these feature values into a machine-learning model to determine a probability that the stationary vehicle is a blocking vehicle and use the probability to generate a trajectory to control motion of the autonomous vehicle.",
    "claims": "\n1. A method comprising:\nreceiving sensor data associated with an environment associated with a vehicle;\ndetermining, based at least in part on the sensor data, an indication of traffic flow associated with an object within a portion of the environment, wherein the object is different than a stationary object;\nproviding, as input to a machine-learning model, the indication;\nreceiving, from the machine-learning model, a probability that the stationary object blocks a path of the vehicle or part of a roadway associated with the vehicle; and\ncontrolling the vehicle based at least in part on the probability.\n2. The method of claim 1, wherein the indication of traffic flow comprises at least one of:\na first distribution of at least one of actions, headings, or velocities of objects in the portion of the environment;\na second distribution of at least one of actions, headings, or velocities of objects of a same classification in the portion of the environment;\na tail characteristic of the first distribution or the second distribution;\nan indication of whether at least one of a heading or velocity associated with the stationary object is in a tail of the first distribution or the second distribution;\na percent of objects having a same heading or velocity as the stationary object based at least in part on the first distribution or the second distribution;\na percentile associated with a velocity of the stationary object based at least in part on the first distribution or the second distribution; or\na frequency with which another object in the portion of the environment completes a type of action.\n3. The method of claim 1, further comprising:\ndetermining, based at least in part on the sensor data, an object track associated with the object, wherein the object track comprises at least one of a current or historic heading and velocity of the object; and\ndetermining, based at least in part on the object track, that the object is currently or has been headed a same direction of travel as the vehicle, wherein:\ndetermining the indication of traffic flow is based at least in part on the object track and determining that the object is currently or has been headed the same direction of travel.\n4. The method of claim 1, further comprising:\ndetermining, based at least in part on the sensor data, an object detection associated with the object, wherein the object detection comprises a classification associated with the object; and\ndetermining, based at least in part on two or more object detections indicating the classification, a distribution of an object track characteristic associated with the two or more object detections, wherein the object track characteristic comprises at least one of a current, historic, or predicted at least one of position, heading, or velocity indicated by object tracks associated with the two or more object detections,\nwherein the distribution is part of the indication of traffic flow.\n5. The method of claim 1, further comprising determining a weight associated with the indication of traffic flow based at least in part on a proximity of the object to the vehicle, wherein the weight is included in the indication of traffic flow.\n6. The method of claim 1, further comprising:\ncontrolling the vehicle to pass the stationary object based at least in part on determining that the probability meets or exceeds a threshold probability, or otherwise\ncontrolling the vehicle to maintain a current action or come to a stop.\n7. A system comprising:\none or more processors; and\na memory storing processor-executable instructions that, when executed by the one or more processors, cause the system to perform operations comprising:\nreceiving sensor data indicating an environment associated with a vehicle;\ndetermining, based at least in part on the sensor data, an indication of movement of an object within a portion of the environment, wherein the object is different than a stationary object;\nproviding, as input to a machine-learning model, the indication;\nreceiving, from the machine-learning model, a probability that the stationary object blocks a path of the vehicle or at least part of a roadway associated with the vehicle; and\ncontrolling the vehicle based at least in part on the probability.\n8. The system of claim 7, wherein the portion of the environment comprises at least one of a first lane in which the vehicle is located or a second lane next to the first lane associated with an object track indicating that a second object moved in the second lane in a same direction of travel as the vehicle.\n9. The system of claim 7, wherein the indication of movement comprises at least one of:\na first distribution of at least one of actions, headings, or velocities of objects in the portion of the environment;\na second distribution of at least one of actions, headings, or velocities of objects of a same classification in the portion of the environment;\na tail characteristic of the first distribution or the second distribution;\nan indication of whether at least one of a heading or velocity associated with the stationary object is in a tail of the first distribution or the second distribution;\na percent of objects having a same heading or velocity as the stationary object based at least in part on the first distribution or the second distribution.\n10. The system of claim 7, wherein the operations further comprise:\ndetermining, based at least in part on the sensor data, an object track associated with the object, wherein the object track comprises at least one of a current or historic heading and velocity of the object; and\ndetermining, based at least in part on the object track, that the object is currently or has been headed a same direction of travel as the vehicle, wherein:\ndetermining the indication of movement is based at least in part on the object track and determining that the object is currently or has been headed the same direction of travel.\n11. The system of claim 7, wherein the operations further comprise:\ndetermining, based at least in part on the sensor data, an object detection associated with the object, wherein the object detection comprises a classification associated with the object; and\ndetermining, based at least in part on two or more object detections indicating the classification, a distribution of an object track characteristic associated with the two or more object detections, wherein the object track characteristic comprises at least one of a current, historic, or predicted at least one of position, heading, or velocity indicated by object tracks associated with the two or more object detections,\nwherein the distribution is part of the indication of movement.\n12. The system of claim 7, wherein the operations further comprise determining a weight associated with the indication of traffic flow based at least in part on a proximity of the object to the vehicle, wherein the weight is included in the indication of traffic flow.\n13. The system of claim 7, wherein the operations further comprise:\ncontrolling the vehicle to pass the stationary object based at least in part on determining that the probability meets or exceeds a threshold probability, or otherwise\ncontrolling the vehicle to maintain a current action or come to a stop.\n14. A non-transitory computer-readable medium storing processor-executable instructions that, when executed by one or more processors, cause the one or more processors to perform operations comprising:\nreceiving sensor data indicating an environment associated with a vehicle;\ndetermining, based at least in part on the sensor data, an indication of movement of an object within a portion of the environment, wherein the object is different than a stationary object;\nproviding, as input to a machine-learning model, the indication;\nreceiving, from the machine-learning model, a probability that the stationary object blocks a path of the vehicle or at least part of a roadway associated with the vehicle; and\ncontrolling the vehicle based at least in part on the probability.\n15. The non-transitory computer-readable medium of claim 14, wherein the portion of the environment comprises at least one of a first lane in which the vehicle is located or a second lane next to the first lane associated with an object track indicating that a second object moved in the second lane in a same direction of travel as the vehicle.\n16. The non-transitory computer-readable medium of claim 14, wherein the indication of movement comprises at least one of:\na first distribution of at least one of actions, headings, or velocities of objects in the portion of the environment;\na second distribution of at least one of actions, headings, or velocities of objects of a same classification in the portion of the environment;\na tail characteristic of the first distribution or the second distribution;\nan indication of whether at least one of a heading or velocity associated with the stationary object is in a tail of the first distribution or the second distribution;\na percent of objects having a same heading or velocity as the stationary object based at least in part on the first distribution or the second distribution.\n17. The non-transitory computer-readable medium of claim 14, wherein the operations further comprise:\ndetermining, based at least in part on the sensor data, an object track associated with the object, wherein the object track comprises at least one of a current or historic heading and velocity of the object; and\ndetermining, based at least in part on the object track, that the object is currently or has been headed a same direction of travel as the vehicle, wherein:\ndetermining the indication of movement is based at least in part on the object track and determining that the object is currently or has been headed the same direction of travel.\n18. The non-transitory computer-readable medium of claim 14, wherein the operations further comprise:\ndetermining, based at least in part on the sensor data, an object detection associated with the object, wherein the object detection comprises a classification associated with the object; and\ndetermining, based at least in part on two or more object detections indicating the classification, a distribution of an object track characteristic associated with the two or more object detections, wherein the object track characteristic comprises at least one of a current, historic, or predicted at least one of position, heading, or velocity indicated by object tracks associated with the two or more object detections,\nwherein the distribution is part of the indication of movement.\n19. The non-transitory computer-readable medium of claim 14, wherein the operations further comprise determining a weight associated with the indication of traffic flow based at least in part on a proximity of the object to the vehicle, wherein the weight is included in the indication of traffic flow.\n20. The non-transitory computer-readable medium of claim 14, wherein the operations further comprise:\ncontrolling the vehicle to pass the stationary object based at least in part on determining that the probability meets or exceeds a threshold probability, or otherwise\ncontrolling the vehicle to maintain a current action or come to a stop.",
    "status": "Active",
    "citations_own": [
        "US5177685A",
        "US6272072B1",
        "CA2474443A1",
        "US20030187578A1",
        "US6707421B1",
        "US20050049785A1",
        "JP2006146889A",
        "JP2008129804A",
        "JP2008225579A",
        "US20110125344A1",
        "US20110205042A1",
        "US8112225B2",
        "US8121749B1",
        "CN103069153A",
        "US8473447B2",
        "CN203032675U",
        "US8620517B2",
        "US8645310B2",
        "US8849494B1",
        "US20140324268A1",
        "US8880272B1",
        "US8996224B1",
        "US9008890B1",
        "US20150147936A1",
        "JP2015516623A",
        "WO2016062568A1",
        "US9368026B1",
        "US9381916B1",
        "US20160201934A1",
        "WO2016130719A2",
        "JP2016191975A",
        "US9495874B1",
        "US9507347B1",
        "JP2016210255A",
        "US9558659B1",
        "US20170031361A1",
        "CN106382942A",
        "US9568915B1",
        "US9612123B1",
        "US20170111262A1",
        "US20170131719A1",
        "WO2017091690A1",
        "US20170192423A1",
        "US20170193338A1",
        "US20170192426A1",
        "US20170213459A1",
        "CN107015559A",
        "GB2547082A",
        "EP3217332A1",
        "US20170277195A1",
        "US20170364758A1",
        "US20180068191A1",
        "US20180089563A1",
        "US20180095465A1",
        "US20180137380A1",
        "US20180144202A1",
        "US20180141544A1",
        "US20180148051A1",
        "US20180164816A1",
        "US20180224860A1",
        "US10061322B1",
        "US20180251126A1",
        "US20190025841A1",
        "US20190051069A1",
        "US20190061765A1",
        "US20190092318A1",
        "US20190122059A1",
        "US20190244058A1",
        "US20190250626A1",
        "US10387736B2",
        "US20190272750A1",
        "US20190308620A1",
        "US20190329769A1",
        "US20190344804A1",
        "US20190354786A1",
        "US10514697B2",
        "US20200086855A1",
        "US20200110416A1",
        "US20200160530A1"
    ],
    "citations_ftf": [],
    "citedby_own": [],
    "citedby_ftf": [
        "US10353390B2",
        "US10671076B1",
        "US10678244B2",
        "US10671349B2",
        "US11157441B2",
        "US11409692B2",
        "US11561791B2",
        "TWI688502B",
        "US10955851B2",
        "US10628686B2",
        "CN110298663B",
        "US10414395B1",
        "US11126873B2",
        "US11215999B2",
        "US11636333B2",
        "US11214265B2",
        "US11562231B2",
        "US11543824B2",
        "US11196678B2",
        "US11295615B2",
        "US11349903B2",
        "US10823855B2",
        "WO2020113187A1",
        "US11537811B2",
        "US11225222B2",
        "US11514310B2",
        "US11610117B2",
        "US10991244B2",
        "US10990105B2",
        "US11435751B2",
        "US10817777B2",
        "US10997461B2",
        "US11567514B2",
        "US10956755B2",
        "US11400924B2",
        "US11100794B2",
        "US11741719B2",
        "US11354913B1",
        "US11605290B2",
        "US20220063661A1",
        "JP6970479B1",
        "CN112650243B",
        "CN112735163B",
        "CN112345272A",
        "US11697429B2",
        "US20220266822A1",
        "US20220355794A1",
        "CN115230722A"
    ]
}