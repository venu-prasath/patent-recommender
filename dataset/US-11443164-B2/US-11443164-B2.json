{
    "patent_id": "US-11443164-B2",
    "title": "Explanation and interpretation generation system ",
    "assignee": "UMNAI Limited",
    "publication_date": "2022-09-13",
    "patent_link": "https://patents.google.com/patent/US11443164B2/en",
    "inventors": [
        "Angelo Dalli",
        "Olga Maximovna FINKEL",
        "Matthew GRECH",
        "Mauro PIRRONE"
    ],
    "classifications": [
        "G06N3/0427",
        "G06N5/045",
        "G06N3/042",
        "G06F16/284",
        "G06F17/18",
        "G06N3/08",
        "G16H50/20",
        "G06N3/045",
        "G06N5/041",
        "G06N5/046",
        "G06N5/048"
    ],
    "abstract": "An exemplary embodiment provides an explanation and interpretation generation system for creating explanations in different human and machine-readable formats from an explainable and/or interpretable machine learning model. An extensible explanation architecture may allow for seamless third-party integration. Explanation scaffolding may be implemented for generating domain specific explanations, while interpretation scaffolding may facilitate the generation of domain and scenario specific interpretations. An exemplary explanation filter interpretation model may provide an explanation and interpretation generation system optional filtering and interpretation filtering and briefing capabilities. An embodiment may cluster explanations into concepts to incorporate information such as taxonomies, ontologies, causal models, statistical hypotheses, data quality controls, domain specific knowledge and allow for collaborative human knowledge injection. An embodiment may include a flexible presentation layer, user model and a goal-plan-action system to enable practical and useful actionable explanations to be generated.",
    "claims": "\n1. A system for providing explanations and interpretations, the system comprising a processor and a memory on which is stored computer program code instructions, wherein the processor operates to provide:\nan explainable model configured to receive an input query and return a model output, wherein the model output comprises an answer and a model explanation;\nan explanation component configured to receive the model output to produce an explanation using an explanation scaffolding, the explanation scaffolding comprising a plurality of components including:\nan explanation model component, comprising the model output indicating the answer, the model explanation, and a model fusion and links component, wherein the model fusion and links component is configured to store metadata and information associated with one or more links between one or more systems and databases;\na hypothetical and causal component, configured to model at least one cause-and-effect relationship by forming one or more structural equation models, structural causal models, and/or causal directed acyclic graphs; and\na scenario, interaction, and presentation component; and\na plurality of interpreters comprising a plurality of interpretation components, the plurality of interpretation components forming an interpretation scaffolding and configured to receive the answer, the model explanation, and the explanation scaffolding to produce an interpretation, the interpretation scaffolding comprising a plurality of interpreter beliefs components, wherein the interpretation scaffolding isolates each of the interpreter beliefs components from each of the other interpreter beliefs components;\nwherein receiving, on the explanation component, the model output using the explanation scaffolding comprises:\nreceiving, on the explanation component, an explanation scaffolding data structure, the explanation scaffolding data structure comprising each of the plurality of components and defined linkages between the plurality of components; and\ndeconstructing the explanation scaffolding data structure into an explanation.\n2. The system of claim 1, wherein the hypothetical and causal component further comprises an abductive logic system for diagnosing an observed effect to identify a cause of the observed effect and one or more recommendations, the recommendations comprising a course of action to remedy the observed effect.\n3. The system of claim 1, wherein the hypothetical and causal component further comprises one or more hypothesis evaluation components and a plurality of concepts associated with groupings of one or more hypotheses,\nwherein each grouping of one or more hypotheses connects one or more concepts in the plurality of concepts by identifying one or more expected relationships between propositions for the one or more concepts, and\nwherein a conceptual framework is formed from the one or more expected relationships, and\nwherein the hypothetical and causal component is further configured to cluster different types of explanations into concepts using a cognitive chunk model, implement a confirmatory factor analysis, and/or implement an explanatory factor analysis.\n4. The system of claim 1, wherein the interpretation scaffolding comprises:\nan explanation and interpretation scenario component;\na framing, protocol, and contextual component; and\nan interpretation model component.\n5. The system of claim 1, wherein the hypothetical and causal component further comprises:\na hypotheses and concepts component configured to store information corresponding to one or more hypotheses applicable to the explanation, wherein the one or more hypotheses include one or more of:\na trial hypothesis comprising a suggested outcome based on evidence, wherein the hypotheses and concepts component is configured to test the evidence to confirm or reject the trial hypothesis;\nan abductive hypothesis comprising a suggested explanation regarding a goal to be achieved;\na statistical hypothesis; or\na causal hypothesis identifying whether one or more of a plurality of features recognized by the explainable model is an effect of a cause triggered by an interaction of one or more of the plurality of features;\na controls and quality component configured to:\ngenerate an output within one or more predetermined parameters;\nidentify and apply one or more predetermined compliance constraints with tolerance parameters;\nstore and retrieve information indicating a state of qualitative or quantitative information of a plurality of variables and data within the system, and determine whether the variables and data within the system are internally consistent;\napply one or more of standardization, cleansing, data transforms, data profiling, data matching, data linking, data conformity checks, data accuracy checks, data precision checks, data bias checks, and data interpolation methods to the variables and data within the system;\napply one or more data privacy and access rules to the variables and data within the system;\ntrigger one or more actions or modify and configure one or more constraints and activating events and triggers in a behavioral model;\nvalidate, compare, and analyze the variables and data within the system in relation to a set of validated reference data to identify one or more new or discrepant values; and\napply one or more of data transforms, timestamp checks, data freshness checks, and data retention policy compliance of the variables and data within the system against a defined service level agreement,\nan interactions and moderators component;\na mediations component;\nan associations and assumptions component;\nan interventions component; and\na counterfactuals component.\n6. The system of claim 5, wherein the interactions and moderators component is configured to discover a plurality of moderators, the moderators comprising categorical or quantitative variable that affects a relationship between one or more interactions,\nwherein the interactions and moderators component is configured to discover the plurality of moderators by at least one of a correlation analysis method and a variance analysis method; and\nwherein the interactions and moderators component further comprises a latent variable model.\n7. The system of claim 5, wherein the system includes the mediations component, and wherein the mediations component comprises statistical and causal mediations applicable to the explainable model and wherein the mediations component is configured to identify one or more mediator variables indicating a relationship between one or more independent variables and one or more dependent variables.\n8. The system of claim 7, wherein the mediations component is further configured to:\nidentify moderators from the interaction and moderator component affecting the relationship between one or more independent variables and one or more dependent variables;\ncreate a new mediated moderation path associated with a new mediator value by applying a moderator effect via the new mediator value and a new indirect path from the independent variables to the dependent variables; and\nassign a label for the moderator effect and the independent variables and the dependent variables according to the identified moderators.\n9. The system of claim 5, wherein the associations and assumptions component is configured to determine one or more of:\nstatistical associations between sets of data variables;\nconditional probabilities between data variables;\ninferences and associations obtained from data using conditional expectation methods;\nanswers to conditional probability sentences of the form P(y|x)=p, where the probability of an event Y=y, given that X=x was observed, is equal to p; and\na scenario analysis.\n10. The system of claim 5, wherein the interventions component is configured to identify a plurality of potential interventions, and is configured to use the potential interventions to determine one or more of:\nconditional probabilities that distinguish between causal relationships from correlative relationships stored in the associations and assumptions component;\none or more of: causal adjustments; multiple interventions; back-door identification and estimation methods; front-door identification and estimation methods; conditional interventions;\ncovariate-specific effect identification and estimation methods; inverse probability weighting and estimation methods; confounder identification; and suppressor variable identification;\ncausal inference obtained from using causal interventions;\nanswers to conditional probability sentences; and\na scenario analysis.\n11. The system of claim 5, wherein the controls and quality component is further configured to integrate with a semiotics component and a domain knowledge component by performing one or more checks, comprising:\nchecks against a predetermined range of values or static interrelationships;\nchecks against aggregated processes and functions held in domain knowledge of the domain knowledge component;\noutlier checks and exception case flagging;\ndrift checks against one or more nominal conditions that are prespecified or automatically discovered by a machine learning system;\nchecks against one or more predefined business as usual expectations;\nchecks using an explainable autoencoder/decoder system for drift, shift and abnormality detection,\nwherein the checks are performed using one or more of: simple generic aggregation rules, complex logic functions on a group of attributes of data input to the processes and functions held in the domain knowledge, and automatically discovered checks discovered via a machine learning process ran against the well-known processes and functions held in the domain knowledge.\n12. The system of claim 5, wherein the interactions and moderators component is configured to:\nidentify statistical correlations and causal interactions in the explainable model, and store the statistical correlations and causal interactions as one or more of:\ntransformations and mappings of subsets of data features;\npredictions from information embedded in a reconstructed state space, a latent space, and/or a phase space;\nco-occurrence statistics indicative of cause-and-effect; and\nestimator functions and estimands together with a set of corresponding resulting estimates, wherein the system is configured to determine an estimate from an estimand using the estimator functions, and wherein the estimator functions comprise one or more of a point estimator or an interval estimator.\n13. The system of claim 5, wherein the counterfactuals component is integrated with a continuous or discrete dynamic systems model, phase space model, recurrent feedback control system model and is configured to identify one or more:\none or more of: hypothetical adjustments; hypothetical interventions; deterministic and non-deterministic counterfactual determination methods; abduction estimation methods; action estimation methods; prediction estimation methods; consequence estimation methods; attribution of causation estimation methods; and direct and indirect effect estimation methods;\ncausal inference obtained from using causal counterfactuals;\nanswers to conditional probability sentences of the form P(yx|x\u2032, y\u2032)=p, provided that the probability of an event Y=y, had X been x, given that X was observed to be x\u2032 and Y to be y\u2032, is equal to p; or\nanswers to a scenario analysis.\n14. The system of claim 4, wherein the framing, protocol, and contextual component comprises an interpretation framing component, an interpretation rules and procedures component, a protocol context component, an interpretation brief component, an interpretation templates component, an interpreter domain knowledge component, an interpreter beliefs component in the plurality of interpreter beliefs components, and an interactive context component,\nwherein the interpretation framing component is configured to identify a framing of the interpretation using one or more models, representations, and/or simplifications to be applied by the interpretation component,\nthe interpretation rules and procedures component is configured to apply one or more interpretation rules and procedures;\nthe protocol context component comprises a protocol to be used when processing the explanation scaffolding; and\nthe interactive context component comprises one or more interactive and iterative processes to be tracked by the interpretation component.\n15. The system of claim 14, wherein the interpreter domain knowledge comprises domain specific knowledge available to a plurality of interpreters, and wherein each interpreter beliefs component in the plurality of interpreter beliefs components comprises a combination of domain-specific and domain-independent knowledge and scenario-specific information.\n16. The system of claim 14, wherein the interpretation model component comprises a scenario model, interpretation model, selection model, and conflict resolver component;\nwherein the scenario model comprises information specific to a scenario observed by the interpretation component;\nwherein the selection model identifies a selection process and method for ranking or scoring the interpretations resulting from the interpretation component; and\nwherein the conflict resolver component is configured to identify one or more conflicts relating to the interpretation component and action triggers configured to be activated when one or more of the conflicts cannot be resolved.\n17. The system of claim 1, further comprising a semiotics, taxonomical, and ontological component comprising a metrics and dimensions component, a taxonomies and ontologies component, a semiotics component, and a domain knowledge component, wherein:\nthe metrics and dimensions component comprises information regarding different systems of measurement and one or more of:\nunderlying units and dimensions of measurement comprising one or more of: a distance function; a differentiable manifold function; a translation, scale and rotational invariant metric function; a vector space metric; a multiset function; and a topological function;\na relationship between the underlying units and dimensions;\na relationship with a base standard topological space comprising at least one map, atlas, or transition map;\na conversion relationship to a base standard metric system; and\na translation process from a machine readable format to a human readable format or from a human readable format to a machine readable format.\n18. The system of claim 17, wherein the semiotics, taxonomical, and ontological component is further configured to:\ntransform encoded information and units used by machine learning systems;\nimplement a gradient descent function and/or a dynamic programming function to output a result in a format specified by a subsequent machine learning system;\nlink taxonomies and ontologies to causal models stored in the hypotheses and concepts component; or\ncombine knowledge found in taxonomies and ontologies with human-generated knowledge and machine-generated knowledge.\n19. The system of claim 17, wherein the semiotics, taxonomical, and ontological component further comprises a third-party data component configured to read and write a set of domain-specific knowledge to the semiotics, taxonomical, and ontological component and a semiotics component configured to implement one or more sign identification methods (kernels) and kernel labelling methods for one or more different transmission modalities of a plurality of symbols;\nwherein the semiotics component comprises:\na plurality of syntactical models one or more properties and interrelations of the symbols based on a representation of the symbols; and\na plurality of semantical models comprising one or more links with taxonomies and ontologies indicating one or more properties of the symbols.\n20. The system of claim 1, wherein the explainable model and/or explanation component are implemented as a hardware circuit, wherein the hardware circuit comprises one or more of an application specific integrated circuit (ASIC), analog circuit, digital circuit, optical-electrical circuit, field-programmable gate array (FPGA), computer processing unit, graphics processing unit, Neuromorphic computing hardware, and Quantum computing hardware.\n21. The system of claim 1, wherein the scenarios, interactions, and presentation component comprises:\na presentation data component comprising data used to present the explanation,\na layouts and templates component comprising layout and format information,\na presentation state component comprising information identifying a state and history of a presentation layer;\na user model, wherein the user model provides a partial or full model of a plurality of users of the system and identifies whether users are human or automated, and is configured to associate a user profile to one or more users of the system, and wherein the scenarios, interactions, and presentation component is configured to constantly update the user model based on new information regarding the users;\nan evaluation component configured to evaluate and log one or more of: a quality, accuracy, precision, complexity, usefulness, satisfaction, fairness, bias, authority, precedence, and effectiveness of the explanation;\na goals component comprising one or more system user goals, a plans and questions component configured to represent and execute one or more plans oriented by the system user goals, and an actions component comprising an action selection policy and a set of allowed actions, wherein the actions component is configured to identify and select a next action for the explainable model to perform and/or output; and\na world and environment model comprising a plurality of models of an interaction environment with which the explainable model is configured to interact and a plurality of models of an external environment beyond the explainable model, wherein one or more of the models of the interaction environment and models of the external environment comprise a behavioral model, a behavioral model hierarchy, an action trigger, and a feedback loop.\n22. The system of claim 1, wherein a filter is configured to selectively apply a specified amount of noise to the input query and/or the model output according to a predetermined noise factor.\n23. The system of claim 1, wherein the explainable model utilizes secure multi-party computation; and\nwherein the system further comprises an access control component, wherein the explanation scaffolding is stored within the memory as the plurality of components, and wherein the access control component is configured to authenticate a plurality of parties and selectively control access to the plurality of components by the plurality of parties, comprising enabling access to at least one component in the plurality of components by a first party in the plurality of parties and enabling access to at least one other component in the plurality of components but not to the at least one component in the plurality of components by a second party in the plurality of parties.\n24. The system of claim 1, wherein the explainable model comprises a plurality of combined decentralized explainable models, wherein each of the plurality of explainable models comprises local samples unique to each explainable model.\n25. The system of claim 1, wherein the explanation comprises one or more user-centric explanations of one or more of the following types:\nhow-type explanations, why-type explanations, why-not-type explanations, what-if explanations, how-to, but-for, counterfactual explanations, and what-else explanations.\n26. The system of claim 1, wherein the model output further comprises a justification corresponding to the answer and/or model explanation.\n27. The system of claim 1, wherein at least one of the plurality of interpreters is configured to receive the explanation scaffolding by a process comprising filtering, with a filter component, deconstructed explanation scaffolding data, selectively removing data from the deconstructed explanation scaffolding data based on a user profile, and outputting filtered explanation scaffolding data to at least one of the interpretation components; and\nwherein the filter component comprises an additional explainable model, or wherein the filter component is configured to apply a learnt function for performing a domain-specific optimization of the explainable model.\n28. The system of claim 1, wherein the explanations comprise one or more of: local explanations, global explanations, post-hoc explanations, ante-hoc explanations, group explanations, user specific explanations, and summary explanations.\n29. The system of claim 1, further comprising an identity-assess-resolve framework configured to identify one or more risks, scenarios, objectives, and/or goals, and assess a plurality of impacts, costs, and/or consequences of the identified risks, scenarios, objectives or goals, and recommend a ranked resolution and action plan; and a recommendation system configured to match one or more users and one or more items and provide an explanation of user behavior.\n30. The system of claim 19, wherein the semiotics component is further configured to implement a neuro-symbolic architecture and to assign a named label to one or more of: a component of the system, a neuron of the explainable model, or a summary of the explanation.",
    "status": "Active",
    "citations_own": [],
    "citations_ftf": [],
    "citedby_own": [],
    "citedby_ftf": []
}