{
    "patent_link": "https://patents.google.com/patent/US20090048482A1/en",
    "patent_id": "US20090048482A1",
    "title": "Image-based Path Planning for Automated Virtual Colonoscopy Navigation",
    "abstract": "A method for automatic virtual endoscopy navigation, including: (a) using a fisheye camera to generate an endoscopic image and a depth image from a current position of the camera in lumen computed tomographic (CT) data; (b) segmenting a first region and a second region from the depth image, wherein the first region identifies a view direction of the camera and the second region is an area through which the camera can be moved without touching an inner surface of the lumen; (c) moving the camera from the current position, while pointing the camera in the view direction, to a next position in the second region; and (d) repeating steps (a-c) in sequence using the next position in step (c) as the current position in step (a).",
    "inventors": [
        "Wei Hong",
        "Gianluca Paladini"
    ],
    "assignee": "Siemens Healthcare GmbH",
    "classifications": [],
    "claims": "\n1. A method for automatic virtual endoscopy navigation, comprising:\n(a) using a fisheye camera to generate an endoscopic image and a depth image from a current position of the camera in lumen computed tomographic (CT) data;\n(b) segmenting a first region and a second region from the depth image, wherein the first region identifies a view direction of the camera and the second region is an area through which the camera can be moved without touching an inner surface of the lumen;\n(c) moving the camera from the current position, while pointing the camera in the view direction, to a next position in the second region; and\n(d) repeating steps (a-c) in sequence using the next position in step (c) as the current position in step (a).\n2. The method of claim 1, further comprising:\ndisplaying the endoscopic image to visualize the movement of the camera.\n3. The method of claim 2, further comprising:\nidentifying a polyp in the lumen in the displayed image.\n4. The method of claim 1, wherein the fisheye camera has up to a 360 degree field of view.\n5. The method of claim 1, wherein the current position of the camera is initially a seed point that is placed in the lumen CT data by a medical practitioner.\n6. The method of claim 1, wherein the method steps for virtual endoscopy navigation are performed immediately after the lumen CT data is received from a CT scanner.\n7. The method of claim 1, wherein a region growing method is used to segment the second region and the segmented first region is used as a seed for the region growing.\n8. The method of claim 1, further comprising:\ncalculating a centroid of the first region and the second region, respectively,\nwherein when the camera is moved from the current position to the second position it is moved along a ray toward the centroid of the second region, while being pointed to the centroid of the first region.\n9. The method of claim 8, further comprising:\ncalculating a view up vector of the camera and restricting the view direction of the camera by the view up vector to smooth the virtual endoscopy navigation.\n10. The method of claim 8, wherein the next position is a point between the current position and a center of the segmented second region.\n11. The method of claim 10, wherein step (d) is performed when the camera is approaching the next position or when the camera reaches the next position.\n12. The method of claim 1, wherein the lumen is a colon.\n13. A system for automatic virtual endoscopy navigation, comprising:\na memory device for storing a program;\na processor in communication with the memory device, the processor operative with the program to:\n(a) use a fisheye camera to generate an endoscopic image and a depth image from a current position of the camera in lumen computed tomographic (CT) data;\n(b) segment a first region and a second region from the depth image, wherein the first region identifies a view direction of the camera and the second region is an area through which the camera can be moved without touching an inner surface of the lumen;\n(c) move the camera from the current position, while pointing the camera in the view direction, to a next position in the second region; and\n(d) repeat steps (a-c) in sequence using the next position in step (c) as the current position in step (a).\n14. The system of claim 13, wherein the processor is further operative with the program to:\ndisplay the endoscopic image to visualize the movement of the camera.\n15. The system of claim 14, wherein the processor is further operative with the program to:\nidentify a polyp in the lumen in the displayed image.\n16. The system of claim 13, wherein the fisheye camera has up to a 360 degree field of view.\n17. The system of claim 13, wherein the current position of the camera is initially a seed point that is placed in the lumen CT data by a medical practitioner.\n18. The system of claim 13, wherein the processor is further operative with the program to execute the virtual endoscopy navigation immediately after the lumen CT data is received from a CT scanner.\n19. The system of claim 13, wherein a region growing method is used to segment the second region and the segmented first region is used as a seed for the region growing.\n20. The system of claim 13, wherein the processor is further operative with the program to:\ncalculate a centroid of the first region and the second region, respectively,\nwherein when the camera is moved from the current position to the second position it is moved along a ray toward the centroid of the second region, while being pointed to the centroid of the first region.\n21. The system of claim 20, wherein the processor is further operative with the program to:\ncalculate a view up vector of the camera and restrict the view direction of the camera by the view up vector to smooth the virtual endoscopy navigation.\n22. The system of claim 20, wherein the next position is a point between the current position and a center of the segmented second region.\n23. The system of claim 22, wherein step (d) is performed when the camera is approaching the next position or when the camera reaches the next position.\n24. The system of claim 13, wherein the lumen is a colon.\n25. A computer readable medium tangibly embodying a program of instructions executable by a processor to perform method steps for automatic virtual endoscopy navigation, the method steps comprising:\n(a) using a fisheye camera to generate an endoscopic image and a depth image from a current position of the camera in lumen computed tomographic (CT) data;\n(b) segmenting a first region and a second region from the depth image, wherein the first region identifies a view direction of the camera and the second region is an area through which the camera can be moved without touching an inner surface of the lumen;\n(c) moving the camera from the current position, while pointing the camera in the view direction, to a next position in the second region; and\n(d) repeating steps (a-c) in sequence using the next position in step (c) as the current position in step (a).",
    "status": "Active",
    "citations_own": [
        "US20070276228A1",
        "US20080118117A1",
        "US20090063118A1"
    ],
    "citations_ftf": [
        "US6331116B1",
        "US7081088B2"
    ],
    "citedby_own": [
        "US20080175459A1",
        "WO2010125481A1",
        "US20110228997A1",
        "US20110242097A1",
        "US20120008860A1",
        "US8514269B2",
        "US8942917B2",
        "CN108778143A",
        "US10492668B2",
        "US11064954B2",
        "US11215711B2",
        "WO2022180753A1",
        "US11710309B2",
        "WO2023138619A1"
    ],
    "citedby_ftf": [
        "US8818060B2",
        "US9477302B2"
    ]
}