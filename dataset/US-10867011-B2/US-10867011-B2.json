{
    "patent_id": "US-10867011-B2",
    "title": "Medical image identification and interpretation ",
    "assignee": "Terarecon, Inc.",
    "publication_date": "2020-12-15",
    "patent_link": "https://patents.google.com/patent/US10867011B2/en",
    "inventors": [
        "Jeffrey L. Sorenson",
        "David W. MacCutcheon",
        "Tiecheng Zhao",
        "Gael Kuhn"
    ],
    "classifications": [
        "G16H30/20",
        "G16H10/60",
        "G16H30/40",
        "G06F19/321",
        "A61B5/0013",
        "A61B5/055",
        "A61B8/565",
        "G06N5/022",
        "G06N5/045",
        "G06T7/0012",
        "G16H15/00",
        "G16H50/20",
        "G16H50/70",
        "A61B2576/00",
        "G06T2207/10116"
    ],
    "abstract": "A plurality of image processing engines are hosted within an image processing system. Each image processing engine performs one or more image processing operations or clinical content processing operations on medical images and clinical content. A user interface allows a user to configure the plurality of image processing engines for a particular study of images. The user interface allows the user to configure the plurality of image processing engines in any one of the following configurations: a series configuration where the image processing engines operate in series so that an output from one image processing engine serves as input to a next image processing engine; a parallel configuration where each image processing engine in the plurality of image processing engines operates without input from any other image processing engine in the plurality of image processing engines; or a a hybrid configuration where a first subset of image processing engines operate in a series configuration, and a second subset of image processing engines operate in a parallel configuration.",
    "claims": "\n1. A medical image interpretation system, comprising:\nan image processing system;\na plurality of image processing engines, hosted by the image processing system, each image processing engine in the plurality of image processing engines performing one or more image processing operations or clinical content processing operations on medical images and clinical content;\na user interface that allows a user to configure the plurality of image processing engines for a particular study of images, the user interface allowing the user to configure the plurality of image processing engines in any one of the following configurations:\na series configuration where the image processing engines operate in series so that an output from one image processing engine serves as input to a next image processing engine,\na parallel configuration where each image processing engine in the plurality of image processing engines operates without input from any other image processing engine in the plurality of image processing engines,\na hybrid configuration where a first subset of image processing engines operate in a series configuration, and a second subset of image processing engines operate in a parallel configuration;\nwherein the image processing system has an output that outputs results generated by the plurality of image processing engines;\nwherein outputs from each image processing engine in the plurality of image processing engines are weighted, so that a supervisor engine of the plurality of image processing engines or the user can weight output of findings differently to affect the results from the output of the image processing system.\n2. A medical image interpretation system as in claim 1, wherein the image processing system is an image processing server.\n3. A medical image interpretation system as in claim 1, wherein each image processing engine in the plurality of image processing engines has a different function than other image processing engines in the plurality of image processing engines, wherein functionality of at least one of the image processing engines in the plurality of image processing engines is one of the following:\nan ability to identify a body par part shown within a medical image;\nan ability to segment a body part shown within a medical image;\nan ability to label anatomy shown within a medical image;\nan ability to detect a disease from information shown within a medical image;\nan ability to match findings with clinical information resources and recommendations to provide assistance and direction to a physician.\n4. A medical image interpretation system as in claim 1, wherein at least one image processing engine in the plurality of image processing engines is associated with a particular body part of a patient.\n5. A medical image interpretation system as in claim 1, wherein at least one image processing engine in the plurality of image processing engines detects findings, where a finding is at least one of the following:\na disease;\nan indication of an abnormality;\na feature within a medical image;\na detection of an object, a shape, or a texture within a medical image;\na measurement made from within a medical image.\n6. A medical image interpretation system as in claim 1, wherein each image processing engine in the plurality of image processing engines is within a software container with a defined set of inputs and outputs.\n7. A medical image interpretation system as in claim 1, wherein all image processing engines in the plurality of image processing engines utilize a standardized interface that allows an abstraction of inputs and outputs of each image processing engine to conform to a standard published schema as supported and updated for the medical image interpretation system.\n8. A medical image interpretation system as in claim 1, wherein a first image processing engine in the plurality of image processing engines runs an algorithm to detect findings that are included in a statistical interface accessible by the user.\n9. A medical image interpretation system as in claim 1, wherein at least one image processing engine in the plurality of image processing engines analyzes multiple studies with a similar modality to determine there is significant interval change between the multiple studies.\n10. A medical image interpretation system as in claim 1, wherein the image processing system includes a tracking module that tracks assignments and processes of the plurality of image processing engines.\n11. A medical image interpretation system as in claim 1, wherein each image processing engine in the plurality of image processing engines is able to invoke image processing tools to perform image processing operations.\n12. A method to perform interpretation of medical images, comprising:\nconfiguring, by a user, a plurality of image processing engines for a particular study of the images, the user configuring the plurality of image processing engines in one of the following configurations:\na series configuration where the image processing engines operate in series so that an output from one image processing engine serves as input to a next image processing engine,\na parallel configuration where each image processing engine in the plurality of image processing engines operates without input from any other image processing engine in the plurality of image processing engines,\na hybrid configuration where a first subset of image processing engines operate in a series configuration, and a second subset of image processing engines operate in a parallel configuration;\nperforming one or more image processing operations or clinical content processing operations on medical images and clinical content by each image processing engine in the plurality of plurality of image processing engines; and\nproviding results from the plurality of image processing engines that interpret the medical images;\nwherein outputs from each image processing engine in the plurality of image processing engines are weighted, so that a supervisor engine of the plurality of image processing engines or the user can weight output of findings differently to affect the results from the output of the image processing system.\n13. A method as in claim 12, wherein at least one image processing engine in the plurality of image processing engines invokes an image processing tools to perform an image processing operation.\n14. A method as in claim 12, wherein each image processing engine in the plurality of image processing engines has a different function than other image processing engines in the plurality of image processing engines, wherein functionality of at least one of the image processing engines in the plurality of image processing engines is one of the following:\nan ability to identify a body part shown within a medical image;\nan ability to segment a body part shown within a medical image;\nan ability to label anatomy shown within a medical image;\nan ability to detect a disease from information shown within a medical image;\nan ability to match findings with clinical information resources and recommendations to provide assistance and direction to a physician.\n15. A method as in claim 12, wherein at least one image processing engine in the plurality of image processing engines is associated with a particular body part of a patient.\n16. A method as in claim 12, wherein at least one image processing engine in the plurality of image processing engines detects findings, where a finding is at least one of the following:\na disease;\nan indication of an abnormality;\na feature within a medical image;\na detection of an object, a shape, or a texture within a medical image;\na measurement made from within a medical image.\n17. A method as in claim 12, wherein all image processing engines in the plurality of image processing engines utilize a standardized interface that allows an abstraction of inputs and outputs of each image processing engine to conform to a standard published schema.\n18. A method as in claim 12, additionally comprising:\ntracking assignments and processes of the plurality of image processing engines.",
    "status": "Active",
    "citations_own": [
        "US20030113038A1",
        "US20120197827A1",
        "US20130058524A1",
        "US20130338496A1",
        "US20140201126A1",
        "US20160307339A1",
        "US20160358333A1"
    ],
    "citations_ftf": [
        "US6785410B2",
        "US6700589B1",
        "WO2004057439A2",
        "US7660352B2",
        "US8099296B2",
        "US8145503B2",
        "US7590440B2",
        "US7747050B2",
        "WO2007099525A2",
        "US20080118130A1",
        "US7751604B2",
        "US8276049B2",
        "US20090103789A1",
        "WO2009073185A1",
        "US8370293B2",
        "US8165368B2",
        "WO2011120010A1",
        "US20140324469A1",
        "US10978184B2",
        "US10515631B2",
        "US9420017B2",
        "US20150331995A1",
        "US9754371B2",
        "US20160092446A1",
        "US9846938B2",
        "US10275877B2",
        "EP3347841A1",
        "US20170337329A1",
        "US10445462B2",
        "US20180144244A1"
    ],
    "citedby_own": [
        "US11620773B2",
        "US11640809B2",
        "US11669969B2",
        "US11701064B2",
        "US11810660B2"
    ],
    "citedby_ftf": [
        "US11244495B2",
        "US20200303047A1",
        "WO2015162037A1",
        "US11213220B2",
        "US20170083665A1",
        "WO2018006058A1",
        "US10445462B2",
        "US20180144244A1",
        "US20180233228A1",
        "DE102017203333A1",
        "JP6885896B2",
        "WO2018195501A2",
        "US10152571B1",
        "US11246550B2",
        "US20190021677A1",
        "US11194852B2",
        "EP3438869A1",
        "WO2019045144A1",
        "WO2019085985A1",
        "US10791082B2",
        "US10783634B2",
        "WO2019111512A1",
        "CN108305671B",
        "US11024025B2",
        "US10943201B2",
        "CN108806773B",
        "US20190392944A1",
        "EP3827442A4",
        "US11101029B2",
        "WO2020026033A2",
        "EP3815096A4",
        "US11158418B2",
        "JP7098498B2",
        "EP3637425A1",
        "WO2020075172A1",
        "US11769573B2",
        "US11449986B2",
        "JP7049974B2",
        "CN112969402A",
        "US10861178B2",
        "EP3706128A4",
        "KR102354396B1",
        "US10818386B2",
        "US11430563B2",
        "US10910098B2",
        "EP3667674A1",
        "US10963757B2",
        "JP7246912B2",
        "EP3680912B1",
        "WO2020159276A1",
        "US10997475B2",
        "WO2020172544A1",
        "US10949974B2",
        "US11200313B2",
        "US10977796B2",
        "US11521716B2",
        "US11423538B2",
        "CN113994435A",
        "EP3786978A1",
        "JP7113798B2",
        "EP4038622A4",
        "US11416360B2",
        "JP7355302B2",
        "CN112749593A",
        "EP3817006A1",
        "KR102470111B1",
        "US11526655B2",
        "CN112116615A",
        "US20210152327A1",
        "US20210174941A1",
        "US20210166805A1",
        "US11429808B2",
        "JP7349345B2",
        "CN111126409B",
        "US11497475B2",
        "KR20210102098A",
        "WO2021167124A1",
        "EP4111411A1",
        "CN111354444A",
        "KR102333726B1",
        "US20210298703A1",
        "US20210330285A1",
        "KR102263544B1",
        "KR102222932B1",
        "KR102405314B1",
        "KR102492463B1",
        "CN115735253A",
        "US11727559B2",
        "US20220079439A1",
        "EP3985679A1",
        "KR102457341B1",
        "KR102457340B1",
        "KR20220116928A",
        "CN112837789A",
        "WO2022197016A1",
        "EP4060609A1",
        "AU2022246663A1",
        "KR102517328B1",
        "WO2022214291A1",
        "US20220328164A1",
        "TWI768841B",
        "US20220338833A1",
        "WO2022229968A1",
        "CN113469981B",
        "WO2023147308A1",
        "CN114756542B"
    ]
}