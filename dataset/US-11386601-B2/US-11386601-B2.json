{
    "patent_id": "US-11386601-B2",
    "title": "Processing user selectable product images and facilitating visualization-assisted virtual dressing ",
    "assignee": "Zeekit Online Shopping Ltd.",
    "publication_date": "2022-07-12",
    "patent_link": "https://patents.google.com/patent/US11386601B2/en",
    "inventors": [
        "Alon Kristal",
        "Nir Appleboim",
        "Yael Wiesel",
        "Israel Harry Zimmerman"
    ],
    "classifications": [
        "G06T11/60",
        "G06Q30/0643",
        "G06F3/0482",
        "G06N20/00",
        "G06N20/20",
        "G06T2200/24",
        "G06T3/40"
    ],
    "abstract": "A technique for combining first and second images respectively depicting first and second subject matter to facilitate virtual presentation. The first image is processed to identify portions or regions of the first subject matter and determine an estimated depth location of each portion or region. A composite image is generated that depicts the second subject matter overlayed, inserted or otherwise combined with the first subject matter. One or more of the portions or regions of the first subject matter are added, removed, enhanced or modified in the composite image in order to generate a realistic appearance of the first subject matter combined with the second subject matter. The composite image is caused to be displayed as a virtual presentation.",
    "claims": "\n1. . A method for combining a first digital image and a second digital image respectively depicting a first subject matter and a second subject matter to facilitate a virtual presentation comprising:\nprocessing the first digital image, to identify portions of the first subject matter and a respective estimated depth location of each portion of the first subject matter;\nprocessing the second digital image by at least:\ninterpolating, via shape-estimation, shapes for hidden areas of the second subject matter not visible in the second digital image, wherein the shapes for the hidden areas compromise one or more regions obstructed by one or more objects in the second digital image; and\nfilling, via shape in-painting, the hidden areas of the second subject matter in the second digital image previously interpolated by the shape-estimation, wherein the shape in-painting fills in the one or more regions, as obstructed by the one or more objects, by using a color or texture near the one or more regions of the second digital image;\ngenerating a composite image that depicts the second subject matter (with the one or more regions filled in via the shape in-painting) overlaid, inserted, or otherwise combined with the first subject matter;\nadding, removing, enhancing, or modifying one or more of the portions of the first subject matter in the composite image to generate a realistic appearance of the first subject matter combined with the second subject matter; and\ncausing the composite image to be displayed as the virtual presentation.\n2. The method of claim 1, wherein processing the first digital image to identify the respective estimated depth location of each portion of the first subject matter comprises generating a volume map of the first subject matter indicating a respective three-dimensional volume or a respective distance or a respective depth of each portion of the first subject matter.\n3. The method of claim 1, wherein processing the first digital image to identify the respective estimated depth location of each portion of the first subject matter comprises creating a 3D estimation, a 3D volume, a 3D mesh extraction, or 3D surface coordinates of the first subject matter.\n4. The method of claim 1, further comprising identifying portions of the second digital image and adding, removing, enhancing or modifying one or more of the portions of the second subject matter in the composite image in order to generate the realistic appearance of the first subject matter combined with the second subject matter.\n5. The method of claim 1, further comprising processing the second subject matter to create a 3D estimation or a 3D volume of the second subject matter.\n6. The method of claim 1, wherein the first digital image and the second digital image each comprise one or more of a respective image, a respective video, a respective stereoscopic image, or a respective three-dimensional representation of the first subject matter or the second subject matter.\n7. The method of claim 1, wherein the composite image is caused to be displayed as the virtual presentation on a device selected from the group consisting of a smartphone, a tablet, a smart-watch, a magic mirror device, a laptop computer, a desktop computer, a device having an imager or camera, a vehicular device or unit, a gaming device, a gaming console, a wearable device, a Virtual Reality (VR) device or helmet or glasses or headgear, an Augmented Reality (AR) device or helmet or glasses or headgear, an Internet of Things (IoT) device or appliance, an Internet-connected device or appliance, and a wireless-connected device or appliance.\n8. A system, comprising:\none or more processors; and\none or more non-transitory computer-readable media storing computing instructions and configured to run on the one or more processors to perform operations for combining a first digital image and a second digital image respectively depicting a first subject matter and a second subject matter to facilitate a virtual presentation, the operations comprising:\nprocessing the first digital image, to identify portions of the first subject matter and respective estimated depth location of each portion of the first subject matter;\nprocessing the second digital image by at least:\ninterpolating, via shape-estimation, shapes for hidden areas of the second subject matter not visible in the second digital image, wherein the shapes for the hidden areas compromise one or more regions obstructed by one or more objects in the second digital image; and\nfilling, via shape in-painting, the hidden areas of the second subject matter in the second digital image previously interpolated by the shape-estimation, wherein the shape in-painting fills in the one or more regions, as obstructed, by the one or more objects by using a color or texture near the one or more regions of the second digital image;\ngenerating a composite image that depicts the second subject matter with the one or more regions filled in via the shape in-painting overlaid, inserted, or otherwise combined with the first subject matter;\nadding, removing, enhancing, or modifying one or more of the portions of the first subject matter in the composite image to generate a realistic appearance of the first subject matter combined with the second subject matter; and\ncausing the composite image to be displayed as the virtual presentation.\n9. The system of claim 8, wherein processing the first digital image to identify the respective estimated depth location of each portion of the first subject matter comprises generating a volume map of the first subject matter indicating a respective three-dimensional volume or a respective distance or a respective depth of the each portion of the first subject matter.\n10. The system of claim 8, wherein processing the first digital image to identify the respective estimated depth location of each portion of the first subject matter comprises creating a 3D estimation, a 3D volume, a 3D mesh extraction, or 3D surface coordinates of the first subject matter.\n11. The system of claim 8, wherein the operations further comprise:\nidentifying portions of the second digital image and adding, removing, enhancing or modifying one or more of the portions of the second subject matter in the composite image in order to generate the realistic appearance of the first subject matter combined with the second subject matter.\n12. The system of claim 8, wherein the operations further comprise:\nprocessing the second subject matter to create a 3D estimation or a 3D volume of the second subject matter.\n13. The system of claim 8, wherein the first digital image and the second digital image each comprise one or more of a respective image, a respective video, a respective stereoscopic image, or a respective three-dimensional representation of the first subject matter or the second subject matter.\n14. The system of claim 8, wherein the composite image is caused to be displayed as the virtual presentation on a device selected from the group consisting of a smartphone, a tablet, a smart-watch, a magic mirror device, a laptop computer, a desktop computer, a device having an imager or camera, a vehicular device or unit, a gaming device, a gaming console, a wearable device, a Virtual Reality (VR) device or helmet or glasses or headgear, an Augmented Reality (AR) device or helmet or glasses or headgear, an Internet of Things (IoT) device or appliance, an Internet-connected device or appliance, and a wireless-connected device or appliance.\n15. A computer program product, comprising:\none or more non-transitory computer-readable media storing computing instructions configured to run on one or more processors to perform operations for combining a first digital image and a second digital image respectively depicting a first subject matter and a second subject matter to facilitate a virtual presentation, the operations comprising:\nprocessing the first digital image, to identify portions of the first subject matter and a respective estimated depth location of each portion of the first subject matter;\nprocessing the second digital image by at least:\ninterpolating, via shape-estimation, shapes for hidden areas of the second subject matter not visible in the second digital image, wherein the shapes for the hidden areas compromise one or more regions obstructed by one or more objects in the second digital image; and\nfilling, via shape in-painting, the hidden areas of the second subject matter in the second digital image previously interpolated by the shape-estimation, wherein the shape in-painting fills in the one or more regions, as obstructed, by the one or more objects by using a color or texture near the one or more regions of the second digital image;\ngenerating a composite image that depicts the second subject matter with the one or more regions filled in via the shape in-painting overlaid, inserted, or otherwise combined with the first subject matter;\nadding, removing, enhancing, or modifying one or more of the portions of the first subject matter in the composite image to generate a realistic appearance of the first subject matter combined with the second subject matter; and\ncausing the composite image to be displayed as the virtual presentation.\n16. The computer program product of claim 15, wherein processing the first digital image to identify the respective estimated depth location of each portion of the first subject matter comprises generating a volume map of the first subject matter indicating a respective three-dimensional volume or a respective distance or a respective depth of the each portion of the first subject matter.\n17. The computer program product of claim 15, wherein processing the first digital image to identify the respective estimated depth location of each portion of the first subject matter comprises creating a 3D estimation, a 3D volume, a 3D mesh extraction, or 3D surface coordinates of the first subject matter.\n18. The computer program product of claim 15, wherein the operations further comprise:\nidentifying portions of the second digital image and adding, removing, enhancing or modifying one or more of the portions of the second subject matter in the composite image in order to generate the realistic appearance of the first subject matter combined with the second subject matter.\n19. The computer program product of claim 15, wherein the operations further comprise:\nprocessing the second subject matter to create a 3D estimation or a 3D volume of the second subject matter.\n20. The computer program product of claim 15, wherein the first digital image and the second digital image each comprise one or more of a respective image, a respective video, a respective stereoscopic image, or a respective three-dimensional representation of the first subject matter or the second subject matter, or other visual content.\n21. The computer program product of claim 15, wherein the composite image is caused to be displayed as the virtual presentation on a device selected from the group consisting of a smartphone, a tablet, a smart-watch, a magic mirror device, a laptop computer, a desktop computer, a device having an imager or camera, a vehicular device or unit, a gaming device, a gaming console, a wearable device, a Virtual Reality (VR) device or helmet or glasses or headgear, an Augmented Reality (AR) device or helmet or glasses or headgear, an Internet of Things (IoT) device or appliance, an Internet-connected device or appliance, and a wireless-connected device or appliance.",
    "status": "Active",
    "citations_own": [
        "US5960411A",
        "US6307568B1",
        "US20020126132A1",
        "US6556222B1",
        "US20090002397A1",
        "US20090300676A1",
        "US20100111370A1",
        "US20100201682A1",
        "US20110078055A1",
        "US20120306918A1",
        "US20130215116A1",
        "US20140176565A1",
        "US20140188670A1",
        "US20140226900A1",
        "US20140314313A1",
        "US20150279113A1",
        "US20150348273A1",
        "US9470911B2",
        "US10290136B2"
    ],
    "citations_ftf": [
        "JP5120926B2",
        "US9176748B2",
        "US10991067B2"
    ],
    "citedby_own": [
        "US20210035260A1"
    ],
    "citedby_ftf": [
        "US10262440B2",
        "US10290136B2",
        "US10528563B2",
        "KR102520627B1",
        "US20180232800A1",
        "US10282897B2",
        "CN110476178A",
        "US10621779B1",
        "US10304227B2",
        "US10949914B2",
        "US20190156390A1",
        "US11232511B1",
        "US10687573B2",
        "US20190272663A1",
        "US11315338B1",
        "US10552714B2",
        "US10321728B1",
        "US11386474B2",
        "USD917529S1",
        "US11244382B1",
        "US11210730B1",
        "US11321769B2",
        "CN112997218A",
        "US11645613B1",
        "US11423564B2",
        "CN111309220A",
        "CN109919740B",
        "US11341367B1",
        "US11676199B2",
        "KR20210020432A",
        "EP4022554A4",
        "US11223855B2",
        "US11250572B2",
        "US11475661B2",
        "US11557065B2",
        "CN111339918B",
        "US11474677B2",
        "US11669999B2",
        "CN111768264A",
        "US11100552B1",
        "US11587271B2",
        "CN112258660B",
        "CN113822175B"
    ]
}