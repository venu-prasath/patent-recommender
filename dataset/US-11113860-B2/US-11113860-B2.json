{
    "patent_id": "US-11113860-B2",
    "title": "Particle-based inverse kinematic rendering system ",
    "assignee": "Electronic Arts Inc.",
    "publication_date": "2021-09-07",
    "patent_link": "https://patents.google.com/patent/US11113860B2/en",
    "inventors": [
        "Paolo Rigiroli",
        "Hitoshi Nishimura"
    ],
    "classifications": [
        "A63F13/52",
        "A63F13/67",
        "G06N3/04",
        "G06N3/042",
        "G06N3/048",
        "G06N3/08",
        "G06T13/40",
        "A63F2300/6607",
        "G06N20/20",
        "G06N3/044",
        "G06N3/045",
        "G06N3/047",
        "G06N5/01",
        "G06N5/025",
        "G06N7/01",
        "G06T2210/56",
        "G06T2213/12"
    ],
    "abstract": "The present disclosure provides embodiments of a particle-based inverse kinematic analysis system. The inverse kinematic system can utilize a neural network, also referred to as a deep neural network, which utilizes machine learning processes in order to create poses that are more life-like and realistic. The system can generate prediction models using motion capture data. The motion capture data can be aggregated and analyzed in order to train the neural network. The neural network can determine rules and constraints that govern how joints and connectors of a character model move in order to create realistic motion of the character model within the game application.",
    "claims": "\n1. A system comprising:\nat least one data store comprising game application data and a plurality of prediction models associated with one or more virtual character models; and\na computing device in electronic communication with the data store and configured to execute a game application based in part on the game application data, the game application configured to:\ngenerate a virtual game environment;\ndetermine a first pose of a first virtual character model within the virtual game environment, the first virtual character model comprising a plurality of rigid bodies connected by a plurality of joints, each joint connected to at least one rigid body, wherein the first pose of the first virtual character model is a first arrangement of the plurality of rigid bodies and the plurality of joints of the first virtual character model;\nrender at least a portion of the first pose of the first virtual character model within a frame during runtime of the game application;\nreceive an instruction to change the first pose of the first virtual character model in response to a first movement of at least one joint of the first virtual character model during runtime of the game application;\ndetermine a second pose for the first virtual character model by:\ncalculating an estimated pose of the first virtual character model based at least in part on a first prediction model of the plurality of prediction models wherein the estimated pose is not output for rendering during runtime of the game application; and\nusing the estimated pose as an input to a second prediction model of the plurality of prediction models;\ncalculating the second pose of the first virtual character model based, at least in part, on an output of the second prediction model of the plurality of prediction models, wherein the estimated pose and the second pose are calculated in response to the first movement of the at least one joint of the first virtual character model, wherein the estimated pose is a pose distinct from the first post and the second pose; and\nrender at least a portion of the second pose of the first virtual character model within a frame during runtime of the game application.\n2. The system of claim 1, wherein the estimated pose and the second pose are calculated using inverse kinematic analysis.\n3. The system of claim 1, wherein each joint of the first virtual character model is associated with a defined set of constraints and rules governing movement of an associated joint of the first virtual character model within the virtual game environment.\n4. The system of claim 1, wherein the first prediction model is associated with at least a first subset of the plurality of joints of the first virtual character model and the second prediction model is associated with at least a second subset of the plurality of joints of the first virtual character model.\n5. The system of claim 4, wherein the game application is further configured to determine a position of each of the plurality of joints not included in the first subset based at least in part on a defined set of constraints and rules associated with each of the plurality of joints.\n6. The system of claim 4, wherein the first subset of the plurality of joints and the second subset of the plurality of joints are the same.\n7. The system of claim 1, wherein the first prediction model receives as an input at least a position of at least a first joint of the plurality of joints of the first virtual character model and outputs at least one position of a second joint of the plurality of joints.\n8. The system of claim 1, wherein each prediction model of the plurality of prediction models is associated with a different subset of joints of the first virtual character model.\n9. The system of claim 1, wherein the plurality of prediction models are machine learning models.\n10. The system of claim 1, wherein the first prediction model and the second prediction model are fully connected neural network models.\n11. A computer-implemented method comprising:\nas implemented by a user computing device configured with specific computer-executable instructions for executing a game application,\ngenerating a virtual game environment;\ndetermining a first pose of a first virtual character model within the virtual game environment, the first virtual character model comprising a plurality of rigid bodies connected by a plurality of joints, each joint connected to at least one rigid body, wherein the first pose of the first virtual character model is a first arrangement of the plurality of rigid bodies and the plurality of joints of the first virtual character model;\nrendering at least a portion of the first pose of the first virtual character model within a frame during runtime of the game application;\nreceiving an instruction to change the first pose of the first virtual character model in response to a first movement of at least one joint of the first virtual character model;\ndetermining a second pose for the first virtual character model by:\ncalculating an estimated pose of the first virtual character model based at least in part on a first prediction model of the plurality of prediction models wherein the estimated pose is not output for rendering during runtime of the game application; and\nusing the estimated pose as an input to a second prediction model of the plurality of prediction models;\ncalculating the second pose of the first virtual character model based, at least in part, on an output of the second prediction model of the plurality of prediction models, wherein the estimated pose and the second pose are calculated in response to the first movement of the at least one joint of the first virtual character model, wherein the estimated pose is a pose distinct from the first post and the second pose; and\nrendering at least a portion of the second pose of the first virtual character model within a frame during runtime of the game application.\n12. The method of claim 11, wherein each joint of the first virtual character model is associated with a defined set of constraints and rules governing movement of an associated joint of the first virtual character model within the virtual game environment.\n13. The method of claim 12 further comprising determining a position of a subset of the plurality of joints based at least in part on the defined set of constraints and rules associated with each of the joints.\n14. The method of claim 12 further comprising iteratively calculating the second pose using the second prediction model until a defined set of constraints are satisfied.\n15. The method of claim 11, wherein the first prediction model receives as an input at least a position of at least a first joint of the plurality of joints and outputs at least one position of a second joint of the plurality of joints.\n16. The method of claim 11, wherein the first prediction model is one of a plurality of prediction models used to generate the estimated pose, wherein each of the plurality of prediction models are associated with a different subset of joints of the plurality of joints.\n17. The method of claim 11, wherein the first prediction model is associated with at least a first subset of the plurality of joints of the first virtual character model and the second prediction model is associated with at least a second subset of the plurality of joints of the first virtual character model.\n18. A non-transitory computer-readable storage medium having stored thereon computer-executable instructions that, when executed, direct a computing system to perform a method comprising:\nexecuting a game application;\ngenerating a virtual game environment;\ndetermining a first pose of a first virtual character model within the virtual game environment, the first virtual character model comprising a plurality of rigid bodies connected by a plurality of joints, each joint connected to at least one rigid body, wherein the first pose of the first virtual character model is a first arrangement of the plurality of rigid bodies and the plurality of joints of the first virtual character model;\nrendering at least a portion of the first pose of the first virtual character model within a frame during runtime of the game application;\nreceiving an instruction to change the first pose of the first virtual character model in response to a first movement of at least one joint of the first virtual character model;\ndetermining a second pose for the first virtual character model by:\ncalculating an estimated pose of the first virtual character model based at least in part on a first prediction model of the plurality of prediction models, wherein the estimated pose is not output for rendering during runtime of the game application; and\nusing the estimated pose as an input to a second prediction model of the plurality of prediction models;\ncalculating the second pose of the first virtual character model based, at least in part, on an output of the second prediction model of the plurality of prediction models, wherein the estimated pose and the second pose are calculated in response to the first movement of the at least one joint of the first virtual character model, wherein the estimated pose is a pose distinct from the first post and the second pose;\nrendering at least a portion of the second pose of the first virtual character model within a frame during runtime of the game application.\n19. The non-transitory computer-readable storage medium of claim 18, wherein the computer-executable instructions further configure the computing system to perform determining a position of a subset of the plurality of joints based at least in part on a defined set of constraints and rules associated with each of the joints.\n20. The non-transitory computer-readable storage medium of claim 18, wherein the computer-executable instructions further configure the computing system to perform iteratively calculating the second pose using the second prediction model until a defined set of constraints are satisfied.",
    "status": "Active",
    "citations_own": [
        "US5274801A",
        "US5548798A",
        "US5982389A",
        "US5999195A",
        "US6064808A",
        "US6088040A",
        "US6253193B1",
        "US20020054054A1",
        "US20020089504A1",
        "US20020180739A1",
        "US20030038818A1",
        "US6556196B1",
        "US20040027352A1",
        "US20040227760A1",
        "US20040227761A1",
        "US20050237550A1",
        "US6961060B1",
        "US20060036514A1",
        "US7006090B2",
        "US20060149516A1",
        "US20060217945A1",
        "US20060262114A1",
        "US20070085851A1",
        "US20070097125A1",
        "US20080049015A1",
        "US20080111831A1",
        "US20080152218A1",
        "US7403202B1",
        "US7415152B2",
        "US20080268961A1",
        "US20080316202A1",
        "US20090066700A1",
        "US20090315839A1",
        "US20100134501A1",
        "US20100251185A1",
        "US20100277497A1",
        "US20110012903A1",
        "US20110074807A1",
        "US20110086702A1",
        "US7944449B2",
        "US20110119332A1",
        "US20110128292A1",
        "US20110164831A1",
        "US20110187731A1",
        "US20110269540A1",
        "US20110292055A1",
        "US8100770B2",
        "US8142282B2",
        "US20120083330A1",
        "US8154544B1",
        "US20120115580A1",
        "CN102509272A",
        "US8207971B1",
        "US20120220376A1",
        "US8267764B1",
        "US20120244941A1",
        "US8281281B1",
        "US20120303343A1",
        "US20120313931A1",
        "US20130050464A1",
        "US8395626B2",
        "US20130063555A1",
        "US8398476B1",
        "US8406528B1",
        "US20130120439A1",
        "US20130121618A1",
        "US20130222433A1",
        "US20130235045A1",
        "US8540560B2",
        "US20130263027A1",
        "US20130311885A1",
        "US20140002463A1",
        "CN103546736A",
        "US8648863B1",
        "US20140198106A1",
        "US20140198107A1",
        "US8860732B2",
        "US20140327694A1",
        "US8914251B2",
        "US20150113370A1",
        "US20150126277A1",
        "US20150187113A1",
        "US20150235351A1",
        "US9117134B1",
        "US20150243326A1",
        "US20150381925A1",
        "US20160026926A1",
        "US20160071470A1",
        "US9317954B2",
        "US20160217723A1",
        "US20160307369A1",
        "US20160314617A1",
        "US9483860B2",
        "US20160354693A1",
        "US9616329B2",
        "US9741146B1",
        "US20170301310A1",
        "US20170301316A1",
        "US9811716B2",
        "US9826898B1",
        "US9858700B2",
        "US9947123B1",
        "US20180122125A1",
        "US9990754B1",
        "US20180165864A1",
        "US10022628B1",
        "US20180211102A1",
        "US10096133B1",
        "US10118097B2",
        "US10198845B1",
        "US10388053B1",
        "US10403018B1",
        "US10535174B1",
        "US10726611B1",
        "US10755466B2",
        "US10792566B1",
        "US10860838B1",
        "US10878540B1",
        "US10902618B2"
    ],
    "citations_ftf": [],
    "citedby_own": [
        "US20200327418A1",
        "US11295479B2",
        "US11504625B2",
        "US11624815B1",
        "US11648480B2",
        "US11656686B2",
        "US11715453B2",
        "US11714492B2",
        "US11727790B2",
        "US11742870B2",
        "US11740018B2",
        "US11798176B2",
        "US11816267B2"
    ],
    "citedby_ftf": [
        "US10792566B1",
        "US10726611B1",
        "US10878540B1",
        "US10535174B1",
        "US10860838B1",
        "JP7069768B2",
        "US11276219B2",
        "JP2021529380A",
        "US10937173B2",
        "US10918941B2",
        "US11205319B2",
        "US11282253B2",
        "US11176723B2",
        "US11348297B2",
        "TWI789568B",
        "US11232621B2",
        "CN111714880B",
        "CN111638791B",
        "US11341703B2",
        "CN113327312B",
        "US11670030B2",
        "US11562523B1",
        "CN113781612A"
    ]
}