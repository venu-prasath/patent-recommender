{
    "patent_id": "US-11645541-B2",
    "title": "Machine learning model interpretation ",
    "assignee": "Adobe Inc.",
    "publication_date": "2023-05-09",
    "patent_link": "https://patents.google.com/patent/US11645541B2/en",
    "inventors": [
        "Piyush Gupta",
        "Nikaash Puri",
        "Balaji Krishnamurthy"
    ],
    "classifications": [
        "G06N3/086",
        "G06N3/08",
        "G06N20/00",
        "G06N3/126",
        "G06N5/045",
        "G06F16/353",
        "G06N20/20",
        "G06N5/01",
        "G06N5/025"
    ],
    "abstract": "A technique is disclosed for generating class level rules that globally explain the behavior of a machine learning model, such as a model that has been used to solve a classification problem. Each class level rule represents a logical conditional statement that, when the statement holds true for one or more instances of a particular class, predicts that the respective instances are members of the particular class. Collectively, these rules represent the pattern followed by the machine learning model. The techniques are model agnostic, and explain model behavior in a relatively easy to understand manner by outputting a set of logical rules that can be readily parsed. Although the techniques can be applied to any number of applications, in some embodiments, the techniques are suitable for interpreting models that perform the task of classification. Other machine learning model applications can equally benefit.",
    "claims": "\n1. A computer-implemented method of interpreting a machine learning model, the method comprising:\nreceiving, by a processor-based system, a set of training data and a set of output classes for classifying a plurality of instances of the set of training data, each instance representing at least one feature of the set of training data;\napplying, by the processor-based system, each instance and at least one perturbation of the respective instance to the machine learning model having a function that takes each instance and each perturbation of the respective instance to obtain, from an output of the machine learning model, a probability that each feature of the respective instance belongs to each of the output classes;\nclassifying, by the processor-based system, each instance into one of the output classes for which the probability that each feature of the respective instance belongs to the respective output class is highest;\nproducing, for each respective instance, a set of instance level conditions each representing a presence or absence of each feature of the respective instance in the output class where the instance is classified;\napplying, by the processor-based system, the instance level conditions for each of the corresponding instances to a genetic algorithm to produce a set of class level rules, each class level rule representing a logical conditional statement that predicts that the respective instances are members of a particular output class, wherein producing the set of class level rules further comprises calculating a fitness score for each class level rule based on (a) a harmonic mean of a precision of the respective class level rule and a coverage of the respective class level rule, (b) a rule length for the respective class level rule, and (c) a conflict metric that represents a degree to which two of the class level rules predict different classes for a single instance;\nfiltering the set of class level rules to produce a filtered set of class level rules by removing, from the set of class level rules, a redundant class level rule, wherein every instance correctly covered by the removed redundant class level rule is also correctly covered by a different class level rule in the filtered set of class level rules;\nselecting a subset of the filtered set of class level rules by applying each of a pair of the class level rules in the filtered set to a second level genetic algorithm that is configured to select the subset using the fitness score; and\nusing the subset to update the set of training data and retrain the machine learning model using the updated set of training data,\nwherein retraining the machine learning model further comprises adjusting a set of model hyper-parameters that define at least one of a number of hidden layers of the machine learning model or a number of nodes per hidden layer of the machine learning model.\n2. The method of claim 1, wherein at least one generation of the genetic algorithm is configured to produce the set of class level rules using the fitness score.\n3. The method of claim 1, further comprising sorting, by the processor-based system, the set of class level rules in descending order of the precision.\n4. The method of claim 1, wherein at least one of the features is a numerical feature, and wherein the method further comprises pre-processing, by the processor-based system, the set of training data to convert the numerical feature into a categorical feature using entropy based binning.\n5. The method of claim 1, wherein the subset of the filtered set of class level rules predict that at least a threshold percentage of the respective instances are members of the particular output class.\n6. The method of claim 1, further comprising selecting a class level rule having a greatest fitness score from the pair of the class level rules using the fitness score.\n7. The method of claim 1, wherein adjusting the set of model hyper-parameters comprises reducing the number of hidden layers of the machine learning model.\n8. A computer program product including one or more non-transitory computer readable mediums having instructions encoded thereon that when executed by one or more computer processors cause the one or more computer processors to perform a process for interpreting a machine learning model, the process including\nreceiving a set of training data and a set of output classes for classifying a plurality of instances of the set of training data, each instance representing at least one feature of the set of training data;\napplying each instance and at least one perturbation of the respective instance to the machine learning model having a function that takes each instance and each perturbation of the respective instance to obtain, from an output of the machine learning model, a probability that each feature of the respective instance belongs to each of the output classes;\nclassifying each instance into one of the output classes for which the probability that each feature of the respective instance belongs to the respective output class is highest;\nproducing, for each respective instance, a set of instance level conditions each representing a presence or absence of each feature of the respective instance in the output class where the instance is classified;\napplying the instance level conditions for each of the corresponding instances to a genetic algorithm to produce a set of class level rules, each class level rule representing a logical conditional statement that predicts that the respective instances are members of a particular output class, wherein producing the set of class level rules further comprises calculating a fitness score for each class level rule based on (a) a harmonic mean of a precision of the respective class level rule and a coverage of the respective class level rule, (b) a rule length for the respective class level rule, and (c) a conflict metric that represents a degree to which two of the class level rules predict different classes for a single instance;\nfiltering the set of class level rules to produce a filtered set of class level rules by removing, from the set of class level rules, a redundant class level rule, wherein every instance correctly covered by the removed redundant class level rule is also correctly covered by a different class level rule in the filtered set of class level rules;\nselecting a subset of the filtered set of class level rules by applying each of a pair of the class level rules in the filtered set to a second level genetic algorithm that is configured to select the subset using the fitness score; and\nusing the subset to update the set of training data and retrain the machine learning model using the updated set of training data,\nwherein retraining the machine learning model further comprises adjusting a set of model hyper-parameters that define at least one of a number of hidden layers of the machine learning model or a number of nodes per hidden layer of the machine learning model.\n9. The computer program product of claim 8, wherein at least one generation of the genetic algorithm is configured to produce the set of class level rules using the fitness score.\n10. The computer program product of claim 8, wherein the process includes sorting the set of class level rules in descending order of the precision.\n11. The computer program product of claim 8, wherein at least one of the features is a numerical feature, and wherein the process includes pre-processing the set of training data to convert the numerical feature into a categorical feature using entropy based binning.\n12. The computer program product of claim 8, wherein the subset of the filtered set of class level rules predict that at least a threshold percentage of the respective instances are members of the particular output class.\n13. The computer program product of claim 8, wherein the process includes selecting a class level rule having a greatest fitness score from the pair of the class level rules using the fitness score.\n14. The computer program product of claim 8, wherein adjusting the set of model hyper-parameters comprises reducing the number of hidden layers of the machine learning model.\n15. A system for interpreting a machine learning model, the system comprising:\none or more storages; and\none or more processors operatively coupled to the one or more storages, the one or more processors configured to execute instructions stored in the one or more storages that when executed cause the one or more processors to carry out a process including\nreceive a set of training data and a set of output classes for classifying a plurality of instances of the set of training data, each instance representing at least one feature of the set of training data;\napply each instance and at least one perturbation of the respective instance to the machine learning model having a function that takes each instance and each perturbation of the respective instance to obtain, from an output of the machine learning model, a probability that each feature of the respective instance belongs to each of the output classes;\nclassify each instance into one of the output classes for which the probability that each feature of the respective instance belongs to the respective output class is highest;\nproduce, for each respective instance, a set of instance level conditions each representing a presence or absence of each feature of the respective instance in the output class where the instance is classified;\napply the instance level conditions for each of the corresponding instances to a genetic algorithm to produce a set of class level rules, each class level rule representing a logical conditional statement that predicts that the respective instances are members of a particular output class, wherein producing the set of class level rules further comprises calculating a fitness score for each class level rule based on (a) a harmonic mean of a precision of the respective class level rule and a coverage of the respective class level rule, (b) a rule length for the respective class level rule, and (c) a conflict metric that represents a degree to which two of the class level rules predict different classes for a single instance;\nfilter the set of class level rules to produce a filtered set of class level rules by removing, from the set of class level rules, a redundant class level rule, wherein every instance correctly covered by the removed redundant class level rule is also correctly covered by a different class level rule in the filtered set of class level rules;\nselect a subset of the filtered set of class level rules by applying each of a pair of the class level rules in the filtered set to a second level genetic algorithm that is configured to select the subset using the fitness score; and\nuse the subset to update the set of training data and retrain the machine learning model using the updated set of training data,\nwherein retraining the machine learning model further comprises adjusting a set of model hyper-parameters that define at least one of a number of hidden layers of the machine learning model or a number of nodes per hidden layer of the machine learning model.\n16. The system of claim 15, wherein at least one generation of the genetic algorithm is configured to produce the set of class level rules using the fitness score.\n17. The system of claim 15, the process further comprising: sort the set of class level rules in descending order of the precision.\n18. The system of claim 15, wherein at least one of the features is a numerical feature, the process further comprising: pre-process the set of training data to convert the numerical feature into a categorical feature using entropy based binning.\n19. The system of claim 15, wherein the subset of the filtered set of class level rules that predict that at least a threshold percentage of the respective instances are members of the particular output class.\n20. The system of claim 15, wherein adjusting the set of model hyper-parameters comprises reducing the number of hidden layers of the machine learning model.",
    "status": "Active",
    "citations_own": [
        "US20060059112A1",
        "US20120089620A1",
        "US20170293849A1",
        "US10824959B1"
    ],
    "citations_ftf": [],
    "citedby_own": [],
    "citedby_ftf": [
        "US11238409B2",
        "US11032149B2",
        "US11386342B2",
        "CN108615071B",
        "US11467803B2",
        "US11367034B2",
        "US11550970B2",
        "CN110729052A",
        "US20210081790A1",
        "US20210089949A1",
        "WO2021072556A1",
        "US11049043B2",
        "US11507840B2",
        "US11055616B2",
        "US11727284B2",
        "US20210192376A1",
        "US11507884B2",
        "US20210232940A1",
        "CN111340102B",
        "US11580455B2",
        "CN111914567A",
        "CN114595823A",
        "TWI774324B",
        "TWI808895B",
        "WO2023028996A1"
    ]
}