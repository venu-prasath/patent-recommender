{
    "patent_id": "US-11645833-B2",
    "title": "Generative adversarial network medical image generation for training of a classifier ",
    "assignee": "Merative Us L.P.",
    "publication_date": "2023-05-09",
    "patent_link": "https://patents.google.com/patent/US11645833B2/en",
    "inventors": [
        "Ali Madani",
        "Mehdi Moradi",
        "Tanveer F. Syeda-Mahmood"
    ],
    "classifications": [
        "G06K9/6259",
        "G06V10/82",
        "A61B6/5217",
        "G06F18/2155",
        "G06F18/24",
        "G06K9/6267",
        "G06N20/00",
        "G06N3/045",
        "G06N3/0454",
        "G06N3/047",
        "G06N3/0472",
        "G06N3/048",
        "G06N3/0481",
        "G06N3/082",
        "G06N5/022",
        "G06T7/0012",
        "G06T7/0014",
        "G06V10/764",
        "G06V10/7753",
        "G16H30/20",
        "G16H30/40",
        "G16H50/20",
        "G06T2207/10116",
        "G06T2207/20081",
        "G06T2207/20084",
        "G06T2207/30048",
        "G06T2207/30096",
        "G06V2201/03"
    ],
    "abstract": "Mechanisms are provided to implement a machine learning training model. The machine learning training model trains an image generator of a generative adversarial network (GAN) to generate medical images approximating actual medical images. The machine learning training model augments a set of training medical images to include one or more generated medical images generated by the image generator of the GAN. The machine learning training model trains a machine learning model based on the augmented set of training medical images to identify anomalies in medical images. The trained machine learning model is applied to new medical image inputs to classify the medical images as having an anomaly or not.",
    "claims": "\n1. A method, in a data processing system comprising a processor and a memory, the memory comprising instructions that are executed by the processor to configure the processor to implement a machine learning training model, the method comprising:\ntraining, by the machine learning training model, a machine learning model based on a set of training medical images to identify anomalies in medical images; and\napplying the trained machine learning model to new medical image inputs to classify the medical images as having an anomaly or not, wherein training the machine learning model comprises training a discriminator of a generative adversarial network (GAN) based on training data, input to the discriminator comprising actual labeled medical image data, actual unlabeled medical image data, and generated medical image data generated by an image generator of the GAN.\n2. The method of claim 1, further comprising training an image generator of the GAN to generate medical images approximating actual medical images, at least by:\nreceiving, by the image generator of the GAN, at least one medical image showing an anatomical structure;\ninputting, by a noise generator, a noise input to the image generator;\ngenerating, by the image generator, at least one generated image based on a combination of the at least one medical image and the noise input;\nproviding the at least one medical image and the at least one generated image to the discriminator of the machine learning training image;\nanalyzing, by the discriminator, the at least one medical image and the at least one generated image to label the at least one medical image and the at least one generated image as either being an actual medical image or a generated medical image; and\nmodifying an operational parameter of the generator based on the results of analyzing the at least one medical image and the at least one generated image by the discriminator.\n3. The method of claim 1, wherein the GAN is trained to classify medical images with regard to whether or not the medical images contain an abnormality.\n4. The method of claim 1, wherein the discriminator is trained, using an adversarial training technique based on the set of training medical images, to discriminate between medical images showing anomalies and medical images showing normal medical conditions.\n5. The method of claim 1, wherein training the image generator comprises training the image generator based on both labeled training medical images and non-labeled medical images, and wherein the training is based on a feedback obtained from an output of the discriminator.\n6. The method of claim 1, wherein the generated medical image data is generated by the image generator of the GAN based on input noise, and wherein training, by the machine learning training model, the image generator to generate medical images approximating actual medical images comprises:\ntraining the discriminator of the GAN to separately classify generated medical images from actual medical images and separately classifying actual medical images showing a normal medical condition from actual medical images showing an abnormal medical condition; and\ntraining the image generator to generate medical images that cause the discriminator to fail to correctly separately classify the generated medical images from actual medical images for a predetermined ratio of instances indicating convergence of the training of the GAN.\n7. The method of claim 1, wherein the discriminator of the GAN is a convolutional neural network with K+1 output nodes, where K is a number of classes of abnormalities that the machine learning model is configured to identify in input medical images and the K+1 class is a class indicating an input medical image to be a generated medical image from the image generator, and wherein the discriminator outputs, for each input medical image, a corresponding vector output having K+1 values indicating into which class the discriminator classifies the input medical image.\n8. The method of claim 1, wherein the discriminator is a convolutional neural network with 2K output nodes, where K is a number of classes of abnormalities that the machine learning model is configured to identify in input medical images and for each class in the K number of classes, there is a separate output node indicating whether the input medical image is a generated medical image from the image generator, or an actual medical image, and wherein the discriminator outputs, for each input medical image, a corresponding vector output having 2K values indicating into which class the discriminator classifies the input medical image.\n9. The method of claim 1, further comprising:\nconfiguring a loss function of a discriminator of the GAN to include error components for each of actual labeled medical images, actual unlabeled medical images, and generated medical images, wherein training the image generator of the GAN to generate medical images approximating actual medical images comprises minimizing the loss function of the discriminator.\n10. The method of claim 1, wherein the generator is one of a plurality of generators, and wherein at least one generator in the plurality of generators is trained to generate medical images approximating actual medical images having a normal medical condition depicted, and wherein at least one other generator in the plurality of generators is trained to generate medical images approximating actual medical images having an abnormal medical condition depicted.\n11. The method of claim 1, wherein the discriminator generates a classification output that classifies input image data into one of a plurality of classifications, the plurality of classifications comprising a first classification for real-normal image data indicating the input image data to be actual image data representing a normal medical condition, at least one second classification for real-abnormal image data indicating the input image data to be actual image data representing a corresponding abnormal medical condition, and a third classification for generated image data indicating the input image data to be image data generated by the image generator.\n12. A computer program product comprising a computer readable storage medium having a computer readable program stored therein, wherein the computer readable program, when executed on a data processing system, causes the data processing system to implement a machine learning training model that operates to:\ntrain a machine learning model based on a set of training medical images to identify anomalies in medical images; and\napply the trained machine learning model to new medical image inputs to classify the medical images as having an anomaly or not, wherein training the machine learning model comprises training a discriminator of a generative adversarial network (GAN) based on training data, input to the discriminator comprising actual labeled medical image data, actual unlabeled medical image data, and generated medical image data generated by an image generator of the GAN.\n13. The computer program product of claim 12, wherein the computer readable program further causes the machine learning training model to train by the machine learning training model, an image generator of the GAN to generate medical images approximating actual medical images, at least by:\nreceiving, by the image generator of the GAN, at least one medical image showing an anatomical structure;\ninputting, by a noise generator, a noise input to the image generator;\ngenerating, by the image generator, at least one generated image based on a combination of the at least one medical image and the noise input;\nproviding the at least one medical image and the at least one generated image to the discriminator of the machine learning training image;\nanalyzing, by the discriminator, the at least one medical image and the at least one generated image to label the at least one medical image and the at least one generated image as either being an actual medical image or a generated medical image; and\nmodifying an operational parameter of the generator based on the results of analyzing the at least one medical image and the at least one generated image by the discriminator.\n14. The computer program product of claim 12, wherein the is a discriminator is trained, using an adversarial training technique based on the set of training medical images, to discriminate between medical images showing anomalies and medical images showing normal medical conditions.\n15. The computer program product of claim 12, wherein the computer readable program further causes the machine learning training model to train the image generator at least by training the image generator based on both labeled training medical images and non-labeled medical images, and wherein the training is based on a feedback obtained from an output of the discriminator.\n16. The computer program product of claim 12, wherein the generated medical image data is generated by the image generator of the GAN based on input noise, and wherein the computer readable program further causes the machine learning training model to train the image generator to generate medical images approximating actual medical images at least by:\ntraining the discriminator of the GAN to separately classify generated medical images from actual medical images and separately classifying actual medical images showing a normal medical condition from actual medical images showing an abnormal medical condition; and\ntraining the image generator to generate medical images that cause the discriminator to fail to correctly separately classify the generated medical images from actual medical images for a predetermined ratio of instances indicating convergence of the training of the GAN.\n17. The computer program product of claim 12, wherein the discriminator of the GAN is a convolutional neural network with K+1 output nodes, where K is a number of classes of abnormalities that the machine learning model is configured to identify in input medical images and the K+1 class is a class indicating an input medical image to be a generated medical image from the image generator, and wherein the discriminator outputs, for each input medical image, a corresponding vector output having K+1 values indicating into which class the discriminator classifies the input medical image.\n18. The computer program product of claim 12, wherein the discriminator is a convolutional neural network with 2K output nodes, where K is a number of classes of abnormalities that the machine learning model is configured to identify in input medical images and for each class in the K number of classes, there is a separate output node indicating whether the input medical image is a generated medical image from the image generator, or an actual medical image, and wherein the machine learning model discriminator outputs, for each input medical image, a corresponding vector output having 2K values indicating into which class the machine learning model discriminator classifies the input medical image.\n19. The computer program product of claim 12, wherein the computer readable program further causes the machine learning training model to:\nconfigure a loss function of a discriminator of the GAN to include error components for each of actual labeled medical images, actual unlabeled medical images, and generated medical images, wherein training the image generator of the GAN to generate medical images approximating actual medical images comprises minimizing the loss function of the discriminator.\n20. An apparatus comprising:\nat least one processor; and\nat least one memory coupled to the at least one processor, wherein the at least one memory comprises instructions which, when executed by the at least one processor, cause the at least one processor to implement a machine learning training model that operates to:\ntrain a machine learning model based on a set of training medical images to identify anomalies in medical images; and\napply the trained machine learning model to new medical image inputs to classify the medical images as having an anomaly or not, wherein training the machine learning model comprises training a discriminator of the GAN based on training data, input to the discriminator, comprising actual labeled medical image data, actual unlabeled medical image data, and generated medical image data generated by the image generator of the GAN.",
    "status": "Active",
    "citations_own": [
        "US20150011401A1",
        "US20160341731A1",
        "US20170337682A1",
        "US20180075581A1",
        "US9922285B1",
        "US20180082150A1",
        "US9971958B2",
        "US20180211164A1",
        "US10055551B2",
        "US10068557B1",
        "US20180336471A1",
        "US20180336439A1",
        "US20190005131A1",
        "US10176405B1",
        "US20190080205A1",
        "US10242665B1",
        "US20190147296A1",
        "US20190198156A1",
        "US20190197368A1",
        "US20190197358A1",
        "US20190325621A1",
        "US20200085382A1"
    ],
    "citations_ftf": [
        "KR102051891B1"
    ],
    "citedby_own": [
        "US20210312242A1",
        "US20230196651A1"
    ],
    "citedby_ftf": [
        "KR102403494B1",
        "US10706534B2",
        "US10679129B2",
        "US10937540B2",
        "US10592779B2",
        "US11007040B2",
        "WO2019180868A1",
        "JP7023162B2",
        "US11100632B2",
        "US11501438B2",
        "KR102184755B1",
        "US20210249142A1",
        "WO2019237240A1",
        "US11100633B2",
        "US11074592B2",
        "EP3827442A4",
        "EP3608701A1",
        "US10825149B2",
        "EP3843627A4",
        "US20200074707A1",
        "DE102019123455A1",
        "US10915792B2",
        "US10796181B2",
        "JP7129869B2",
        "EP3864586A4",
        "WO2020086867A1",
        "US10818386B2",
        "US10930386B2",
        "US11049239B2",
        "US11475247B2",
        "US11252169B2",
        "US11423538B2",
        "US11195277B2",
        "US11068753B2",
        "CN110414362A",
        "CN110309917B",
        "DE102019210545A1",
        "US11106943B2",
        "WO2021020339A1",
        "US11551357B2",
        "US11435719B2",
        "US20210097372A1",
        "US11538576B2",
        "JP2021069793A",
        "US11068752B2",
        "CN110827265B",
        "CN110830490B",
        "CN110992315A",
        "US11019087B1",
        "CN110929786B",
        "US11158090B2",
        "CN111105032B",
        "CN110895828B",
        "EP3836022A1",
        "CN111126226B",
        "CN111192343B",
        "CN111126574B",
        "US11429812B2",
        "EP4104114A4",
        "CN111340725A",
        "WO2021169292A1",
        "CN111368912A",
        "CN111388000B",
        "US11068750B1",
        "CN111353995B",
        "US11593814B2",
        "US10922788B1",
        "CN111639676B",
        "US11379991B2",
        "US20210383174A1",
        "CN111709408B",
        "CN112215868A",
        "US20220084204A1",
        "CN112163991A",
        "US20230335222A1",
        "CN112151153A",
        "US11720650B2",
        "WO2022094911A1",
        "CN112529154A",
        "AU2021396186A1",
        "CN112508835A",
        "CN112800852A",
        "US11550991B2",
        "DE102021205273A1",
        "CN113505876A",
        "CN113421212B",
        "CN113470448A",
        "CN113627498A",
        "CN113627503B",
        "WO2023014789A1",
        "CN113628057B",
        "WO2023043810A1",
        "CN113886226B",
        "CN114332269B",
        "CN113902752B",
        "CN114387264B",
        "DE202022100604U1",
        "EP4239576A1",
        "CN115393242A"
    ]
}