{
    "patent_id": "US-11574470-B2",
    "title": "Suggested actions for images ",
    "assignee": "Google Llc",
    "publication_date": "2023-02-07",
    "patent_link": "https://patents.google.com/patent/US11574470B2/en",
    "inventors": [
        "Juan Carlos ANORGA",
        "David Lieb",
        "Madhur Khandelwal",
        "Evan Millar",
        "Timothy NOVIKOFF",
        "Mugdha Kulkarni",
        "Leslie Ikemoto",
        "Jorge Verdu",
        "Jingyu Cui",
        "Sharadh Ramaswamy",
        "Raja Ratna Murthy Ayyagari",
        "Marc Cannon",
        "Alexander Roe",
        "Shaun Tungseth",
        "Songbo Jin",
        "Matthew Bridges",
        "Ruirui Jiang",
        "Jeremy Selier",
        "Austin Suszek",
        "Gang Song"
    ],
    "classifications": [
        "G06F3/048",
        "G06F16/50",
        "G06F16/51",
        "G06F16/5838",
        "G06F16/5846",
        "G06F18/24",
        "G06K9/6267",
        "G06N20/00",
        "G06N3/044",
        "G06N3/0445",
        "G06N3/045",
        "G06N3/0454",
        "G06V20/20",
        "G06V20/30",
        "G06V20/35",
        "G06V20/70",
        "G06V30/40",
        "G06V30/413",
        "G06F16/54",
        "G06F16/583",
        "G06N20/10",
        "G06N7/005",
        "G06N7/01",
        "G06V10/10"
    ],
    "abstract": "Implementations relate to causing a command to be executed based on an image. In some implementations, a computer-implemented method includes obtaining and programmatically analyzing an image to determine suggested actions. The method causes a user interface to be displayed that includes user interface elements corresponding to default actions, and to suggested actions that are determined based on analyzing the image. The method receives user input indicative of selection of a particular action from the default actions and the suggested actions. The method causes a command to be executed by a computing device for the particular action that was selected.",
    "claims": "\n1. A method comprising:\nobtaining an image;\nprogrammatically analyzing the image including determining one or more categories for the image, wherein programmatically analyzing the image comprises:\ndetermining an image feature in the image; and\napplying a classifier to the image to determine the one or more categories for the image based on a prominence of the image feature in the image, wherein the prominence of the image feature is based on at least one of:\na size of the image feature with respect to an area of the image, or\na location of the image feature in the image with respect to borders of the image;\ndetermining one or more suggested actions for the image based on at least one category of the one or more categories, wherein each of the one or more suggested actions is associated with a respective command executable by one or more processors of a device;\ncausing a user interface to be displayed that includes the image and one or more user interface elements each corresponding to a respective suggested action of the one or more suggested actions;\nreceiving user input indicative of selection of a particular action from the one or more suggested actions; and\nin response to the user input, causing the command associated with the particular action to be executed by the one or more processors of the device.\n2. The method of claim 1, wherein applying the classifier includes determining that the one or more categories for the image are one or more categories of the image feature in response to the size of the image feature being greater than a threshold percentage of the area of the image.\n3. The method of claim 1, wherein applying the classifier includes determining that the one or more categories for the image are one or more categories of the image feature in response to the image feature having a location in the image within a threshold distance of a center of the image.\n4. The method of claim 1, wherein programmatically analyzing the image comprises identifying at least two distinct portions of the image, and wherein the one or more suggested actions include at least two respective suggested actions that are each associated with a respective portion of the at least two distinct portions.\n5. The method of claim 1, wherein programmatically analyzing the image comprises determining a parameter for the command based on at least one of: image data that includes values of a plurality of pixels of the image, or image metadata, wherein the command is associated with a software application, and wherein causing the command to be executed includes invoking the software application with the parameter.\n6. The method of claim 1, wherein the one or more suggested actions include at least one suggested action, and further comprising checking that the at least one suggested action is determined within a threshold time period after obtaining the image, wherein causing the user interface to be displayed includes causing the user interface to be displayed within the threshold time period after obtaining the image, wherein the user interface includes a particular user interface element that corresponds to the at least one suggested action.\n7. The method of claim 6, wherein causing the user interface to be displayed further comprises causing one or more additional user interface elements to be added to the user interface after the threshold time period, each of the one or more additional user interface elements corresponding to a respective suggested action of one or more additional suggested actions of the one or more suggested actions.\n8. The method of claim 1, wherein obtaining the image comprises detecting that the image has been captured based on at least one of:\ndetecting activation of a camera, the method being performed by an application different from a camera application displaying the user interface, or\nreceiving a notification from an operating system that the image has been written to a local memory.\n9. The method of claim 1, wherein:\nobtaining the image includes at least one of: obtaining the image from an image capture device or obtaining the image over a network, and\ncausing the user interface to be displayed includes causing the user interface to be displayed within a threshold time period after obtaining the image.\n10. The method of claim 1, further comprising determining an amount of prior selections of prior suggested actions by a user, wherein determining the one or more suggested actions is based, at least in part, on the amount of prior selections by the user.\n11. The method of claim 1, wherein programmatically analyzing the image comprises:\napplying a local classifier to the image to determine a local classification result for the image that classifies content of the image;\ndetermining whether server classification is to be utilized, wherein determination that the server classification is to be utilized is based on at least one of: the local classification result indicating no category for the image, or the local classification result providing a confidence score for at least one of the one or more categories that does not meet a confidence score threshold;\nin response to determining that the server classification is not to be utilized, determining the one or more categories and the one or more suggested actions based on the local classification result; and\nin response to determining that the server classification is to be utilized:\nsending a representation of the image to a server, and\nreceiving a response from the server, wherein the response includes at least one of the one or more suggested actions.\n12. The method of claim 11 wherein, in response to determining that the server classification is to be utilized, additionally sending a response time threshold to the server that specifies an amount of time after sending the representation of the image to the server, wherein the response from the server is to be received within the amount of time specified by the response time threshold, and further comprising:\ndetermining whether the response from the server is received within the amount of time specified by the response time threshold,\nwherein determining whether the server classification is to be utilized includes determining that the server classification is to be utilized in response to the response from the server being received within the amount of time specified by the response time threshold.\n13. The method of claim 1, wherein programmatically analyzing the image comprises:\napplying a local classifier to the image to determine a local classification result for the image that classifies content of the image;\ndetermining whether server classification is to be utilized, wherein determination that the server classification is to be utilized is based on at least one of: the local classification result indicating no category for the image, or the local classification result providing a confidence score for at least one of the one or more categories that does not meet a confidence score threshold;\nin response to determining that the server classification is not to be utilized, determining the one or more suggested actions based on the local classification result; and\nin response to determining that the server classification is to be utilized:\nsending a representation of the image to a server to perform the server classification;\nreceiving a response from the server, wherein the response includes a server classification result; and\ndetermining at least one of the one or more suggested actions based on the server classification result.\n14. A system comprising:\none or more hardware processors; and\na storage device coupled to the one or more hardware processors, with instructions stored thereon that, when executed by the one or more hardware processors, cause the one or more hardware processors to perform operations comprising:\nobtaining an image;\nprogrammatically analyzing the image including determining one or more categories for the image, wherein programmatically analyzing the image comprises:\ndetermining an image feature in the image; and\napplying a classifier to the image to determine the one or more categories for the image based on a prominence of the image feature in the image, wherein the prominence of the image feature is based on at least one of:\na size of the image feature with respect to an area of the image, or\na location of the image feature in the image with respect to borders of the image;\ndetermining one or more suggested actions for the image based on at least one category of the one or more categories, wherein each of the one or more suggested actions is associated with a respective command executable by the one or more hardware processors;\ncausing a user interface to be displayed that includes the image and one or more user interface elements each corresponding to a respective suggested action of the one or more suggested actions;\nreceiving user input indicative of selection of a particular action from the one or more suggested actions; and\nin response to the user input, causing the command for associated with the particular action to be executed by the one or more hardware processors.\n15. The system of claim 14, wherein the operation of applying the classifier based on the prominence of the image feature includes determining that the one or more categories for the image are one or more categories of the image feature in response to at least one of:\nthe size of the image feature being greater than a threshold percentage of the area of the image; or\nthe image feature having a location in the image within a threshold distance of a center of the image.\n16. The system of claim 14, wherein the operations further comprise:\nstoring metadata of the image in the storage device, the metadata indicating the one or more categories for the image;\nreceiving second user input indicative of selection of a particular category of the one or more categories; and\nin response to receiving the second user input:\nidentifying in the storage device the image based on the metadata indicating the one or more categories corresponding to the particular category, and causing the image to be displayed.\n17. The system of claim 14, wherein the operation of programmatically analyzing the image comprises:\napplying a local classifier to the image to determine a local classification result for the image that classifies content of the image;\ndetermining whether server classification is to be utilized, wherein determination that the server classification is to be utilized is based on at least one of: the local classification result indicating no category for the image, or the local classification result providing a confidence score for at least one of the one or more categories that do not meet a confidence score threshold;\nin response to determining that the server classification is not to be utilized, determining the one or more suggested actions based on the local classification result; and\nin response to determining that the server classification is to be utilized:\nsending a representation of the image to a server to perform the server classification, wherein the representation includes an image thumbnail that has a smaller data size than the image; and\nreceiving a response from the server, wherein the response includes at least one of the one or more suggested actions.\n18. A non-transitory computer readable medium with instructions stored thereon that, when executed by a processor, cause the processor to perform operations comprising:\nobtaining an image;\nprogrammatically analyzing the image including determining one or more categories for the image, wherein programmatically analyzing the image comprises:\ndetermining an image feature in the image; and\napplying a classifier to the image to determine the one or more categories for the image based on a prominence of the image feature in the image, wherein the prominence of the image feature is based on at least one of:\na size of the image feature with respect to an area of the image, or\na location of the image feature in the image with respect to borders of the image;\ndetermining one or more suggested actions for the image based on at least one category of the one or more categories, wherein each of the one or more suggested actions is associated with a respective command executable by the processor;\ncausing a user interface to be displayed that includes the image and one or more user interface elements each corresponding to a respective suggested action of the one or more suggested actions;\nreceiving user input indicative of selection of a particular action from the one or more suggested actions; and\nin response to the user input, causing the command associated with the particular action to be executed by the processor.\n19. The non-transitory computer readable medium of claim 18, wherein the operation of applying the classifier based on the prominence of the image feature includes determining that the one or more categories for the image are one or more categories of the image feature in response to at least one of:\nthe size of the image feature being greater than a threshold percentage of the area of the image; or\nthe image feature having a location in the image within a threshold distance of a center of the image.\n20. The non-transitory computer readable medium of claim 18, wherein the operation of determining the one or more categories comprises at least one of:\ndetermining that the image includes contact information, and further comprising extracting one or more of an e-mail address, a phone number, a physical address, or a social media address from the image, wherein the one or more suggested actions include adding a contact in an address book based on the extracting;\ndetermining that the image includes a media item, and wherein one or more suggested actions include one or more of: adding the media item to a wishlist, adding the media item to a playlist, or purchasing the media item; or\ndetermining that the image is for archival and the one or more categories includes one or more of document, meme, or screenshot; and\nwherein the operations further comprise causing one or more second user interface elements to be displayed in the user interface, each of the second user interface elements corresponding to a respective default action of one or more default actions, wherein the one or more default actions include at least one of sharing the image, archiving the image, or performing a visual search based on the image.",
    "status": "Active",
    "citations_own": [
        "US5963649A",
        "US6092102A",
        "JP2000298676A",
        "US20020040297A1",
        "JP2002132804A",
        "US20020103837A1",
        "US20030105589A1",
        "US20030182374A1",
        "EP1376392A2",
        "EP1394713A1",
        "WO2004104758A2",
        "US6883140B1",
        "US20050146621A1",
        "US20060004685A1",
        "US20060021023A1",
        "US20060029106A1",
        "US20060150119A1",
        "US20060156209A1",
        "US20060172749A1",
        "US20070030364A1",
        "US20070094217A1",
        "CN1989497A",
        "CN1988461A",
        "US20070162942A1",
        "US20070244980A1",
        "CN101159576A",
        "WO2008045811A2",
        "US20080120371A1",
        "US20080153526A1",
        "US20080189367A1",
        "US20090007019A1",
        "US20090076795A1",
        "US20090119584A1",
        "US7603413B1",
        "US20090282114A1",
        "US20090313194A1",
        "US20090327436A1",
        "JP2010044495A",
        "US20100077029A1",
        "US20100118115A1",
        "US20100228590A1",
        "US20100251158A1",
        "US20100260426A1",
        "WO2011002989A1",
        "KR20110003462A",
        "CN101983396A",
        "US7904187B2",
        "US20110074685A1",
        "US20110091092A1",
        "US20110098056A1",
        "US20110107223A1",
        "US20110145068A1",
        "US20110164163A1",
        "US20110202836A1",
        "US20110212717A1",
        "US20110221912A1",
        "US20110230174A1",
        "US20110252207A1",
        "US20110252108A1",
        "CN102222079A",
        "US20120030289A1",
        "US20120033876A1",
        "JP2012027950A",
        "US20120041973A1",
        "US20120042036A1",
        "US20120041941A1",
        "US20120089847A1",
        "US20120096097A1",
        "CN102467574A",
        "US20120131520A1",
        "US20120140124A1",
        "US20120179717A1",
        "US20120224743A1",
        "US8266109B1",
        "US20120239761A1",
        "CA2828011A1",
        "US20120245944A1",
        "US20120278164A1",
        "JP2012221480A",
        "EP2523436A1",
        "US20120322428A1",
        "WO2012173681A1",
        "KR20130008036A",
        "US20130022231A1",
        "US20130021266A1",
        "US20130036162A1",
        "EP2560104A2",
        "US20130050507A1",
        "US8391618B1",
        "US20130061148A1",
        "US20130073366A1",
        "US8423577B1",
        "KR20130050871A",
        "KR20130061387A",
        "CN103226949A",
        "US8515958B2",
        "US20130218877A1",
        "US20130260727A1",
        "US8554701B1",
        "US8589407B2",
        "USD695755S1",
        "US20130346235A1",
        "US20140004889A1",
        "US20140012927A1",
        "EP2688014A1",
        "CN103548025A",
        "US8645697B1",
        "US20140035846A1",
        "US8650210B1",
        "US20140047413A1",
        "EP2703980A2",
        "US20140067371A1",
        "US20140071324A1",
        "USD701228S1",
        "US20140088954A1",
        "US8688698B1",
        "US8700480B1",
        "US20140108562A1",
        "US20140129942A1",
        "JP2014086088A",
        "US20140150068A1",
        "CN103841007A",
        "US20140156801A1",
        "US20140163954A1",
        "US20140164506A1",
        "US20140171133A1",
        "US20140189538A1",
        "US20140189027A1",
        "US20140195621A1",
        "US20140201675A1",
        "KR20140093494A",
        "JP2014142919A",
        "US20140228009A1",
        "CN103995872A",
        "US20140237057A1",
        "US20140232889A1",
        "US8825474B1",
        "CN104035947A",
        "JP2014170397A",
        "US20140298364A1",
        "US20140317030A1",
        "USD716338S1",
        "US20140337438A1",
        "US20140341476A1",
        "US20140344058A1",
        "CN104202718A",
        "US20140372540A1",
        "US20140372349A1",
        "US20150006143A1",
        "US8938669B1",
        "US20150026642A1",
        "US20150026101A1",
        "US20150032724A1",
        "US20150058720A1",
        "EP2852105A1",
        "US20150088998A1",
        "US8996639B1",
        "US20150095855A1",
        "KR20150037935A",
        "US20150100537A1",
        "US9019415B2",
        "US9020956B1",
        "US20150127453A1",
        "US9043407B1",
        "US20150171133A1",
        "US20150178371A1",
        "US20150178388A1",
        "US20150185995A1",
        "US20150207765A1",
        "US20150222617A1",
        "US20150220806A1",
        "CN104836720A",
        "US20150227797A1",
        "US20150244653A1",
        "US20150248411A1",
        "US20150250936A1",
        "KR20150108096A",
        "CN104951428A",
        "US20150288633A1",
        "US20150286371A1",
        "US20150302301A1",
        "JP2015531136A",
        "US20150350117A1",
        "WO2015183493A1",
        "US20150347617A1",
        "US20150370830A1",
        "US9230241B1",
        "US20160011725A1",
        "CN105262675A",
        "US20160037311A1",
        "US20160043974A1",
        "US20160043817A1",
        "US20160042252A1",
        "US9262517B2",
        "US20160055246A1",
        "US20160065519A1",
        "US20160072737A1",
        "US20160092044A1",
        "WO2016072117A1",
        "US20160140447A1",
        "US20160140477A1",
        "US20160179816A1",
        "US20160196040A1",
        "CN105786455A",
        "US20160210279A1",
        "US20160210962A1",
        "CN105814519A",
        "US20160224524A1",
        "US20160226804A1",
        "US20160234553A1",
        "WO2016130788A1",
        "CN105898627A",
        "CN105940397A",
        "US20160283454A1",
        "US20160284011A1",
        "US20160292217A1",
        "US9467435B1",
        "US20160308794A1",
        "US20160321052A1",
        "EP3091445A1",
        "US20160342895A1",
        "US20160350304A1",
        "US20160352656A1",
        "WO2016204428A1",
        "US20160378080A1",
        "US20170004383A1",
        "US20170017648A1",
        "US9560152B1",
        "US20170031575A1",
        "US20170075878A1",
        "KR20170032883A",
        "US20170093769A1",
        "US20170098122A1",
        "US20170098152A1",
        "US9633048B1",
        "US20170118152A1",
        "US20170134316A1",
        "US20170142046A1",
        "US20170147202A1",
        "US20170149703A1",
        "US20170153792A1",
        "US20170171117A1",
        "US20170180276A1",
        "US20170180294A1",
        "US20170185236A1",
        "US20170187654A1",
        "US9715496B1",
        "US9727584B2",
        "US20170250936A1",
        "US20170250930A1",
        "US20170250935A1",
        "US20170277701A1",
        "US20170288942A1",
        "US20170293834A1",
        "US20170308249A1",
        "US20170308589A1",
        "US20170324868A1",
        "US9817813B2",
        "US20170339076A1",
        "US20170344224A1",
        "US20170357432A1",
        "US20170359701A1",
        "US20170359279A1",
        "US20170359703A1",
        "US20170359285A1",
        "US20170359702A1",
        "US20170359281A1",
        "US20170357442A1",
        "US20170359282A1",
        "US20170359283A1",
        "US20170366479A1",
        "US20180004397A1",
        "US20180005272A1",
        "US20180032499A1",
        "US20180032997A1",
        "US20180060705A1",
        "US20180083898A1",
        "US20180083901A1",
        "US20180083894A1",
        "US20180089230A1",
        "US20180090135A1",
        "US20180109526A1",
        "WO2018089109A1",
        "US20180196854A1",
        "US20180210874A1",
        "US20180293601A1",
        "US20180309706A1",
        "US20180316637A1",
        "US20180322403A1",
        "US20180336415A1",
        "US10146748B1",
        "US20180352393A1",
        "US20180367484A1",
        "US20180367483A1",
        "US20180373683A1",
        "US20190204868A1"
    ],
    "citations_ftf": [],
    "citedby_own": [
        "US11709691B2"
    ],
    "citedby_ftf": [
        "JP6209952B2",
        "CN108781175B",
        "WO2017112796A1",
        "US10387461B2",
        "WO2018057536A1",
        "US10547574B2",
        "US10015124B2",
        "US10416846B2",
        "US10860854B2",
        "CN111406249B",
        "US10348658B2",
        "US10404636B2",
        "US10474890B2",
        "US11176485B2",
        "KR102035531B1",
        "US10679101B2",
        "KR20190053675A",
        "US10812463B2",
        "KR102437640B1",
        "US11209442B2",
        "US10891526B2",
        "US11410075B2",
        "US10884769B2",
        "US11270215B2",
        "US10217029B1",
        "US11036811B2",
        "AU201816179S",
        "USD890203S1",
        "US11698927B2",
        "US10877927B2",
        "US11281996B2",
        "KR102125402B1",
        "US11100160B2",
        "USD933079S1",
        "USD915451S1",
        "USD895664S1",
        "WO2020068917A1",
        "USD928174S1",
        "USD916781S1",
        "US20200151453A1",
        "USD896263S1",
        "USD897366S1",
        "KR102189307B1",
        "KR20200100918A",
        "CN110097086B",
        "US11302080B1",
        "US10825254B1",
        "WO2021006363A1",
        "CN110543579A",
        "US11403285B2",
        "US11036724B2",
        "US11556736B2",
        "US11403849B2",
        "CN110826120B",
        "US20220392247A1",
        "KR20210062477A",
        "US20210158147A1",
        "US11321737B2",
        "KR20210087788A",
        "US11687778B2",
        "CN113254680B",
        "US11023814B1",
        "US10938979B1",
        "US11140434B1",
        "US11431895B2",
        "WO2022023988A1",
        "CN112004033B",
        "US11112945B1",
        "US20220188676A1",
        "CN116888586A",
        "US20230074640A1",
        "US11755859B2",
        "US20230215198A1"
    ]
}