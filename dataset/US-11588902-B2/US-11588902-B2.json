{
    "patent_id": "US-11588902-B2",
    "title": "Intelligent reasoning framework for user intent extraction ",
    "assignee": "Newton Howard",
    "publication_date": "2023-02-21",
    "patent_link": "https://patents.google.com/patent/US11588902B2/en",
    "inventors": [
        "Newton Howard"
    ],
    "classifications": [
        "H04L67/306",
        "G06F16/9535",
        "G06F16/5854",
        "G06N20/00",
        "G06N5/022",
        "G06N5/025",
        "G06N5/041",
        "G08B19/00",
        "H04L12/2829",
        "H04L67/535",
        "G06N3/006",
        "G06N3/042",
        "G06N5/043",
        "G06N7/01"
    ],
    "abstract": "Embodiments of the present systems and methods may provide an intelligent systems framework for analysis of user-generated content from various capture points to determine user intent. For example, a method may be implemented in a computer system comprising a processor, memory accessible by the processor, and computer program instructions stored in the memory and executable by the processor, the method may comprise receiving, at the computer system, data relating to a plurality of aspects of at least one person, including data from at least one of physical or physiological sensors and communicatively connected devices, extracting, at the computer system, from the received data, features relevant to events relating to at least one person, extracting, at the computer system, at least one intent of at least one event relating to at least one person, and performing, at the computer system, an action based on the extracted at least one intent.",
    "claims": "\n1. A method implemented in a computer system comprising a processor, memory accessible by the processor, and computer program instructions stored in the memory and executable by the processor, the method comprising:\nreceiving, at the computer system, data relating to a plurality of aspects of at least one person, including data from at least one of physical or physiological sensors and communicatively connected devices;\nextracting, at the computer system, from the received data, features relevant to events relating to at least one person;\nextracting, at the computer system, at least one intent of at least one event relating to at least one person, wherein the extracted intent comprises a strategic intent comprising that which the at least one person seeks to achieve over a long-term in a domain and a tactical intent comprising that which the at least one person seeks to achieve over a short-term, wherein extracting the at least one intent comprises performing intention awareness processing to form multidimensional intention awareness vectors and determining a component of at least one multidimensional intention awareness vector as a barycenter of the weighted points of the vector, including consistent tracking and extrapolation of objects in an environment and circumstantial semantics, performing Sentic processing to form multidimensional intention Sentic vectors and determining a component of at least one multidimensional intention Sentic vector as a barycenter of the weighted points of the vector, including using conceptual and affective information associated with objects and actors of the environment, and generating an ensemble datastream representing the extracted at least one intent by fusing the intention awareness vectors and the Sentic vectors; and\nperforming, at the computer system, an action based on the extracted at least one intent.\n2. The method of claim 1, wherein the data relating to a plurality of aspects of at least one person comprises live data retrieved from a plurality of capture points that at least one person is exposed to and interacts with;\nthe communicatively connected device comprises at least one of a microphone, room camera, fridge camera, smart mobile, smart refrigerator, smart watch, smart fire alarm, smart door lock, smart bicycle, medical sensor, fitness tracker, smart security system, voice controller, dash button, doorbell cam, mobile robot, smart light switch, and air quality monitor;\nthe physical and physiological sensor comprises at least one of an audio sensor, video sensor, electro-encephalogram sensor, electro-cardiogram sensor, heart rate sensor, breathing rate sensor, blood pressure sensor, body temperature sensor, head movement sensor, body posture sensor, and blood oxygenation level sensor, humidity sensor, biometric sensor; and\nthe data further comprises at least one of browsing history, bookmarks, browsing behavior, time spent on particular web pages, location history, calendar with past and upcoming events, social media activity, posts, social network graph, text, audio, video, social media content, chat, Short Message Service (SMS), email, medical visits, current diseases, medical treatments, real-time movements, breathing, cardiac frequency, and sleep patterns.\n3. The method of claim 2, wherein the features relevant to events relating to at least one person are extracted using artificial intelligence and machine learning models trained using data relating to a plurality of aspects of at least one person, wherein data relating to actions that are highly-specific predictors for particular intents are tagged.\n4. The method of claim 3, wherein at least one intent of at least one event relating to at least one person is extracted using ontologies data relating to subject areas that shows the properties and the relations between the subject area; and\nontologies methodology is used to create a supporting framework for intention query by defining concepts, sub-concepts, relationships, and aggregations of multiple concepts.\n5. The method of claim 4, wherein the physical action comprises at least one of generating an alarm, providing information or suggestions, and providing narrativization of events.\n6. A system comprising a processor, memory accessible by the processor, and computer program instructions stored in the memory and executable by the processor to perform:\nreceiving data relating to a plurality of aspects of at least one person, including data from at least one of physical or physiological sensors and communicatively connected devices;\nextracting from the received data, features relevant to events relating to at least one person;\nextracting, at the computer system, at least one intent of at least one event relating to at least one person, wherein the extracted intent comprises a strategic intent comprising that which the at least one person seeks to achieve over a long-term in a domain and a tactical intent comprising that which the at least one person seeks to achieve over a short-term, wherein extracting the at least one intent comprises performing intention awareness processing to form multidimensional intention awareness vectors and determining a component of at least one multidimensional intention awareness vector as a barycenter of the weighted points of the vector, including consistent tracking and extrapolation of objects in an environment and circumstantial semantics, performing Sentic processing to form multidimensional intention Sentic vectors and determining a component of at least one multidimensional intention Sentic vector as a barycenter of the weighted points of the vector, including using conceptual and affective information associated with objects and actors of the environment, and generating an ensemble datastream representing the extracted at least one intent by fusing the intention awareness vectors and the Sentic vectors; and\nperforming an action based on the extracted at least one intent.\n7. The system of claim 6, wherein the data relating to a plurality of aspects of at least one person comprises live data retrieved from a plurality of capture points that at least one person is exposed to and interacts with;\nthe communicatively connected device comprises at least one of a microphone, room camera, fridge camera, smart mobile, smart refrigerator, smart watch, smart fire alarm, smart door lock, smart bicycle, medical sensor, fitness tracker, smart security system, voice controller, dash button, doorbell cam, mobile robot, smart light switch, and air quality monitor;\nthe physical and physiological sensor comprises at least one of an audio sensor, video sensor, electro-encephalogram sensor, electro-cardiogram sensor, heart rate sensor, breathing rate sensor, blood pressure sensor, body temperature sensor, head movement sensor, body posture sensor, and blood oxygenation level sensor, humidity sensor, biometric sensor; and\nthe data further comprises at least one of browsing history, bookmarks, browsing behavior, time spent on particular web pages, location history, calendar with past and upcoming events, social media activity, posts, social network graph, text, audio, video, social media content, chat, Short Message Service (SMS), email, medical visits, current diseases, medical treatments, real-time movements, breathing, cardiac frequency, and sleep patterns.\n8. The system of claim 7, wherein the features relevant to events relating to at least one person are extracted using artificial intelligence and machine learning models trained using data relating to a plurality of aspects of at least one person, wherein data relating to actions that are highly-specific predictors for particular intents are tagged.\n9. The system of claim 8, wherein at least one intent of at least one event relating to at least one person is extracted using ontologies data relating to subject areas that shows the properties and the relations between the subject area; and\nontologies methodology is used to create a supporting framework for intention query by defining concepts, sub-concepts, relationships, and aggregations of multiple concepts.\n10. The method of claim 9, wherein the physical action comprises at least one of generating an alarm, providing information or suggestions, and providing narrativization of events.\n11. A computer program product comprising a non-transitory computer readable storage having program instructions embodied therewith, the program instructions executable by a computer, to cause the computer to perform a method comprising:\nreceiving, at the computer system, data relating to a plurality of aspects of at least one person, including data from at least one of physical or physiological sensors and communicatively connected devices;\nextracting, at the computer system, from the received data, features relevant to events relating to at least one person;\nextracting, at the computer system, at least one intent of at least one event relating to at least one person, wherein the extracted intent comprises a strategic intent comprising that which the at least one person seeks to achieve over a long-term in a domain and a tactical intent comprising that which the at least one person seeks to achieve over a short-term, wherein extracting the at least one intent comprises performing intention awareness processing to form multidimensional intention awareness vectors and determining a component of at least one multidimensional intention awareness vector as a barycenter of the weighted points of the vector, including consistent tracking and extrapolation of objects in an environment and circumstantial semantics, performing Sentic processing to form multidimensional intention Sentic vectors and determining a component of at least one multidimensional intention Sentic vector as a barycenter of the weighted points of the vector, including using conceptual and affective information associated with objects and actors of the environment, and generating an ensemble datastream representing the extracted at least one intent by fusing the intention awareness vectors and the Sentic vectors; and\nperforming, at the computer system, an action based on the extracted at least one intent.\n12. The computer program product of claim 11, wherein the data relating to a plurality of aspects of at least one person comprises live data retrieved from a plurality of capture points that at least one person is exposed to and interacts with;\nthe communicatively connected device comprises at least one of a microphone, room camera, fridge camera, smart mobile, smart refrigerator, smart watch, smart fire alarm, smart door lock, smart bicycle, medical sensor, fitness tracker, smart security system, voice controller, dash button, doorbell cam, mobile robot, smart light switch, and air quality monitor;\nthe physical and physiological sensor comprises at least one of an audio sensor, video sensor, electro-encephalogram sensor, electro-cardiogram sensor, heart rate sensor, breathing rate sensor, blood pressure sensor, body temperature sensor, head movement sensor, body posture sensor, and blood oxygenation level sensor, humidity sensor, biometric sensor; and\nthe data further comprises at least one of browsing history, bookmarks, browsing behavior, time spent on particular web pages, location history, calendar with past and upcoming events, social media activity, posts, social network graph, text, audio, video, social media content, chat, Short Message Service (SMS), email, medical visits, current diseases, medical treatments, real-time movements, breathing, cardiac frequency, and sleep patterns.\n13. The computer program product of claim 12, wherein the features relevant to events relating to at least one person are extracted using artificial intelligence and machine learning models trained using data relating to a plurality of aspects of at least one person, wherein data relating to actions that are highly-specific predictors for particular intents are tagged.\n14. The computer program product of claim 13, wherein at least one intent of at least one event relating to at least one person is extracted using ontologies data relating to subject areas that shows the properties and the relations between the subject area; and\nontologies methodology is used to create a supporting framework for intention query by defining concepts, sub-concepts, relationships, and aggregations of multiple concepts.\n15. The computer program product of claim 14, wherein the physical action comprises at least one of generating an alarm, providing information or suggestions, and providing narrativization of events.",
    "status": "Active",
    "citations_own": [
        "US6745168B1",
        "US20090037832A1",
        "US20100090835A1",
        "US8606735B2",
        "US20140079195A1",
        "US20150100943A1",
        "US9124694B2",
        "US20150269150A1",
        "US20150356405A1",
        "US9652797B2",
        "US20170199866A1",
        "US20180039745A1",
        "US20180114527A1",
        "US20180211175A1",
        "US20190155577A1",
        "US20190215290A1",
        "US20190251626A1",
        "US20190332647A1"
    ],
    "citations_ftf": [
        "US10846601B1"
    ],
    "citedby_own": [],
    "citedby_ftf": [
        "US10999296B2",
        "US20200065513A1",
        "US11074368B2",
        "WO2020252614A1",
        "KR20210023367A",
        "EP3804915A1",
        "CN111221984A",
        "CN115082750A",
        "WO2022263005A1",
        "US20230136939A1",
        "WO2023133144A1",
        "US11625450B1"
    ]
}