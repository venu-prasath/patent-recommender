{
    "patent_id": "US-11768636-B2",
    "title": "Generating a transformed dataset for use by a machine learning model in an artificial intelligence infrastructure ",
    "assignee": "Pure Storage, Inc.",
    "publication_date": "2023-09-26",
    "patent_link": "https://patents.google.com/patent/US11768636B2/en",
    "inventors": [
        "Brian Gold",
        "Emily Watkins",
        "Ivan Jibaja",
        "Igor Ostrovsky",
        "Roy Kim"
    ],
    "classifications": [
        "G06F3/0679",
        "G06F16/1794",
        "G06F16/245",
        "G06F3/0604",
        "G06F3/0608",
        "G06F3/0646",
        "G06F3/0649",
        "G06F3/067",
        "G06F9/4881",
        "G06F9/5027",
        "G06N20/00",
        "G06N3/063",
        "G06N3/08",
        "G06Q30/0243",
        "G06T1/20",
        "G06T1/60",
        "G06F16/248",
        "G06F16/972",
        "G06T2200/28"
    ],
    "abstract": "Generating a transformed dataset for use by a machine learning model in an artificial intelligence infrastructure that includes one or more storage systems and one or more graphical processing unit (\u2018GPU\u2019) servers, including: storing, within one or more storage systems, a transformed dataset generated by applying one or more transformations to a dataset that are identified based on one or more expected input formats of data received as input data by one or more machine learning models to be executed on one or more servers; and transmitting, from the one or more storage systems to the one or more servers without reapplying the one or more transformations on the dataset, the transformed dataset including data in the one or more expected formats of data to be received as input data by the one or more machine learning models.",
    "claims": "\n1. A method comprising:\nstoring, within one or more storage systems, a transformed dataset generated by applying one or more transformations to a dataset that are identified based on one or more expected input formats of data received as input data by one or more machine learning models to be executed on one or more servers; and\ntransmitting, from the one or more storage systems to the one or more servers without reapplying the one or more transformations on the dataset, the transformed dataset including data in the one or more expected formats of data to be received as input data by the one or more machine learning models.\n2. The method of claim 1 further comprising generating the transformed dataset by applying the transformations to an initial version of the dataset.\n3. The method of claim 1 wherein transmitting the transformed dataset further comprises transmitting the transformed dataset from the one or more storage systems directly to application memory on at least one of the servers.\n4. The method of claim 3 wherein transmitting the transformed dataset from the one or more storage systems directly to application memory on at least one of the servers further comprises transmitting the transformed data dataset from the one or more storage systems to the server via remote direct memory access (\u2018RDMA\u2019).\n5. The method of claim 1 further comprising executing, by one or more of the servers, one or more machine learning algorithms associated with the machine learning model using the transformed dataset as input.\n6. The method of claim 1 further comprising:\nscheduling, by a unified management plane, one or more transformations for one or more of the storage systems to apply to the dataset; and\nscheduling, by the unified management plane, execution of one or more machine learning algorithms associated with the machine learning model by the one or more servers.\n7. The method of claim 1 further comprising providing, by a unified management plane to the one or more servers, information describing the dataset, the one or more transformations applied to the dataset, and the transformed dataset.\n8. An artificial intelligence infrastructure configured to carry out steps of:\nstoring, within one or more storage systems, a transformed dataset generated by applying one or more transformations to a dataset that are identified based on one or more expected input formats of data received as input data by one or more machine learning models to be executed on one or more servers; and\ntransmitting, from the one or more storage systems to the one or more servers without reapplying the one or more transformations on the dataset, the transformed dataset including data in the one or more expected formats of data to be received as input data by the one or more machine learning models.\n9. The artificial intelligence infrastructure of claim 8 wherein the artificial intelligence infrastructure is further configured to carry out the step of generating, by at least one of the storage systems, the transformed dataset by applying the transformations to an initial version of the dataset.\n10. The artificial intelligence infrastructure of claim 8 wherein transmitting the transformed dataset further comprises transmitting the transformed dataset from the one or more storage systems directly to application memory on at least one of the servers.\n11. The artificial intelligence infrastructure of claim 10 wherein transmitting the transformed dataset from the one or more storage systems directly to application memory on the server further comprises transmitting the transformed data dataset from the one or more storage systems to the server via remote direct memory access (\u2018RDMA\u2019).\n12. The artificial intelligence infrastructure of claim 8 wherein the artificial intelligence infrastructure is further configured to carry out the step of executing, by one or more of the servers, one or more machine learning algorithms associated with the machine learning model using the transformed dataset as input.\n13. The artificial intelligence infrastructure of claim 8 wherein the artificial intelligence infrastructure is further configured to carry out the steps of:\nscheduling, by a unified management plane, one or more transformations for one or more of the storage systems to apply to the dataset; and\nscheduling, by the unified management plane, execution of one or more machine learning algorithms associated with the machine learning model by the one or more servers.\n14. The artificial intelligence infrastructure of claim 8 wherein the artificial intelligence infrastructure is further configured to carry out the step of providing, by a unified management plane to the one or more servers, information describing the dataset, the one or more transformations applied to the dataset, and the transformed dataset.\n15. An apparatus comprising a computer processor, a computer memory operatively coupled to the computer processor, the computer memory having disposed within it computer program instructions that, when executed by the computer processor, cause the apparatus to carry out steps of:\nstoring, within one or more storage systems, a transformed dataset generated by applying one or more transformations to a dataset that are identified based on one or more expected input formats of data received as input data by one or more machine learning models to be executed on one or more servers; and\ntransmitting, from the one or more storage systems to the one or more servers without reapplying the one or more transformations on the dataset, the transformed dataset including data in the one or more expected formats of data to be received as input data by the one or more machine learning models.\n16. The apparatus of claim 15 wherein the apparatus further comprises computer program instructions that, when executed by the computer processor, cause the apparatus to carry out step of generating the transformed dataset by applying the transformations to an initial version of the dataset.\n17. The apparatus of claim 15 wherein transmitting the transformed dataset further comprises transmitting the transformed dataset from the one or more storage systems directly to application memory on at least one of the servers.\n18. The apparatus of claim 15 further comprising computer program instructions that, when executed by the computer processor, cause the apparatus to carry out the steps of:\nscheduling, by a unified management plane, one or more transformations for one or more of the storage systems to apply to the dataset; and\nscheduling, by the unified management plane, execution of one or more machine learning algorithms associated with the machine learning model by the one or more servers.\n19. The apparatus of claim 15 further comprising computer program instructions that, when executed by the computer processor, cause the apparatus to carry out the step of providing, by a unified management plane to the one or more servers, information describing the dataset, the one or more transformations applied to the dataset, and the transformed dataset.\n20. The apparatus of claim 15 further comprising computer program instructions that, when executed by the computer processor, cause the apparatus to carry out the step of executing, by one or more of the servers, one or more machine learning algorithms associated with the machine learning model using the transformed dataset as input."
}