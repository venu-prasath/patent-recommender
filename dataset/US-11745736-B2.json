{
    "patent_id": "US-11745736-B2",
    "title": "System and method for vehicle occlusion detection ",
    "assignee": "Tusimple, Inc.",
    "publication_date": "2023-09-05",
    "patent_link": "https://patents.google.com/patent/US11745736B2/en",
    "inventors": [
        "Hongkai YU",
        "Zhipeng Yan",
        "Panqu Wang",
        "Pengfei Chen"
    ],
    "classifications": [
        "B60W30/0956",
        "B60W60/00272",
        "G01S13/867",
        "G06F18/2155",
        "G06F18/24",
        "G06F18/2413",
        "G06F18/285",
        "G06N20/20",
        "G06V10/25",
        "G06V10/44",
        "G06V10/7753",
        "G06V10/87",
        "G06V20/56",
        "G06V20/58",
        "G08G1/167",
        "B60W2050/0088",
        "B60W2420/42",
        "G01S13/89",
        "G01S13/931",
        "G05D1/0221"
    ],
    "abstract": "A system and method for vehicle occlusion detection is disclosed. A particular embodiment includes: receiving training image data from a training image data collection system; obtaining ground truth data corresponding to the training image data; performing a training phase to train a plurality of classifiers, a first classifier being trained for processing static images of the training image data, a second classifier being trained for processing image sequences of the training image data; receiving image data from an image data collection system associated with an autonomous vehicle; and performing an operational phase including performing feature extraction on the image data, determining a presence of an extracted feature instance in multiple image frames of the image data by tracing the extracted feature instance back to a previous plurality of N frames relative to a current frame, applying the first trained classifier to the extracted feature instance if the extracted feature instance cannot be determined to be present in multiple image frames of the image data, and applying the second trained classifier to the extracted feature instance if the extracted feature instance can be determined to be present in multiple image frames of the image data.",
    "claims": "\n1. A system comprising:\na data processor; and\nan autonomous vehicle occlusion detection system, executable by the data processor, the autonomous vehicle occlusion detection system being configured to:\nreceive image data from an image data collection system associated with an autonomous vehicle;\nperform feature extraction on the image data;\ndetermine a presence of an extracted feature in a plurality of image frames of the image data by tracing the extracted feature across the plurality of image frames;\napply a trained image sequence classifier to the extracted feature in the plurality of image frames;\ndetect an occlusion status of the extracted feature; and\nperform object-level contour detection on the extracted feature.\n2. The system of claim 1 being further configured to receive training image data from a training image data collection system; obtain ground truth data corresponding to the training image data; and perform a training phase to train the image sequence classifier for processing image sequences of the training image data.\n3. The system of claim 2 wherein the training phase being configured to obtain ground truth data comprising labeling data and object relationship information for the training image data, the object relationship information comprising a status for each of a plurality of objects in a frame of the training image data, the status comprising a state from the group consisting of: 1) occluding another object; (2) occluded by another object; (3) there is no overlap with another object, and (4) in between two objects.\n4. The system of claim 1 being configured to associate a plurality of feature dimensions with the extracted feature.\n5. The system of claim 1 being configured to apply a trained static image classifier to the extracted feature.\n6. The system of claim 1 being configured to apply a bounding box to the extracted feature, the bounding box being partitioned into a plurality of portions.\n7. The system of claim 1 being configured to apply a pixel-level object label and bounding box to the extracted feature.\n8. A computer-implemented vehicle occlusion detection method comprising:\nreceiving image data from an image data collection system associated with an autonomous vehicle;\nusing an in-vehicle data processor to perform feature extraction on the image data;\nusing the in-vehicle data processor to determine a presence of an extracted feature in a plurality of image frames of the image data by tracing the extracted feature across the plurality of image frames;\nusing the in-vehicle data processor to apply a trained image sequence classifier to the extracted feature in the plurality of image frames;\nusing the in-vehicle data processor to detect an occlusion status of the extracted feature; and\nusing the in-vehicle data processor to perform object-level contour detection on the extracted feature.\n9. The method of claim 8 comprising training the image sequence classifier for processing image sequences of the training image data.\n10. The method of claim 9 wherein the occlusion status of the extracted feature comprising a state from the group consisting of: 1) occluding another object, (2) occluded by another object, (3) there is no overlap with another object, and (4) in between two objects.\n11. The method of claim 8 wherein the extracted feature is a vehicle object.\n12. The method of claim 8 comprising associating a plurality of feature dimensions the extracted feature processed by the trained image sequence classifier.\n13. The method of claim 8 comprising applying a bounding box to the extracted feature.\n14. The method of claim 8 comprising applying a pixel-level object label to the extracted feature.\n15. A non-transitory machine-useable storage medium embodying instructions which, when executed by a machine, cause the machine to:\nreceive image data from an image data collection system associated with an autonomous vehicle;\nperform feature extraction on the image data;\ndetermine a presence of an extracted feature in a plurality of image frames of the image data by tracing the extracted feature across the plurality of image frames;\napply a trained image sequence classifier to the extracted feature in the plurality of image frames;\ndetect an occlusion status of the extracted feature; and\nperform object-level contour detection on the extracted feature.\n16. The non-transitory machine-useable storage medium of claim 15 being further configured to receive training image data from a training image data collection system; obtain ground truth data corresponding to the training image data; and perform a training phase to train a static image classifier for processing static images of the training image data.\n17. The non-transitory machine-useable storage medium of claim 16 wherein the training phase being configured to obtain ground truth data comprising labeling data and object relationship information for the training image data.\n18. The non-transitory machine-useable storage medium of claim 16 being configured to associate a plurality of feature dimensions of quantity F with the extracted feature processed by the static image classifier.\n19. The non-transitory machine-useable storage medium of claim 15 wherein the occlusion status of the extracted feature comprising a state from the group consisting of: 1) occluding another object, and (2) occluded by another object.\n20. The non-transitory machine-useable storage medium of claim 15 wherein the trained image sequence classifier is trained neural network."
}