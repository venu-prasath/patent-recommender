{
    "patent_link": "https://patents.google.com/patent/US20160078361A1/en",
    "patent_id": "US20160078361A1",
    "title": "Optimized training of linear machine learning models",
    "abstract": "An indication of a data source to be used to train a linear prediction model is obtained. The model is to generate predictions using respective parameters assigned to a plurality of features derived from observation records of the data source. The parameter values are stored in a parameter vector. During a particular learning iteration of the training phase of the model, one or more features for which parameters are to be added to the parameter vector are identified. In response to a triggering condition, parameters for one or more features are removed from the parameter vector based on an analysis of relative contributions of the features represented in the parameter vector to the model's predictions. After the parameters are removed, at least one parameter is added to the parameter vector.",
    "inventors": [
        "Michael Brueckner",
        "Daniel Blick"
    ],
    "assignee": "Amazon Technologies Inc",
    "classifications": [
        "G06N20/00",
        "G06N99/005",
        "H04L67/10",
        "G06F18/214",
        "G06F18/2411",
        "G06N5/025",
        "G06N7/01"
    ],
    "claims": "\n1. A system, comprising:\none or more computing devices configured to:\nreceive, at a machine learning service of a provider network, an indication of a data source to be used for generating a linear prediction model, wherein, to generate a prediction, the linear prediction model is to utilize respective weights assigned to individual ones of a plurality of features derived from observation records of the data source, wherein the respective weights are stored in a parameter vector of the linear prediction model;\ndetermine, based at least in part on examination of a particular set of observation records of the data source, respective weights for one or more features to be added to the parameter vector during a particular learning iteration of a plurality of learning iterations of a training phase of the linear prediction model;\nin response to a determination that a triggering condition has been met during the training phase,\nidentify one or more pruning victims from a set of features whose weights are included in the parameter vector, based at least in part on a quantile analysis of the weights, wherein the quantile analysis is performed without a sort operation; and\nremove at least a particular weight corresponding to a particular pruning victim of the one or more pruning victims from the parameter vector; and\ngenerate, during a post-training-phase prediction run of the linear prediction model, a prediction using at least one feature for which a weight is determined after the particular weight of the particular pruning victim is removed from the parameter vector.\n2. The system as recited in claim 1, wherein the triggering condition is based at least in part on a population of the parameter vector.\n3. The system as recited in claim 1, wherein the triggering condition is based at least in part on a goal indicated by a client.\n4. The system as recited in claim 1, wherein the one or more computing devices are further configured to:\nduring a subsequent learning iteration of the plurality of learning iterations, performed after the particular learning iteration,\ndetermine that a weight for the particular pruning victim is to be re-added to the parameter vector; and\nadd the weight corresponding to the particular pruning victim to the parameter vector.\n5. The system as recited in claim 1, wherein a first feature of the one or more features whose weights are to be added to the parameter vector during the particular learning iteration is derived from one or more variables of the observation records of the data source via a transformation that comprises a use of one or more of: (a) a quantile bin function, (b) a Cartesian product function, (c) a bi-gram function, (d) an n-gram function, (e) an orthogonal sparse bigram function, (f) a calendar function, (g) an image processing function, (h) an audio processing function, (i) a bio-informatics processing function, (j) a natural language processing function or (k) a video processing function.\n6. A method, comprising:\nperforming, by one or more computing devices:\nreceiving an indication of a data source to be used for training a machine learning model, wherein, to generate a prediction, the machine learning model is to utilize respective parameters assigned to individual ones of a plurality of features derived from observation records of the data source, wherein the respective parameters are stored in a parameter vector of the machine learning model;\nidentifying one or more features for which respective parameters are to be added to the parameter vector during a particular learning iteration of a plurality of learning iterations of a training phase of the machine learning model;\nin response to determining that a triggering condition has been met in the training phase, removing respective parameters of one or more pruning victim features from the parameter vector, wherein the one or more pruning victim features are selected based at least in part on an analysis of relative contributions of features whose parameters are included in the parameter vector to predictions made using the machine learning model; and\ngenerating, during a post-training-phase prediction run of the machine learning model, a particular prediction using at least one feature for which a parameter is determined after the one or more pruning victim features are selected.\n7. The method as recited in claim 6, wherein the analysis of relative contributions comprises a quantile analysis of weights included in the parameter vector.\n8. The method as recited in claim 6, wherein the analysis of relative contributions (a) does not comprise a sort operation and (b) does not comprise copying values of the parameters included in the parameter vector.\n9. The method as recited in claim 6, wherein said determining that the triggering condition has been met comprises determining that a population of the parameter vector exceeds a threshold.\n10. The method as recited in claim 6, wherein the triggering condition is based at least in part on a resource capacity constraint of a server of a machine learning service.\n11. The method as recited in claim 6, wherein the triggering condition is based at least in part on a goal indicated by a client.\n12. The method as recited in claim 6, further comprising performing, by the one or more computing devices:\nduring a subsequent learning iteration of the plurality of learning iterations, performed after the particular learning iteration,\ndetermining that a parameter for a particular feature which was previously selected as a pruning victim feature is to be re-added to the parameter vector; and\nadding the parameter for the particular feature to the parameter vector.\n13. The method as recited in claim 6, wherein a first feature of the one or more features for which respective parameters are to be added to the parameter vector during the particular learning iteration is determined from one or more variables of observation records of the data source via a transformation that comprises a use of one or more of: (a) a quantile bin function, (b) a Cartesian product function, (c) a bi-gram function, (d) an n-gram function, (e) an orthogonal sparse bigram function, (f) a calendar function, (g) an image processing function, (h) an audio processing function, (i) a bio-informatics processing function, (j) a natural language processing function, or (k) a video processing function.\n14. The method as recited in claim 6, further comprising performing, by the one or more computing devices:\nimplementing a stochastic gradient descent technique to update, during the particular learning iteration, one or more previously-generated parameters included in the parameter vector.\n15. The method as recited in claim 6, wherein the machine learning model comprises a generalized linear model.\n16. The method as recited in claim 6, further comprising performing, by the one or more computing devices:\nreceiving, via a programmatic interface of a machine learning service implemented at a provider network, wherein the machine learning service comprises a plurality of training servers at one or more data centers, a client request indicating the data source; and\nassigning, to a particular training server of the plurality of training servers by a job scheduler of the machine learning service, asynchronously with respect to said receiving the client request, a job comprising the plurality of learning iterations.\n17. A non-transitory computer-accessible storage medium storing program instructions that when executed on one or more processors implements a model generator of a machine learning service, wherein the model generator is configured to:\ndetermine a data source to be used for generating a model, wherein, to generate a prediction, the model is to utilize respective parameters assigned to individual ones of a plurality of features derived from observation records of the data source, wherein the respective parameters are stored in a parameter vector of the model;\nidentify one or more features for which parameters are to be added to the parameter vector during a particular learning iteration of a plurality of learning iterations of a training phase of the model;\nin response to a determination that a triggering condition has been met, remove respective parameters assigned to one or more pruning victim features from the parameter vector, wherein the one or more pruning victim features are selected based at least in part on an analysis of relative contributions of features whose parameters are included in the parameter vector to predictions made using the model; and\nadd, subsequent to a removal from the parameter vector of at least one parameter assigned to a pruning victim feature, at least one parameter to the parameter vector.\n18. The non-transitory computer-accessible storage medium as recited in claim 17, wherein the analysis of relative contributions comprises a determination of a deviation of a particular parameter value included in the parameter vector from an a priori parameter value.\n19. The non-transitory computer-accessible storage medium as recited in claim 18, wherein the particular parameter value comprises a probability distribution, and wherein the determination of the deviation comprises an estimation of a Kullback-Leibler (KL) divergence.\n20. The non-transitory computer-accessible storage medium as recited in claim 17, wherein to determine whether the triggering condition has been met, the model generator is configured to determine whether a population of the parameter vector exceeds a threshold.\n21. The non-transitory computer-accessible storage medium as recited in claim 17, wherein the data source comprises a source of a stream of observation records transmitted to a network endpoint of a machine learning service.",
    "status": "Active",
    "citations_own": [
        "US20020032670A1",
        "US20020087797A1",
        "US20030176931A1",
        "US20100179930A1",
        "US20100191685A1"
    ],
    "citations_ftf": [
        "US4821333A",
        "US6807537B1",
        "US6230131B1",
        "US6681383B1",
        "US20100223211A1",
        "US6804691B2",
        "US7606714B2",
        "US8983934B2",
        "US7167849B2",
        "US7593903B2",
        "US7328218B2",
        "US8160400B2",
        "US8280915B2",
        "US20080033900A1",
        "US7743003B1",
        "US8078556B2",
        "JP5133775B2",
        "US8781915B2",
        "US8204838B2",
        "US8522085B2",
        "US8314973B2",
        "US9020871B2",
        "US8904149B2",
        "US8566746B2",
        "US20120089446A1",
        "US8682814B2",
        "US20120158791A1",
        "US8499010B2",
        "US8595154B2",
        "US20120253927A1",
        "EP2705471A1",
        "US8229864B1",
        "US8370280B1",
        "CN102622441A",
        "US8775576B2",
        "US9380032B2",
        "US8886576B1",
        "US8429103B1",
        "US20130346347A1",
        "US8510238B1",
        "US20140046879A1",
        "US9373087B2",
        "WO2014144869A1",
        "US9069737B1",
        "US10963810B2",
        "US10452992B2",
        "US10102480B2",
        "US10540606B2",
        "US9886670B2",
        "US11100420B2",
        "US10169715B2",
        "US9672474B2",
        "US10339465B2",
        "CN104123192A",
        "CN104536902A"
    ],
    "citedby_own": [
        "US20140337255A1",
        "US20150379423A1",
        "US20150379428A1",
        "US20160188207A1",
        "US20160226722A1",
        "US20160260047A1",
        "US20170032300A1",
        "US20170063886A1",
        "US20170187604A1",
        "US20170199904A1",
        "WO2017177048A1",
        "WO2017217957A1",
        "US20170372069A1",
        "WO2017176356A3",
        "US9942264B1",
        "US10002029B1",
        "US20180181915A1",
        "US10069938B1",
        "WO2018170028A1",
        "US20180285775A1",
        "WO2018183004A1",
        "US20180293098A1",
        "US20180300598A1",
        "US20180307654A1",
        "US20180307509A1",
        "US10120926B1",
        "US10169715B2",
        "US10173703B2",
        "US10205735B2",
        "US10220167B2",
        "US10229357B2",
        "WO2019113501A1",
        "US20190179648A1",
        "US10339320B2",
        "US10360069B2",
        "US20190253490A1",
        "CN110222087A",
        "US20190286747A1",
        "US10459932B2",
        "WO2019246116A1",
        "US10523712B1",
        "US10530662B2",
        "US10553319B1",
        "US20200050443A1",
        "CN110796594A",
        "WO2020036622A1",
        "US10572828B2",
        "US10575022B2",
        "CN110869949A",
        "US10616133B2",
        "US10643150B2",
        "US10642896B2",
        "US10650046B2",
        "US10650045B2",
        "CN111143628A",
        "US10657158B2",
        "US10664777B2",
        "US10671916B1",
        "CN111222553A",
        "US10680875B2",
        "US10685004B2",
        "US20200193239A1",
        "US10700992B1",
        "US10699184B2",
        "US10719777B2",
        "US20200234395A1",
        "US10748090B2",
        "CN111597187A",
        "US20200279187A1",
        "CN111652368A",
        "US10795935B2",
        "US20200320436A1",
        "US10803105B1",
        "US10817669B2",
        "US10824815B2",
        "US10831704B1",
        "JPWO2019087526A1",
        "CN111937084A",
        "US10838922B2",
        "US10846622B2",
        "US10853661B2",
        "US10867071B2",
        "US20200401632A1",
        "US10885469B2",
        "US10884769B2",
        "US10902844B2",
        "US20210035025A1",
        "US20210035020A1",
        "JPWO2019187594A1",
        "US20210081611A1",
        "US10956132B1",
        "US10979320B2",
        "WO2021087129A1",
        "US20210150407A1",
        "WO2021096684A1",
        "US11023284B2",
        "US20210191946A1",
        "WO2021097494A3",
        "US20210240144A1",
        "US20210248009A1",
        "US11100158B1",
        "US11106802B2",
        "US11126893B1",
        "CN113468035A",
        "US11138515B2",
        "CN113516297A",
        "US11170104B1",
        "US11176480B2",
        "US11176483B1",
        "WO2021230463A1",
        "US20210358579A1",
        "WO2021236529A1",
        "WO2021242329A1",
        "US20210373914A1",
        "US20210374600A1",
        "US11195093B2",
        "US11210140B1",
        "US11216742B2",
        "US11227188B2",
        "US20220027755A1",
        "US11238366B2",
        "US11252044B2",
        "US11263273B2",
        "US11270227B2",
        "US20220076084A1",
        "US11276013B2",
        "US20220083395A1",
        "SE2051156A1",
        "US20220129315A1",
        "US20220156643A1",
        "WO2022115779A1",
        "US11372694B2",
        "WO2022139595A1",
        "US11379655B1",
        "WO2022143621A1",
        "US20220222047A1",
        "CN114756211A",
        "US11392411B2",
        "US11403290B1",
        "CN114861781A",
        "US20220269895A1",
        "US11436505B2",
        "US11443242B2",
        "US11449798B2",
        "US11449796B2",
        "US11455168B1",
        "CN115130929A",
        "WO2022212518A1",
        "US11481190B2",
        "US11494692B1",
        "US11507850B2",
        "US20220374719A1",
        "US11514327B2",
        "US11514359B2",
        "US11526746B2",
        "US11537931B2",
        "US11539663B2",
        "US11537841B2",
        "US11544623B2",
        "US20230006936A1",
        "US11551652B1",
        "US20230008999A1",
        "US20230034011A1",
        "US11573803B2",
        "US11582207B2",
        "US20230071347A1",
        "US20230089968A1",
        "US11615339B2",
        "US11620571B2",
        "US11625640B2",
        "US11630881B2",
        "US11635994B2",
        "US11647039B2",
        "US20230148337A1",
        "WO2023081303A1",
        "US11651003B2",
        "US20230164208A1",
        "US11663519B2",
        "US11669658B2",
        "US11687571B2",
        "US11704370B2",
        "US11734614B1",
        "US11750631B2",
        "US11755957B2",
        "US11757920B2",
        "US11757849B2",
        "US11762635B2",
        "US11775850B2"
    ],
    "citedby_ftf": [
        "US20180299847A1",
        "US11321637B2",
        "US11637866B2",
        "US11323484B2",
        "US11477245B2",
        "US10628456B2",
        "CN107292326A",
        "EP3376373A1",
        "US11580061B2",
        "US11531927B2",
        "US10073763B1",
        "US10642721B2",
        "US10740223B1",
        "US10983761B2",
        "US11625401B2",
        "US11537949B2",
        "US11310250B2",
        "US11175907B2",
        "US11295020B2",
        "US11301226B2",
        "US11714789B2",
        "US11256493B1"
    ]
}