{
    "patent_id": "US-11435748-B2",
    "title": "System and method for real world autonomous vehicle trajectory simulation ",
    "assignee": "Tusimple, Inc.",
    "publication_date": "2022-09-06",
    "patent_link": "https://patents.google.com/patent/US11435748B2/en",
    "inventors": [
        "Xing Sun",
        "Wutu LIN",
        "Liu Liu",
        "Kai-Chieh MA",
        "Zijie XUAN",
        "Yufei Zhao"
    ],
    "classifications": [
        "G05D1/0221",
        "G05B13/048",
        "G05D1/0088",
        "G06N20/00",
        "G06N3/08",
        "G06N7/01"
    ],
    "abstract": "A system and method for real world autonomous vehicle trajectory simulation may include: receiving training data from a data collection system; obtaining ground truth data corresponding to the training data; performing a training phase to train a plurality of trajectory prediction models; and performing a simulation or operational phase to generate a vicinal scenario for each simulated vehicle in an iteration of a simulation. Vicinal scenarios may correspond to different locations, traffic patterns, or environmental conditions being simulated. Vehicle intention data corresponding to a data representation of various types of simulated vehicle or driver intentions.",
    "claims": "\n1. A system comprising:\na data processor;\na real world data collection system interface for receiving training data collected from a real world data collection system, the training data including perception or sensor data from at least one image generating device;\na vicinal scene data generator to generate, by the data processor, a different vicinal scenario for each simulated vehicle in an iteration of a simulation, the different vicinal scenarios corresponding to different vehicle status, traffic patterns, or environmental conditions being simulated;\na memory for storage of vehicle intention data representing simulated vehicle intentions for a plurality of different vehicle actions and behaviors;\na trajectory simulation module, executable by the data processor, the trajectory simulation module being configured to:\ngenerate, by the data processor, a trajectory corresponding to perception data and the vehicle intention data;\nexecute, by the data processor, at least one of a plurality of prediction models to generate a distribution of predicted vehicle trajectories for each of a plurality of simulated vehicles of the simulation based on a corresponding vicinal scenario and the vehicle intention data, the plurality of prediction models being trained with the training data,\nselect, by the data processor, at least one vehicle trajectory from the distribution based on pre-defined criteria, and\nupdate, by the data processor, a state and trajectory of each of the plurality of simulated vehicles based on the selected vehicle trajectory from the distribution; and\nan autonomous vehicle control system configured using the plurality of trained prediction models and predicted traffic trajectory information from the simulation.\n2. The system of claim 1 wherein the real world data collection system is further configured to perform a training phase to train the plurality of prediction models with the training data to produce a plurality of trained trajectory prediction models, the plurality of trained trajectory prediction models being used for configuring the autonomous vehicle control system for an autonomous vehicle.\n3. The system of claim 1 wherein the sensor devices, installed at various traffic locations or installed on moving test vehicles, are configured to collect perception or sensor data from the various traffic locations or from the moving test vehicles, the plurality of trained trajectory prediction models comprising at least one trained trajectory prediction model configured to model a variable level of simulated driver aggressiveness, the collected training data being transferred to the data collection system.\n4. The system of claim 1 further comprising a memory device configured to store training data acquired by moving test vehicles or by sensors installed at various traffic locations.\n5. The system of claim 1 wherein the trajectory simulation module is further configured to receive an array of sensor information gathered at various traffic locations by the real world data collection system, the array of sensor information comprising any of traffic image data, vehicle image data, roadway data, environmental data, distance from LIDAR devices, distance from radar devices, or other sensor information positioned adjacent to monitored locations.\n6. The system of claim 1 wherein the different vicinal scenarios correspond to different vehicle occupant status.\n7. A method comprising:\nreceiving, by a data processor, training data from a real world data collection system, the training data including data from at least one image generating device;\nperforming, by the data processor, a training phase to train a plurality of trajectory prediction models;\nperforming, by the data processor, a simulation to:\ngenerate a different vicinal scenario for each simulated vehicle in an iteration of a simulation, the different vicinal scenarios corresponding to different vehicle status, traffic patterns, or environmental conditions being simulated;\nprovide vehicle intention data corresponding to a data representation of various types of simulated vehicle or driver intentions;\ngenerate, by the data processor, a trajectory corresponding to perception data and the vehicle intention data;\nexecute, by the data processor, at least one of the plurality of trained trajectory prediction models to generate a distribution of predicted vehicle trajectories for each of a plurality of simulated vehicles of the simulation based on a corresponding vicinal scenario and the vehicle intention data;\nselect, by the data processor, at least one vehicle trajectory from the distribution based on pre-defined criteria; and\nupdate, by the data processor, a state and trajectory of each of the plurality of simulated vehicles based on the selected vehicle trajectory from the distribution; and\nconfiguring an autonomous vehicle control system using the plurality of trained prediction models and predicted traffic trajectory information from the simulation.\n8. The method of claim 7 wherein the method further comprises transferring gathered perception and sensor data wirelessly to the data processor.\n9. The method of claim 7 wherein the method further comprises storing gathered perception and sensor data in a memory device, wherein the memory device is located in a test vehicle comprising information gathering devices, the information gathering devices comprising image generating devices.\n10. The method of claim 7 wherein the distribution of predicted vehicle trajectories includes data indicative of a degree of likelihood or probability that a particular simulated vehicle will actually traverse a corresponding trajectory of the distribution.\n11. The method of claim 7, wherein the different vicinal scenarios are represented by an occupancy grid, a collection of vehicle states on a map, or a graphical representation.\n12. The method of claim 7, wherein different vicinal scenarios are generated for each simulated vehicle in the simulation for each iteration.\n13. The method of claim 7 including receiving an array of sensor information gathered at various traffic locations by the real world data collection system.\n14. The method of claim 7 including using a loss function in the training phase to examine and correct results of the training provided to the plurality of trajectory prediction models.\n15. A non-transitory machine-useable storage medium embodying instructions which, when executed by a machine, cause the machine to:\nreceive training data, by a data processor in a computing system, from a real world data collection system, the training data including data from at least one image generating device;\nperform a training phase to train a plurality of trajectory prediction models;\nperform a simulation to generate a different vicinal scenario for each simulated vehicle in an iteration of a simulation, the different vicinal scenarios corresponding to different vehicle status, traffic patterns, or environmental conditions being simulated, provide vehicle intention data corresponding to a data representation of various types of simulated vehicle or driver intentions, generate a trajectory corresponding to perception data and the vehicle intention data, execute at least one of the plurality of trained trajectory prediction models to generate a distribution of predicted vehicle trajectories for each of a plurality of simulated vehicles of the simulation based on a corresponding vicinal scenario and the vehicle intention data, select at least one vehicle trajectory from the distribution based on pre-defined criteria, and update a state and trajectory of each of the plurality of simulated vehicles based on the selected vehicle trajectory from the distribution; and\nconfigure an autonomous vehicle control system using the plurality of trained prediction models and predicted traffic trajectory information from the simulation.\n16. The non-transitory machine-useable storage medium of claim 15 wherein the instructions include machine learnable components.\n17. The non-transitory machine-useable storage medium of claim 15 wherein the instructions are executed over multiple iterations.\n18. The non-transitory machine-useable storage medium of claim 15 wherein the distribution of predicted vehicle trajectories includes data indicative of a degree of likelihood or probability that a particular simulated vehicle will actually traverse a corresponding trajectory of the distribution.\n19. The non-transitory machine-useable storage medium of claim 15 wherein the instructions being further configured to receive an array of sensor information gathered at various traffic locations by the real world data collection system.\n20. The non-transitory machine-useable storage medium of claim 15 wherein the instructions are configured to train the plurality of trajectory prediction models under different scenarios and different driver intentions.",
    "status": "Active",
    "citations_own": [
        "WO2005098751A1",
        "WO2005098739A1",
        "WO2005098782A1",
        "US20090024357A1",
        "US7689559B2",
        "US20100106356A1",
        "US20100226564A1",
        "WO2010109419A1",
        "US20100281361A1",
        "US20100292886A1",
        "US20110206282A1",
        "US8041111B1",
        "US8064643B2",
        "US20120083947A1",
        "US8164628B2",
        "EP2448251A2",
        "US20120140076A1",
        "US20120274629A1",
        "US8378851B2",
        "US8401292B2",
        "WO2013045612A1",
        "US8553088B2",
        "US20140114556A1",
        "US20140145516A1",
        "US20140198184A1",
        "WO2014201324A1",
        "US8917169B2",
        "US8993951B2",
        "US9008369B2",
        "US9025880B2",
        "US9042648B2",
        "WO2015083009A1",
        "WO2015103159A1",
        "US9118816B2",
        "US9117133B2",
        "WO2015125022A2",
        "US9120485B1",
        "US9122954B2",
        "US9147255B1",
        "US9147353B1",
        "US9176006B2",
        "US9183447B1",
        "US20150321699A1",
        "WO2015186002A2",
        "US9233659B2",
        "US9233688B2",
        "US9277132B2",
        "US20160059855A1",
        "US9280711B2",
        "US9299004B2",
        "US9297641B2",
        "US20160094774A1",
        "US9317776B1",
        "US9330334B2",
        "US9355635B2",
        "US20160200317A1",
        "US20160210528A1",
        "WO2016135736A2",
        "US9436880B2",
        "US9443163B2",
        "US9459515B2",
        "EP3081419A1",
        "US20160325743A1",
        "US20170016734A1",
        "WO2017013875A1",
        "US9555803B2",
        "US20170031361A1",
        "US20170039890A1",
        "US9612123B1",
        "US20170123428A1",
        "US20170124781A1",
        "US20170132334A1",
        "US20170269561A1",
        "CN107452207A",
        "US20170364776A1",
        "US20180086344A1",
        "US20180120843A1",
        "US20180164804A1",
        "US10019011B1",
        "US20180349547A1",
        "US20190025853A1",
        "US20190072973A1",
        "US20190072966A1",
        "US20190129436A1",
        "US20190129831A1",
        "US20190163181A1",
        "US20190163182A1",
        "US10466716B1",
        "US20190337525A1",
        "US20190367020A1",
        "US20200047769A1",
        "US10564643B2",
        "US10569773B2",
        "US20200082248A1",
        "US10710592B2",
        "US10782693B2",
        "US10830669B2",
        "US10953881B2",
        "US10953880B2"
    ],
    "citations_ftf": [
        "US7103460B1",
        "US7783403B2",
        "US6777904B1",
        "US20080249667A1",
        "US7839292B2",
        "US20100049397A1",
        "US8385688B2",
        "US8392117B2",
        "US9002632B1",
        "US8509982B2",
        "US8625889B2",
        "US8824797B2",
        "FR2984254B1",
        "JP5605381B2",
        "US9476970B1",
        "US9134402B2",
        "US9111444B2",
        "US9092430B2",
        "US8788134B1",
        "US9342074B2",
        "US9438878B2",
        "US9315192B1",
        "US9738280B2",
        "DE102014205170A1",
        "CN105100134A",
        "US9720418B2",
        "US9457807B2",
        "US9746550B2",
        "KR101664582B1",
        "US10635761B2",
        "US10019657B2",
        "DE102015211926A1",
        "US10346996B2",
        "US9587952B1",
        "EP3141926B1",
        "WO2017095493A2",
        "US9632502B1",
        "WO2017079341A2",
        "US9568915B1",
        "US9535423B1",
        "US10394245B2",
        "CN114900858A",
        "CN109937343B",
        "US10210756B2",
        "US11112796B2",
        "US20190164007A1"
    ],
    "citedby_own": [
        "US20230004165A1"
    ],
    "citedby_ftf": [
        "MX2019009397A",
        "KR102090919B1",
        "US10481044B2",
        "US10782693B2",
        "US10782694B2",
        "US10953881B2",
        "US10953880B2",
        "WO2019089015A1",
        "US11027751B2",
        "US11295455B2",
        "US10562538B2",
        "US11084504B2",
        "US10860018B2",
        "JP2019105684A",
        "EP3759563A4",
        "US10740914B2",
        "US11120688B2",
        "US11370446B2",
        "US11584379B2",
        "US11030364B2",
        "US11577750B2",
        "US20200166896A1",
        "CN113366495A",
        "US11676063B2",
        "US11763191B2",
        "US11403853B2",
        "US11591012B2",
        "CN114761942A",
        "US11635758B2",
        "US11480963B2",
        "US11613269B2",
        "US11300957B2",
        "US20210200229A1",
        "US11409287B2",
        "US11577746B2",
        "US11714971B2",
        "CN111339649B",
        "US11644331B2",
        "US11702101B2",
        "US20210276587A1",
        "US20210286924A1",
        "US11782438B2",
        "CN116194350A",
        "CN112133089B",
        "US20220048503A1",
        "CN114283576B",
        "US11321211B1",
        "CN112307566B",
        "CN112347567B",
        "CN112758106B",
        "CN112885079B",
        "CN112818598A",
        "CN113159096A",
        "GB202102789D0",
        "CN112926657A",
        "CN113325855B",
        "CN113959446A",
        "US20230159033A1",
        "WO2023196207A1",
        "US11491987B1",
        "CN115221722A",
        "CN115203062B"
    ]
}