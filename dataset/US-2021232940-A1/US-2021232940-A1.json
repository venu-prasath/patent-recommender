{
    "patent_id": "US-2021232940-A1",
    "title": "Encoding and transmission of knowledge, data and rules for explainable ai ",
    "assignee": "UMNAI Limited",
    "publication_date": "2021-07-29",
    "patent_link": "https://patents.google.com/patent/US20210232940A1/en",
    "inventors": [
        "Angelo Dalli",
        "Mauro PIRRONE"
    ],
    "classifications": [
        "G06N5/025",
        "G06N5/045",
        "G06N3/042",
        "G06N3/048",
        "G06N3/049",
        "G06N3/08",
        "G06N3/088",
        "G06N5/022",
        "G06N7/01",
        "G16H50/20",
        "G06N5/048"
    ],
    "abstract": "A method for encoding and transmitting knowledge, data and rules, such as for an explainable AI system, may be shown and described. In an exemplary embodiment, the rules may be presented in the disjunctive normal form using first order symbolic logic. Thus, the rules may be machine and human readable, and may be compatible with any known programming language. In an exemplary embodiment, rules may overlap, and a priority function may be assigned to prioritize rules in such an event. The rules may be implemented in a flat or a hierarchical structure. An aggregation function may be used to merge results from multiple rules and a split function may be used to split results from multiple rules. In an exemplary embodiment, rules may be implemented as an explainable neural network (XNN), explainable transducer transformer (XTT), or any other explainable system.",
    "claims": "\n1. A method for encoding and transmitting knowledge, comprising:\npartitioning a set of data to form a plurality of partitions based on a plurality of features found in the data, wherein each partition includes data with related features, comprising:\ndetermining a localization trigger for each partition;\nfitting one or more local models to one or more partitions, wherein a local model in the one or more local models corresponds to each partition in the one or more partitions, wherein fitting one or more local models to the one or more partitions comprises providing a local partition input to each partition in the one or more partitions and receiving a local partition output for said partition in the one or more partitions;\ndetermining, for each partition, an equation specific to said partition, wherein each equation comprises one or more coefficients, wherein each coefficient corresponds to one or more of: a level of importance of each feature, a boundary of a feature, a boundary of a partition, possible feature values, feature discontinuity boundaries, feature continuity characteristics, and a transformed feature value, and wherein each equation is configured to produce an answer given a corresponding input based on a set of relevant coefficients among the plurality of coefficients;\ndetermining an explanation relating to each partition, the explanation comprising information corresponding to the set of relevant coefficients;\nidentifying one or more rules for each partition, each rule comprising the localization trigger and the equation; and\ngenerating explanations associated with each rule.\n2. The method for encoding and transmitting knowledge of claim 1, wherein one or more partitions overlap, wherein the method further comprises selecting, with a priority function, one specific partition in the one or more partitions to use as the partition when the one or more partitions overlap.\n3. The method for encoding and transmitting knowledge of claim 1, further comprising presenting the answer in the form of at least one of a probability and a predicted value.\n4. The method for encoding and transmitting knowledge of claim 1, further comprising presenting the answer in a binary form along with a probability of accuracy.\n5. The method for encoding and transmitting knowledge of claim 1, further comprising presenting the explanation in a human-understandable form.\n6. The method for encoding and transmitting knowledge of claim 1, further comprising producing one or more additional explanations corresponding to one answer.\n7. The method for encoding and transmitting knowledge of claim 1, further comprising identifying a target user for which the answer and the explanation is intended and personalizing the answer and the explanation based on the identification of the target user and one or more external factors, wherein the external factors include data from one or more of: goal-task-action-plan models, question-answering and interactive systems, Reinforcement Learning world models, user/agent models, and workflow systems.\n8. The method for encoding and transmitting knowledge of claim 1, further comprising identifying an answer context and an explanation context, by identifying and recording one or more external factors affecting at least one of the answer and the explanation.\n9. The method for encoding and transmitting knowledge of claim 1, further comprising structuring the rules in a hierarchy.\n10. The method for encoding and transmitting knowledge of claim 1, further comprising encoding the answer and explanation in a machine-readable form.\n11. The method for encoding and transmitting knowledge of claim 1, further comprising applying one or more transformations, forming a transformation function pipeline, wherein the transformation function pipeline comprises one or more linear and non-linear transformations, wherein the transformations are applied to the one or more local models.\n12. The method for encoding and transmitting knowledge of claim 1, further comprising receiving user feedback and iteratively determining additional applicable rules based on the user feedback, adding the additional rules to a set of rules comprising the one or more rules, and generating explanations associated with the additional rules.\n13. A system for encoding and transmitting knowledge, the system comprising a processor and a memory and configured to implement steps of:\npartitioning a set of data to form a plurality of partitions based on a plurality of features found in the data, wherein each partition includes data with related features, comprising:\ndetermining a localization trigger for each partition;\nfitting one or more local models to one or more partitions, wherein a local model in the one or more local models corresponds to each partition in the one or more partitions, wherein fitting one or more local models to the one or more partitions comprises providing a local partition input to each partition in the one or more partitions and receiving a local partition output for said partition in the one or more partitions;\ndetermining, for each partition, an equation specific to said partition, wherein each equation comprises one or more coefficients, wherein each coefficient corresponds to one or more of: a level of importance of each feature, a boundary of a feature, a boundary of a partition, possible feature values, feature discontinuity boundaries, feature continuity characteristics, and a transformed feature value, and wherein each equation is configured to produce an answer given a corresponding input based on a set of relevant coefficients among the plurality of coefficients;\ndetermining an explanation relating to each partition, the explanation comprising information corresponding to the set of relevant coefficients;\nidentifying one or more rules for each partition, each rule comprising the localization trigger and the equation; and\ngenerating explanations associated with each rule.\n14. The system for encoding and transmitting knowledge of claim 13, further comprising identifying a target user for which the answer and the explanation is intended and personalizing the answer and the explanation based on the identification of the target user.\n15. The system for encoding and transmitting knowledge of claim 13, further comprising identifying an answer context and an explanation context, by identifying and recording one or more external factors affecting at least one of the answer, justification, and the explanation.\n16. The system for encoding and transmitting knowledge of claim 13, further comprising receiving user feedback and iteratively determining additional applicable rules based on the user feedback, adding the additional rules to a set of rules comprising the one or more rules, and generating explanations associated with the additional rules.\n17. A non-transitory computer-readable medium containing program code that, when executed, causes a processor to perform steps of:\npartitioning a set of data to form a plurality of partitions based on a plurality of features found in the data, wherein each partition includes data with related features, comprising:\ndetermining a localization trigger for each partition;\nfitting one or more local models to one or more partitions, wherein a local model in the one or more local models corresponds to each partition in the one or more partitions, wherein fitting one or more local models to the one or more partitions comprises providing a local partition input to each partition in the one or more partitions and receiving a local partition output for said partition in the one or more partitions;\ndetermining, for each partition, an equation specific to said partition, wherein each equation comprises one or more coefficients, wherein each coefficient corresponds to one or more of: a level of importance of each feature, a boundary of a feature, a boundary of a partition, possible feature values, feature discontinuity boundaries, feature continuity characteristics, and a transformed feature value, and wherein each equation is configured to produce an answer given a corresponding input based on a set of relevant coefficients among the plurality of coefficients;\ndetermining an explanation relating to each partition, the explanation comprising information corresponding to the set of relevant coefficients;\nidentifying one or more rules for each partition, each rule comprising the localization trigger and the equation; and\ngenerating explanations associated with each rule.\n18. The non-transitory computer-readable medium containing program code of claim 17, further comprising encoding the answer in a machine-readable form and presenting the explanation in a human-understandable form.\n19. The non-transitory computer-readable medium containing program code of claim 17, further comprising presenting the answer in the form of at least one of: an enumerated value, a classification, a probability, a binary value with a probability of accuracy, a regressed value, a predicted value with a probability of accuracy, an ordered sequence of predicted values, an ordered sequence of regressed values, an ordered sequence of enumerated values, and an ordered sequence of classifications.\n20. The non-transitory computer-readable medium containing program code of claim 17, further comprising receiving user feedback and iteratively determining additional applicable rules based on the user feedback, adding the additional rules to a set of rules comprising the one or more rules, and generating explanations associated with the additional rules.\n21. The method for encoding and transmitting knowledge of claim 1, wherein the rules are represented in one of: if-then format, a disjunctive normal form, conjunctive normal form, first-order logic assertions, Boolean logic, first order logic, second order logic, propositional logic, predicate logic, modal logic, probabilistic logic, many-valued logic, fuzzy logic, intuitionistic logic, non-monotonic logic, non-reflexive logic, quantum logic, and paraconsistent logic.\n22. The method for encoding and transmitting knowledge of claim 1, wherein the method is implemented as one or more of an explainable neural network (XNN), explainable transducer transformer (XTT), explainable spiking network (XSN), explainable memory network (XMN), explainable reinforcement learning agent (XRL), explainable generative adversarial network (XGAN), or an explainable autoencoder/decoder (XAED).\n23. The method for encoding and transmitting knowledge of claim 1, wherein an aggregation function merges results from multiple partitions.\n24. The method for encoding and transmitting knowledge of claim 1, wherein a split function splits at least one partition into two or more partitions.\n25. The method for encoding and transmitting knowledge of claim 11, wherein the transformation pipeline is further configured to perform transformations that analyze one or more temporally ordered data sequences according to the value of one or more variables.\n26. The system for encoding and transmitting knowledge of claim 13, wherein the system is implemented on one or more of a field programmable gate array (FPGA), application specific integrated circuit (ASIC), a neuromorphic computing architecture, and a quantum computing architecture.\n27. The method for encoding and transmitting knowledge of claim 1, wherein the localization trigger is based on a causal model and further comprises a plurality of conditions on a plurality of attributes with causal variables taken from one or more of a structural causal model or a causal directed acyclic graph.\n28. The method for encoding and transmitting knowledge of claim 11, wherein the transformation transforms the prediction output to be structured as one of: a hierarchical tree or network, a causal diagram, a directed or undirected graph, a multimedia structure, and a set of hyperlinked graphs.\n29. The method for encoding and transmitting knowledge of claim 1, wherein the explanation indicates the presence of one or more of: bias, strength, weakness, and level of confidence.\n30. The method for encoding and transmitting knowledge of claim 1, further comprising a causal analysis.\n31. The method for encoding and transmitting knowledge of claim 1, further comprising converting the resulting set of rules into an explainable neural network.\n32. The method for encoding and transmitting knowledge of claim 1, further comprising integrating the set of rules with an expert system.\n33. The method for encoding and transmitting knowledge of claim 1, wherein the method is implemented as one or more of workflows, process flows, process description, state-transition charts, Petri networks, electronic circuits, logic gates, optical circuits, digital-analogue hybrid circuits, bio-mechanical interface, bio-electrical interface, or quantum circuits.\n34. The method for encoding and transmitting knowledge of claim 1, further comprising integrating the set of rules with a digital-analogue hybrid system, optical system, quantum entangled system, bio-electrical interface, bio-mechanical interface, entangled photon source, photonic processor, interferometer, or neural interface.",
    "status": "Pending",
    "citations_own": [],
    "citations_ftf": [
        "US11645541B2",
        "US11615331B2",
        "US11386342B2"
    ],
    "citedby_own": [
        "US20210295427A1",
        "CN113486600A"
    ],
    "citedby_ftf": []
}