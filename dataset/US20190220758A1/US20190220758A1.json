{
    "patent_link": "https://patents.google.com/patent/US20190220758A1/en",
    "patent_id": "US20190220758A1",
    "title": "Systems and methods for fault tolerance recover during training of a model of a classifier using a distributed system",
    "abstract": "A distributed system for training a classifier is provided. The system comprises machine learning (ML) workers and a parameter server (PS). The PS is configured for parallel processing to provide the model to each of the ML workers, receive model updates from each of the ML workers, and iteratively update the model using each model update. The PS contains gradient datasets associated with a respective ML worker, for storing a model-update-identification (delta-M-ID) indicative of the computed model update and the respective model update, a global dataset that stores, the delta-M-ID, an identification of the ML worker (ML-worker-ID) that computed the model update, and a model version that marks a new model in PS that is computed from merging the model update with a previous model in PS; and a model download dataset that stores the ML-worker-ID and the model version of each transmitted model.",
    "inventors": [
        "Roman Talyansky",
        "Zach Melamed",
        "Natan Peterfreund",
        "Zuguang WU"
    ],
    "assignee": "Huawei Technologies Co Ltd",
    "classifications": [
        "G06N20/00",
        "G06N5/043",
        "G06F17/18",
        "G06F18/214",
        "G06F18/24",
        "G06K9/6256",
        "G06K9/6267",
        "G06N20/20",
        "G06F11/1479"
    ],
    "claims": "\n1. A system for training a classifier, the system comprising:\na plurality of machine learning (ML) workers each comprising at least one processor configured for computing a model update for a model of the classifier parameterized by a set of model parameters;\na parameter server (PS) comprising at least one processor, the parameter server being configured to provide the model of the classifier to each of the ML workers, receive respective model updates from each of the plurality of ML workers, and iteratively update the model of the classifier using each received model update; and\none or more storage devices storing:\na plurality of gradient datasets each associated with a respective ML worker of the plurality of ML workers, wherein each gradient dataset stores a model-update-identification (delta-M-ID) indicative of the respective model update computed by the respective ML worker, and stores the respective model update associated with each respective delta-M-ID;\na global dataset that stores, the delta-M-ID associated with each model update used by the PS in each respective iteration to update the model of the classifier, an identification of the ML worker (ML-worker-ID) that computed the model update associated with the delta-M-ID of the respective iteration, and a model version that marks a new model of the classifier in PS that is computed from merging the model update with a previous model of the classifier in PS; and\na model download dataset that stores the ML-worker-ID and the model version associated with each transmission of the model of the classifier from the PS to a certain ML worker of the plurality of ML workers.\n2. The system according to claim 1,\nwherein, in response to a first ML worker of the plurality of ML workers computing a first model update, the first model update and the first delta-M-ID associated with the first model update are stored in the first gradient dataset associated with the first ML worker;\nwherein, in response to the PS creating a second model of the classifier by merging the first model update with the first model of the classifier, the following are stored in the global dataset: the first delta-M-ID of the first model update, the ML-worker-ID of the first ML worker, and a second model version of the second model of the classifier;\nwherein in response to a second ML worker of the plurality of ML workers receiving the second model of the classifier from the PS, the second model version of the second model of the classifier and a second ML-worker-ID of the second ML worker are stored in the model download dataset.\n3. The system according to claim 1, further comprising:\na controller computing device associated with the PS, wherein the controller is configured to:\nreceive an indication of a failure in a processor of the at least one processor of the PS;\naccess the model download dataset to identify a second model version and an associated second ML-worker-ID of a second ML-worker that downloaded a second model of the classifier, wherein the second model version denotes the most recent entry in the model download dataset after the first model version;\naccess the second ML-worker using the second ML-worker-ID obtained from the model download dataset, and retrieve the second model of the classifier according to the second model version obtained from the model download dataset; and\ninitialize the PS using the second model of the classifier.\n4. The system according to claim 3, wherein the controller is further configured to:\naccess the global dataset to retrieve a third delta-M-ID and a third ML-worker-ID associated with a third model version, wherein the third model version denotes the most recent entry in the global dataset after the second model version;\naccess a third ML-worker according to the third ML-worker-ID to retrieve a third model update according to the third delta-M-ID;\ninstruct the PS to merge the third model update with the second model to recover the third model of the classifier corresponding to the third model of the classifier prior to the failure.\n5. The system according to claim 3, wherein the controller is further configured to:\nreceive an indication of a failure in a processor of the at least one processor of the second ML-worker;\naccess the model download dataset to identify the first model version and the associated first ML-worker-ID of the first ML-worker that downloaded the first model of the classifier, wherein the first model version denotes the entry in the model download dataset before the second model version;\naccess the first ML-worker using the first ML-worker-ID obtained from the model download dataset, and retrieve the first model of the classifier according to the first model version obtained from the model download dataset; and\ninitialize the PS using the first model of the classifier.\n6. The system according to claim 5, wherein the controller is further configured to:\naccess the global dataset to retrieve the second delta-M-ID and a third delta-M-ID and the second ML-worker-ID and a third ML-worker-ID associated with the second model version and a third model version, respectively, wherein the second and third model versions denote the entries in the global dataset after the first model version;\naccess the second and third ML-worker according to the second and third ML-worker-IDs to retrieve the second and third model updates according to the second and third delta-M-IDs;\ninstruct the PS to merge the second and third model updates with the first model of the classifier to recover a third model of the classifier corresponding to the third model of the classifier prior to the failure of at least one of the processors of the plurality of processors of PS.\n7. The system according to claim 1, wherein the number of entries of model version and associated ML-worker-IDs in the model download dataset is selected according to a probability that each ML-worker with a corresponding ML-worker-ID stored in the model download dataset that fails during the recovery process is less than a predefined requirement.\n8. The system according to claim 7, further comprising:\na controller computing device associated with the model download dataset, wherein the controller is configured to:\ndelete the oldest entry of model version and associated ML-worker-ID stored in the model download dataset in response to a new entry of model version and associated ML-worker-ID being added and stored in the model download dataset, to maintain a same number of entries;\ndelete the entries from the global dataset having a value of the model version that represents earlier or equal values of the model version of the oldest entry in the model download dataset that has been deleted;\ninstruct removal of entries associated with gradient datasets having values of the delta-M-ID that appear in corresponding entries of the global dataset that are deleted.\n9. The system according to claim 1, wherein a number of entries storing delta-M-ID and associated model update in each gradient dataset associated with each ML-worker is at most two when the plurality of ML-workers have computational performance characteristics within a tolerance.\n10. The system according to claim 1, wherein a number of entries N in the model download dataset is chosen such that a probability that all N ML workers, whose ML-worker-IDs are stored in the model download dataset, fail during the recovery process is below a defined negligible probability value.\n11. The system according to claim 1, wherein a plurality of weights of a fully connected layer in each model update is implemented as a multiplication of two vectors.\n12. The system according to claim 1, wherein the PS is implemented using a distributed system comprising a plurality of computing devices each including at least one processor.\n13. The system according to claim 1, wherein at least two of the ML workers are implemented using distinct computing devices.\n14. A method for training a classifier by a plurality of machine learning (ML) workers, the method comprising:\nproviding, by a parameter server (PS), a model of the classifier to each ML worker of the plurality ML workers;\nreceiving, by the PS, model updates from each ML worker of the plurality of ML workers;\nstoring a model-update-identification (delta-M-ID) indicative of the respective model update computed by the respective ML worker;\nstoring the respective model update associated with each respective delta-M-ID; and\niteratively updating the model of the classifier based on each received model updates;\nstoring an identification of the ML worker, the ML-worker-ID that computed the model update associated with the delta-M-ID of the respective iteration, and a model version that marks a new model of the classifier in PS that is computed from merging the model update with a previous model of the classifier in PS.\n15. The method according to claim 14, wherein a plurality of weights of a fully connected layer in each model update is implemented as a multiplication of two vectors.\n16. The method according to claim 14, wherein the PS is implemented using a distributed system comprising a plurality of computing devices each including at least one processor.\n17. The method according to claim 14, wherein at least two of the ML workers are implemented using distinct computing devices.\n18. A computer-readable storage medium storing a computer program that, when executed by at least one processor of at least one computer, causes training of a classifier by a plurality of machine learning (ML) workers, by performing the steps of.\nproviding, by a parameter server (PS), a model of the classifier to each ML worker of the plurality ML workers;\nreceiving, by the PS, model updates from each ML worker of the plurality of ML workers;\nstoring a model-update-identification (delta-M-ID) indicative of the respective model update computed by the respective ML worker;\nstoring the respective model update associated with each respective delta-M-ID; and\niteratively updating the model of the classifier based on each received model updates;\nstoring an identification of the ML worker, the ML-worker-ID that computed the model update associated with the delta-M-ID of the respective iteration, and a model version that marks a new model of the classifier in PS that is computed from merging the model update with a previous model of the classifier in PS.\n19. The computer-readable storage medium according to claim 18, wherein the PS is implemented using a distributed system comprising a plurality of computing devices each including at least one processor.\n20. The computer-readable storage medium according to claim 18, wherein at least two of the ML workers are implemented using distinct computing devices.",
    "status": "Active",
    "citations_own": [],
    "citations_ftf": [
        "US9098326B1",
        "US9218573B1",
        "US20150324690A1",
        "US9984337B2",
        "CN104714852B",
        "US10915850B2"
    ],
    "citedby_own": [
        "US20190385043A1",
        "CN110909027A",
        "US20210049408A1",
        "US11132602B1",
        "US11249861B2",
        "WO2022041143A1",
        "US20220253443A1",
        "US11475304B2",
        "US11620570B2"
    ],
    "citedby_ftf": [
        "EP3564873B1",
        "EP3564883B1",
        "EP3565218B1",
        "CN109102075A",
        "US20200202243A1",
        "CN110490316B",
        "CN111105016B",
        "US11748835B2",
        "US11218293B2",
        "CN111461343B"
    ]
}