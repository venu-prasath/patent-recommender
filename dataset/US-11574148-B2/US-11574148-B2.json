{
    "patent_id": "US-11574148-B2",
    "title": "System and method for deep reinforcement learning ",
    "assignee": "Royal Bank Of Canada",
    "publication_date": "2023-02-07",
    "patent_link": "https://patents.google.com/patent/US11574148B2/en",
    "inventors": [
        "Bilal KARTAL",
        "Pablo Francisco HERNANDEZ LEAL",
        "Matthew Edmund TAYLOR"
    ],
    "classifications": [
        "G06K9/6262",
        "G06N3/006",
        "G06F18/217",
        "G06F18/2185",
        "G06N3/045",
        "G06N3/0454",
        "G06N3/047",
        "G06N3/0472",
        "G06N3/08",
        "G06N3/084",
        "G06N5/01",
        "G06N7/01",
        "G06V10/82"
    ],
    "abstract": "A computer system and method for extending parallelized asynchronous reinforcement learning for training a neural network is described in various embodiments, through coordinated operation of plurality of hardware processors or threads such that each functions as a worker agent that is configured to simultaneously interact with a target computing environment for local gradient computation based on a loss determination and to update global network parameters based at least on local gradient computation to train the neural network through modifications of weighted interconnections between interconnected computing units as gradient computation is conducted across a plurality of iterations of a target computing environment, the loss determination including at least a policy loss term (actor), a value loss term (critic), and an auxiliary control loss. Variations are described further where the neural network is adapted to include terminal state prediction and action guidance.",
    "claims": "\n1. A computer system for extending parallelized asynchronous reinforcement learning to include terminal state prediction for training a neural network, the system comprising:\na data storage configured to store one or more data structures representing interconnected computing units of the neural network, including data fields storing weighted interconnections between the interconnected computing units;\na plurality of hardware processors or threads of hardware processors;\na parallel processing controller configured for coordinated operation of the plurality of hardware processors or threads of hardware processors such that each functions as a worker agent that is configured to simultaneously interact with a target computing environment for local gradient computation based on a loss determination and to update global network parameters based at least on the local gradient computation to train the neural network through modifications of the weighted interconnections between the interconnected computing units as gradient computation is conducted across a plurality of iterations of the target computing environment;\nwherein the loss determination includes at least a policy loss term (actor), a value loss term (critic), and a terminal state prediction control loss.\n2. The system as claimed in claim 1, wherein the terminal state prediction control loss is determined by using mean squared error between the predicted probability of closeness to a terminal state of any given state.\n3. The system as claimed in claim 2, wherein the neural network is configured to utilize a terminal state prediction control loss function in accordance with the relation:\n4. The system as claimed in claim 3, wherein the neural network includes a plurality of convolutional layers, and a plurality of fully connected layers.\n5. The system as claimed in claim 4, wherein the neural network is configured to utilize a loss function in accordance with the relation:\n\nA3C-TP= A3C+\u03bbTP TP\nwherein \u03bbTP comprises a weight term; and\nwherein A3C, comprises the policy loss term and the value loss term.\n6. A computer system for extending parallelized asynchronous reinforcement learning to include planner imitation for training a neural network, the system comprising:\na data storage configured to store one or more data structures representing interconnected computing units of the neural network, including data fields storing weighted interconnections between the interconnected computing units;\na plurality of hardware processors or threads of hardware processors;\na parallel processing controller configured for coordinated operation of the plurality of hardware processors or threads of hardware processors such that each functions as a worker agent that is configured to simultaneously interact with a target computing environment for local gradient computation based on a loss determination and to update global network parameters based at least on the local gradient computation to train the neural network through modifications of the weighted interconnections between the interconnected computing units as gradient computation is conducted across a plurality of iterations of the target computing environment;\nwherein the loss determination includes at least a policy loss term (actor), a value loss term (critic), and a planner imitation control loss.\n7. The system as claimed in claim 6, wherein the planner imitation control loss is determined by using a supervised cross entropy loss between a one-hot encoded action used by a planner in response to an observation, and an action that a policy network would take for the same observation during an episode of length N.\n8. The system as claimed in claim 7, wherein the neural network is configured to utilize a planner imitation control loss function in accordance with the relation:\n9. The system as claimed in claim 8, wherein the neural network includes a plurality of convolutional layers, and a plurality of fully connected layers.\n10. The system as claimed in claim 9, wherein the neural network is configured to utilize a loss function in accordance with the relation:\n\nPI-A3C= A3C+\u03bbPI PI\nwherein \u03bbPI is a weight term; and\nwherein A3C, comprises the policy loss term and the value loss term.\n11. A computer implemented method for extending parallelized asynchronous reinforcement learning to include terminal state prediction for training a neural network, the method comprising:\nmaintaining one or more data structures representing interconnected computing units of the neural network, including data fields storing weighted interconnections between the interconnected computing units;\ncoordinating operation of a plurality of hardware processors or threads of hardware processors such that each functions as a worker process that is configured to simultaneously interact with a target computing environment for local gradient computation based on a loss determination function and to update global network parameters based at least on the local gradient computation to train the neural network through modifications of the weighted interconnections between the interconnected computing units as gradient computation is conducted across a plurality of iterations of the target computing environment;\nwherein the loss determination function includes at least a policy loss term (actor), a value loss term (critic), and a terminal state prediction control loss.\n12. The method as claimed in claim 11, wherein the terminal state prediction control loss is determined by using mean squared error between the predicted probability of closeness to a terminal state of any given state.\n13. The method as claimed in claim 12, wherein the neural network is configured to utilize a terminal state prediction control loss function in accordance with the relation:\n14. The method as claimed in claim 13, wherein the neural network includes a plurality of convolutional layers, and a plurality of fully connected layers.\n15. The method as claimed in claim 14, wherein the neural network is configured to utilize a loss function in accordance with the relation:\n\nA3C-TP= A3C+\u03bbTP TP\nwherein \u03bbTP comprises a weight term; and\nwherein A3C, comprises the policy loss term and the value loss term.\n16. A computer implemented method for extending parallelized asynchronous reinforcement learning to include planner imitation for training a neural network, the method comprising:\nmaintaining one or more data structures representing interconnected computing units of the neural network, including data fields storing weighted interconnections between the interconnected computing units;\ncoordinating operation of a plurality of hardware processors or threads of hardware processors such that each functions as a worker process that is configured to simultaneously interact with a target computing environment for local gradient computation based on a loss determination function and to update global network parameters based at least on the local gradient computation to train the neural network through modifications of the weighted interconnections between the interconnected computing units as gradient computation is conducted across a plurality of iterations of the target computing environment;\nwherein the loss determination function includes at least a policy loss term (actor), a value loss term (critic), and a planner imitation control loss.\n17. The method as claimed in claim 16, wherein the planner imitation control loss is determined by using a supervised cross entropy loss between a one-hot encoded action used by a planner in response to an observation, and an action that a policy network would take for the same observation during an episode of length N.\n18. The method as claimed in claim 17, wherein the neural network is configured to utilize a planner imitation control loss function in accordance with the relation:\n19. The method as claimed in claim 18, wherein the neural network includes a plurality of convolutional layers, and a plurality of fully connected layers.\n20. The method as claimed in claim 19, wherein the neural network is configured to utilize a loss function in accordance with the relation:\n\nPI-A3C= A3C+\u03bbPI PI\nwherein \u03bbPI is a weight term; and\nwherein A3C, comprises the policy loss term and the value loss term.",
    "status": "Active",
    "citations_own": [
        "US8103606B2",
        "US20170358293A1",
        "US20180060301A1",
        "US20190049957A1",
        "US20190258938A1",
        "US20190258918A1",
        "US20200033869A1",
        "US20200143208A1",
        "US20200143239A1",
        "US20210192358A1",
        "US20220165253A1"
    ],
    "citations_ftf": [],
    "citedby_own": [],
    "citedby_ftf": [
        "DE102019203024A1",
        "US11308362B2",
        "DE102019210372A1",
        "US11221897B2",
        "US20210216879A1",
        "US20210334646A1",
        "US11055639B1",
        "US11394799B2",
        "CN111814988B",
        "CN111818570B",
        "CN112149824B",
        "US11710276B1",
        "CN112307778A",
        "CN112487146B",
        "CN112732436B",
        "CN112859889B",
        "CN112966431B",
        "CN112905794B",
        "CN112784499A",
        "CN113052372B",
        "WO2022207443A1",
        "CN113189983B",
        "CN113192330B",
        "CN113076745A",
        "CN113392396B",
        "CN113554166A",
        "CN113485313A",
        "CN113326902B",
        "WO2023023848A1",
        "CN113688977A",
        "CN113759929B",
        "US20230117768A1",
        "CN113890596B",
        "CN114217524A",
        "CN114077258A",
        "CN113918826B",
        "CN114242169B",
        "CN114374638A",
        "CN114613159B",
        "CN114189470B",
        "CN114613168B",
        "CN114609918B",
        "CN114779792B",
        "CN115330276B",
        "CN116384469B"
    ]
}