{
    "patent_id": "US-11553874-B2",
    "title": "Dental image feature detection ",
    "assignee": "VideaHealth, Inc.",
    "publication_date": "2023-01-17",
    "patent_link": "https://patents.google.com/patent/US11553874B2/en",
    "inventors": [
        "Florian Hillen"
    ],
    "classifications": [
        "A61B5/4547",
        "A61B5/7267",
        "A61B5/743",
        "A61B5/7475",
        "G06F18/214",
        "G06F18/2413",
        "G06K9/6256",
        "G06N20/00",
        "G06N3/045",
        "G06N3/08",
        "G06T7/0012",
        "G06T7/0014",
        "G06V10/764",
        "G06V10/774",
        "G16H20/30",
        "G16H30/40",
        "G16H50/20",
        "G06N20/20",
        "G06N7/01",
        "G06T2207/10072",
        "G06T2207/10116",
        "G06T2207/20081",
        "G06T2207/20084",
        "G06T2207/30036",
        "G06T2207/30096",
        "G06V2201/03"
    ],
    "abstract": "A system includes a computing device that includes a memory configured to store instructions. The system also includes a processor to execute the instructions to perform operations that include receiving data representing one or more images of dental information associated with a patient. Operations include adjusting the data representing the one or more images of dental information into a predefined format, wherein adjusting the data includes adjusting one or more visual parameters associated with the one or more images of dental information. Operations include using a machine learning system to determine a confidence score for one or more portions of the one or more images of dental information, and producing a representation of the determined confidence scores to identify one or more detected features present in the one or more images of dental information.",
    "claims": "\n1. A computing device implemented method comprising:\nreceiving data representing one or more images of dental information associated with a patient, the one or more images containing one or more unidentified image features of the patient;\nadjusting the data representing the one or more images of dental information into a predefined format, wherein adjusting the data includes adjusting one or more visual parameters associated with the one or more images of dental information;\nusing a machine learning system based on one or more neural networks to determine one or more confidence scores for the presence of at least one detectable feature,\neach of the one or more confidence scores corresponding to one or more distinct portions of the one or more images of dental information,\nthe at least one detectable feature representing at least one or more diseases, one or more prior procedures performed upon the patient, or one or more anatomical structure characteristics, and\nthe machine learning system being trained with dental imagery comprising one or more training images, wherein annotations of the one or more training images are provided by different annotators;\nproducing a representation based on the determined one or more confidence scores, the representation comprising information about\na presence or absence of the at least one detectable feature, and\na tooth number associated with the at least one detectable feature, if present, within the one or more images of dental information,\nwherein the information in the produced representation is selectively presented based upon user input;\ncomparing the at least one detectable feature and patient data to represent a mapping and to represent a measure of a dental management system, and\ngenerating a report comprising the at least one detectable feature.\n2. The computing device implemented method of claim 1, further comprising: transferring the data representing the one or more images of dental information associated with the patient to one or more networked computing devices for statistical analysis.\n3. The computing device implemented method of claim 1, wherein the machine learning system employs a convolution neural network.\n4. The computing device implemented method of claim 1, wherein the at least one detectable feature includes a radiolucent lesion or an opaque lesion.\n5. The computing device implemented method of claim 1, wherein the produced representation includes a graphical representation that is presentable on a user interface of the computing device.\n6. The computing device implemented method of claim 1, further comprising producing a graphical alert.\n7. The computing device implemented method of claim 1, further comprising: providing the at least one detectable feature to the machine learning system for further training of the machine learning system.\n8. A system comprising:\na computing device comprising:\na memory configured to store instructions; and\na processor to execute the instructions to perform operations comprising:\nreceiving data representing one or more images of dental information associated with a patient, the one or more images containing one or more unidentified image features of the patient;\nadjusting the data representing the one or more images of dental information into a predefined format, wherein adjusting the data includes adjusting one or more visual parameters associated with the one or more images of dental information;\nusing a machine learning system based on one or more neural networks to determine one or more confidence scores for the presence of at least one detectable feature,\neach of the one or more confidence scores corresponding to one or more distinct portions of the one or more images of dental information,\nthe at least one detectable feature representing at least one or more diseases, one or more prior procedures performed upon the patient, or one or more anatomical structure characteristics, and\nthe machine learning system being trained with dental imagery comprising one or more training images, wherein annotations of the one or more training images are provided by different annotators;\nproducing a representation based on the determined one or more confidence scores, the representation comprising information about\na presence or absence of the at least one detectable feature, and\na tooth number associated with the at least one detectable feature, if present, within the one or more images of dental information,\nwherein the information in the produced representation is selectively presented based upon user input;\ncomparing the at least one detectable feature and patient data to represent a mapping and to represent a measure of a dental management system, and\ngenerating a report comprising the at least one detectable feature.\n9. The system of claim 8, wherein the operations further comprise: transferring the data representing the one or more images of dental information associated with the patient to one or more networked computing devices for statistical analysis.\n10. The system of claim 8, wherein the machine learning system employs a convolution neural network.\n11. The system of claim 8, wherein the at least one detectable feature includes a radiolucent lesion or an opaque lesion.\n12. The system of claim 8, wherein the produced representation includes a graphical representation that is presentable on a user interface of the computing device.\n13. The system of claim 8, wherein the operations further comprise producing a graphical alert.\n14. One or more non-transitory computer readable media storing instructions that are executable by a processing device, and upon such execution cause the processing device to perform operations comprising:\nreceiving data representing one or more images of dental information associated with a patient, the one or more images containing one or more unidentified image features of the patient;\nadjusting the data representing the one or more images of dental information into a predefined format, wherein adjusting the data includes adjusting one or more visual parameters associated with the one or more images of dental information;\nusing a machine learning system based on one or more neural networks to determine one or more confidence scores for the presence of at least one detectable feature,\neach of the one or more confidence scores corresponding to one or more distinct portions of the one or more images of dental information,\nthe at least one detectable feature representing at least one or more diseases, one or more prior procedures performed upon the patient, or one or more anatomical structure characteristics, and\nthe machine learning system being trained with dental imagery comprising one or more training images, wherein annotations of the one or more training images are provided by different annotators;\nproducing a representation based on the determined one or more confidence scores, the representation comprising information about\na presence or absence of the at least one detectable feature, and\na tooth number associated with the at least one detectable feature, if present, within the one or more images of dental information,\nwherein the information in the produced representation is selectively presented based upon user input;\ncomparing the at least one detectable feature and patient data to represent a mapping and to represent a measure of a dental management system, and\ngenerating a report comprising the at least one detectable feature.\n15. The non-transitory computer readable media of claim 14, wherein the operations further comprise: transferring the data representing the one or more images of dental information associated with the patient to one or more networked computing devices for statistical analysis.\n16. The non-transitory computer readable media of claim 14, wherein the machine learning system employs a convolution neural network.\n17. The non-transitory computer readable media of claim 14, wherein the at least one detectable feature includes a radiolucent lesion or an opaque lesion.\n18. The non-transitory computer readable media of claim 14, wherein the produced representation includes a graphical representation that is presentable on a user interface of the computing device.\n19. The non-transitory computer readable media of claim 14, wherein the operations further comprise producing a graphical alert."
}