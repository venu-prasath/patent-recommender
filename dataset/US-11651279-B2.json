{
    "patent_id": "US-11651279-B2",
    "title": "LAT based answer generation using anchor entities and proximity ",
    "assignee": "International Business Machines Corporation",
    "publication_date": "2023-05-16",
    "patent_link": "https://patents.google.com/patent/US11651279B2/en",
    "inventors": [
        "Timothy A. Bishop",
        "Stephen A. Boxwell",
        "Benjamin L. Brumfield",
        "Stanley J. Vernier"
    ],
    "classifications": [
        "G06N20/00",
        "G06F16/00",
        "G06F40/284",
        "G06F40/295",
        "G06N5/022"
    ],
    "abstract": "Mechanisms are provided for implementing a proximity based candidate answer pre-processor engine that outputs a sub-set of candidate answers to a question and answer (QA) system. The mechanisms receive a lexical answer type (LAT) and an entity specified in an input natural language question as well as an ontology data structure representing a corpus of natural language content. The mechanisms identify a set of candidate answers having associated nodes in the ontology data structure that are within a predetermined proximity of a node corresponding to the entity, and a sub-set of candidate answers in the set of candidate answers having an entity type corresponding to the LAT. The mechanisms output, to the QA system, the sub-set of candidate answers as candidate answers to the input natural language question for evaluation and selection of a final answer to the input natural language question.",
    "claims": "\n1. A method, in a data processing system comprising at least one processor and at least one memory, wherein the at least one memory comprises instructions that are executed by the at least one processor to configure the data processing system to implement a proximity based candidate answer pre-processor engine that outputs a sub-set of candidate answers to a question and answer (QA) system, the method comprising:\nreceiving, by the proximity based candidate answer pre-processor engine, a lexical answer type (LAT), an entity specified in an input natural language question, and an ontology data structure representing a corpus of natural language content, wherein the ontology data structure comprises a graph of nodes representing entities and edges connecting nodes, where the edges represent relationships between connected entities;\nidentifying, by the proximity based candidate answer pre-processor engine, a set of candidate answers having associated nodes in the ontology data structure that are within a predetermined proximity of a node corresponding to the entity;\nidentifying, by the proximity based candidate answer pre-processor engine, a sub-set of candidate answers in the set of candidate answers having an entity type corresponding to the LAT; and\noutputting, by the proximity based candidate answer pre-processor engine, to the QA system, the sub-set of candidate answers as a final sub-set of candidate answers to the input natural language question for evaluation and selection of a final answer to the input natural language question, wherein outputting the sub-set of candidate answers to the QA system comprises bypassing at least one question processing stage of a QA pipeline of the QA system, such that the at least one question processing stage is not executed when processing the question.\n2. The method of claim 1, wherein the input natural language question comprises a plurality of entities and wherein the entity specified in the input natural language question is part of a sub-set of anchor entities in the plurality of entities, and wherein anchor entities are entities having an entity type that has been previously identified to provide accurate results in generating candidate answers for input natural language questions.\n3. The method of claim 2, wherein the entity types associated with anchor entities are specified in a configuration data structure of the proximity based candidate answer pre-processor engine, and wherein the entity types of anchor entities are specified either manually by a user or are automatically identified based on a machine learning process.\n4. The method of claim 2, wherein the entity types associated with anchor entities are specified in a configuration data structure of the proximity based candidate answer pre-processor engine, and wherein the method further comprises:\nperforming, by the proximity based candidate answer pre-processor engine, a data driven machine learning operation on training natural language questions to learn strengths of relationships between entity types of entities in the training natural language questions and entities specified in correct answers to the training natural language questions;\nselecting, by the proximity based candidate answer pre-processor engine, a set of entity types having strengths equal to or greater than a threshold strength as entity types for anchor entities; and\nstoring the selected set of entity types as an anchor entity configuration data structure in the proximity based candidate answer pre-processor engine.\n5. The method of claim 2, wherein the identifying operations are performed for each anchor entity in the sub-set of anchor entities, and wherein outputting the sub-set of candidate answers to the QA system comprises aggregating the sub-sets of candidate answers generated for each anchor entity to generate the final sub-set of candidate answers.\n6. The method of claim 1, wherein the predetermined proximity specifies a nodal distance from the node corresponding to the entity, and wherein the proximity based candidate answer pre-processor engine operates with regard to a plurality of domains of input natural language questions, and wherein there are different tunable predetermined proximities, specifying different nodal distances, for at least two of the domains in the plurality of domains.\n7. The method of claim 1, further comprising:\nperforming, by the QA system, evidence based confidence scoring of each of the candidate answers in the final sub-set of candidate answers;\nranking, by the QA system, the candidate answers in the final sub-set of candidate answers based on confidence scores associated with the candidate answers;\nselecting, by the QA system, a final candidate answer as an answer to the input natural language question based on the ranking of the candidate answers; and\noutputting, by the QA system to an originator system that provided the input natural language question, the final candidate answer as the answer to the input natural language question.\n8. The method of claim 7, wherein:\nthe input natural language question comprises a plurality of entities and wherein a confidence score weight value associated with candidate answers generated based on the entity is set according to a determined strength of the entity,\nthe strength of the entity is determined based on an evaluation, during training of the proximity based candidate answer pre-processor engine using training natural language questions, of relationships between an entity type of the entity to entities specified in correct answers to the training natural language questions, and\nperforming evidence based confidence scoring of each of the candidate answers comprises applying the confidence score weight value to confidence score calculations for the candidate answers.\n9. The method of claim 1, wherein the at least one question processing stage is bypassed at least by outputting, by the proximity based candidate answer pre-processor engine, to a scoring stage of the QA pipeline, the sub-set of candidate answers as a final sub-set of candidate answers to the input natural language question for evaluation and selection of a final answer to the input natural language question.\n10. The method of claim 1, wherein the at least one question processing stage comprises at least one of a question decomposition stage or a hypothesis generation stage of the QA pipeline.\n11. A computer program product comprising a computer readable storage medium having a computer readable program stored therein, wherein the computer readable program, when executed on a computing device, causes the computing device to implement a proximity based candidate answer pre-processor engine that outputs a sub-set of candidate answers to a question and answer (QA) system at least by:\nreceiving a lexical answer type (LAT), an entity specified in an input natural language question, and an ontology data structure representing a corpus of natural language content, wherein the ontology data structure comprises a graph of nodes representing entities and edges connecting nodes, where the edges represent relationships between connected entities;\nidentifying a set of candidate answers having associated nodes in the ontology data structure that are within a predetermined proximity of a node corresponding to the entity;\nidentifying a sub-set of candidate answers in the set of candidate answers having an entity type corresponding to the LAT; and\noutputting, to the QA system, the sub-set of candidate answers as a final sub-set of candidate answers to the input natural language question for evaluation and selection of a final answer to the input natural language question, wherein outputting the sub-set of candidate answers to the QA system comprises bypassing at least one question processing stage of a QA pipeline of the QA system, such that the at least one question processing stage is not executed when processing the question.\n12. The computer program product of claim 11, wherein the input natural language question comprises a plurality of entities and wherein the entity specified in the input natural language question is part of a sub-set of anchor entities in the plurality of entities, and wherein anchor entities are entities having an entity type that has been previously identified to provide accurate results in generating candidate answers for input natural language questions.\n13. The computer program product of claim 12, wherein the entity types associated with anchor entities are specified in a configuration data structure of the proximity based candidate answer pre-processor engine, and wherein the entity types of anchor entities are specified either manually by a user or are automatically identified based on a machine learning process.\n14. The computer program product of claim 12, wherein the entity types associated with anchor entities are specified in a configuration data structure of the proximity based candidate answer pre-processor engine, and wherein the computer readable program further causes the proximity based candidate answer pre-processor engine to output the sub-set of candidate answers to the QA system at least by:\nperforming a data driven machine learning operation on training natural language questions to learn strengths of relationships between entity types of entities in the training natural language questions and entities specified in correct answers to the training natural language questions;\nselecting a set of entity types having strengths equal to or greater than a threshold strength as entity types for anchor entities; and\nstoring the selected set of entity types as an anchor entity configuration data structure in the proximity based candidate answer pre-processor engine.\n15. The computer program product of claim 12, wherein the identifying operations are performed for each anchor entity in the sub-set of anchor entities, and wherein outputting the sub-set of candidate answers to the QA system comprises aggregating the sub-sets of candidate answers generated for each anchor entity to generate the final sub-set of candidate answers.\n16. The computer program product of claim 11, wherein the predetermined proximity specifies a nodal distance from the node corresponding to the entity, and wherein the proximity based candidate answer pre-processor engine operates with regard to a plurality of domains of input natural language questions, and wherein there are different tunable predetermined proximities, specifying different nodal distances, for at least two of the domains in the plurality of domains.\n17. The computer program product of claim 11, wherein the computer readable program further causes the computing device to:\nperform, by the QA system, evidence based confidence scoring of each of the candidate answers in the final sub-set of candidate answers;\nrank, by the QA system, the candidate answers in the final sub-set of candidate answers based on confidence scores associated with the candidate answers;\nselect, by the QA system, a final candidate answer as an answer to the input natural language question based on the ranking of the candidate answers; and\noutput, by the QA system to an originator system that provided the input natural language question, the final candidate answer as the answer to the input natural language question.\n18. The computer program product of claim 17, wherein:\nthe input natural language question comprises a plurality of entities and wherein a confidence score weight value associated with candidate answers generated based on the entity is set according to a determined strength of the entity,\nthe strength of the entity is determined based on an evaluation, during training of the proximity based candidate answer pre-processor engine using training natural language questions, of relationships between an entity type of the entity to entities specified in correct answers to the training natural language questions, and\nperforming evidence based confidence scoring of each of the candidate answers comprises applying the confidence score weight value to confidence score calculations for the candidate answers.\n19. An apparatus comprising:\na processor; and\na memory coupled to the processor, wherein the memory comprises instructions which, when executed by the processor, cause the processor to implement a proximity based candidate answer pre-processor engine that outputs a sub-set of candidate answers to a question and answer (QA) system at least by:\nreceiving a lexical answer type (LAT), an entity specified in an input natural language question, and an ontology data structure representing a corpus of natural language content, wherein the ontology data structure comprises a graph of nodes representing entities and edges connecting nodes, where the edges represent relationships between connected entities;\nidentifying a set of candidate answers having associated nodes in the ontology data structure that are within a predetermined proximity of a node corresponding to the entity;\nidentifying a sub-set of candidate answers in the set of candidate answers having an entity type corresponding to the LAT; and\noutputting, to the QA system, the sub-set of candidate answers as a final sub-set of candidate answers to the input natural language question for evaluation and selection of a final answer to the input natural language question, wherein outputting the sub-set of candidate answers to the QA system comprises bypassing at least one question processing stage of a QA pipeline of the QA system, such that the at least one question processing stage is not executed when processing the question."
}