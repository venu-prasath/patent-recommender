{
    "patent_id": "US-11615341-B2",
    "title": "Customizable machine learning models ",
    "assignee": "Shl Us Llc",
    "publication_date": "2023-03-28",
    "patent_link": "https://patents.google.com/patent/US11615341B2/en",
    "inventors": [
        "Arya Ryan Aminzadeh",
        "Aman Cherian Alexander"
    ],
    "classifications": [
        "G06N20/00",
        "G06N7/005",
        "G06N7/01"
    ],
    "abstract": "Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for customizable machine learning models. In some implementations, data is received, including (i) example data sets and (ii) data specifying one or more criteria to be assessed. A set of multiple models is trained, where each model in the set of models is trained using a training data set comprising a different subset of the example data sets. Output of the models is obtained for various example data sets, and a combination of n-grams is selected based on the outputs. The example data sets are used to train a classifier to evaluate input data with respect to the specified one or more criteria based on whether the input data includes the n-grams in the selected combination of n-grams.",
    "claims": "\n1. A method comprising:\naccessing, by a computing system comprising one or more computers, (i) example data sets that each include information about a different individual and (ii) data specifying one or more criteria to be assessed;\nfor each of multiple features identified the example data sets, determining, by the computing system, one or more measures of association between the feature and the one or more criteria being assessed;\nselecting, by the computing system, a first set of features based on the measures of association;\nevaluating, by the computing system, multiple groups of models, wherein each group of models includes a plurality of different models that are (i) each trained to generate a prediction based on a same subset of features from among the first set of features and (ii) each trained based on a different subset of the example data sets, wherein the models in different groups are trained to generate predictions based on different subsets of the features in the first set of features;\nobtaining, by the computing system, data indicating a second set of features selected based on the evaluating the multiple groups of models; and\nproviding, by the computing system, a model that is configured to generate a prediction with respect to the one or more criteria based on data for the second set of features selected based on the evaluating the multiple groups of models.\n2. The method of claim 1, comprising using the provided model to generate a classification result with respect to the one or more criteria based on whether input data include features in the second set of features.\n3. The method of claim 1, comprising using, by the computing system, the example data sets to train a classifier to evaluate input data specifying values for the second set of features and determine, based on the input data, a likelihood that a person having the values specified by the input data would achieve a minimum level of performance specified by the one or more criteria.\n4. The method of claim 1, wherein the first set of features includes one or more features representing the occurrence of different n-grams in text and one or more features that do not represent the occurrence of n-grams in text.\n5. The method of claim 1, wherein selecting the second set of features is performed based on (i) efficacy measures respectively indicating predictive ability of different groups of models and (ii) consistency measures respectively indicating variability of the predictive ability within different groups of models.\n6. The method of claim 5, wherein the consistency measures are measures of consistency of efficacy in the respective groups of models.\n7. The method of claim 5, wherein the consistency measures comprise, for each group of the multiple groups of models, a standard deviation or variance of the efficacy across the plurality of models in the group that are trained to generate predictions based on the same subset of features.\n8. The method of claim 1, wherein data for at least some of the example data sets comprise at least one of resume data, curriculum vitae data, job application data, job performance data, education data, or work history data.\n9. The method of claim 1, wherein the features in the first set of features are first features, and wherein the method further comprises:\nfor each of the first features, determining, by the computing system, a correlation measure indicative of a frequency that the first feature occurs in example data sets determined to satisfy the specified one or more criteria; and\nselecting, by the computing system, a group of the first features based on the correlation measures,\nwherein the different subsets of the first features that occur in the example data sets are different combinations of first features from the group of the first features selected based on the correlation measures.\n10. The method of claim 9, wherein selecting the group of the first features based on the correlation measures comprises:\ngenerating a rank-ordered list of the first features according to associated correlation measures; and\nselecting a number of the top-ranked first features from the rank-ordered list as the group of the first features.\n11. The method of claim 10, wherein the rank-ordered list of first features is generated using a binary logistic regression.\n12. The method of claim 9, wherein the models in each set of multiple models are configured to classify input data by:\nobtaining, with a machine learning model, weights associated with each first feature in the combination of first features using a training data set.\n13. The method of claim 9, comprising determining, based on the data specifying one or more criteria to be assessed, a cost function that is used to define a top performance tier;\nwherein the plurality of different models comprise a set of multiple models for each of multiple different combinations of the first features;\nwherein evaluating the plurality of different models comprises determining, for each model in each of the sets of models corresponding to different combinations of the first features, an efficacy for each model based on (i) a performance metric of example data sets ranked within the top performance tier by the model and (ii) an average performance metric of the example data sets within a test data set; and\nwherein the method comprises selecting, as the second set of features, the features in one of the combinations of first features based on the efficacy determined for the model that corresponds to the one of the combinations of first features.\n14. The method of claim 13, wherein the performance metric of example data sets ranked within the top performance tier by the model is an average of performance metrics of example data sets ranked within the top performance tier by the model.\n15. The method of claim 1, wherein the one or more criteria to be assessed specify (i) a particular performance measure with which to evaluate the example data sets and (ii) a threshold value of the performance measure that is needed for an example data set to satisfy the one or more criteria; and\nwherein determining the one or more measures of association between the feature and the one or more criteria being assessed comprises determining, for each of the multiple features, a measure quantifying the prevalence of the feature among example data sets that satisfy the one or more criteria by being scored as having at least the threshold value for the performance measure.\n16. The method of claim 1, wherein, in each group of models, each of the plurality of models in the group is trained based on a different division of the example data sets into training data subset and a testing data subset, wherein each division of the example data sets is performed randomly or pseudo-randomly.\n17. A system comprising:\none or more computers; and\none or more computer-readable media storing instructions that, when executed by the one or more computers, cause the one or more computers to perform operations comprising:\naccessing, by the one or more computers, (i) example data sets that each include information about a different individual and (ii) data specifying one or more criteria to be assessed;\nfor each of multiple features identified the example data sets, determining, by the one or more computers, one or more measures of association between the feature and the one or more criteria being assessed;\nselecting, by the one or more computers, a first set of features based on the measures of association;\nevaluating, by the one or more computers, multiple groups of models, wherein each group of models includes a plurality of different models that are (i) each trained to generate a prediction based on a same subset of features from among the first set of features and (ii) each trained based on a different subset of the example data sets, wherein the models in different groups are trained to generate predictions based on different subsets of the features in the first set of features;\nobtaining, by the one or more computers, data indicating a second set of features selected based on the evaluating the multiple groups of models; and\nproviding, by the one or more computers, a model that is configured to generate a prediction with respect to the one or more criteria based on data for the second set of features selected based on the evaluating the multiple groups of models.\n18. The system of claim 17, wherein the first set of features includes one or more features representing the occurrence of different n-grams in text and one or more features that do not represent the occurrence of n-grams in text.\n19. The system of claim 17, wherein the selecting the second set of features is performed based on (i) efficacy measures for the respective groups of models, each efficacy measure indicating an accuracy of predictions of the corresponding group of models and (ii) consistency measures for the respective groups of models, each consistency measure indicating variability in the accuracy of predictions of across the models in the group of models corresponding to the consistency measure.\n20. One or more non-transitory computer-readable media storing instructions that, when executed by one or more computers, cause the one or more computers to perform operations comprising:\naccessing, by the one or more computers, (i) example data sets that each include information about a different individual and (ii) data specifying one or more criteria to be assessed;\nfor each of multiple features identified the example data sets, determining, by the one or more computers, one or more measures of association between the feature and the one or more criteria being assessed;\nselecting, by the one or more computers, a first set of features based on the measures of association;\nevaluating, by the one or more computers, multiple groups of models, wherein each group of models includes a plurality of different models that are (i) each trained to generate a prediction based on a same subset of features from among the first set of features and (ii) each trained based on a different subset of the example data sets, wherein the models in different groups are trained to generate predictions based on different subsets of the features in the first set of features;\nobtaining, by the one or more computers, data indicating a second set of features selected based on the evaluating the multiple groups of models; and\nproviding, by the one or more computers, a model that is configured to generate a prediction with respect to the one or more criteria based on data for the second set of features selected based on the evaluating the multiple groups of models."
}