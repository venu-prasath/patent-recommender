{
    "patent_id": "US-2022230056-A1",
    "title": "Neuromorphic hardware for processing a knowledge graph represented by observed triple statements and method for training a learning component ",
    "assignee": "Siemens Aktiengesellschaft",
    "publication_date": "2022-07-21",
    "patent_link": "https://patents.google.com/patent/US20220230056A1/en",
    "inventors": [
        "Josep SOLER GARRIDO",
        "Dominik Dold"
    ],
    "classifications": [
        "G06N3/063",
        "G06N3/049",
        "G05B13/0265",
        "G06N3/04",
        "G06N3/042",
        "G06N3/047",
        "G06N3/065",
        "G06N3/08",
        "G06N3/084",
        "G06N3/088",
        "G06N5/02",
        "G06N5/022",
        "G06N5/041",
        "G05B2219/25428",
        "G06N3/045",
        "G06N3/048",
        "G06N5/01",
        "G06N7/01"
    ],
    "abstract": "Provided is neuromorphic hardware for processing a knowledge graph, with a learning component, having an input layer containing node embedding populations of neurons, with each node embedding populations representing an entity contained in the observed statements, and an output layer, containing output neurons configured for representing a likelihood for each possible triple statement, and modeling a probabilistic, sampling-based model derived from an energy function, wherein the observed statements have minimal energy, and with a control component, configured for switching the learning component into a data-driven learning mode, configured for training the component with a maximum likelihood learning algorithm minimizing energy in the probabilistic, sampling-based model, using only the observed statements, which are assigned low energy values, in which the learning component supports generation of triple statements, and into a model-driven learning mode, configured for training the component, with the learning component learning to assign high energy values.",
    "claims": "\n1. A neuromorphic hardware for processing a knowledge graph represented by observed triple statements,\nwith a learning component,\nconsisting of\nan input layer containing node embedding populations of neurons, with each node embedding populations representing an entity contained in the observed triple statements, and\nan output layer, containing output neurons configured for representing a likelihood for each possible triple statement,\nand modeling a probabilistic, sampling-based model derived from an energy function, wherein the observed triple statements have minimal energy, and\nwith a control component, configured for switching the learning component\ninto a data-driven learning mode, configured for training the component with a maximum likelihood learning algorithm minimizing energy in the probabilistic, sampling-based model, using only the observed triple statements, which are assigned low energy values,\ninto a sampling mode, in which the learning component supports generation of triple statements, and\ninto a model-driven learning mode, configured for training the component with the maximum likelihood learning algorithm using only the generated triple statements, with the learning component learning to assign high energy values to the generated triple statements.\n2. The neuromorphic hardware according to claim 1,\nwherein the control component is configured to alternatingly\npresent inputs to the learning component by selectively activating subject and object populations among the node embedding populations,\nset hyperparameters of the learning component, in particular a factor (\u03b7) that modulates learning updates of the learning component,\nread output of the learning component, and\nuse output of the learning component as feedback to the learning component.\n3. The neuromorphic hardware according to claim 1,\nwherein the output layer has one output neuron for each possible relation type of the knowledge graph.\n4. The neuromorphic hardware according to claim 3,\nwherein the output neurons are stochastic dendritic output neurons, storing embeddings of relations that are given between a subject and an object in the observed triple statements in their dendrites, summing all dendritic branches into a final score, which is transformed into a probability using an activation function.\n5. The neuromorphic hardware according to claim 4,\nwherein depending on the mode of the learning component, an output of the activation function is a prediction of the likelihood of a triple statement or a transition probability.\n6. The neuromorphic hardware according to claim 4,\nwherein learning updates for relation embeddings are computed directly in dendritic trees of the stochastic, dendritic output neurons.\n7. The neuromorphic hardware according to claim 1,\nwherein learning updates for entity embeddings are computed using static feedback connections from each output neuron to neurons of the node embedding populations.\n8. The neuromorphic hardware according to claim 1,\nwherein in the sampling mode, by sampling from the activation function, a binary output signals to the control component whether a triple statement is accepted.\n9. The neuromorphic hardware according to claim 1,\nwherein the neuromorphic hardware is an application specific integrated circuit, a field-programmable gate array, a wafer-scale integration, a hardware with mixed-mode VLSI neurons, or a neuromorphic processor, in particular a neural processing unit or a mixed-signal neuromorphic processor.\n10. The neuromorphic hardware according to claim 1,\nwherein the learning component contains first neurons forming a first node embedding population, representing a first entity contained in the observed triple statements by first spike times of the first neurons during a recurring time interval,\nwherein the learning component contains second neurons forming a second node embedding population, representing a second entity contained in the observed triple statements by second spike times of the second neurons during the recurring time interval, and\nwherein a relation between the first entity and the second entity is represented as the differences between the first spike times and the second spike times.\n11. The neuromorphic hardware according to claim 10,\nwherein the differences between the first spike times and the second spike times consider an order of the first spike times) in relation to the second spike times, or\nwherein the differences are absolute values.\n12. The neuromorphic hardware according to claim 10,\nwherein the relation is stored in one of the output neurons, and\nwherein the relation is in particular given by vector components that are stored in dendrites of the output neuron.\n13. The neuromorphic hardware according to claim 10,\nwherein the first neurons are connected to a monitoring neuron,\nwherein each first neuron is connected to a corresponding parrot neuron,\nwherein the parrot neurons are connected to the output neurons, and\nwherein the parrot neurons are connected to an inhibiting neuron.\n14. The neuromorphic hardware according to claim 10,\nwherein the first neurons and the second neurons are spiking neurons, in particular non-leaky integrate-and-fire neurons or current-based leaky integrate-and-fire neurons.\n15. The neuromorphic hardware according to claim 10,\nwherein each of the first neurons and second neurons only spikes once during the recurring time interval, or\nwherein only a first spike during the recurring time interval is counted.\n16. The neuromorphic hardware according to claim 1,\nwherein each node embedding population is connected to an inhibiting neuron, and therefore selectable by inhibition of the inhibiting neuron.\n17. An industrial device,\nwith the neuromorphic hardware according to claim 1.\n18. The industrial device according to claim 17,\nwherein the industrial device is a field device, an edge device, a sensor device, an industrial controller, in particular a PLC controller, an industrial PC implementing a SCADA system, a network hub, a network switch, in particular an industrial ethernet switch, or an industrial gateway connecting an automation system to cloud computing resources.\n19. The industrial device according to claim 17,\nwith at least one sensor and/or at least one data source configured for providing raw data, with an ETL component, configured for converting the raw data into the observed triple statements, using mapping rules,\nwith a triple store, storing the observed triple statements, and\nwherein the learning component is configured for performing an inference in an inference mode.\n20. The industrial device according to claim 19,\nwith a statement handler, configured for triggering an automated action based on the inference of the learning component.\n21. A server,\nwith a neuromorphic hardware according to claim 1.\n22. A method for training a learning component to learn inference on a knowledge graph represented by observed triple statements, comprising:\nswitching, by a control component, a learning component that is consisting of\nan input layer comprising node embedding populations, with each node embedding populations representing an entity contained in the observed triple statements, and\nan output layer, comprising output neurons configured for representing a likelihood for each possible triple statement,\nand modeling a probabilistic, sampling-based model derived from an energy function, wherein the observed triple statements have minimal energy,\ninto a data-driven learning mode, wherein the learning component is trained with a maximum likelihood learning algorithm minimizing energy in the probabilistic, sampling-based model, using only the observed triple statements, which are assigned low energy values,\nswitching, by the control component, the learning component into a sampling mode, in which the learning component supports generation of triple statements,\nswitching, by the control component, the learning component into a model-driven learning mode, wherein the learning component is trained with the maximum likelihood learning algorithm using only the generated triple statements, with the learning component learning to assign high energy values to the generated triple statements.\n23. The method according to claim 22,\nwherein the knowledge graph is an industrial knowledge graph describing parts of an industrial system,\nwith nodes of the knowledge graph representing physical objects including sensors, in particular industrial controllers, robots, drives, manufactured objects, tools and/or elements of a bill of materials, and\nwith nodes of the knowledge graph representing abstract entities including sensor measurements, in particular attributes, configurations or skills of the physical objects, production schedules and plans.\n24. A computer-readable storage media having stored thereon:\ninstructions executable by one or more processors of a computer system, wherein execution of the instructions causes the computer system to perform the method according to claim 22.\n25. The computer program,\nwhich is being executed by one or more processors of a computer system and performs the method according to claim 22.",
    "status": "Pending",
    "citations_own": [],
    "citations_ftf": [
        "CN107665230B",
        "CN111597352B"
    ],
    "citedby_own": [],
    "citedby_ftf": [
        "CN115456149B",
        "CN115457299B",
        "CN115829033B"
    ]
}