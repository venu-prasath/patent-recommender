{
    "patent_id": "US-11748480-B2",
    "title": "Policy-based detection of anomalous control and data flow paths in an application program ",
    "assignee": "Arkose Labs Holdings, Inc.",
    "publication_date": "2023-09-05",
    "patent_link": "https://patents.google.com/patent/US11748480B2/en",
    "inventors": [
        "Suresh Chari",
        "Ashish Kundu",
        "Ian Michael Molloy",
        "Dimitrios Pendarakis"
    ],
    "classifications": [
        "G06F21/566",
        "G06F8/433",
        "G06N20/00",
        "G06N5/022",
        "G06N7/01",
        "G06F2221/033",
        "G06N5/01"
    ],
    "abstract": "Anomalous control and data flow paths in a program are determined by machine learning the program's normal control flow paths and data flow paths. A subset of those paths also may be determined to involve sensitive data and/or computation. Learning involves collecting events as the program executes, and associating those event with metadata related to the flows. This information is used to train the system about normal paths versus anomalous paths, and sensitive paths versus non-sensitive paths. Training leads to development of a baseline \u201cprovenance\u201d graph, which is evaluated to determine \u201csensitive\u201d control or data flows in the \u201cnormal\u201d operation. This process is enhanced by analyzing log data collected during runtime execution of the program against a policy to assign confidence values to the control and data flows. Using these confidence values, anomalous edges and/or paths with respect to the policy are identified to generate a \u201cprogram execution\u201d provenance graph associated with the policy.",
    "claims": "\n1. A method of detecting anomalous behavior of an application program, comprising:\nreceiving trace data comprising instruction-level traces generated from multiple invocations of the application program, the instruction-level traces comprising control flow information for the application program;\nbased at least in part on the received trace data, building a baseline provenance graph generated at least in part by supervised machine learning incorporating a plurality of rounds of training, wherein the baseline provenance graph models a normal control flow or data flow in the application program, the baseline provenance graph comprising a plurality of edges or paths;\nbased at least in part on the baseline provenance graph, classifying at least one of the plurality of edges or paths associated with a control flow or data flow of the application program represented by the baseline provenance graph as a sensitive edge or path involving sensitive data or computation and at least one of the plurality of edges or paths associated with the control flow or data flow of the application program represented by the baseline provenance graph as a non-sensitive edge or path that does not involve sensitive data or computation;\nduring runtime execution of the application program against a policy, receiving log data;\nusing the received log data to assign confidence values to at least one of the control or data flows with respect to the policy;\nidentifying, from the assigned confidence values, one or more anomalous edges or paths of the plurality of edges or paths with respect to the policy, the anomalous edges or paths representing the anomalous behavior; and\nresponsive to detecting that the anomalous behavior occurs within the sensitive edge or path, taking a further corrective action.\n2. The method as described in claim 1 further including building a program execution provenance graph associated with the policy and that includes the control or data flows and their assigned confidence values.\n3. The method as described in claim 2 wherein the program execution provenance graph is built using machine learning.\n4. The method as described in claim 3 further including adjusting a confidence value assigned to a given control or data flow based on the machine learning.\n5. The method as described in claim 1 wherein the baseline provenance graph comprises a control flow graph, and a data flow graph.\n6. The method as described in claim 1 wherein the policy is one of: a security policy, and a compliance policy.\n7. The method as described in claim 2 further including reporting an application program behavior anomaly identified from the program execution provenance graph.\n8. An apparatus for detecting anomalous behavior of an application program, comprising:\na processor;\ncomputer memory holding computer program instructions executed by the processor, the computer program instructions configured to:\nreceive trace data comprising instruction-level traces generated from multiple invocations of the application program, the instruction-level traces comprising control flow information for the application program;\nbased at least in part on the received trace data, build a baseline provenance graph generated at least in part by supervised machine learning incorporating a plurality of rounds of training, wherein the baseline provenance graph models a normal control flow or data flow in the application program, the baseline provenance graph comprising a plurality of edges or paths;\nbased at least in part on the baseline provenance graph, classify at least one of the plurality of edges or paths associated with a control flow or data flow of the application program represented by the baseline provenance graph as a sensitive edge or path involving sensitive data or computation and at least one of the plurality of edges or paths associated with the control flow or data flow of the application program represented by the baseline provenance graph as a non-sensitive edge or path that does not involve sensitive data or computation;\nduring runtime execution of the application program against a policy, receive log data;\nuse the received log data to assign confidence values to at least one of the control or data flows with respect to the policy;\nidentify from the assigned confidence values one or more anomalous edges or paths of the plurality of edges or paths with respect to the policy, the anomalous edges or paths representing the anomalous behavior; and\nresponsive to detecting that the anomalous behavior occurs within the sensitive edge or path, take a further corrective action.\n9. The apparatus as described in claim 8 wherein the computer program instructions are further configured to build a program execution provenance graph associated with the policy and that includes the control or data flows and their assigned confidence values.\n10. The apparatus as described in claim 9 wherein the program execution provenance graph is built using machine learning.\n11. The apparatus as described in claim 10 wherein the computer program instructions are further configured to adjust a confidence value assigned to a given control or data flow based on the machine learning.\n12. The apparatus as described in claim 8 wherein the baseline provenance graph comprises a control flow graph, and a data flow graph.\n13. The apparatus as described in claim 8 wherein the policy is one of: a security policy, and a compliance policy.\n14. The apparatus as described in claim 9 wherein the computer program instructions are further configured to report an application program behavior anomaly identified from the program execution provenance graph.\n15. A computer program product in a non-transitory computer readable medium for use in a data processing system for detecting anomalous behavior of an application program the computer program product holding computer program instructions that, when executed by the data processing system, are configured to:\nreceive trace data comprising instruction-level traces generated from multiple invocations of the application program, the instruction-level traces comprising control flow information for the application program;\nbased at least in part on the received trace data, build a baseline provenance graph generated at least in part by supervised machine learning incorporating a plurality of rounds of training, wherein the baseline provenance graph models a normal control flow or data flow in the application program, the baseline provenance graph comprising a plurality of edges or paths;\nbased at least in part on the baseline provenance graph, classify at least one of the plurality of edges or paths associated with a control flow or data flow of the application program represented by the baseline provenance graph as a sensitive edge or path involving sensitive data or computation and at least one of the plurality of edges or paths associated with the control flow or data flow of the application program represented by the baseline provenance graph as a non-sensitive edge or path that does not involve sensitive data or computation;\nduring runtime execution of the application program against a policy, receive log data; and\nuse the received log data to assign confidence values to at least one of the control or data flows with respect to the policy;\nidentify from the assigned confidence values one or more anomalous edges or paths of the plurality of edges or paths with respect to the policy, the anomalous edges or paths representing the anomalous behavior; and\nresponsive to detecting that the anomalous behavior occurs within the sensitive edge or path, take a further corrective action.\n16. The computer program product as described in claim 15 wherein the computer program instructions are further configured to build a program execution provenance graph associated with the policy and that includes the control or data flows and their assigned confidence values.\n17. The computer program product as described in claim 16 wherein the program execution provenance graph is built using machine learning.\n18. The computer program product as described in claim 17 wherein the computer program instructions are further configured to adjust a confidence value assigned to a given control or data flow based on the machine learning.\n19. The computer program product as described in claim 15 wherein the baseline provenance graph comprises a control flow graph, and a data flow graph.\n20. The computer program product as described in claim 15 wherein the policy is one of: a security policy, and a compliance policy.\n21. The computer program product as described in claim 16 wherein the computer program instructions are further configured to report an application program behavior anomaly identified from the program execution provenance graph.",
    "status": "Active",
    "citations_own": [
        "US6847979B2",
        "US20150271030A1",
        "US20160028762A1",
        "US9306965B1",
        "US20180018459A1",
        "US10043006B2",
        "US20180225446A1"
    ],
    "citations_ftf": [
        "US8479188B2"
    ],
    "citedby_own": [],
    "citedby_ftf": [
        "US10476673B2",
        "US9967292B1",
        "US10904272B2",
        "US10389574B1",
        "US10038611B1",
        "US10270794B1",
        "CN108429746B",
        "US11366680B2",
        "US10411978B1",
        "US11601442B2",
        "US10740209B2",
        "US10594718B1",
        "US10719424B1",
        "US10965702B2",
        "US20210026969A1",
        "US11165814B2",
        "US10742530B1",
        "US11388072B2",
        "US10742677B1",
        "US11704129B2",
        "US11165823B2",
        "US11551230B2",
        "US11503054B2",
        "US11093371B1",
        "CN111596926B",
        "US11563756B2",
        "US11616790B2",
        "US11711379B2",
        "US11645397B2",
        "US20210406254A1",
        "US20230289460A1",
        "US11310256B2",
        "US11463466B2",
        "US20220138325A1",
        "CN112527307B",
        "CN112988443B",
        "CN112671671B",
        "US11374838B1",
        "EP4068127A1",
        "US11349861B1",
        "US20230034910A1",
        "US11797576B2",
        "US11296967B1",
        "US11733980B2",
        "US20230289444A1",
        "US20230308470A1",
        "US20230315609A1",
        "CN115543951B"
    ]
}