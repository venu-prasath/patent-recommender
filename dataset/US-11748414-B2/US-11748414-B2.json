{
    "patent_id": "US-11748414-B2",
    "title": "Methods and systems of operating computerized neural networks for modelling CSR-customer relationships ",
    "assignee": "Priyadarshini Mohanty, Pullak Kumar Mohanty",
    "publication_date": "2023-09-05",
    "patent_link": "https://patents.google.com/patent/US11748414B2/en",
    "inventors": [
        "Priyadarshini Mohanty",
        "Pullak Kumar Mohanty"
    ],
    "classifications": [
        "G06F16/90332",
        "G06F40/20",
        "G06F40/284",
        "G06N3/044",
        "G06N3/045",
        "G06N3/048",
        "G06N3/049",
        "G06N3/084",
        "G06N5/041",
        "G06Q10/06393",
        "G06Q30/01",
        "G06Q30/0201",
        "G06Q30/0282",
        "G06N20/10",
        "G06N3/047",
        "G06N5/01",
        "G06N5/025",
        "G06N5/04",
        "G06N7/01"
    ],
    "abstract": "In one aspect, a computerized method for operating computerized neural networks for modelling CSR-customer relationships includes the step of receiving a user query. The user query comprises a set of digital text from a customer as input into an online CSR system. The method includes the step of filtering out unnecessary content of the user query. The method includes the step of splitting filtered user query in a sentence wise manner. The method includes the step of feeding the tokenized user query into a contextualized word representation model. The method includes the step of generating a set of context-aware feature vectors from the contextualized word representation model. With the set of context-aware feature vectors, the method implements a decision-making function to generate an identified customer query. The method includes the step of receiving an agent response, wherein the agent response is a response to the user query, and wherein the agent response comprises a set of digital text from an agent. With an LSTM network, the method generates a user query tensor vector. With the LSTM network, generating an agent query tensor vector. The method includes the step of concatenating the user query tensor vector and the agent query tensor vector to produce a single tensor, wherein the single tensor is processable by a neural network.",
    "claims": "\n1. A computerized method for operating computerized neural networks for modelling customer service representative (CSR) customer relationships comprising:\nreceiving a user query, wherein the user query comprises a set of digital text from a customer as input into an online CSR system;\nfiltering out unnecessary content of the user query;\nsplitting filtered user query in a sentence wise manner;\nfeeding the tokenized user query into a contextualized word representation model;\ngenerating a set of context-aware feature vectors from the contextualized word representation model;\nwith the set of context-aware feature vectors, implementing a decision-making function to generate an identified customer query;\nreceiving an agent response, wherein the agent response is a response to the user query, and wherein the agent response comprises a set of digital text from an agent;\nwith a long short-term memory (LSTM) network, generating a user query tensor vector;\nwith the LSTM network, generating an agent query tensor vector;\nconcatenating the user query tensor vector and the agent query tensor vector to produce a single tensor, wherein the single tensor is processable by a neural network;\nproviding the single tensor to a Bi-Directional Gated recurrent unit (GRU) layer to capture both forward and backward sequential dependencies between the user query and the agent response output to a capsule neural network to predict an answer;\nreceiving the answer from the capsule neural network;\nimplementing a connected sigmoid layer on a plurality of answers to generate a final confidence score for each of the plurality of answers;\nimplementing an optimization model on a plurality of confidence-scored answers trained with a stochastic optimization and a cross entropy model to select an optimum answer; and\nformatting the optimum answer for output via a computer system of the user.\n2. The computerized method of claim 1, wherein the contextualized word representation model comprises an ELMo (Embeddings from Language Models) model.\n3. The computerized method of claim 2, wherein the ELMo model models a specified set of characteristics of each word use in the tokenized user query to determine how each word use in a context of the user query.\n4. The computerized method of claim 3, wherein the decision-making function used to generate an identified customer query comprises an LSTM network, wherein the LSTM networks comprises a set of LSTM units, and wherein the LSTM units comprises a building unit for layers of a recurrent neural network.\n5. The computerized method of claim 4, wherein the LSTM network captures a sequential dependency in each sentence and a sigmoid layer that provides a confidence score of each sentence being a question.\n6. The computerized method of claim 5, wherein the filtered user query is split in a sentence wise manner using a smart sentence tokenizer.\n7. A computerized method for operating computerized neural networks for modelling customer service representative (CSR) customer relationships comprising:\nreceiving a user query, wherein the user query comprises a set of digital text from a customer as input into an online CSR system;\nfiltering out unnecessary content of the user query;\nsplitting filtered user query in a sentence wise manner;\nfeeding the tokenized user query into a contextualized word representation model;\ngenerating a set of context-aware feature vectors from the contextualized word representation model;\nwith the set of context-aware feature vectors, implementing a decision-making function to generate an identified customer query;\nreceiving an agent response, wherein the agent response is a response to the user query, and wherein the agent response comprises a set of digital text from an agent;\nwith a long short-term memory (LSTM) network, generating a user query tensor vector;\nwith the LSTM network, generating an agent query tensor vector;\nconcatenating the user query tensor vector and the agent query tensor vector to produce a single tensor, wherein the single tensor is processable by a neural network; and\nproviding the single tensor to a Bi-Directional Gated recurrent unit (GRU) layer to capture both forward and backward sequential dependencies between the user query and the agent response output to a capsule neural network to predict an answer,\nwherein the contextualized word representation model comprises an ELMo (Embeddings from Language Models) model,\nwherein the ELMo model models a specified set of characteristics of each word use in the tokenized user query to determine how each word use in a context of the user query,\nwherein the decision-making function used to generate an identified customer query comprises an LSTM network, wherein the LSTM networks comprises a set of LSTM units, and wherein the LSTM units comprises a building unit for layers of a recurrent neural network,\nwherein the LSTM network captures a sequential dependency in each sentence and a sigmoid layer that provides a confidence score of each sentence being a question, and\nwherein the filtered user query is split in a sentence wise manner using a smart sentence tokenizer.",
    "status": "Active",
    "citations_own": [
        "US20180129742A1",
        "US20190197109A1",
        "US20190287685A1",
        "US20200105272A1",
        "US11228379B1"
    ],
    "citations_ftf": [],
    "citedby_own": [],
    "citedby_ftf": [
        "US10812417B2",
        "US10997372B2",
        "US11475329B2",
        "US11176502B2",
        "CN111898752A",
        "CN112231477B",
        "CN112328469B",
        "TWI744057B",
        "WO2022109203A1",
        "CN113190681B",
        "CN113010642A",
        "CN113362857A",
        "CN113890109B",
        "US20230113607A1",
        "CN116452212B",
        "CN116628284B"
    ]
}