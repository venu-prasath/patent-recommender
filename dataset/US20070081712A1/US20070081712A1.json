{
    "patent_link": "https://patents.google.com/patent/US20070081712A1/en",
    "patent_id": "US20070081712A1",
    "title": "System and method for whole body landmark detection, segmentation and change quantification in digital images",
    "abstract": "A method for segmenting digitized images includes providing a training set comprising a plurality of digitized whole-body images, providing labels on anatomical landmarks in each image of said training set, aligning each said training set image, generating positive and negative training examples for each landmark by cropping the aligned training volumes into one or more cropping windows of different spatial scales, and using said positive and negative examples to train a detector for each landmark at one or more spatial scales ranging from a coarse resolution to a fine resolution, wherein the spatial relationship between a cropping windows of a coarse resolution detector and a fine resolution detector is recorded.",
    "inventors": [
        "Xiaolei Huang",
        "Xiang Zhou",
        "Anna Jerebko",
        "Arun Krishnan",
        "Haiying Guan",
        "Toshiro Kubota",
        "Vaclav Potesil"
    ],
    "assignee": "Siemens Healthcare GmbH",
    "classifications": [
        "G06T7/174",
        "G06T7/155",
        "G06T7/33",
        "G06T7/38",
        "G06T2207/10072",
        "G06T2207/20016",
        "G06T2207/20081",
        "G06T2207/20164",
        "G06T2207/30004",
        "G06T2207/30204"
    ],
    "claims": "\n1. A method for segmenting digitized images comprising the steps of:\nproviding a training set comprising a plurality of digitized whole-body images, each image comprising a plurality of intensities corresponding to a domain of points on an 3-dimensional grid;\nproviding labels on anatomical landmarks in each image of said training set;\naligning each said training set image;\ngenerating positive and negative training examples for each landmark by cropping the aligned training volumes into one or more cropping windows of different spatial scales; and\nusing said positive and negative examples to train a detector for each landmark at one or more spatial scales ranging from a coarse resolution to a fine resolution, wherein the spatial relationship between a cropping windows of a coarse resolution detector and a fine resolution detector is recorded.\n2. The method of claim 1, wherein said training set images are aligned to a common target volume.\n3. The method of claim 1, further comprising testing said detector on a validation set of digitized whole-body images, wherein false positives are added into the negative training set and false negatives are added into the positive training set, wherein said detector is re-trained using said positive and negative examples.\n4. The method of claim 1, further comprising providing a new digitized image and a set of search window parameters and using at least one of said detectors to search for its associated landmark in said new image, and classifying the sub-volume within the search window as either as positive example that contains said landmark, or a negative example that does not contain said landmark.\n5. The method of claim 1, wherein a positive training example is generated by cropping a largest size landmark neighborhood to train a coarse-level detector, training a succession of higher resolution detectors on a succession of decreasing sized neighborhoods centered at the landmark.\n6. The method of claim 5, wherein a negative training example is generated by pre-selecting a sample from a training volume at each resolution for which a positive example is generated, wherein pre-selecting includes one or more of cropping a training volume at a location not centered on an anatomical landmark, cropping sub-volumes of a training volume at different spatial scales, and rotating a sub-volume.\n7. The method of claim 2, wherein aligning each training set image to a common target volume further comprises calculating transformations based on landmark correspondences, wherein a higher weight is given to those landmarks with less size and shape variability among the anatomical landmarks labeled in the training set.\n8. A method for quantifying changes across sub-volumes of digitized images comprising the steps of:\nproviding a plurality of new digitized images, said images representing a same patient at different time points;\nselecting a point in a sub-volume of interest in each of said plurality of images;\nsegmenting said sub-volume of interest in each image; and\nquantifying changes in the sub-volume of interest over the different images of one or more properties including intensity, volume, shape, topology, location, and texture.\n9. The method of claim 8, wherein said digitized images include positron emission tomography images and single photon emission computed tomography images.\n10. The method of claim 8, further comprising manually adjusting said segmentation results.\n11. The method of claim 8, wherein said point in said sub-volume of interest is manually selected in a first of said succession of images, and further comprising extracting a region containing said sub-volume of interest, for each succeeding image, extracting a plurality of regions, each region containing a sub-volume, calculating a likelihood that each sub-volume corresponds to the manually selected sub-volume, and selecting the maximum likelihood sub-volume in each succeeding image as the sub-volume that corresponds to the manually selected sub-volume of interest.\n12. The method of claim 8, wherein said points in said sub-volumes of interest in each of said plurality of images are automatically selected based on statistics of landmark appearances, landmark detection, determining the organ context of said sub-volumes, and a statistical classification of said sub-volume as being normal or abnormal, and further comprising establishing links between corresponding sub-volumes in each of said succession of images.\n13. The method of claim 8, wherein segmenting said sub-volume of interest further comprises:\nsetting said selected point in said sub-volume as a current point;\nselecting a set of neighboring points connected to said current point;\nselecting from said set of neighboring points a new point with a maximum associated value,\nwherein if said new point is not the current point, resetting said current point to be said new point, and repeating said steps of selecting a set of neighboring points and selecting a point with a maximum associated value until said new point is the same as said current point.\n14. The method of claim 13, further comprising:\ncomputing a segmentation threshold value;\nsetting a seed point as said new point with said maximum associated value in said set of neighboring points;\ninitializing a set of points in a segmentation mask;\nselecting those neighbors of said seed point whose associated value exceeds said threshold as being included in said sub-volume;\nfor each point included in said sub-volume, selecting those neighbors whose associated value exceeds said threshold as being included in said sub-volume;\nmarking those points included in said sub-volume in said segmentation mask with a first value and those points not included in said sub-volume in said segmentation mask with a second value, wherein a boundary for said sub-volume includes those points with a first value in said segmentation mask that are adjacent to a point with a second value in said segmentation mask.\n15. A method for segmenting digitized images comprising the steps of:\nproviding a digitized whole-body image, said image comprising a plurality of intensities corresponding to a domain of points on an 3-dimensional grid;\ncalculating one or more characteristic feature functions of said body for each axial slice in said image; and\nanalyzing said one or more characteristic feature functions to label the body slices according to their anatomical regions.\n16. The method of claim 15, wherein analyzing said characteristic feature functions comprises:\nproviding an anatomical model for each anatomical region by maximizing a likelihood probability function Pr(Observed|Model) on training samples for the characteristic feature function in each anatomical region;\ncomputing the probability function Pr(Observed|Model) in a window that slides along the ordinate axis of the characteristic feature function to locate a sub-region that maximizes said probability function, wherein the sub-region of the maximum likelihood value with respect to each anatomical model is the associated anatomical region.\n17. The method of claim 15, further comprising:\nextracting a sub-region from said anatomical region with abnormal intensity values;\ninitializing each point in said sub-region by transforming the intensity value of each point into probability values xi, x2 of the point belonging to a normal sub-region or an abnormal sub-region; forward integrating x1, x2 according to\n\n{dot over (x)} i =x i(f i \u2212 f )+\u03bc\u22072 x i,\nwherein {dot over (x)}i is a time derivative of xi,fi is a fitness measure associated with xi,\nf\n_\n=\n\u2211\ni\n\u2062\nx\ni\n\u2062\nf\ni\nis an average fitness, and \u03bc is a pre-determined constant, until each point has one dominant probability, wherein the probability of the dominant state is assigned to extract the sub-egion.\n18. The method of claim 15, wherein said characteristic feature include a centroid of each axial slice and a mean intensity of each slice.\n19. The method of claim 15, wherein said anatomical regions include the neck, lungs, and torso.\n20. A method for segmenting digitized images comprising the steps of:\nproviding a training set comprising a plurality of digitized whole-body images, each image comprising a plurality of intensities corresponding to a domain of points on an 3-dimensional grid;\nproviding contours to delineate anatomical landmarks on said training images;\nfitting each delineated anatomical landmark to a Gaussian function and determining a distance d from the center of each said Gaussian to said contour from d=K % c, wherein c is the width of the Gaussian; and\naveraging K across all slices of all training images, wherein a segmentation threshold for said anatomical landmark is determined from a Gaussian function of (b\u2212Kc), wherein b is a centroid location.\n21. The method of claim 20, comprising fitting Gaussians of different scales by extracting sub-volumes containing said anatomical landmark of different sizes, and selecting an optimum size for said Gaussian fitting by selecting a sub-volume containing points whose intensities are within pre-defined percentage limits.\n22. The method of claim 20, further comprising calculating a probability map of point intensities from said set of aligned training images acquired from healthy and unhealthy patients, wherein said probability map estimates the probability of each point as belonging to normal or abnormal tissue;\ncreating a model image from said set of aligned training images; providing a new digitized image;\naligning said new image to said model image by registering bright spots in said model image to bright spots in said new image, wherein bright spots in said new that cannot be mapped to corresponding bright spots in said model image are labeled as abnormal candidates; and\ndetermining the probability of points in said abnormal candidates as bing abnormal from said probability map.\n23. The method of claim 22, wherein said probability map is a 2-dimensional map based on intensity projections on the coronal plane.\n24. A method for joint segmentation of a region of interest in a plurality of images, said method comprising the steps of:\nproviding a plurality of digitized images acquired through differing modalities at the same clinical time point of a same patient, each said image comprising a plurality of intensities corresponding to a domain of points on an 3-dimensional grid;\nsegmenting a region-of-interest in a first of said plurality of images;\npropagating said segmented region of interest to the rest of said plurality of images based on the spatial relationship between said first image and the rest of said plurality of images; and\nupdating the segmentation in each of the rest of said plurality of images according to one or more of spatial or intensity features in each of the rest of said plurality of images.\n25. The method of claim 24, further comprising\nmorphologically eroding a first segmentation mask corresponding to said segmented region-of-interest in said first of said plurality of images, wherein a segmented mask containing only abnormal points is obtained;\nmorphologically dilating and logically complementing said first segmentation mask wherein a segmented mask containing only normal points is obtained;\nobtaining a non-parametric probabilistic model of tumor tissue attenuation in a second modality image in said plurality of images from said segmented tumor mask;\nobtaining a non-parametric statistical model of the background tissue attenuation from said segmented normal mask;\nnormalizing intensity values in said first modality image wherein a likelihood map of abnormal activity is obtained; and\nmeasuring a probability of an image point as being abnormal tissue from a likelihood ratio test, wherein a point probability value greater than 1 indicates that said point represents abnormal tissue.\n26. A program storage device readable by a computer, tangibly embodying a program of instructions executable by the computer to perform the method steps for segmenting digitized images, said method comprising the steps of:\nproviding a training set comprising a plurality of digitized whole-body images, each image comprising a plurality of intensities corresponding to a domain of points on an 3-dimensional grid;\nproviding labels on anatomical landmarks in each image of said training set;\naligning each said training set image;\ngenerating positive and negative training examples for each landmark by cropping the aligned training volumes into one or more cropping windows of different spatial scales; and\nusing said positive and negative examples to train a detector for each landmark at one or more spatial scales ranging from a coarse resolution to a fine resolution, wherein the spatial relationship between a cropping windows of a coarse resolution detector and a fine resolution detector is recorded.\n27. The computer readable program storage device of claim 26, the method further comprising providing a plurality of new digitized images, said images representing a same patient at different time points;\nselecting a point in a sub-volume of interest in each of said plurality of images;\nsegmenting said sub-volume of interest in each image; and\nquantifying changes in the sub-volume of interest over the different images of one or more properties including intensity, volume, shape, topology, location, and texture.\n28. The computer readable program storage device of claim 26, the method further comprising providing a digitized whole-body image, said image comprising a plurality of intensities corresponding to a domain of points on an 3-dimensional grid;\ncalculating one or more characteristic feature functions of said body for each axial slice in said image; and\nanalyzing said one or more characteristic feature functions to label the body slices according to their anatomical regions.\n29. The computer readable program storage device of claim 26, the method further comprising providing a training set comprising a plurality of digitized whole-body images, each image comprising a plurality of intensities corresponding to a domain of points on an 3-dimensional grid;\nproviding contours to delineate anatomical landmarks on said training images;\nfitting each delineated anatomical landmark to a Gaussian function and determining a distance d from the center of each said Gaussian to said contour from d=K % c, wherein c is the width of the Gaussian; and\naveraging K across all slices of all training images, wherein a segmentation threshold for said anatomical landmark is determined from a Gaussian function of (b\u2212Kc), wherein b is a centroid location.\n30. The computer readable program storage device of claim 26, the method further comprising providing a plurality of digitized images acquired through differing modalities at the same clinical time point of a same patient, each said image comprising a plurality of intensities corresponding to a domain of points on an 3-dimensional grid;\nsegmenting a region-of-interest in a first of said plurality of images;\npropagating said segmented region of interest to the rest of said plurality of images based on the spatial relationship between said first image and the rest of said plurality of images; and\nupdating the segmentation in each of the rest of said plurality of images according to one or more of spatial or intensity features in each of the rest of said plurality of images.",
    "status": "Active",
    "citations_own": [
        "US6320976B1",
        "US20030120147A1",
        "US20050010445A1",
        "US20060120572A1",
        "US20060171586A1"
    ],
    "citations_ftf": [],
    "citedby_own": [
        "US20050100208A1",
        "US20050152617A1",
        "US20060025673A1",
        "US20070167784A1",
        "US20070167697A1",
        "US20070263769A1",
        "US20080027917A1",
        "US20080037851A1",
        "US20080144939A1",
        "US20080197284A1",
        "WO2008129506A1",
        "US20080265166A1",
        "US20080317317A1",
        "US20090034813A1",
        "WO2009039391A1",
        "US20090092301A1",
        "US20090116716A1",
        "US20090129641A1",
        "WO2009073185A1",
        "US20090148012A1",
        "US20090161938A1",
        "WO2009084995A1",
        "US20090174707A1",
        "US20090208081A1",
        "US20090226060A1",
        "US20090324038A1",
        "US20100014756A1",
        "US20100053208A1",
        "US20100061609A1",
        "US20100067768A1",
        "US20100088644A1",
        "WO2010064187A1",
        "US20100195878A1",
        "US20100226566A1",
        "US20100272330A1",
        "US20100316294A1",
        "US20110002520A1",
        "US20110019889A1",
        "WO2011010231A1",
        "US20110026797A1",
        "US20110129132A1",
        "WO2011065950A1",
        "WO2011073832A1",
        "US20110172514A1",
        "US20110182493A1",
        "US20110201935A1",
        "US20110206260A1",
        "US20110228997A1",
        "US20110228995A1",
        "DE102010018261A1",
        "US20110262016A1",
        "US20110262013A1",
        "US20120078823A1",
        "GB2457577B",
        "US8160364B2",
        "US20120134557A1",
        "US20120219201A1",
        "US20130057547A1",
        "US20130136322A1",
        "US8467856B2",
        "US20130223704A1",
        "US20130243298A1",
        "US20130266223A1",
        "US20130329973A1",
        "US20130336553A1",
        "US20140003686A1",
        "US8675931B2",
        "US20140161337A1",
        "US8795204B2",
        "US20140219548A1",
        "US20140323845A1",
        "US8938102B2",
        "US8942917B2",
        "WO2015010745A1",
        "US20150087974A1",
        "US20150178925A1",
        "US20150260819A1",
        "US9153045B2",
        "US20150287188A1",
        "US9171369B2",
        "US20150342552A1",
        "US20150363963A1",
        "US20150379365A1",
        "US20160063695A1",
        "US20160148388A1",
        "WO2016118332A1",
        "US20160253784A1",
        "WO2016160538A1",
        "CN106133789A",
        "US20170039737A1",
        "TWI577342B",
        "US9861337B2",
        "US9870614B1",
        "US20180137621A1",
        "US20180310993A1",
        "CN109035208A",
        "WO2018232210A1",
        "US10176570B2",
        "EP3316965A4",
        "GB2564939A",
        "US10229493B2",
        "CN109767448A",
        "US10307209B1",
        "US10340046B2",
        "US10402991B2",
        "US10417737B2",
        "CN110415246A",
        "US10492723B2",
        "CN110720128A",
        "CN111105427A",
        "CN111312373A",
        "CN111340792A",
        "US10699163B1",
        "EP3719746A1",
        "US10910099B2",
        "US20210049793A1",
        "US10973486B2",
        "US11172889B2",
        "US11189374B2",
        "KR102331034B1",
        "KR102334519B1",
        "US11215711B2",
        "US20220005586A1",
        "WO2022008374A1",
        "US11273283B2",
        "US11321844B2",
        "CN114494160A",
        "US11364361B2",
        "US20220215556A1",
        "US11386988B2",
        "US11452839B2",
        "CN115294518A",
        "US11534125B2",
        "US11544407B1",
        "US11564621B2",
        "US20230119427A1",
        "US11657508B2",
        "CN116485801A",
        "US11710309B2",
        "US11717686B2",
        "US11723579B2"
    ],
    "citedby_ftf": [
        "DE102006020864A1",
        "JP4855141B2",
        "DE102006061320B4",
        "US8121362B2",
        "JP5159242B2",
        "US8243991B2",
        "US8369585B2",
        "US8175376B2",
        "US8659603B2",
        "US8625869B2",
        "KR101972356B1",
        "CN102727200B",
        "US20130136329A1",
        "US9443633B2",
        "ITTO20130306A1",
        "US9082193B2",
        "US9122959B2",
        "DE102013218047B3",
        "US9454712B2",
        "US9626584B2",
        "CA2967003C",
        "US10169873B2",
        "US9870615B2",
        "US10706262B2",
        "US11398026B2",
        "US20220028068A1"
    ]
}