{
    "patent_id": "US-11693902-B2",
    "title": "Relevance-based image selection ",
    "assignee": "Google Llc",
    "publication_date": "2023-07-04",
    "patent_link": "https://patents.google.com/patent/US11693902B2/en",
    "inventors": [
        "Gal Chechik",
        "Samy Bengio"
    ],
    "classifications": [
        "G06F16/7867",
        "G06F16/70",
        "G06F16/738",
        "G06F16/743",
        "G06F16/78",
        "G06F16/783",
        "G06N20/00",
        "G06F16/7844"
    ],
    "abstract": "A system, computer readable storage medium, and computer-implemented method presents video search results responsive to a user keyword query. The video hosting system uses a machine learning process to learn a feature-keyword model associating features of media content from a labeled training dataset with keywords descriptive of their content. The system uses the learned model to provide video search results relevant to a keyword query based on features found in the videos. Furthermore, the system determines and presents one or more thumbnail images representative of the video using the learned model.",
    "claims": "\n1. A computer-implemented method for providing searchable videos, the method executed by a computer system comprising one or more processors, and comprising:\nstoring a searchable video index associated with a plurality of videos that each include a plurality of frames, the searchable video index including a mapping between two or more frames of each of the plurality of videos and one or more keyword representations, the mapping generated based at least in part on a machine-learned model trained to learn correlations between visual content of individual video frames and keyword representations;\nreceiving a search query including one or more textual keywords;\nselecting a first video from the searchable video index based on the one or more textual keywords;\ndetermining a frame of the first video based at least in part on the one or more textual keywords and the mapping between the two or more frames of each of the plurality of videos and the one or more keyword representations; and\nproviding a result set including the frame of the first video and a link to the first video in response to the search query.\n2. The computer-implemented method of claim 1, further comprising:\nreceiving a labeled training dataset comprising a set of training videos together with textual data descriptive of visual content for each of two or more frames of each training video;\nextracting from the set of training videos one or more features characterizing the visual content of each of the two or more frames from each of the training videos;\ntraining the machine-learned model based at least in part on the labeled training dataset to learn correlations between the one or more features characterizing the visual content of each of the two or more frames and the one or more keyword representations;\ninputting to the machine-learned model data associated with the two or more frames of each of the plurality of videos; and\ngenerating, for each of the two or more frames of the plurality of videos, at least one keyword representation based on one or more outputs of the machine-learned model for said each of the two or more frames.\n3. The computer-implemented method of claim 2, further comprising:\ngenerating the searchable video index based at least in part on the machine-learned model.\n4. The computer-implemented method of claim 3, further comprising:\ngenerating at least one feature vector for each of the two or more frames of each of the plurality of videos associated with the searchable video index;\nwherein inputting to the machine-learned model data associated with the two or more frames of each of the plurality of videos includes inputting the at least one feature vector for each of the two or more frames.\n5. The computer-implemented method of claim 4, wherein the one or more features extracted from the set of training videos is one or more feature vectors.\n6. The computer-implemented method of claim 5, further comprising:\nextracting a plurality of keyword representations from the labeled training dataset;\nwherein training the machine-learned model includes training the machine-learned model to learn correlations between the one or more feature vectors and the one or more keyword representations based at least in part of the plurality of keyword representations extracted from the labeled training data.\n7. The computer-implemented method of claim 1, further comprising:\ntransmitting, by the computing system to a client device, one or more responses to the search query including the frame of the first video and the link to the first video.\n8. One or more non-transitory computer readable storage media storing computer executable code that when executed by one or more processors cause the one or more processors to perform operations, the operations comprising:\nstoring a searchable video index associated with a plurality of videos that each include a plurality of frames, the searchable video index including a mapping between two or more frames of each of the plurality of videos and one or more keyword representations, the mapping generated based at least in part on a machine-learned model trained to learn correlations between visual content of individual video frames and keyword representations;\nreceiving a search query including one or more textual keywords;\nselecting a first video from the searchable video index based on the one or more textual keywords;\ndetermining a frame of the first video based at least in part on the one or more textual keywords and the mapping between the two or more frames of each of the plurality of videos and the one or more keyword representations; and\nproviding a result set including the frame of the first video and a link to the first video in response to the search query.\n9. The one or more non-transitory computer readable storage media of claim 8, wherein the operations further comprise:\nreceiving a labeled training dataset comprising a set of training videos together with textual data descriptive of visual content for each of two or more frames of each training video;\nextracting from the set of training videos one or more features characterizing the visual content of each of the two or more frames from each of the training videos;\ntraining the machine-learned model based at least in part on the labeled training dataset to learn correlations between the one or more features characterizing the visual content of each of the two or more frames and the one or more keyword representations;\ninputting to the machine-learned model data associated with the two or more frames of each of the plurality of videos; and\ngenerating, for each of the two or more frames of the plurality of videos, at least one keyword representation based on one or more outputs of the machine-learned model for said each of the two or more frames.\n10. The one or more non-transitory computer readable storage media of claim 9, wherein the operations further comprise:\ngenerating the video index based at least in part on the machine-learned model.\n11. The one or more non-transitory computer readable storage media of claim 10, wherein the operations further comprise:\ngenerating at least one feature vector for each of the two or more frames of each of the plurality of videos associated with the searchable video index;\nwherein inputting to the machine-learned model data associated with the two or more frames of each of the plurality of videos includes inputting the at least one feature vector for each of the two or more frames.\n12. The one or more non-transitory computer readable storage media of claim 11, wherein the one or more features extracted from the set of training videos is one or more feature vectors.\n13. The one or more non-transitory computer readable storage media of claim 12, wherein the operations further comprise:\nextracting a plurality of keyword representations from the labeled training dataset;\nwherein training the machine-learned model includes training the machine-learned model to learn correlations between the one or more feature vectors and the one or more keyword representations based at least in part of the plurality of keyword representations extracted from the labeled training data.\n14. The one or more non-transitory computer readable storage media of claim 8, wherein the operations further comprise:\ntransmitting to a client device one or more responses to the search query including the frame of the first video and the link to the first video.\n15. A computing system having one or more processors configured to perform operations comprising:\nreceiving a labeled training dataset comprising a set of training videos together with textual data descriptive of visual content for each of two or more frames of each training video;\nextracting from the set of training videos one or more features characterizing the visual content of each of the two or more frames from each of the training videos;\ntraining a machine-learned model based at least in part on the labeled training dataset to learn correlations between the one or more features characterizing the visual content of each of the two or more frames and one or more keyword representations;\ninputting to the machine-learned model data associated with two or more frames of each of a plurality of videos associated with a searchable video index;\ngenerating, for each of the two or more frames of the plurality of videos associated with the searchable video index, at least one keyword representation based on one or more outputs of the machine-learned model for said each of the two or more frames; and\nstoring the searchable video index including a mapping between the two or more frames of each of the plurality of videos and the at least one keyword representation.\n16. The computing system of claim 15, wherein the operations further comprise:\nproviding, in response to a search query including one or more query terms, one or more responses indicative of a first video and a first frame of the first video based at least in part on the one or more query terms and at least one keyword representation in the searchable video index for the first frame of the first video.\n17. The computing system of claim 16, wherein the operations further comprise:\nselecting, in response to the search query including one or more query terms, the first video and the first frame of the first video based at least in part on the one or more query terms and the at least one keyword representation in the searchable video index for the first frame of the first video;\nwherein the one or more responses include the first frame of the first video and a link to the first video.\n18. The computing system of 15, wherein:\nthe one or more features are one or more feature vectors;\nthe operations further comprise extracting a plurality of keyword representations from the labeled training dataset; and\ntraining the machine-learned model includes training the machine-learned model to learn correlations between the one or more feature vectors and the one or more keyword representations based at least in part of the plurality of keyword representations extracted from the labeled training dataset.\n19. The computing system of claim 18, further comprising:\ngenerating at least one feature vector for each of the two or more frames of each of the plurality of videos associated with the searchable video index;\nwherein inputting to the machine-learned model data associated with each of the two or more frames of each of the plurality of videos associated with the searchable video index includes inputting the at least one feature vector for each of the two or more frames.\n20. The computing system of claim 15, further comprising:\ngenerating the searchable video index including a mapping between each of the two or more frames of the plurality of videos and the at least one keyword representation.",
    "status": "Active",
    "citations_own": [
        "US20020164070A1",
        "US20030097301A1",
        "US6574378B1",
        "US20030103565A1",
        "US20030126136A1",
        "US20040125877A1",
        "US20050267879A1",
        "US20060179051A1",
        "US20060179454A1",
        "US20070067724A1",
        "US20070094251A1",
        "US20070255755A1",
        "US20070255565A1",
        "CN101071439A",
        "US20080118151A1",
        "US20080120291A1",
        "US20080165960A1",
        "US20080193016A1",
        "US20090263014A1",
        "US20090327856A1",
        "US20100191689A1",
        "US20100246944A1"
    ],
    "citations_ftf": [
        "US7263659B2",
        "US8682097B2",
        "US7639387B2",
        "US8156427B2",
        "EP2049983A2",
        "US20080154889A1",
        "US8806320B1",
        "US20090327236A1",
        "US8983192B2",
        "US8873813B2",
        "US9916538B2",
        "US9070046B2",
        "US9779304B2"
    ],
    "citedby_own": [],
    "citedby_ftf": [
        "US20200257596A1",
        "WO2009144698A1",
        "US8111923B2",
        "US9477667B2",
        "JP5911809B2",
        "WO2011090798A1",
        "US20110218994A1",
        "US20110225133A1",
        "CN102193946A",
        "US8910046B2",
        "CN103202017B",
        "US9544598B2",
        "WO2012033971A1",
        "US8971651B2",
        "US8923607B1",
        "US20130334300A1",
        "US8886015B2",
        "US8856212B1",
        "US9997196B2",
        "US11747972B2",
        "FR2973134B1",
        "US8938393B2",
        "US8879835B2",
        "US9536564B2",
        "US20130073933A1",
        "US20130073961A1",
        "US9075825B2",
        "US9098533B2",
        "US8649613B1",
        "CN102542066B",
        "EP3557442A1",
        "US9846696B2",
        "US9146993B1",
        "US9292552B2",
        "US9633015B2",
        "US8935246B2",
        "CN103714063B",
        "US9172740B1",
        "US9311692B1",
        "US9225979B1",
        "US10594763B2",
        "US10445367B2",
        "US9521189B2",
        "US10311038B2",
        "US10289810B2",
        "US10108617B2",
        "CN104995639B",
        "US9189834B2",
        "US9286540B2",
        "WO2015112870A1",
        "US9728230B2",
        "US9779775B2",
        "WO2015127385A1",
        "US9767540B2",
        "WO2016038522A1",
        "US10318575B2",
        "US10074102B2",
        "US9847101B2",
        "US9842390B2",
        "US10095786B2",
        "CN104881798A",
        "US20160378863A1",
        "US10062015B2",
        "US10242033B2",
        "US10140880B2",
        "EP3326083A4",
        "US9779304B2",
        "US9858967B1",
        "CN106708876B",
        "CN105488183B",
        "US10592750B1",
        "US10381022B1",
        "US10678853B2",
        "KR20170098079A",
        "US10891019B2",
        "CN105787087B",
        "US9858340B1",
        "US10289642B2",
        "US10008218B2",
        "US10467257B2",
        "US10311112B2",
        "US10664514B2",
        "US10645142B2",
        "US10606887B2",
        "US11580589B2",
        "CN106776890B",
        "US10685047B1",
        "US11367011B2",
        "US10430661B2",
        "US10606814B2",
        "US10216766B2",
        "CN107025275B",
        "US10268897B2",
        "US10540444B2",
        "CN107609461A",
        "US10970334B2",
        "CN109598527A",
        "US10740394B2",
        "US10372991B1",
        "US11507619B2",
        "US20190354608A1",
        "US10965985B2",
        "CN110795597A",
        "CN109089133B",
        "WO2020051704A1",
        "WO2020060538A1",
        "US11210335B2",
        "CN109376145B",
        "US11609949B2",
        "US11250039B1",
        "US11803556B1",
        "CN109933688A",
        "CN111800671B",
        "CN110110140A",
        "CN110362694A",
        "CN110381368A",
        "US11531707B1",
        "US11500927B2",
        "CA3144489A1",
        "US11606613B2",
        "US11128910B1",
        "US11243995B2",
        "CN111432282B",
        "CN114080817A",
        "US11645733B2",
        "US20220114361A1",
        "CN112399262A",
        "CN112733779B",
        "US11532111B1",
        "US20220406038A1",
        "CN113378781B",
        "WO2023000950A1",
        "CN113901263B",
        "US20230222129A1"
    ]
}