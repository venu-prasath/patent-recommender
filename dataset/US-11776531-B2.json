{
    "patent_id": "US-11776531-B2",
    "title": "Encoder-decoder models for sequence to sequence mapping ",
    "assignee": "Google Llc",
    "publication_date": "2023-10-03",
    "patent_link": "https://patents.google.com/patent/US11776531B2/en",
    "inventors": [
        "Hasim Sak",
        "Sean Matthew Shannon"
    ],
    "classifications": [
        "G10L15/16",
        "G06N3/02",
        "G06N3/044",
        "G06N3/045",
        "G06N3/084",
        "G10L15/14",
        "G10L15/22",
        "G06N7/01",
        "G10L15/02",
        "G10L15/063",
        "G10L15/183",
        "G10L2015/025"
    ],
    "abstract": "Methods, systems, and apparatus for performing speech recognition. In some implementations, acoustic data representing an utterance is obtained. The acoustic data corresponds to time steps in a series of time steps. One or more computers process scores indicative of the acoustic data using a recurrent neural network to generate a sequence of outputs. The sequence of outputs indicates a likely output label from among a predetermined set of output labels. The predetermined set of output labels includes output labels that respectively correspond to different linguistic units and to a placeholder label that does not represent a classification of acoustic data. The recurrent neural network is configured to use an output label indicated for a previous time step to determine an output label for the current time step. The generated sequence of outputs is processed to generate a transcription of the utterance, and the transcription of the utterance is provided.",
    "claims": "\n1. An apparatus for training a recurrent neural network to process received input acoustic sequences and generate sequences of outputs, the generated sequence of outputs indicating output labels from among a predetermined set of output labels including output labels that respectively correspond to different linguistic units and to a blank label that does not represent a classification of a received input acoustic sequence, the apparatus comprising:\nprocessing circuitry configured to\nobtain a plurality of training examples, each training example comprising (i) an input acoustic sequence of scores indicative of acoustic data at each of multiple time steps in a series of time steps, the input acoustic sequence representing a known utterance, and (ii) a corresponding target sequence of linguistic units representing a transcription of the known utterance, and\ntrain the recurrent neural network to minimize a negative log likelihood loss function using the plurality of training examples by\nrepresenting possible alignments between the input acoustic sequence and the target sequence of linguistic units as a lattice, the possible alignments constrained to allow blank label repetitions only and each node in the lattice represents a respective state of the recurrent neural network, each state of the recurrent neural network being dependent on a respective time step from the series of time steps and a respective position in the target sequence of linguistic units, and wherein transitions between nodes in the lattice represent probabilities of observing respective subsequent linguistic units or blank labels in the target sequence of linguistic units,\nperforming forward calculations through the lattice to update each recurrent neural network state,\napproximating the log likelihood loss function using the updated recurrent neural network states, and\nperforming back propagation techniques using the approximated log likelihood function to adjust recurrent neural network parameters to trained recurrent neural network parameters.\n2. The apparatus of claim 1, wherein the processing circuitry is further configured to\ntrain the recurrent neural network to minimize an expected loss function using the plurality of training examples.\n3. The apparatus of claim 2, wherein the processing circuitry is further configured to train the recurrent neural network to minimize the expected loss function using the plurality of training examples by\nperforming back propagation techniques using the expected loss function to adjust recurrent neural network parameters to trained recurrent neural network parameters.\n4. The apparatus of claim 1, wherein the recurrent neural network comprises one or more recurrent neural network layers and an output layer.\n5. The apparatus of claim 4, wherein the output layer estimates a conditional probability distribution representing the probability of an alignment between the scores indicative of the acoustic data and the sequence of outputs, wherein\nthe conditional probability distribution comprises a product of output conditional probabilities for each time step, each output conditional probability representing the probability of an output for a respective time step given the score for the respective time step, and an output for a preceding time step.\n6. The apparatus of claim 4, wherein the one or more recurrent neural network layers comprises long short-term memory neural network layers and the output layer comprises a softmax output layer.\n7. The apparatus of claim 1, wherein the processing circuitry is further configured to define, as an output label representing the blank label, a generated output for a first time step in the series of time steps.\n8. The apparatus of claim 1, wherein the performing the forward calculations through the lattice to update each recurrent neural network state includes\ndetermining values of multiple forward variables, each forward variable corresponding to a respective time step from {1, . . . , t} and representing a probability of outputting a particular sequence of n linguistic units up to the respective time step.\n9. The apparatus of claim 1, wherein the performing the forward calculations through the lattice to update each recurrent neural network state includes\ndetermining that two different transitions between start node (t\u22121, n\u22121) and end node (t, n) exist in the lattice, the two different transitions comprising a first transition through a first intermediate node (t, n\u22121) and a second transition through a second intermediate node (t\u22121, n),\nupdating the recurrent neural network state for the end node to equal a recurrent neural network state corresponding to the start node (t\u22121, n\u22121) if the product of a forward variable for node (t\u22121, n\u22121), and probability of outputting a linguistic unit at node (t\u22121, n\u22121) is greater than the product of a forward variable for node (t\u22121, n), and probability of outputting a blank label at node (t\u22121, n), and\nupdating the recurrent neural network state for the end node to equal a recurrent neural network state corresponding to the second intermediate node (t\u22121, n) if the product of a forward variable for node (t\u22121, n\u22121), and probability of outputting a linguistic unit at node (t\u22121, n\u22121) is not greater than the product of a forward variable for node (t\u22121, n), and probability of outputting a blank label at node (t\u22121, n).\n10. The apparatus of claim 9, wherein the processing circuitry is further configured to define multiple backward variables as the probability of outputting a particular sequence of N-n linguistic units from the particular time t.\n11. The apparatus of claim 10, wherein the approximating the log likelihood loss function includes\ndetermining the value of a backward variable for time t=0 and n=0.\n12. The apparatus of claim 1, wherein the performing the forward calculations through the lattice to update each recurrent neural network state includes\ndefining a first unit in the sequence of outputs as the blank label.\n13. The apparatus of claim 1, wherein the linguistic units are context-dependent phones.\n14. A non-transitory computer-readable storage medium comprising instructions stored thereon that are executable by a processing device and upon such execution cause the processing device to train a recurrent neural network to process received input acoustic sequences and generate sequences of outputs, the generated sequence of outputs indicating output labels from among a predetermined set of output labels including output labels that respectively correspond to different linguistic units and to a blank label that does not represent a classification of a received input acoustic sequence, the training comprising:\nobtaining a plurality of training examples, each training example comprising (i) an input acoustic sequence of scores indicative of acoustic data at each of multiple time steps in a series of time steps, the input acoustic sequence representing a known utterance, and (ii) a corresponding target sequence of linguistic units representing a transcription of the known utterance; and\ntraining the recurrent neural network to minimize a negative log likelihood loss function using the plurality of training examples by\nrepresenting possible alignments between the input acoustic sequence and the target sequence of linguistic units as a lattice, the possible alignments constrained to allow placeholder label repetitions only and each node in the lattice represents a respective state of the recurrent neural network, each state of the recurrent neural network being dependent on a respective time step from the series of time steps and a respective position in the target sequence of linguistic units, and wherein transitions between nodes in the lattice represent probabilities of observing respective subsequent linguistic units or placeholder labels in the target sequence of linguistic units,\nperforming forward calculations through the lattice to update each recurrent neural network state,\napproximating, the log likelihood loss function using the updated recurrent neural network states, and\nperforming back propagation techniques using the approximated log likelihood function to adjust recurrent neural network parameters to trained recurrent neural network parameters.\n15. The non-transitory computer-readable storage medium of claim 14, further comprising\ntraining the recurrent neural network to minimize an expected loss function using the plurality of training examples.\n16. The non-transitory computer-readable storage medium of claim 14, wherein the recurrent neural network comprises one or more recurrent neural network layers and an output layer.\n17. The non-transitory computer-readable storage medium of claim 16, wherein the output layer estimates a conditional probability distribution representing the probability of an alignment between the scores indicative of the acoustic data and the sequence of outputs, wherein\nthe conditional probability distribution comprises a product of output conditional probabilities for each time step, each output conditional probability representing the probability of an output for a respective time step given the score for the respective time step, and an output for a preceding time step.\n18. The non-transitory computer-readable storage medium of claim 16, wherein the one or more recurrent neural network layers comprises long short-term memory neural network layers and the output layer comprises a softmax output layer.\n19. The non-transitory computer-readable storage medium of claim 14, further comprising defining, as an output label representing the blank label, a generated output for a first time step in the series of time steps.\n20. The non-transitory computer-readable storage medium of claim 14, wherein the performing the forward calculations through the lattice to update each recurrent neural network state includes\ndetermining values of multiple forward variables, each forward variable corresponding to a respective time step from {1, . . . , t} and representing a probability of outputting a particular sequence of n linguistic units up to the respective time step."
}