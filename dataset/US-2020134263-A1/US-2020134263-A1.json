{
    "patent_id": "US-2020134263-A1",
    "title": "Non-factoid question-answering device ",
    "assignee": "National Institute Of Information And Communications Technology",
    "publication_date": "2020-04-30",
    "patent_link": "https://patents.google.com/patent/US20200134263A1/en",
    "inventors": [
        "Jonghoon Oh",
        "Kentaro Torisawa",
        "Canasai KRUENGKRAI",
        "Ryu IIDA",
        "Julien KLOETZER"
    ],
    "classifications": [
        "G06F40/30",
        "G06F16/3329",
        "G06F16/3347",
        "G06F40/279",
        "G06N3/045",
        "G06N3/08",
        "G06N3/082",
        "G06N3/084",
        "G06N5/041",
        "G06N20/10",
        "G06N3/048"
    ],
    "abstract": "A question answering device includes: a general word vector converter converting a question and an answer to semantic vectors in accordance with general context; a general sentence level CNN 214, in response to similarities of semantic vectors between words in question and answer and to strength of causality between the words, for weighting each semantic vector to calculate sentence level representations of the question and the answer; a general passage level CNN 218, in response to similarity between sentence level representations of question and answer, and to strength of relation of vectors in the sentence level representations viewed from causality, for weighting the sentence level representation to calculate a passage level representation for the question and answer passage; and a classifier determining whether or not an answer is a correct answer, based on the similarities between outputs from CNNs 214 and 218.",
    "claims": "\n1. A non-factoid question-answering device, receiving a pair of a question and an answer passage and determining whether or not the answer passage is a correct answer to the question, comprising:\na first word semantic vector converting means for converting the question and the answer passage to word semantic vector sequences in accordance with meanings from a certain viewpoint;\na first sentence level representation output means for weighting each word semantic vector to calculate and output sentence level representations of said question and said answer passage, in response to similarities of word semantic vectors between words in said question sentence and in said answer passage converted by said first word semantic vector converting means, and in response to a coefficient reflecting strength of a first prescribed relation between words;\na first passage level representation output means for calculating and outputting a passage level representation for each of said question and said answer passage, by executing for a prescribed number of times weighting of said sentence level representation, in response to similarity between said sentence level representation of said question and said sentence level representation of said answer passage output by said first sentence level representation output means, and in response to a coefficient reflecting strength of relation of vectors in said sentence level representations viewed in a context of said first prescribed relation; and\na determining means for determining whether or not said answer passage is a correct answer to said question, based on the similarity between said sentence level representations for each of said question and said answer passage output from said first sentence level representation output means, and based on the similarity between said passage level representations for each of said question and said answer passage output from said first passage level representation output means.\n2. The non-factoid question-answering device according to claim 1, wherein\nsaid first sentence level representation output means includes:\na similarity attention matrix calculating means for calculating, for combinations of each of word semantic vectors contained in said word semantic vector sequence of said question sentence and each of word semantic vectors contained in said word semantic vector sequence of said answer passage, similarity representing semantic similarity between each other, and for calculating a similarity attention matrix;\na first attention matrix calculating means for calculating, for the combinations of each of the words contained in said question sentence and each of the words contained in said answer passage, a measure representing frequency that the two words respectively appear at prescribed positions in a sentence in accordance with said first prescribed relation, and for calculating an attention matrix related to said first prescribed relation;\na word vector calculating means for performing, on the word semantic vector sequences contained in said word semantic word vector sequences of said question sentence and said word semantic vector sequences of said answer passage, an operation of adding weight of the similarity attention determined by said similarity attention matrix and the first attention determined by said first attention matrix and thereby for calculating each word vector; and\na CNN for performing sentence-by-sentence convolution and pooling on both of said word semantic sequence of said question sentence and said word semantic vector sequence of said answer passage calculated by said word vector calculating means, and thereby for outputting said first sentence level representation.\n3. The non-factoid question-answering device according to claim 2, further comprising\na sparse processing means for making sparse each said word vector by updating any negative element of each said word vector to zero prior to calculation of said each word vector by said word vector calculating means.\n4. The non-factoid question-answering device according to claim 1, further comprising:\na second word semantic vector converting means for converting the question and the answer passage to word semantic vector sequences respectively in accordance with meanings from another viewpoint different from said certain viewpoint;\na second sentence level representation output means for weighting each word semantic vector to calculate and output sentence level representations of said question and said answer passage, in response to similarities of word semantic vectors between words in said question sentence and in said answer passage converted by said second word semantic vector converting means, and in response to a coefficient reflecting strength of a second prescribed relation between words; and\na second passage level representation output means for calculating and outputting a passage level representation for each of said question and said answer passage, by executing for a prescribed number of times weighting of said sentence level representation, in response to similarity between said sentence level representation of said question and said sentence level representation of said answer passage output by said second sentence level representation output means, and in response to a coefficient reflecting strength of relation of vectors in said sentence level representations viewed in a context of said second prescribed relation; wherein\nsaid determining means includes means for determining whether or not said answer passage is a correct answer to said question, based on the similarity between said sentence level representations for each of said question and said answer passage output from said first and second sentence level representation output means, and based on the similarity between said passage level representations for each of said question and said answer passage output from said first and second passage level representation output means.\n5. The non-factoid question-answering device according to claim 4, wherein said second prescribed relation is the same as said first prescribed relation.\n6. The non-factoid question-answering device according to claim 1, wherein said first relation is causality.",
    "status": "Active",
    "citations_own": [],
    "citations_ftf": [
        "JP5825676B2",
        "JP6150282B2",
        "JP6618735B2",
        "JP6929539B2",
        "US20180341871A1"
    ],
    "citedby_own": [
        "US20190163812A1",
        "CN110674280A",
        "US20200151542A1",
        "CN111666770A",
        "US10860809B2",
        "US10922486B2",
        "US20210264260A1",
        "US11295077B2",
        "CN114357156A",
        "CN114547313A"
    ],
    "citedby_ftf": [
        "CN111382573A",
        "CN109710770A",
        "US20220043972A1",
        "CN110033022A",
        "CN110134771B",
        "CN110060749B",
        "JP7077265B2",
        "CN110134964B",
        "CN110263162B",
        "CN110222163B",
        "CN110347813B",
        "CN110442691A",
        "JP7290861B2",
        "CN110909538A",
        "CN112685543A",
        "CN110795934B",
        "CN111241848B",
        "JP6789426B1",
        "JP7200154B2",
        "CN111178458B",
        "CN111563152A",
        "JP2022067234A",
        "CN112948546B"
    ]
}