{
    "patent_id": "US-11769061-B2",
    "title": "Processing computational graphs ",
    "assignee": "Google Llc",
    "publication_date": "2023-09-26",
    "patent_link": "https://patents.google.com/patent/US11769061B2/en",
    "inventors": [
        "Paul A. Tucker",
        "Jeffrey Adgate Dean",
        "Sanjay Ghemawat",
        "Yuan Yu"
    ],
    "classifications": [
        "G06F9/5005",
        "G06N3/098",
        "G06F9/5038",
        "G06F9/5066",
        "G06N20/00",
        "G06N3/045",
        "G06N3/063",
        "G06N3/08",
        "G06N3/084",
        "G06N5/04",
        "G06N5/048"
    ],
    "abstract": "Methods, systems, and apparatus, including computer programs encoded on computer storage media, for receiving a request from a client to process a computational graph; obtaining data representing the computational graph, the computational graph comprising a plurality of nodes and directed edges, wherein each node represents a respective operation, wherein each directed edge connects a respective first node to a respective second node that represents an operation that receives, as input, an output of an operation represented by the respective first node; identifying a plurality of available devices for performing the requested operation; partitioning the computational graph into a plurality of subgraphs, each subgraph comprising one or more nodes in the computational graph; and assigning, for each subgraph, the operations represented by the one or more nodes in the subgraph to a respective available device in the plurality of available devices for operation.",
    "claims": "\n1. A method comprising:\nreceiving a request from a client to process a computational graph that models a neural network having a plurality of network layers;\nobtaining data representing the computational graph, the computational graph comprising a plurality of nodes and directed edges, each node representing a respective operation of the neural network modeled by the computational graph, and each directed edge connecting a respective first node to a respective second node that represents an operation that receives, as input, an output of an operation represented by the respective first node; and\nprocessing the computational graph, comprising:\nanalyzing the computational graph to identify a plurality of groups of nodes, each group of nodes representing a respective subset of operations of the neural network, wherein the nodes in each group are selected for inclusion in the group based on an indication that the nodes form a chain structure of nodes connected in series by a succession of directed edges, wherein the chain structures in the plurality of groups of nodes are determined to minimize a number of subgraphs that will be formed from the plurality of groups of nodes;\npartitioning the computational graph into a plurality of subgraphs, each subgraph being a portion of the computational graph for a different one of the plurality of groups of nodes that represents a different, respective subset of operations of the neural network, wherein partitioning the computational graph includes;\nassigning the respective subset of operations of the neural network for each subgraph to a respective available device among a plurality of available devices for processing, including assigning the respective subsets of operations of the neural network for at least two subgraphs to different ones of the plurality of available devices for processing; and\ncausing each device to perform the operations assigned to the device.\n2. The method of claim 1,\nwherein the request specifies a subset of the plurality of nodes and directed edges of the computational graph, and\nwherein partitioning the computational graph into the plurality of subgraphs comprises generating the plurality of subgraphs only from the specified subset of nodes and directed edges.\n3. The method of claim 2, wherein the request specifies the subset of the plurality of nodes and directed edges of the computational graph using one or more client-provided labels on the plurality of nodes and directed edges.\n4. The method of claim 1, wherein the computational graph is a first computational graph, and wherein the method further comprises:\nreceiving a designation from the client that a portion of the first computational graph is a re-usable function;\nreceiving a request to process a second computational graph and obtaining data representing the second computational graph, the data representing a plurality of nodes and directed edges of the second computational graph and one or more references to the re-usable function in the second computational graph; and\nprocessing the second computational graph using the plurality of available devices, wherein the processing comprises augmenting the second computational graph by replacing references to the re-usable function in the second computational graph with the portion of the first computational graph.\n5. The method of claim 4, wherein the portion of the first computational graph comprises nodes representing operations of a network layer of the plurality of network layers of the neural network.\n6. The method of claim 1, wherein the request specifies one or more particular outputs from one or more respective nodes, and wherein the method further comprises:\nreceiving, from a device to which the one or more respective nodes are assigned, the one or more particular outputs; and\nproviding the one or more particular outputs to the client.\n7. The method of claim 1, wherein each device in the plurality of available devices is a hardware resource that performs operations independent of other devices in the plurality of available devices.\n8. The method of claim 1, comprising assigning the operations to an available device having a computational capability necessary to perform the operations represented by the respective group of nodes in the subgraph.\n9. The method of claim 1, comprising identifying a second first group of nodes among the plurality of groups of nodes based on the first group of nodes including a first node that produces shared data for processing by multiple other nodes in the first group of nodes, wherein partitioning includes assigning each node in the first group of nodes to a same one of the plurality of subgraphs based on having identified that the first node produces shared data for processing multiple other nodes in the first group of nodes.\n10. The method of claim 1, comprising identifying a first group of nodes among the plurality of groups of nodes based on determining that a respective available device has sufficient memory to accommodate a maximum memory requirement of the operations represented by the first group of nodes.\n11. The method of claim 1, comprising determining, for a first subgraph of the plurality of subgraphs, a maximum size of a tensor that the first subgraph is configured to process, including calculating, for each directed edge connecting a respective pair of nodes in the first subgraph, a dimension of a respective tensor along the directed edge,\nwherein assigning the respective subset of operations of the neural network for each subgraph to a respective available device among a plurality of available devices for processing includes assigning (i) the first subgraph to a first device that is determined to have sufficient memory to store a tensor having the maximum size of the tensor that the first subgraph is configured to process and (ii) a second subgraph of the plurality of subgraphs to a second device other than the first device.\n12. A system comprising:\none or more computers and one or more storage devices on which are stored instructions that are operable, when executed by the one or more computers, to cause the one or more computers to perform operations comprising:\nreceiving a request from a client to process a computational graph that models a neural network having a plurality of network layers;\nobtaining data representing the computational graph, the computational graph comprising a plurality of nodes and directed edges, each node representing a respective operation of the neural network modeled by the computational graph, and each directed edge connecting a respective first node to a respective second node that represents an operation that receives, as input, an output of an operation represented by the respective first node; and\nprocessing the computational graph, comprising:\nanalyzing the computational graph to identify a plurality of groups of nodes, each group of nodes representing a respective subset of operations of the neural network, wherein the nodes in each group are selected for inclusion in the group based on an indication that the nodes form a chain structure of nodes connected in series by a succession of directed edges, wherein the chain structures in the plurality of groups of nodes are determined to minimize a number of subgraphs that will be formed from the plurality of groups of nodes;\npartitioning the computational graph into a plurality of subgraphs, each subgraph being a portion of the computational graph for a different one of the plurality of groups of nodes that represents a different, respective subset of operations of the neural network, wherein partitioning the computational graph includes assigning each node in the first group of nodes to a same one of the plurality of subgraphs based on having determined that the first group of nodes forms the chain structure;\nassigning the respective subset of operations of the neural network for each subgraph to a respective available device among a plurality of available devices for processing, including assigning the respective subsets of operations of the neural network for at least two subgraphs to different ones of the plurality of available devices for processing; and\ncausing each device to perform the operations assigned to the device.\n13. The system of claim 12, wherein the request specifies a subset of the plurality of nodes and directed edges of the computational graph, and\nwherein partitioning the computational graph into the plurality of subgraphs comprises generating the plurality of subgraphs only from the specified subset of nodes and directed edges.\n14. The system of claim 13, wherein the request specifies the subset of the plurality of nodes and directed edges of the computational graph using one or more client-provided labels on the plurality of nodes and directed edges.\n15. The system of claim 12, wherein the computational graph is a first computational graph, and wherein the operations further comprise:\nreceiving a designation from the client that a portion of the first computational graph is a re-usable function;\nreceiving a request to process a second computational graph and obtaining data representing the second computational graph, the data representing a plurality of nodes and directed edges of the second computational graph and one or more references to the re-usable function in the second computational graph; and\nprocessing the second computational graph using the plurality of available devices, wherein the processing comprises augmenting the second computational graph by replacing references to the re-usable function in the second computational graph with the portion of the first computational graph.\n16. The system of claim 15, wherein the portion of the first computational graph comprises nodes representing operations of a network layer of the plurality of network layers of the neural network.\n17. The system of claim 12, wherein the request specifies one or more particular outputs from one or more respective nodes, and wherein the operations further comprise:\nreceiving, from a device to which the one or more respective nodes are assigned, the one or more particular outputs; and\nproviding the one or more particular outputs to the client.\n18. The system of claim 12, wherein each device in the plurality of available devices is a hardware resource that performs operations independent of other devices in the plurality of available devices.\n19. The system of claim 12, comprising assigning the operations to an available device having a computational capability necessary to perform the operations represented by the respective group of nodes in the subgraph.\n20. The system of claim 12, wherein the operations comprise determining, for a first subgraph of the plurality of subgraphs, a maximum size of a tensor that the first subgraph is configured to process, including calculating, for each directed edge connecting a respective pair of nodes in the first subgraph, a dimension of a respective tensor along the directed edge,\nwherein assigning the respective subset of operations of the neural network for each subgraph to a respective available device among a plurality of available devices for processing includes assigning (i) the first subgraph to a first device that is determined to have sufficient memory to store a tensor having the maximum size of the tensor that the first subgraph is configured to process and (ii) a second subgraph of the plurality of subgraphs to a second device other than the first device.\n21. A method comprising:\nreceiving a request from a client to process a computational graph that models a neural network having a plurality of network layers;\nobtaining data representing the computational graph, the computational graph comprising a plurality of nodes and directed edges, each node representing a respective operation of the neural network modeled by the computational graph, and each directed edge connecting a respective first node to a respective second node that represents an operation that receives, as input, an output of an operation represented by the respective first node; and\nprocessing the computational graph, comprising:\nanalyzing the computational graph to identify a plurality of groups of nodes, each group of nodes representing a respective subset of operations of the neural network;\npartitioning the computational graph into a plurality of subgraphs, each subgraph being a portion of the computational graph for a different one of the plurality of groups of nodes that represents a different, respective subset of operations of the neural network,\ndetermining, for a first subgraph of the plurality of subgraphs, a maximum size of a tensor that the first subgraph is configured to process, including calculating, for each directed edge connecting a respective pair of nodes in the first subgraph, a dimension of a respective tensor along the directed edge;\nassigning the respective subset of operations of the neural network for each subgraph to a respective available device among a plurality of available devices for processing, including assigning (i) the first subgraph to a first device that is determined to have sufficient memory to store a tensor having the maximum size of the tensor that the first subgraph is configured to process and (ii) a second subgraph of the plurality of subgraphs to a second device other than the first device; and\ncausing each device to perform the operations assigned to the device.",
    "status": "Active",
    "citations_own": [
        "JPH04211858A",
        "JPH05108595A",
        "JP2001117900A",
        "JP2004185271A",
        "US20060095722A1",
        "US20060095721A1",
        "US20100325621A1",
        "US7961636B1",
        "US20120079490A1",
        "JP2014102996A",
        "JP2014102917A",
        "US20140215477A1",
        "US20150007182A1",
        "US20150148919A1",
        "CN104683488A",
        "CN104820945A",
        "US20150324690A1",
        "US20160092765A1",
        "US20160103901A1",
        "US20160204795A1",
        "US9489639B2",
        "US20170039485A1",
        "US20170091668A1",
        "US20180247197A1",
        "US10282809B2"
    ],
    "citations_ftf": [
        "US5768594A",
        "US6175957B1",
        "JP2014059862A",
        "JP5965498B2",
        "JP6036848B2",
        "JP5987720B2"
    ],
    "citedby_own": [],
    "citedby_ftf": [
        "JP6983154B2",
        "US10506016B2",
        "US10275287B2",
        "US10656970B2",
        "US11615285B2",
        "US10318355B2",
        "US10534657B2",
        "US11138516B2",
        "EP3580698A1",
        "US10887235B2",
        "US10642582B2",
        "US10599482B2",
        "US11620490B2",
        "GB2569270B",
        "EP3502975A1",
        "US11119808B2",
        "WO2019151984A1",
        "CN108491259B",
        "US11514054B1",
        "WO2019235551A1",
        "US11663478B2",
        "US20190392287A1",
        "CN110764744A",
        "CN110765821B",
        "CN110879744B",
        "KR20200053318A",
        "CN109508412B",
        "US20200184366A1",
        "US11714992B1",
        "CN109669772B",
        "CN109902819B",
        "CN111563584B",
        "CN111667046A",
        "CN109919315B",
        "CN111694571B",
        "US11569978B2",
        "US11652603B2",
        "US11423254B2",
        "US11671111B2",
        "CN111832714A",
        "US11790250B2",
        "CN112070221A",
        "CN110188871B",
        "US11080200B2",
        "US11687789B2",
        "KR102325047B1",
        "US11494237B2",
        "US10963301B2",
        "WO2021012215A1",
        "EP4024202A4",
        "CN110689121A",
        "CN110689116B",
        "KR102068279B1",
        "KR102068277B1",
        "US11580401B2",
        "US11651210B2",
        "US11797827B2",
        "EP4078927A1",
        "US11709059B2",
        "CN111190741B",
        "US11620502B2",
        "US20210248115A1",
        "CN111309479B",
        "CN111338635B",
        "JP6834097B1",
        "US11461130B2",
        "CN111723935A",
        "CN111708641A",
        "CN111860820A",
        "WO2022261447A1",
        "WO2022265412A1",
        "KR102457152B1",
        "US11782706B1",
        "KR20230049468A",
        "JP7179237B1",
        "CN114840322B",
        "CN116795519A"
    ]
}