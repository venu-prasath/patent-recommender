{
    "patent_link": "https://patents.google.com/patent/US5987468A/en",
    "patent_id": "US5987468A",
    "title": "Structure and method for efficient parallel high-dimensional similarity join",
    "abstract": "Multidimensional similarity join finds pairs of multi-dimensional points that are within some small distance of each other. Databases in domains such as multimedia and time-series can require a high number of dimensions. The \u03b5-k-d-B tree has been proposed as a data structure that scales better as number of dimensions increases compared to previous data structures such as the R-tree (and variations), grid-file, and k-d-B tree. We present a cost model of the \u03b5-k-d-B tree and use it to optimize the leaf size. This new leaf size is shown to be better in most situations compared to previous work that used a constant leaf size. We present novel parallel procedures for the \u03b5-k-d-B tree. A load-balancing strategy based on equi-depth histograms is shown to work well for uniform or low-skew situations, whereas another based on weighted, equi-depth histograms works far better for high-skew datasets. The latter strategy is only slightly slower than the former strategy for low skew datasets. The weights for the latter strategy are based on the same cost model that is used to determine optimal leaf sizes.",
    "inventors": [
        "Vineet Singh",
        "Khaled Alsabti",
        "Sanjay Ranka"
    ],
    "assignee": "Hitachi America Ltd",
    "classifications": [
        "G06F16/2264",
        "G06F16/2246",
        "Y10S707/99936",
        "Y10S707/99937"
    ],
    "claims": "\n1. In a computing system having a plurality of interconnected processing elements and a memory storing an object set comprising a plurality of objects, a method of joining ones of said objects based on predetermined similarity criteria, the steps of the method comprising:\nstoring in said memory, references to said plurality of objects in said object set;\npartitioning said object set into a plurality of subpartitions to associate ones of said plurality of objects among said plurality of processing elements;\nwithin each particular processing element, constructing an object tree structure organizing said ones of said plurality of objects associated with said particular processing element;\nwithin each particular processing element, determining intersecting regions with neighboring processing elements for each said particular processing element based on predetermined first rules;\nexchanging objects between each said particular processing element and said neighboring processing elements based on predetermined second rules; and\njoining said objects based on a predetermined object similarity criteria to generate joined groups of multi-dimensional objects.\n2. The method in claim 1, wherein said object set comprises a data set and at least ones of said objects comprise multi-dimensional data objects.\n3. The method in claim 1, wherein said object set comprises a multi-dimensional data set and said objects comprise multi-dimensional data points within said data set.\n4. The method in claim 1, further comprising the steps of:\nprior to said step of partitioning said objects, sensing a physical system and generating a data object representative of said sensed physical system, and receiving a data object from a source separate from said processing elements or said memory associated with said processing elements; and\nafter said step of exchanging objects between each said particular processing element and said neighboring processing elements, generating a set of multi-dimensional object join sets, and generating a decision metric based on said object join sets.\n5. The method in claim 1 wherein, said memory comprises random access memory.\n6. The method in claim 1 wherein, said memory comprises non-volatile disk memory.\n7. The method in claim 1 wherein, said objects comprise multi-dimensional data points and said references to said plurality of objects comprise database pointers, each pointing to one of said plurality of data points.\n8. The method in claim 1 wherein, said objects comprise d-dimensional data points, and said step of partitioning said object set to associate ones of said plurality of objects among said plurality of processing elements comprises the steps of:\nselecting a number of partitioning dimensions D for a number of points n, and a plurality of processors P;\nestimating p1/D quantile values using the ith dimension of the points (pdi) for each subpartition;\ndividing each said subpartition into p1/D subpartitions based on said estimated quantile values;\nredistributing said data points among said p1/D new subpartitions;\ncomparing the current partitioning dimension D after each said estimation, dividing, and redistribution to determine if the current level of partitioning i has a predefined magnitude relationship relative to said number of partitioning dimensions, and if said predefined magnitude relationship is satisfied returning from said partitioning, and otherwise recursively applying said steps of estimating, dividing, and redistributing for each subpartition at the next partitioning level having the partitioned data set.\n9. The method in claim 8, wherein said partitioning comprising applying single pass quantiling procedure having a sampling subprocedure and a quantile finding subprocedure.\n10. The method in claim 1 where in said tree is an \u03b5-k-d-B tree.\n11. The method in claim 1 wherein, said objects comprise d-dimensional data points, and said step of partitioning said object set to associate ones of said plurality of objects among said plurality of processing elements determines quantiles estimated based on a sample data set and comprises the steps of:\nidentifying a number of processors p among which said data set (DS) is to be partitioned;\nsampling said entire data set (DS) to generate a sample set of points (SS) which are fewer than said entire data set;\ndistributing said sample set of points over said identified number of processors;\nidentifying a partitioning rule for associating particular ones of said data points among said identified number of processing elements without redistributing said data points;\ndetermining partition region boundaries for said identified partitions;\nbroadcasting said region boundaries for said partitioned sample set (SS) by each said processing element to every other of said processing elements; and\nredistributing, by each said processing element, said entire data set (DS) using said region boundaries determined from said sampled data set quantiles.\n12. The method in claim 1 wherein, said objects comprise d-dimensional data points, and said step of partitioning said object set to associate ones of said plurality of objects among said plurality of processing elements determines quantiles based on a weighting for each data point, and comprises the steps of:\nselecting a sample size s;\ngenerating a sampled data set of size s from said entire data set;\npartitioning said sampled data set using a quantile partitioning procedure;\nwithin each said processing element, constructing a local \u03b5-k-d-B tree for each data points associated with each said partitioned sampled data set on a point-by-point basis until all data points in said partition have been placed in said tree;\nidentifying and exchanging intersected regions among said processing elements;\ncomputing the number of join tests that would be required to join the data sets but without actually joining said data;\ncomputing a data point weight value (W) for each point based on said computed number of join tests;\nperforming weighted partitioning of said data set using said weight values to take into account the work load associated with particular ones of said points in addition to the number of points in each partition to determine weighted region boundaries for each of said processing elements; and\nredistributions said entire data set using region boundaries identified by said weighted partitioning.\n13. The method in claim 12, wherein said step of performing weighted partitioning to determine weighted region boundaries for each of said processing elements comprises the steps of:\nrecursively performing for each subpartition at each partitioning dimension (D) the steps of:\nsorting said data set along a partitioning dimension i;\ncomputing a prefix-sum on said point weight values; and\nredistributing said data set in each subpartition using region boundaries determined for said subpartition.\n14. The method in claim 12, wherein said weights are assigned to said data points on the basis of the estimated work associated with the number of join tests required for each said point and the work associated with traversing the tree for each data point.\n15. The method in claim 12, wherein said point weight values (W) are assigned to each point (q) according to the equation W(q)=(r\u00d7d)+(k\u00d73depth) where r is the estimated number of join tests required for point q, d is the dimensionality of the data points, k is a constant of proportionality, and depth is the depth of the \u03b5-k-d-B tree.\n16. The method in claim 15, wherein k is a positive constant in the range between 0.1 and 10.\n17. The method in claim 15, wherein k is a positive constant in the range between 1 and 3.\n18. The method in claim 1 wherein, said step of constructing an object tree structure organizing said ones of said plurality of objects associated with said particular processing element comprises constructing an \u03b5-k-d-B tree.\n19. The method in claim 1 wherein, said step of determining intersecting regions by each processing element with neighboring processing elements for each said particular processing element based on predetermined first rules comprises the steps of:\nidentifying neighboring processors;\nbuilding a first list database structure and a second list database structure for each level of said local \u03b5-k-d-B tree in each processing element, said first list identifying for each location in said tree whether the sub-tree at that level is empty or stores a data point;\nexchanging said first and second lists between said processing elements including communicating said first and second list to every other of said processing elements over said interconnect network and receiving a communication of other of said first and second list from said other processing elements;\ndetermining an intersected region by comparing entries in said first list of a particular processing element with said second list of every other one of said processing elements to generate a third resultant list data structure in memory; and\nassigning intersected regions to said processing elements based on predetermined rules.\n20. The method in claim 19, wherein elements of said first and second lists comprise binary values and said step of determining an intersected region comprising performing an element-by-element logical operation between said first and second lists.\n21. The method in claim 1, wherein said step of joining said objects based on a predetermined object similarity criteria to generate joined groups of multi-dimensional objects comprises performing a self-join procedure for each non-leaf node including a non-self-join procedure, and performing a leaf-self-join procedure for each leaf-node including a leaf-non-self-join procedure for each leaf-node.\n22. A computer readable storage medium for use with a computer system, the system having a plurality of processors and a user interface for receiving commands from a user, said storage medium storing a plurality of objects and a plurality of executable procedures wherein each said procedure comprises at least one executable instruction which instructs said computer to search said plurality of objects according to query inputs from said user to identify ones of said plurality of objects having a similar characteristic, said plurality of instructions comprising:\ninstructions which instruct the computer to store ones of said plurality of objects in said memory;\ninstructions which instruct the computer to partition said objects into a plurality of subpartitions and to associate ones of said plurality of objects among said plurality of processors;\ninstructions which instruct the computer to construct a local \u03b5-k-d-B object tree structure organizing said ones of said plurality of objects associated with said particular processor;\ninstructions which instruct the computer to determine intersecting regions of said object space with neighboring processors;\ninstructions which instruct the computer to exchange objects with neighboring processors based on predetermined rules where said neighboring processors are processors associated with objects that are within some predetermined distance; and\ninstructions which instruct the computer to join said objects based on a predeterained object similarity criteria to generate joined groups of multi-dimensional objects; and\nsaid objects comprising a data structure representing said objects in hierarchical manner, and including an array of database elements and indices and pointers associated therewith;\nsaid procedures further including instructions for traversing said data structure using said array of indices and pointers to access the contents of said database elements; and\nprocedures for establishing said data structure in said memory to represent said joined groups of multi-dimensional objects.\n23. A computer system comprising:\na plurality of process in g elements each said processing element having a processor for executing instructions and an associated memory connected to said processing element, said memory storing o objects and a plurality of procedures;\nstorage means for storing a plurality of objects;\nan interconnect network coupling said processing elements with said associated memory and to said storage means;\nsaid plurality of procedures including a procedure for performing a multi-dimensional similarity join operation on said objects to generate pairs of joined multi-dimensional objects; and\nmeans for executing said procedure for performing a multi-dimensional similarity join operation to generate said pairs of joined multi-dimensional objects.\n24. The computer system in claim 23, wherein said means for executing said procedure comprises:\nmeans for storing in said memory, references to said plurality of objects in said object set;\nmeans for partitioning said object set into a plurality of subpartitions to associate ones of said plurality of objects among said plurality of processing elements;\nmeans, within each processing element, for constructing an \u03b5-k-d-B object tree structure organizing said ones of said plurality of objects associated with said particular processing element;\nmeans, within each particular processing element, for determining intersecting regions with neighboring processing elements for each said particular processing element based on predetermined first rules;\nmeans for exchanging objects between each said particular processing element and said neighboring processing elements based on predetermined second rules; and\nmeans for joining said objects based on a predetermined object similarity criteria to generate joined groups of multi-dimensional objects.\n25. In a computer system having a multiplicity of processing elements each having a central processing unit and memory and wherein said processing elements are connected by an interconnection network, a method for rapidly and efficiently performing a parallel query of a database of high-dimensional data items to identify similar items having user defined similarity characteristics and joining said similar items into an output set of data items; said method characterized in that:\nsaid database comprises an \u03b5-k-d-B tree structure and is partitioned among said multiplicity of processing elements based on a load balancing weighting operation rather than on the number of points along;\nsaid weighting are computed based on a traversal cost and a computation cost for said \u03b5-k-d-B tree in combination; and\nsaid joining of said similar items into an output set of data items generating a joined set of multi-dimensional data items.\n26. A weighted quantiling method of partitioning a database comprised of a d-dimensional data set of items among a plurality of processing elements and memory associated with each said processing elements, said method comprising the steps of:\ngenerating a sampled data set of size s from said entire data set;\npartitioning said sampled data set using a quantile partitioning procedure;\nwithin each said processing element, constructing a local \u03b5-k-d-B tree for each data points associated with each said partitioned sampled data set on a point-by-point basis until all data points in said partition have been placed in said tree;\nidentifying and exchanging intersected regions among said processing elements;\ncomputing the number of join tests that would be required to join the data sets but without actually joining said data;\ncomputing a data point weight value for each point based on said computed number of join tests;\nperforming weighted partitioning of said data set using said weight values to take into account the work load associated with particular ones of said points in addition to the number of points in each partition to determine weighted region boundaries for each of said processing elements; and\nredistributing said entire data set using region boundaries identified by said weighted partitioning.\n27. The method in claim 26, wherein said step of perform weighted partitioning to determine weighted region boundaries for each of said processing elements comprises the steps of:\nrecursively performing for each subpartition at each partitioning dimension (D) the steps of:\nsorting said data set along a partitioning dimension i;\ncomputing a prefix-sum on said point weights (W); and\nredistributing said data set in each subpartition using region boundaries determined for said subpartition.\n28. The method in claim 27, wherein said weights are assigned to said data points on the basis of the estimated work associated with the number of join tests required for each said point and the work associated with traversing the tree for each data point.\n29. The method in claim 27, wherein said point weight values (W) are assigned to each point (q) according to the equation W(q)=(r\u00d7d)+(k\u00d73depth) where r is the estimated number of join tests required for point q, d is the dimensionality of the data points, k is a constant of proportionality , and depth is the depth of the \u03b5-k-d-B tree.\n30. The method in claim 29, wherein k is a positive constant in the range between substantially 1 and 3.",
    "status": "Expired - Fee Related",
    "citations_own": [
        "US4811210A",
        "US5579471A",
        "US5647058A",
        "US5842031A"
    ],
    "citations_ftf": [],
    "citedby_own": [
        "US6052689A",
        "US6275920B1",
        "US6282533B1",
        "US6311179B1",
        "US6389424B1",
        "US20020062309A1",
        "WO2002061626A1",
        "US6484182B1",
        "US6496817B1",
        "US20030009467A1",
        "US20030037025A1",
        "US6532476B1",
        "US20030061228A1",
        "US20030097357A1",
        "US20030182291A1",
        "US20030187616A1",
        "US20030204576A1",
        "US6654760B2",
        "US6671694B2",
        "US6704721B1",
        "US6735595B2",
        "US20040093320A1",
        "US6745198B1",
        "US20040139096A1",
        "US6785687B2",
        "US6816856B2",
        "US6819967B2",
        "US6865567B1",
        "KR100472949B1",
        "US20060101045A1",
        "US20060101056A1",
        "US7058952B1",
        "US20060206513A1",
        "US20060282765A1",
        "US7194477B1",
        "US20070083505A1",
        "US20070133410A1",
        "US20070136341A1",
        "US20070226744A1",
        "US20070239790A1",
        "US20070250522A1",
        "US20080098029A1",
        "US20080109437A1",
        "US20080109423A1",
        "US7428528B1",
        "US20090024568A1",
        "US20090089658A1",
        "US20090125482A1",
        "US7617184B2",
        "US20100031003A1",
        "US20100049722A1",
        "US20100082417A1",
        "US20100100553A1",
        "US20100106934A1",
        "US20100169360A1",
        "US20100185672A1",
        "US20100287015A1",
        "US7912823B2",
        "US20110208872A1",
        "US20110218978A1",
        "US8019752B2",
        "US20110238677A1",
        "US20120317092A1",
        "US20130325873A1",
        "US8676802B2",
        "US20140129298A1",
        "US8782514B1",
        "US8886796B2",
        "US20140379692A1",
        "US20150347495A1",
        "US20160055611A1",
        "US9392026B2",
        "CN106095968A",
        "US9665573B2",
        "US9928260B2",
        "US10114846B1",
        "US10133770B2",
        "EP3308282A4",
        "US10402316B2",
        "US10452268B2",
        "US10496638B2",
        "US10558678B2",
        "US10585889B2",
        "US10685306B2",
        "US10698628B2",
        "US10783022B2",
        "US10809923B2",
        "US10826930B2",
        "US10922005B2",
        "US11036715B2",
        "US11086521B2",
        "US20210318998A1",
        "US11200249B2",
        "US11269514B2",
        "US11615094B2",
        "US11727009B2"
    ],
    "citedby_ftf": [
        "US11113314B2",
        "CN111046092B"
    ]
}