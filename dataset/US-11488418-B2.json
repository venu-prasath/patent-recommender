{
    "patent_id": "US-11488418-B2",
    "title": "Three-dimensional (3D) pose estimation from a monocular camera ",
    "assignee": "Nvidia Corporation",
    "publication_date": "2022-11-01",
    "patent_link": "https://patents.google.com/patent/US11488418B2/en",
    "inventors": [
        "Umar Iqbal",
        "Pavlo Molchanov",
        "Thomas Michael Breuel",
        "Jan Kautz"
    ],
    "classifications": [
        "G06V10/82",
        "G06N3/045",
        "G06N3/08",
        "G06N3/084",
        "G06N5/046",
        "G06T7/579",
        "G06T7/73",
        "G06V10/764",
        "G06V40/107",
        "G06V40/28",
        "G06N3/047",
        "G06T2200/04",
        "G06T2207/10028",
        "G06T2207/20081",
        "G06T2207/20084",
        "G06T2207/30196"
    ],
    "abstract": "Estimating a three-dimensional (3D) pose of an object, such as a hand or body (human, animal, robot, etc.), from a 2D image is necessary for human-computer interaction. A hand pose can be represented by a set of points in 3D space, called keypoints. Two coordinates (x,y) represent spatial displacement and a third coordinate represents a depth of every point with respect to the camera. A monocular camera is used to capture an image of the 3D pose, but does not capture depth information. A neural network architecture is configured to generate a depth value for each keypoint in the captured image, even when portions of the pose are occluded, or the orientation of the object is ambiguous. Generation of the depth values enables estimation of the 3D pose of the object.",
    "claims": "\n1. A computer-implemented method, comprising:\nreceiving locations of keypoints for a three-dimensional (3D) object, wherein each location includes pixel coordinates and a normalized depth value, the pixel coordinates corresponding to pixels within a two-dimensional (2D) image of the 3D object, the 2D image associated with camera attributes and the normalized depth values corresponding to normalized relative depth values of each one of the keypoints with respect to a reference keypoint;\ncomputing a depth of the reference keypoint with respect to a camera based on the locations and the camera attributes; and\ncomputing a scale normalized 3D pose of the 3D object based on the locations, the depth of the reference keypoint and the camera attributes.\n2. The computer-implemented method of claim 1, further comprising receiving a scale factor corresponding to the 3D object.\n3. The computer-implemented method of claim 2, further comprising generating, according to the scale factor, an absolute 3D pose of the 3D object from the scale normalized 3D pose.\n4. The computer-implemented method of claim 2, wherein the scale factor is estimated and corresponds to a component of the 3D object.\n5. The computer-implemented method of claim 2, wherein the scale factor is measured and corresponds to a component of the 3D object.\n6. The computer-implemented method of claim 2, wherein the scale factor is a distance between two vertices or two keypoints of the 3D object.\n7. The computer-implemented method of claim 1, wherein the normalized depth values are computed relative to a reference keypoint.\n8. The computer-implemented method of claim 7, wherein computing the scale normalized 3D pose is based on a depth of the reference keypoint that is calculated using the locations.\n9. The computer-implemented method of claim 1, wherein the normalized depth values are invariant for changes in a scale of the 3D object.\n10. The computer-implemented method of claim 1, wherein the normalized depth values are invariant for changes in a translation of the 3D object.\n11. A system, comprising:\na processor configured to:\nreceive locations of keypoints for a three-dimensional (3D) object, wherein each location includes pixel coordinates and a normalized depth value, the pixel coordinates corresponding to pixels within a two-dimensional (2D) image of the 3D object, the 2D image associated with camera attributes and the normalized depth values corresponding to normalized relative depth values of each one of the keypoints with respect to a reference keypoint;\ncompute a depth of the reference keypoint with respect to a camera based on the locations and the camera attributes; and\ncompute a scale normalized 3D pose of the 3D object based on the locations, the depth of the reference keypoint and the camera attributes.\n12. The system of claim 11, wherein the processor is further configured to receive a scale factor corresponding to the 3D object.\n13. The system of claim 12, wherein the processor is further configured to generate, according to the scale factor, an absolute 3D pose of the 3D object from the scale normalized 3D pose.\n14. The system of claim 12, wherein the scale factor is estimated and corresponds to a component of the 3D object.\n15. The system of claim 12, wherein the scale factor is a distance between two vertices or two keypoints of the 3D object.\n16. The system of claim 11, wherein the normalized depth values are computed relative to a reference keypoint.\n17. The system of claim 16, wherein computing the scale normalized 3D pose is based on a depth of the reference keypoint that is calculated using the locations.\n18. A non-transitory computer-readable media storing computer instructions that, when executed by one or more processors, cause the one or more processors to perform the steps of:\nreceiving locations of keypoints for a three-dimensional (3D) object, wherein each location includes pixel coordinates and a normalized depth value, the pixel coordinates corresponding to pixels within a two-dimensional (2D) image of the 3D object, the 2D image associated with camera attributes and the normalized depth values corresponding to normalized relative depth values of each one of the keypoints with respect to a reference keypoint;\ncomputing a depth of the reference keypoint with respect to a camera based on the locations and the camera attributes; and\ncomputing a scale normalized 3D pose of the 3D object based on the locations, the depth of the reference keypoint and the camera attributes.\n19. The non-transitory computer-readable media of claim 18, further comprising receiving a constant scale factor corresponding to the 3D object.\n20. The non-transitory computer-readable media of claim 19, further comprising generating, according to a scale factor, an absolute 3D pose of the 3D object from the scale normalized 3D pose."
}