{
    "patent_link": "https://patents.google.com/patent/US20110188715A1/en",
    "patent_id": "US20110188715A1",
    "title": "Automatic Identification of Image Features",
    "abstract": "Automatic identification of image features is described. In an embodiment, a device automatically identifies organs in a medical image using a decision forest formed of a plurality of distinct, trained decision trees. An image element from the image is applied to each of the trained decision trees to obtain a probability of the image element representing a predefined class of organ. The probabilities from each of the decision trees are aggregated and used to assign an organ classification to the image element. In another embodiment, a method of training a decision tree to identify features in an image is provided. For a selected node in the decision tree, a training image is analyzed at a plurality of locations offset from a selected image element, and one of the offsets is selected based on the results of the analysis and stored in association with the node.",
    "inventors": [
        "Jamie Daniel Joseph Shotton",
        "Antonio Criminisi"
    ],
    "assignee": "Microsoft Technology Licensing LLC",
    "classifications": [
        "G06F18/24323",
        "G06F18/00",
        "G06T7/0012",
        "G06V2201/031"
    ],
    "claims": "\n1. A device for automatically identifying organs in a medical image, comprising:\na communication interface arranged to receive the medical image;\nat least one processor; and\na memory arranged to store a decision forest comprising a plurality of distinct trained decision trees, and arranged to store executable instructions configured to cause the processor to: select an image element from the medical image; apply the image element to each of the trained decision trees to obtain a plurality of probabilities of the image element representing one of a plurality of predefined classes of organ; and aggregate the probabilities from each of the trained decision trees and assign an organ classification to the image element in dependence thereon.\n2. A device according to claim 1, wherein the medical image is a three-dimensional volumetric image and the image element is a voxel.\n3. A device according to claim 1, wherein the executable instructions are configured to cause the processor to aggregate the probabilities by averaging the probabilities from each of the trained decision trees.\n4. A device according to claim 1, wherein the executable instructions are configured to cause the processor to assign an organ classification to the image element using at least one of: a maximum value from the aggregate probabilities; a threshold minimum value of the aggregate probabilities; and a maximum a-posteriori classification for the aggregate probabilities.\n5. A device according to claim 1, wherein the executable instructions are further configured to cause the processor to repeat the select, apply, aggregate and assign operations for each image element in the medical image, and the executable instructions are further configured to estimate a location for the centre of a selected organ using the aggregate probabilities for each image element in the medical image.\n6. A device according to claim 5, further comprising a display device, and wherein the executable instructions are further configured to cause the processor to display the medical image on the display device, centered on the location of the centre of the selected organ.\n7. A device according to claim 1, wherein the executable instructions are configured to cause the processor to apply the image element to each of the trained decision trees by passing the image element through a plurality of nodes in each tree until a leaf node is reached in each tree, and wherein the plurality of probabilities are determined in dependence on the leaf node reached in each tree.\n8. A device according to claim 7, wherein each of the plurality of nodes in each tree performs a test to determine a subsequent node to which to send the image element.\n9. A device according to claim 8, wherein the test utilizes predefined parameters determined during a training process.\n10. A computer-implemented method of training a decision tree to identify features within an image, comprising:\nselecting a node of the decision tree;\nselecting at least one image element in a training image;\ngenerating a plurality of spatial offset values;\nanalyzing the training image at a plurality of locations to obtain a plurality of results, wherein each location is offset from the or each image element by a respective one of the spatial offset values;\nselecting a chosen offset from the spatial offset values in dependence on the results; and\nstoring the chosen offset in association with the node at a storage device.\n11. A method according to claim 10, wherein the step of analyzing the training image comprises at least one of: analyzing an intensity value of at least one image element; and analyzing a magnitude of an intensity gradient for at least one image element.\n12. A method according to claim 10, wherein the image is a three-dimensional medical volumetric image, the or each image element is a voxel, and the features are organs.\n13. A method according to claim 12, further comprising the step of generating a plurality of cuboid dimensions, and wherein each location comprises a portion of the volumetric image encompassed by a cuboid having a respective one of the plurality of cuboid dimensions.\n14. A method according to claim 13, wherein the plurality of cuboid dimensions are randomly generated.\n15. A method according to claim 13, wherein the step of analyzing comprises summing at least one parameter from each voxel in the cuboid at each location.\n16. A method according to claim 10, wherein the step of selecting a chosen offset comprises determining an information gain for each of the plurality of results, and selecting the chosen offset as the spatial offset value giving the maximum information gain.\n17. A method according to claim 16, wherein the step of determining an information gain for each of the plurality of results comprises: comparing each of the plurality of results to a plurality of threshold values to obtain a plurality of comparison values for each of the plurality of results; and determining an information gain for each of the plurality of comparison values.\n18. A method according to claim 17, wherein the method further comprises: selecting a chosen threshold as the threshold value giving the maximum information gain; and storing the chosen threshold in association with the node at the storage device.\n19. A method according to claim 16, further comprising repeating the steps of the method until the maximum information gain is less than a predefined minimum value or the node of the decision tree has a maximum predefined depth.\n20. A computer-implemented method of automatically identifying a location of a center of an organ in a three-dimensional medical volumetric image, comprising:\nreceiving the three-dimensional medical volumetric image at a processor;\naccessing a decision forest comprising a plurality of distinct trained decision trees stored on a storage device;\nselecting a voxel from the medical volumetric image;\napplying the voxel to each of the trained decision trees to obtain a plurality of probabilities of the voxel representing one of a plurality of predefined classes of organ;\naggregating the probabilities from each of the trained decision trees to obtain an overall organ probability for the voxel;\nrepeating the steps of selecting, applying and aggregating for each voxel in the medical volumetric image; and\nestimating the location of the centre of the organ using the overall organ probability for each voxel in the medical volumetric image.",
    "status": "Abandoned",
    "citations_own": [
        "US6058205A",
        "US20050010445A1",
        "US20060064017A1",
        "US20070055153A1",
        "US20070053563A1",
        "US20080075367A1",
        "US20080087561A1",
        "US7451123B2",
        "US7453472B2",
        "US20080317331A1",
        "US20100260396A1"
    ],
    "citations_ftf": [],
    "citedby_own": [
        "US20110229020A1",
        "US20110307423A1",
        "US20120177269A1",
        "US20130156298A1",
        "WO2013114262A1",
        "US20140122381A1",
        "US20140133729A1",
        "US20150043799A1",
        "US20150379376A1",
        "US20160155236A1",
        "US9466012B2",
        "US9619561B2",
        "WO2018182981A1",
        "CN108846022A",
        "US10152651B2",
        "US10235605B2",
        "DE102017217543A1",
        "US10387801B2",
        "CN110261850A",
        "US10657671B2",
        "US10733561B2",
        "CN111723208A",
        "CN113096141A",
        "CN113268893A",
        "US11151721B2",
        "US11215711B2",
        "US11238544B2",
        "US11256991B2",
        "EP3819827A4",
        "US11334836B2",
        "US11710309B2"
    ],
    "citedby_ftf": []
}