{
    "patent_id": "US-10528878-B2",
    "title": "Tailoring question answering system output based on user experience ",
    "assignee": "International Business Machines Corporation",
    "publication_date": "2020-01-07",
    "patent_link": "https://patents.google.com/patent/US10528878B2/en",
    "inventors": [
        "Nicholas V. Bruno",
        "Donna K. Byron",
        "Julius Goth, Iii",
        "Dwi S. Mansjur"
    ],
    "classifications": [
        "G06N5/04",
        "G06N20/00",
        "G06N5/022"
    ],
    "abstract": "A mechanism is provided in a data processing system for tailoring question answering system output based on user expertise. The mechanism receives an input question from a questioning user and determines a set of features associated with text of the input question. The mechanism determines an expertise level of the questioning user based on the set of features associated with the text of the input question using a trained expertise model. The mechanism generates one or more candidate answers for the input question and tailors output of the one or more candidate answers based on the expertise level of the questioning user.",
    "claims": "\n1. A method, in a data processing system, for tailoring question answering system output based on user expertise, the method comprising:\ntraining a machine learning model to form a trained expertise model, wherein the trained expertise model comprises a question partition trained using questions in a collection of question and answer postings and an answer partition trained using answers in the collection of question and answer postings;\nreceiving an input question from a questioning user;\ndetermining a set of features associated with text of the input question, wherein determining the set of features associated with the text of the input question comprises extracting a plurality of features from the text of the input question;\nobtaining features from the questioning user's posting history within a collection of question and answer postings;\ndetermining an expertise level of the questioning user based on the set of features associated with the text of the input question using the question partition of the trained expertise model;\ngenerating one or more candidate answers for the input question; and\ntailoring output of the one or more candidate answers based on the expertise level of the questioning user.\n2. The method of claim 1, wherein the plurality of features comprises at least one of content words formed into unigram/ngram lexical features, social hedges, specificity of words, specific experience level indicators, or references to external expertise.\n3. The method of claim 1, wherein determining the set of features associated with the text of the input question further comprises:\nobtaining features from responses by other users to the questioning user's posting history within the collection of question and answer postings.\n4. The method of claim 1, wherein generating the one or more candidate answers for the input question comprises generating the one or more candidate answers from a collection of question and answer postings.\n5. The method of claim 4, wherein tailoring output of the one or more candidate answers comprises:\ndetermining an expertise level of a contributing user providing evidence for a given candidate answer, comprising:\nobtaining features from the contributing user's posting history within the collection of question and answer postings; and\nobtaining features from responses by other users within the collection of question and answer postings.\n6. The method of claim 1, wherein tailoring output of the one or more candidate answers comprises:\ndetermining an expertise level of each of the one or more candidate answers using the trained expertise model; and\nranking the one or more candidate answers based on the expertise levels of the one or more candidate answers.\n7. The method of claim 1, wherein tailoring output of the one or more candidate answers comprises:\nselecting only candidate answers that have a high confidence score and match the expertise level of the questioning user.\n8. The method of claim 1, wherein training the trained expertise model comprises:\nharvesting the collection of question and answer postings;\nlabeling questions and answers in the collection with predetermined expertise levels;\ndetermining a set of features associated with text of each question and answer; and\ntraining the machine learning model based on the predetermined expertise levels and the sets of features associated with the text of the questions and answers to form the trained expertise model.\n9. The method of claim 8, wherein determining the set of features associated with text of a given question or answer comprises:\nextracting a plurality of features from the text of the given question or answer using an annotation engine pipeline;\nobtaining features from posting history of a contributing user associated with the given question or answer; and\nobtaining features from responses by other users within the collection of question and answer postings.\n10. A computer program product comprising a computer readable storage medium having a computer readable program stored therein, wherein the computer readable program, when executed on a computing device, causes the computing device to:\ntrain a machine learning model to form a trained expertise model, wherein the trained expertise model comprises a question partition trained using questions in a collection of question and answer postings and an answer partition trained using answers in the collection of question and answer postings;\nreceive an input question from a questioning user;\ndetermine a set of features associated with text of the input question, wherein determining the set of features associated with the text of the input question comprises extracting a plurality of features from the text of the input question;\nobtain features from the questioning user's posting history within a collection of question ad answer postings;\ndetermine an expertise level of the questioning user based on the set of features associated with the text of the input question using the question partition of the trained expertise model;\ngenerate one or more candidate answers for the input question; and\ntailor output of the one or more candidate answers based on the expertise level of the questioning user.\n11. The computer program product of claim 10, wherein tailoring output of the one or more candidate answers comprises:\ndetermining an expertise level of each of the one or more candidate answers using the trained expertise model; and\nranking the one or more candidate answers based on the expertise levels of the one or more candidate answers.\n12. The computer program product of claim 10, wherein tailoring output of the one or more candidate answers comprises:\nselecting only candidate answers that have a high confidence score and match the expertise level of the questioning user.\n13. The computer program product of claim 10, wherein training the trained expertise model comprises:\nharvesting the collection of question and answer postings;\nlabeling questions and answers in the collection with predetermined expertise levels;\ndetermining a set of features associated with text of each question and answer, and\ntraining the machine learning model based on the predetermined expertise levels and the sets of features associated with the text of the questions and answers to form the trained expertise model.\n14. The computer program product of claim 10, wherein determining the set of features associated with the text of the input question further comprises:\nobtaining features from responses by other users to the questioning user's posting history within the collection of question and answer postings.\n15. The computer program product of claim 10, wherein generating the one or more candidate answers for the input question comprises generating the one or more candidate answers from a collection of question and answer postings.\n16. The computer program product of claim 10, wherein determining the set of features associated with text of a given question or answer comprises:\nextracting a plurality of features from the text of the given question or answer using an annotation engine pipeline;\nobtaining features from posting history of a contributing user associated with the given question or answer; and\nobtaining features from responses by other users within the collection of question and answer postings.\n17. An apparatus comprising:\na processor; and\na memory coupled to the processor, wherein the memory comprises instructions which, when executed by the processor, cause the processor to:\ntrain a machine learning model to form a trained expertise model, wherein the trained expertise model comprises a question partition trained using questions in a collection of question and answer postings and answer partition trained using answers in the collection of question answer postings;\nreceive an input question from a questioning user;\ndetermine a set of features associated with text of the input question, wherein determining the set of features associated with the text of the input question comprises extracting a plurality of features from the text of the input question using an annotation engine pipeline in the data processing system;\nobtain features from the questioning user's posting history within a collection of question and answer postings;\ndetermine an expertise level of the questioning user based on the set of features associated with the text of the input question using the question partition of the trained expertise model;\ngenerate one or more candidate answers for the input question; and\ntailor output of the one or more candidate answers based on the expertise level of the questioning user.\n18. The apparatus of claim 17, wherein tailoring output of the one or more candidate answers comprises:\ndetermining an expertise level of each of the one or more candidate answers using the trained expertise model; and\nranking the one or more candidate answers based on the expertise levels of the one or more candidate answers.\n19. The apparatus of claim 17, wherein training the trained expertise model comprises:\nharvesting the collection of question and answer postings;\nlabeling questions and answers in the collection with predetermined expertise levels;\ndetermining a set of features associated with text of each question and answer; and\ntraining the machine learning model based on the predetermined expertise levels and the sets of features associated with the text of the questions and answers to form the trained expertise model.\n20. The computer program product of claim 15, wherein tailoring output of the one or more candidate answers comprises:\ndetermining an expertise level of a contributing user providing evidence for a given candidate answer, comprising:\nobtaining features from the contributing user's posting history within the collection of question and answer postings; and\nobtaining features from responses by other users within the collection of question and answer postings.",
    "status": "Active",
    "citations_own": [
        "US6195426B1",
        "US20030009448A1",
        "US20050262114A1",
        "EP1761015A1",
        "US20070094183A1",
        "US20070219863A1",
        "US20080059308A1",
        "US20090043621A1",
        "US20090287678A1",
        "US20100191686A1",
        "US20110066587A1",
        "US20110125734A1",
        "US20110212430A1",
        "US20120150771A1",
        "US20120253825A1",
        "US20130007055A1",
        "US20130018652A1",
        "US20130060756A1",
        "US20130066886A1",
        "US20130226852A1",
        "US20130262453A1",
        "US20130282698A1",
        "US20130325779A1",
        "US20140087355A1",
        "US20140229164A1",
        "US8935192B1",
        "US20150088906A1",
        "US20150120718A1",
        "US20150161230A1",
        "US20150161512A1",
        "US20150161513A1",
        "US20150193429A1",
        "US20150254785A1",
        "US20160034512A1",
        "US9292791B2",
        "US9396236B1",
        "US20170213178A1"
    ],
    "citations_ftf": [],
    "citedby_own": [
        "US10872206B2"
    ],
    "citedby_ftf": [
        "US10813584B2",
        "US20180260387A1",
        "KR102033388B1",
        "KR20160065671A",
        "US20160180216A1",
        "US10475043B2",
        "US10083213B1",
        "US10755294B1",
        "US10134050B1",
        "US10402435B2",
        "US10447777B1",
        "US10147037B1",
        "US10475044B1",
        "US10268956B2",
        "US10394804B1",
        "US10242093B2",
        "US9478145B1",
        "US9910912B2",
        "US9858336B2",
        "US10599699B1",
        "US9973460B2",
        "US10409824B2",
        "US10162734B1",
        "US10467541B2",
        "US10460398B1",
        "US10445332B2",
        "US10572954B2",
        "US10733677B2",
        "US10552843B1",
        "US10679008B2",
        "EP3559869A1",
        "US11138208B2",
        "US10748157B1",
        "US10372813B2",
        "US11227230B2",
        "US11093841B2",
        "KR101853091B1",
        "US10922367B2",
        "JP6740187B2",
        "US10902738B2",
        "US11093951B1",
        "US11010656B2",
        "US10572801B2",
        "US11087097B2",
        "US11436642B1",
        "US10303978B1",
        "US11269665B1",
        "US20190340503A1",
        "KR20200010131A",
        "KR102015075B1",
        "EP3881251A4",
        "CN111177328B",
        "US20200159836A1",
        "US10679150B1",
        "CN109739995B",
        "CN111611355A",
        "US11500951B1",
        "CN110263247A",
        "GB201911760D0",
        "US11250719B2",
        "US20210192973A1",
        "US11188991B2",
        "US11657819B2",
        "US11782974B2",
        "US11798551B2",
        "US11558319B2",
        "WO2023017532A1",
        "US11423680B1",
        "US11599836B2"
    ]
}