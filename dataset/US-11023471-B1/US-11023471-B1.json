{
    "patent_id": "US-11023471-B1",
    "title": "Scalable natural language processing for large and dynamic text environments ",
    "assignee": "Ontocord, LLC",
    "publication_date": "2021-06-01",
    "patent_link": "https://patents.google.com/patent/US11023471B1/en",
    "inventors": [
        "Hiep Huu Nguyen"
    ],
    "classifications": [
        "G06F40/216",
        "G06F16/24575",
        "G06F16/635",
        "G06F40/211",
        "G06F40/247",
        "G06F40/268",
        "G06F40/284",
        "G06F40/295",
        "G06F40/30",
        "G06N20/00",
        "G06N3/042",
        "G06N5/025",
        "G06N5/041",
        "G06N5/046",
        "G06N3/02",
        "G06N3/044",
        "G06N3/045",
        "G06N3/084",
        "G06N3/088"
    ],
    "abstract": "Briefly stated, the invention is directed to retrieving a semantically matched knowledge structure. A question and answer pair is received, wherein the answer is received from a query of a search engine. A question is constraint-matched with the answer based on maximizing a plurality of constraints, wherein at least one of the plurality of the constraints is a similarity score between question and answer, wherein the constraint matching generates a matched sequence. For one or more answer sequences, a subsequence is found that are not parsed as answer slots. Query results are obtained from another search engine based on a combination of the answer or question, and the non-answer subsequence. And a KB based is refined on the query results and the constraint matching and based on a neural network training, for a further subsequent semantic matching, wherein the KB includes a dense semantic vector indication of concepts.",
    "claims": "\n1. A system for retrieving a semantically matched knowledge structure, comprising:\na first device for refining at least a portion of an ontology;\na network for communicating data; and\na second device connected to the first device through the network, wherein the second device performs steps comprising:\nconstraint-matching a query semantic sequence received through the input component with a candidate semantic sequence stored on the memory component based on maximizing a plurality of constraints,\nwherein at least one of the plurality of the constraints is a similarity score between a subsequence of the query semantic sequence and another subsequence of the candidate semantic sequence, and\nwherein the constraint matching generates a matched sequence and an associated matching score;\nfinding the candidate semantic sequence for constraint-matching with the query semantic sequence, wherein the finding is based at least in part on a semantic comprised in the query semantic sequence; and\nproviding a resulting semantic sequence chosen between the matched sequence and another matched sequence based at least in part on a comparison of the associated matching score and another associated matching score of the other matched sequence.\n2. The system of claim 1, wherein the steps further comprise:\nconstraint-matching another generated query semantic sequence of a query sentence with another generated candidate semantic sequence of a candidate sentence to provide the other matched sequence and other associated matching score; and\ndetermining the resulting semantic sequence between the matched sequence and the other matched sequence based at least in part on a comparison of the associated matching score and the other associated matching score using a cosine similarity function.\n3. The system of claim 1, wherein the steps further comprise:\ngenerating a plurality of found sequences based on a search result list provided by a query-expansion search for, in part, a search term based on a provided semantic, wherein the query semantic sequence and the candidate semantic sequence are comprised in the plurality of found sequences;\nif the matching score is above a threshold, determining a resulting semantic from the candidate sequence wherein the resulting semantic is associated with a slot-hint; and\nincluding the resulting semantic in a semantically matched knowledge structure within the ontology.\n4. The system of claim 1, wherein the query semantic sequence and the candidate semantic sequence comprises a plurality of semantics, wherein at least one of the plurality of semantics comprises at least one of a grammatical type of a word, at least one ontological class of the word, a morphological stem of the word, or a slot-hint of the word, wherein the ontological class of the words matched is based on a least common subsumer of the words matched.\n5. The system of claim 1, wherein the similarity score is based on a function of at least a distance in ontological space between a semantic comprised in the subsequence and another semantic comprised in the other subsequence, a size of an intersection between attributes of the semantic and other attributes of the other semantic, or a morphological similarity between a word associated with the semantic and another word associated with the other semantic.\n6. The system of claim 1, wherein the refining comprises a neural network training of words or items in the ontology to create affinities between the words or items for measuring similarities in a vector space.\n7. The system of claim 1, wherein the matching score is based on a function of a plurality of similarity scores for matched subsequences.\n8. The system of claim 1, wherein the matched sequence comprises a matched subsequence that is matched against a query subsequence comprised in the query semantic, and wherein the matched subsequence is matched against a candidate subsequence comprised in the candidate semantic sequence.\n9. The system of claim 1, wherein the steps further comprise:\ngenerating the query semantic sequence based at least in part on a sequence of semantic heads of sub-trees from a level of a natural language parse tree of a query sentence.\n10. The system of claim 1, wherein the steps further comprise:\ngenerating the query semantic sequence based at least in part a portion of leaves of a natural language parse tree of a sentence.\n11. A device for retrieving a semantically matched knowledge structure, comprising:\nan input component for receiving an input;\na memory component for storing a dense semantic vector indication of concepts;\na processor connected to the input component and the memory component, wherein the processor performs steps comprising:\nconstraint-matching a query semantic sequence received through the input component with a candidate semantic sequence stored on the memory component based on maximizing a plurality of constraints;\nfinding the candidate semantic sequence for constraint-matching with the query semantic sequence, wherein the finding is based at least in part on a semantic comprised in the query semantic sequence; and\nproviding a resulting semantic sequence chosen between the matched sequence and another matched sequence based at least in part on a comparison of the associated matching score and another associated matching score of the other matched sequence.\n12. The device of claim 11, wherein the query semantic sequence and the candidate semantic sequence comprises a plurality of semantics, wherein at least one of the plurality of semantics comprises at least one of a grammatical type of a word, at least one ontological class of the word, a morphological stem of the word, or a slot-hint of the word, wherein the ontological class of the words matched is the least common subsumer of the words matched.\n13. The device of claim 11, wherein the steps further comprise:\ndetermining a slot-hint for a semantic in the query semantic sequence based at least in part on a named-entity-recognition function.\n14. The device of claim 11, wherein the steps further comprise:\nproviding the query semantic sequence based at least in part on a sequence of semantic nodes in a natural language parse tree of a query sentence; and\ndetermining an answer slot-hint for the query sentence; and retrieving an answer semantic from the matched sequence based at least in part on a comparison of a slot-hint of the answer semantic and the answer slot-hint.\n15. The device of claim 11, wherein the steps further comprise:\nselecting the candidate sequence from a search result list provided by a query-expansion search for, in part, a search term based on the semantic.\n16. The device of claim 11, wherein constraint-matching the query semantic sequence with the candidate semantic sequence comprises at least a common subsequence match, a Rabin-Karp pattern match, a Knuth-Morris-Pratt pattern match, Boyer-Moore pattern match, or a Diff pattern match.\n17. The device of claim 11, wherein the steps further comprise:\ndisambiguating an ontological class set of a semantic of the matched sequence based at least in part on a word-sense-disambiguation function.\n18. The device of claim 11, wherein the steps further comprise:\ngenerating the candidate semantic sequence based at least in part on a sequence of nodes of a natural language parse of a candidate sentence; and\ngenerating the query semantic sequence based at least in part on a sequence of nodes of a natural language parse of a candidate of query sentence.\n19. The device of claim 11, wherein the steps further comprise:\nbefore constraint-matching the query semantic sequence with the candidate semantic, determining a slot-hint for a semantic in the candidate semantic sequence or the query semantic sequence based at least in part on a named-entity-recognition function.\n20. A method for retrieving a semantically matched knowledge structure, comprising:\nreceiving a question and answer pair, wherein the question and answer pair includes a question and an answer, and wherein the answer is received from a query of a search engine;\nconstraint-matching the question with the answer based on maximizing a plurality of constraints, wherein at least one of the plurality of the constraints is a similarity score between the question and the answer, wherein the constraint matching generates a matched sequence;\nfinding, for the matched sequence, a subsequence that is not parsed as an answer slot;\nsending to an information retrieval engine the subsequence that is not parsed as the answer slot;\nproviding a frame of other answers from results of the information retrieval engine; and\ngeneralizing an ontology based on the frame.",
    "status": "Active",
    "citations_own": [],
    "citations_ftf": [
        "US6076051A",
        "WO2002063493A1",
        "US7328209B2",
        "US9015031B2"
    ],
    "citedby_own": [
        "US20220005461A1"
    ],
    "citedby_ftf": [
        "CN109840321B",
        "US11194974B2",
        "US11194849B2",
        "US11562135B2",
        "US11501765B2",
        "US11468071B2",
        "US11321536B2",
        "US10445745B1",
        "US11477140B2",
        "US10868778B1",
        "CN110704642B",
        "US11675828B2",
        "CN112035631A",
        "CN111143303B",
        "CN111341308B",
        "CN111666372B",
        "US20220245179A1",
        "US11080294B1",
        "US11748453B2",
        "CN113722452A",
        "US20230067828A1",
        "US20230127907A1",
        "CN114490928B",
        "CN114117022B"
    ]
}