{
    "patent_id": "US-11711438-B2",
    "title": "Systems and methods for controlling data exposure using artificial-intelligence-based periodic modeling ",
    "assignee": "Grey Market Labs, PBC",
    "publication_date": "2023-07-25",
    "patent_link": "https://patents.google.com/patent/US11711438B2/en",
    "inventors": [
        "Kristopher P. Schroeder",
        "Timothy R. Underwood"
    ],
    "classifications": [
        "H04L67/303",
        "G06F18/217",
        "G06F18/24",
        "G06F21/60",
        "G06F21/6263",
        "G06N20/00",
        "H04L63/102",
        "H04L63/107",
        "H04L63/1416",
        "H04L63/145",
        "H04L63/0407"
    ],
    "abstract": "Systems and methods for periodically modifying data privacy elements are provided. The systems and methods may identify a set of data privacy elements. A data privacy element can characterizes a feature of a computing device and can be detectable by a network host. A first artificial profile can be generated by modifying a first data privacy element based on an artificial profile model that defines a relationship associated with one or more constraints between the set of data privacy elements. Subsequent to generating the first artificial profile, a second artificial profile can be generated by periodically modifying a second data privacy element in accordance with the relationship defined by the artificial profile model. The computer device can be masked from being identified by the network host by sending the second artificial profile including the second data privacy element to a requested network location.",
    "claims": "\n1. A computer-implemented method, comprising:\nidentifying, at a platform-secured network element between a computing device and a gateway device, a set of data privacy elements, wherein the set of data privacy elements characterizes a set of features of the computing device, and wherein the set of data privacy elements is detectable by a network host;\ntraining an artificial profile model using a data set of data privacy elements, wherein the artificial profile model is trained to define a relationship that is associated with one or more constraints between the set of data privacy elements;\ngenerating a first artificial profile, wherein the first artificial profile includes the set of data privacy elements, and wherein the first artificial profile is generated by modifying a first data privacy element based on the artificial profile model;\nsubsequent to generating the first artificial profile, periodically modifying a second data privacy element to generate a second artificial profile, wherein the second data privacy element is modified in accordance with a constraint associated with the relationship defined by the artificial profile model;\nreceiving a signal indicating that the computing device is requesting access to a network location; and\nmasking the computing device from being identified by the network host by sending the second artificial profile including the second data privacy element to the network location.\n2. The computer-implemented method of claim 1, wherein the second data privacy element is dynamically modified based on a trigger event, and wherein the trigger event is based on a detection of a malware signature.\n3. The computer-implemented method of claim 2, wherein the trigger event is based on one or more parameters comprising suspicious API calling, suspicious instruction execution, or suspicious accessing of a certain IP address.\n4. The computer-implemented method of claim 1, wherein the second data privacy element is modified after a period of time in accordance with the constraint included in the artificial profile model, and wherein the constraint represents a dependency between two or more data privacy elements of the set of data privacy elements.\n5. The computer-implemented method of claim 1, further comprising:\nidentifying the set of data privacy elements based on an organization specific feature of the computing device within an organization; and\nmodifying the first data privacy element and the second data privacy element based on the relationship, wherein the relationship is based on the organization specific feature and is associated with the one or more constraints between the set of data privacy elements.\n6. The computer-implemented method of claim 1, wherein the second data privacy element is modified in accordance with the constraint to create a specific number of artificial profiles.\n7. The computer-implemented method of claim 1, wherein the second artificial profile is inserted into an isolated virtual environment that monitors for malware activity.\n8. A system, comprising:\none or more data processors; and\na non-transitory computer-readable storage medium containing instructions which, when executed on the one or more data processors, cause the one or more data processors to perform operations including:\nidentifying, at a platform-secured network element between a computing device and a gateway device, a set of data privacy elements, wherein the set of data privacy elements characterizes a set of features of the computing device, and wherein the set of data privacy elements is detectable by a network host;\ntraining an artificial profile model using a data set of data privacy elements, wherein the artificial profile model is trained to define a relationship that is associated with one or more constraints between the set of data privacy elements;\ngenerating a first artificial profile, wherein the first artificial profile includes the set of data privacy elements, and wherein the first artificial profile is generated by modifying a first data privacy element based on the artificial profile model;\nsubsequent to generating the first artificial profile, periodically modifying a second data privacy element to generate a second artificial profile, wherein the second data privacy element is modified in accordance with a constraint associated with the relationship defined by the artificial profile model;\nreceiving a signal indicating that the computing device is requesting access to a network location; and\nmasking the computing device from being identified by the network host by sending the second artificial profile including the second data privacy element to the network location.\n9. The system of claim 8, wherein the second data privacy element is dynamically modified based on a trigger event, and wherein the trigger event is based on a detection of a malware signature.\n10. The system of claim 9, wherein the trigger event is based on one or more parameters comprising suspicious API calling, suspicious instruction execution, or suspicious accessing of a certain IP address.\n11. The system of claim 8, wherein the second data privacy element is modified after a period of time in accordance with the constraint included in the artificial profile model, and wherein the constraint represents a dependency between two or more data privacy elements of the set of data privacy elements.\n12. The system of claim 8, wherein the operations further comprise:\nidentifying the set of data privacy elements based on an organization specific feature of the computing device within an organization; and\nmodifying the first data privacy element and the second data privacy element based on the relationship, wherein the relationship is based on the organization specific feature and is associated with the one or more constraints between the set of data privacy elements.\n13. The system of claim 8, wherein the second data privacy element is modified in accordance with the constraint to create a specific number of artificial profiles.\n14. The system of claim 8, wherein the second artificial profile is inserted into an isolated virtual environment that monitors for malware activity.\n15. A computer-program product tangibly embodied in a non-transitory machine-readable storage medium, including instructions configured to cause a data processing apparatus to perform operations including:\nidentifying, at a platform-secured network element between a computing device and a gateway device, a set of data privacy elements, wherein the set of data privacy elements characterizes a set of features of the computing device, and wherein the set of data privacy elements is detectable by a network host;\ntraining an artificial profile model using a data set of data privacy elements, wherein the artificial profile model is trained to define a relationship that is associated with one or more constraints between the set of data privacy elements;\ngenerating a first artificial profile, wherein the first artificial profile includes the set of data privacy elements, and wherein the first artificial profile is generated by modifying a first data privacy element based on the artificial profile model;\nsubsequent to generating the first artificial profile, periodically modifying a second data privacy element to generate a second artificial profile, wherein the second data privacy element is modified in accordance with a constraint associated with the relationship defined by the artificial profile model;\nreceiving a signal indicating that the computing device is requesting access to a network location; and\nmasking the computing device from being identified by the network host by sending the second artificial profile including the second data privacy element to the network location.\n16. The computer-program product of claim 15, wherein the second data privacy element is dynamically modified based on a trigger event, and wherein the trigger event is based on a detection of a malware signature.\n17. The computer-program product of claim 15, wherein the second data privacy element is modified after a period of time in accordance with the constraint included in the artificial profile model, and wherein the constraint represents a dependency between two or more data privacy elements of the set of data privacy elements.\n18. The computer-program product of claim 15, wherein the operations further comprise:\nidentifying the set of data privacy elements based on an organization specific feature of the computing device within an organization; and\nmodifying the first data privacy element and the second data privacy element based on the relationship, wherein the relationship is based on the organization specific feature and is associated with the one or more constraints between the set of data privacy elements.\n19. The computer-program product of claim 15, wherein the second data privacy element is modified in accordance with the constraint to create a specific number of artificial profiles.\n20. The computer-program product of claim 15, wherein the second artificial profile is inserted into an isolated virtual environment that monitors for malware activity.\n21. The computer-program product of claim of claim 16, wherein the trigger event is based on one or more parameters comprising suspicious API calling, suspicious instruction execution, or suspicious accessing of a certain IP address.",
    "status": "Active",
    "citations_own": [
        "US20080034223A1",
        "US20090254994A1",
        "US20120124372A1",
        "US20120166582A1",
        "US8522052B1",
        "US8761403B2",
        "US8893285B2",
        "US20160092699A1",
        "US20160098360A1",
        "US20160170778A1",
        "WO2016149237A1",
        "US20170206365A1",
        "US20170243028A1",
        "US9786281B1",
        "US20180121552A1",
        "US20180176192A1",
        "US20180225230A1",
        "US20180300504A1",
        "US20180336368A1",
        "US20180336370A1",
        "US10178067B1",
        "US10296548B2",
        "US10356050B1",
        "US20190332814A1",
        "US10803197B1",
        "US10936744B1",
        "US20210084057A1"
    ],
    "citations_ftf": [],
    "citedby_own": [],
    "citedby_ftf": [
        "US20220164840A1",
        "US11366786B2",
        "US11328092B2",
        "US11354435B2",
        "US11222142B2",
        "US11294939B2",
        "US11416589B2",
        "US11651104B2",
        "US11651106B2",
        "US10909265B2",
        "US11341447B2",
        "US10318761B2",
        "US11416109B2",
        "US11544667B2",
        "US11343284B2",
        "US11727141B2",
        "US11461500B2",
        "US11392720B2",
        "US10284604B2",
        "US11403377B2",
        "US11562097B2",
        "US11625502B2",
        "US10909488B2",
        "US11354434B2",
        "US11418492B2",
        "US11586700B2",
        "US11636171B2",
        "US11475136B2",
        "US10949565B2",
        "US11222139B2",
        "US11675929B2",
        "US11438386B2",
        "US11227247B2",
        "US10592648B2",
        "US11520928B2",
        "US10878127B2",
        "US11366909B2",
        "US11134086B2",
        "US11188615B2",
        "US10846433B2",
        "US11336697B2",
        "US11301796B2",
        "US11481710B2",
        "US10510031B2",
        "US11416590B2",
        "US11410106B2",
        "US11416798B2",
        "US11295316B2",
        "US10685140B2",
        "US11188862B2",
        "US10740487B2",
        "US10678945B2",
        "US10013577B1",
        "WO2020041473A1",
        "US11544409B2",
        "US10803202B2",
        "US11070632B2",
        "US10484532B1",
        "US20210136059A1",
        "US20210158140A1",
        "US20220109672A1",
        "CN113515770A",
        "US11756112B2",
        "WO2022011142A1",
        "US11444976B2",
        "US20230289376A1",
        "US11436373B2",
        "US20230334158A1",
        "WO2022099023A1",
        "US20220222356A1",
        "WO2022159901A1",
        "US11442906B2",
        "US20220255962A1",
        "WO2022170254A1",
        "US11601464B2",
        "US11777959B2",
        "WO2022178089A1",
        "US11546661B2",
        "WO2022192269A1",
        "US11562078B2",
        "US11620142B1"
    ]
}