{
    "patent_link": "https://patents.google.com/patent/US20030236789A1/en",
    "patent_id": "US20030236789A1",
    "title": "Cost conversant classification of objects",
    "abstract": "The present invention provides methods, apparatus and systems for cost conversant classification of objects. In order to achieve this, we create an efficient tree structure to store different classification rules. The methods particularly relate to objects with multiple attributes and classification rules that are defined in terms of these attributes. The techniques can handle rules that can be represented as a single or multiple hypercubes in attribute space. Furthermore, the present techniques are effective when the number of relevant object attributes are large and no specialized classification hardware is accessible. Such methods can be used in various applications such as classification of web sessions in an e-commerce application, classification of connection request in TCP connections etc.",
    "inventors": [
        "Dashi Agrawal",
        "David Olshefski",
        "Dinesh Verma"
    ],
    "assignee": "International Business Machines Corp",
    "classifications": [
        "G06F16/2264",
        "Y10S707/955",
        "Y10S707/957",
        "Y10S707/958",
        "Y10S707/99942"
    ],
    "claims": "\n1. A method for object classification comprising:\nobtaining a set of hypercubes representing a set of rules for the object;\nassociating a cost weight for each hypercube in said set of hypercubes; and\nbuilding a search tree for said set of hypercubes by splitting intermediate tree nodes of said search tree based on a predicted future cost weight of child sub-trees within said search tree, wherein each node in said search tree includes decision dimension and a splitting threshold.\n2. A method as recited in claim 1, wherein the step of obtaining a set of hypercubes includes decomposing a region in a multidimensional space into at least one hypercube.\n3. A method as recited in claim 1, wherein the step of obtaining a set of hypercubes includes combining hypercubes which result in a similar classification into a bigger hypercube.\n4. A method as recited in claim 1, further comprising employing said search tree for classifying said object.\n5. A method as recited in claim 1, wherein the step of associating includes obtaining said cost weights.\n6. A method as recited in claim 5, wherein the step of obtaining said cost weights includes employing a cost weight listing of costs of arbitrarily shaped regions.\n7. A method as recited in claim 6, wherein the step of employing a cost weight listing includes assigning cost for at least one hypercube in proportion to a volume of said at least one hypercube.\n8. A method as recited in claim 6, wherein the step of employing a cost weight listing includes assigning cost for at least one hypercube according to a projection of said hypercube into at least one of said arbitrarily shaped region.\n9. A method as recited in claim 1, wherein the step of building includes declaring a next node to be a leaf node based on a leaf node criterion.\n10. A method as recited in claim 9, wherein the step of declaring a next node to be leaf node includes computing for said next node a total number of rules and comparing said total number of rules to a depth of said next node.\n11. A method as recited in claim 1, wherein the step of splitting intermediate tree nodes includes constructing left and right child nodes of each intermediate node.\n12. A method as recited in claim 11, wherein the step of constructing left and right child nodes includes assigning a subset of intermediate node hypercubes to each child node.\n13. A method as recited in claim 12, wherein the step of assigning a subset of intermediate node hypercubes includes finding a decision dimension and a splitting threshold for the intermediate node and comparing the boundaries of said hypercubes in said decision dimension to said splitting threshold.\n14. A method as recited in claim 11, wherein the step of constructing left and right child nodes includes finding a decision dimension for each intermediate node.\n15. A method as recited in claim 11, wherein the step of constructing left and right child nodes includes finding a splitting threshold for each intermediate node.\n16. A method as recited in claim 14, wherein the step of finding a decision dimension includes locating a dimension with a high level of uncertainty.\n17. A method as recited in claim 16, wherein the step locating a dimension with a high level of uncertainty includes computing an entropy for each dimension and choosing as a particular dimension a dimension having a highest entropy.\n18. A method as recited in claim 17, wherein the step of computing an entropy for each dimension includes finding possible splitting thresholds in the dimension.\n19. A method as recited in claim 17, wherein the step of computing an entropy includes calculating a marginal weight distribution for each dimension.\n20. A method as recited in claim 15, wherein the step of finding a splitting threshold includes finding possible threshold values in each dimension.\n21. A method as recited in claim 15, wherein the step of finding a splitting threshold includes computing expected future uncertainty for each possible threshold values and choosing a threshold which has lowest future uncertainty.\n22. A method as recited in claim 21, wherein the step of computing expected future uncertainty includes the step of computing a weighted average of the uncertainty for left and right child nodes.\n23. A method as recited in claim 13, wherein the step of choosing decision dimension and splitting threshold involves choosing a dimension and threshold which projects lowest future uncertainty among all possible choices of dimensions and thresholds.\n24. An article of manufacture comprising a computer usable medium having computer readable program code means embodied therein for building a search tree, the computer readable program code means in said article of manufacture comprising computer readable program code means for causing a computer to effect the steps of claim 1.\n25. An apparatus comprising:\na preprocessor to obtain a set of hypercubes representing a set of rules for an object;\nan associator to associate a cost weight for each hypercube in said set of hypercubes; and\na builder module to build a search tree for said set of hypercubes by splitting intermediate tree nodes of said search tree based on a predicted future cost weight of child sub-trees within said search tree, wherein each node in said search tree includes a hypercube subset taken from said set of hypercubes, a decision dimension, and a splitting threshold.\n26. A apparatus as recited in claim 25, further comprising a classifier module to classify objects.\n27. A apparatus as recited in claim 25, wherein the builder module includes a decision maker to declare a next node to be a leaf node based on a comparison of a total number of rules in the next node with a depth of said next node.\n28. A apparatus as recited in claim 25, wherein the builder module includes a splitter module to determine a decision dimension and a splitting threshold for said intermediate nodes.\n29. A apparatus as recited in claim 28, wherein the splitter module includes a locator to locate a decision dimension with a high level of uncertainty.\n30. A apparatus as recited in claim 29, wherein the locator includes a calculator to calculate an entropy for each attribute dimension and to choose the attribute dimension having a highest entropy as the decision dimension.\n31. A apparatus as recited in claim 30, wherein the calculator calculates a weighted average of the expected uncertainty for each possible splitting threshold values in said decision dimension and chooses a threshold which has a lowest weighted average as the splitting threshold.\n32. A apparatus as recited in claim 29, wherein the locator includes a calculator to choose the decision dimension and splitting threshold as a particular dimension and particular threshold that project lowest future uncertainty among available choices of dimensions and thresholds.\n33. A computer program product comprising a computer usable medium having computer readable program code means embodied therein for causing object classification, the computer readable program code means in said computer program product comprising computer readable program code means for causing a computer to effect the functions of claim 25.\n34. A program storage device readable by machine, tangibly embodying a program of instructions executable by the machine to perform method steps for object classification, said method steps comprising the steps of claim 1.",
    "status": "Expired - Fee Related",
    "citations_own": [
        "US6138123A",
        "US6377945B1"
    ],
    "citations_ftf": [],
    "citedby_own": [
        "US20040260727A1",
        "US20080147589A1",
        "US20130013915A1",
        "CN103597417A",
        "US20140122381A1",
        "US10874338B2",
        "US11531576B2"
    ],
    "citedby_ftf": [
        "US7991769B2",
        "US20080010250A1",
        "CN110196882B"
    ]
}