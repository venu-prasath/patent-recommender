{
    "patent_id": "US-11379660-B2",
    "title": "Deep learning approach to computing spans ",
    "assignee": "International Business Machines Corporation",
    "publication_date": "2022-07-05",
    "patent_link": "https://patents.google.com/patent/US11379660B2/en",
    "inventors": [
        "Joshua Cason",
        "Chris Mwarabu",
        "Thomas Hay Rogers",
        "Corville O. Allen"
    ],
    "classifications": [
        "G06F40/205",
        "G06F40/30",
        "G06F40/20",
        "G06F40/279",
        "G06N20/00",
        "G06N5/01",
        "G06N5/022",
        "G06N5/041",
        "G16H10/20",
        "G16H10/60",
        "G16H50/20",
        "G16H70/20",
        "G16H70/60"
    ],
    "abstract": "A method, system, and computer program product for using a natural language processor is disclosed. Included are importing highlighted and non-highlighted training text each including training nodes, one-hot encoding the training text, training a projection model using the training text, processing the highlighted training text using the projection model, and training a classifier model using the highlighted processed training text. Also included are importing new text including new nodes, one-hot encoding the new text, processing the new text using the projection model, and determining, using the classifier model, whether one of the new nodes is in a sought-after class.",
    "claims": "\n1. A method of using a natural language processor, the method comprising:\nimporting a highlighted training text including a first plurality of training nodes;\nimporting a non-highlighted training text including a second plurality of training nodes;\nenhanced-one-hot encoding the highlighted and non-highlighted training text, wherein\nenhanced-one-hot encoding comprises:\ngenerating a parse tree having a plurality of nodes; and\ngenerating a vector table that includes a first row and a second row, wherein:\nthe first row represents a first traversal through the parse tree from a trigger node to a first target node, wherein the trigger node includes a first attribute and a second attribute, and wherein the first target node includes a third attribute and a fourth attribute; and\nthe second row represents a second traversal through the parse tree from the trigger node to a second target node, wherein the second target node includes a fifth attribute and a sixth attribute;\nwherein the column headings of the vector table comprise a plurality of attributes including the first attribute, the second attribute, the third attribute, the fourth attribute, the fifth attribute, and the sixth attribute;\nwherein each position in the first row of the vector table includes a \u201c1\u201d for each column heading that is true for the first traversal; and\nwherein each position in the first row of the vector table includes a \u201c0\u201d for each column heading that is false for the first traversal;\ntraining a projection model using the highlighted and non-highlighted training text;\nprocessing the highlighted training text using the projection model;\ntraining a classifier model using the highlighted processed training text;\nimporting new text including a plurality of new nodes;\nenhanced-one-hot encoding the new text;\nprocessing the new text using the projection model; and\ndetermining, using the classifier model, whether one of the plurality of new nodes is in a sought-after class.\n2. The method of claim 1, wherein the sought-after class is members of a hypothetical text span.\n3. The method of claim 1, further comprising:\noutputting a highlighted new text that indicates each of the plurality of new nodes is in the sought-after class.\n4. The method of claim 1, further comprising:\ntraining an enhanced-one-hot encoder using the highlighted and non-highlighted training text.\n5. The method of claim 1, wherein the enhanced-one-hot encoding the highlighted training text generates highlighted training vectors that are then processed using the projection model, the method further comprising:\nprocessing the highlighted processed training vectors using the classifier model to determine whether each node is in the sought-after class;\ncomparing the determinations of whether each node is in the sought-after class with the highlighting of each node; and\nadjusting the classifier model to increase the number of determinations that are the same as the highlighting.\n6. The method of claim 1, further comprising:\nmaking a feature selection; and\nremoving a node from the highlighted and non-highlighted training text, based on the feature selection, prior to training the projection model.\n7. A method of training a natural language processor, the method comprising:\nimporting a highlighted training text including a first plurality of training nodes;\nimporting a non-highlighted training text including a second plurality of training nodes;\nconverting the highlighted training text into highlighted training conversion tables;\nconverting the non-highlighted training text non-highlighted training conversion tables;\ntraining an enhanced-one-hot encoder using the highlighted and non-highlighted training conversion tables;\nenhanced-one-hot encoding the highlighted training conversion tables to generate highlighted training vectors;\nenhanced-one-hot encoding the non-highlighted conversion tables to generate non-highlighted training vectors,\nwherein enhanced-one-hot encoding comprises:\ngenerating a parse tree having a plurality of nodes; and\ngenerating a vector table that includes a first row and a second row, wherein:\nthe first row represents a first traversal through the parse tree from a trigger node to a first target node, wherein the trigger node includes a first attribute and a second attribute, and wherein the first target node includes a third attribute and a fourth attribute; and\nthe second row represents a second traversal through the parse tree from the trigger node to a second target node, wherein the second target node includes a fifth attribute and a sixth attribute;\nwherein the column headings of the vector table comprise a plurality of attributes including the first attribute, the second attribute, the third attribute, the fourth attribute, the fifth attribute, and the sixth attribute;\nwherein each position in the first row of the vector table includes a \u201c1\u201d for each column heading that is true for the first traversal; and\nwherein each position in the first row of the vector table includes a \u201c0\u201d for each column heading that is false for the first traversal;\ntraining a projection model using the highlighted and non-highlighted training vectors;\nprocessing the highlighted training vectors using the projection model to generate highlighted processed training vectors; and\ntraining a classifier model using the highlighted processed training vectors,\nwherein the classifier model determines whether a node is in a sought-after class.\n8. The method of claim 7, wherein the sought-after class is members of a hypothetical text span or members of a factual text span.\n9. The method of claim 7, further comprising:\nconverting the highlighted training text into highlighted parse trees; and\nconverting the non-highlighted training text into non-highlighted parse trees.\n10. The method of claim 7, further comprising:\nprocessing the highlighted processed training vectors using the classifier model to determine whether each node is in the sought-after class;\ncomparing determinations using the classifier model of whether each node is in the sought-after class with the highlighting of each node; and\nadjusting the classifier model to increase the number of determinations that are the same as the highlighting.\n11. The method of claim 7, further comprising:\nmaking a feature selection; and\nremoving a column from the highlighted and non-highlighted training vectors, based on the feature selection, prior to training the projection model.\n12. A system to find nodes in a span, the system comprising:\na plurality of highlighted parse trees representing labeled natural language text;\na plurality of non-highlighted parse trees representing unlabeled natural language text;\na new parse tree representing new natural language text;\na natural language processing (NLP) learning machine configured to process the plurality of highlighted parse trees, the plurality of non-highlighted parse trees, and the new parse tree, wherein the NLP learning machine includes a computing processor; and\na memory coupled to the computing processor, wherein the memory comprises instructions which, when executed by the computing processor, specifically configures the computing processor and causes the computing processor to:\nimport a highlighted training text including a first plurality of training nodes;\nimport a non-highlighted training text including a second plurality of training nodes;\nenhanced-one-hot encode the highlighted and non-highlighted training text, wherein enhanced-one-hot encoding comprises:\ngenerating a parse tree having a plurality of nodes; and\ngenerating a vector table that includes a first row and a second row, wherein:\nthe first row represents a first traversal through the parse tree from a trigger node to a first target node, wherein the trigger node includes a first attribute and a second attribute, and wherein the first target node includes a third attribute and a fourth attribute; and\nthe second row represents a second traversal through the parse tree from the trigger node to a second target node, wherein the second target node includes a fifth attribute and a sixth attribute;\nwherein the column headings of the vector table comprise a plurality of attributes including the first attribute, the second attribute, the third attribute, the fourth attribute, the fifth attribute, and the sixth attribute;\nwherein each position in the first row of the vector table includes a \u201c1\u201d for each column heading that is true for the first traversal; and\nwherein each position in the first row of the vector table includes a \u201c0\u201d for each column heading that is false for the first traversal;\ntrain a projection model using the highlighted and non-highlighted training text;\nprocessing the highlighted training text using the projection model;\ntrain a classifier model using the highlighted processed training text;\nimport new text including a plurality of new nodes;\nenhanced-one-hot encode the new text;\nprocess the new text using the projection model; and\ndetermine, using the classifier model, whether one of the plurality of new nodes is in a sought-after class.\n13. The system of claim 12, wherein the sought-after class is members of a hypothetical text span.\n14. The system of claim 12, wherein the memory further comprises instructions which, when executed by the computing processor, specifically configures the computing processor and causes the computing processor to:\noutput a highlighted new text that indicates each of the plurality of new nodes is in the sought-after class.\n15. The system of claim 12, wherein the memory further comprises instructions which, when executed by the computing processor, specifically configures the computing processor and causes the computing processor to:\ntrain an enhanced-one-hot encoder using the highlighted and non-highlighted training text.\n16. The system of claim 12, wherein the enhanced-one-hot encoding the highlighted training text generates highlighted training vectors that are then processed using the projection model, and wherein the memory further comprises instructions which, when executed by the computing processor, specifically configures the computing processor and causes the computing processor to:\nprocess the highlighted processed training vectors using the classifier model to determine whether each node is in the sought-after class;\ncompare the determinations of whether each node is in the sought-after class with the highlighting of each node; and\nadjust the classifier model to increase the number of determinations that are the same as the highlighting.\n17. The system of claim 12, wherein the memory further comprises instructions which, when executed by the computing processor, specifically configures the computing processor and causes the computing processor to:\nmake a feature selection; and\nremove a node from the highlighted and non-highlighted training text, based on the feature selection, prior to training the projection model.\n18. A system to find nodes in a span, the system comprising:\na plurality of highlighted parse trees representing labeled natural language text;\na plurality of non-highlighted parse trees representing unlabeled natural language text;\na new parse tree representing new natural language text;\na natural language processing (NLP) learning machine configured to process the plurality of highlighted parse trees, the plurality of non-highlighted parse trees, and the new parse tree, wherein the NLP learning machine includes a computing processor;\nand a memory coupled to the computing processor, wherein the memory comprises instructions which, when executed by the computing processor, specifically configures the computing processor and causes the computing processor to:\nconvert the highlighted training text into highlighted training conversion tables;\nconvert the non-highlighted training text non-highlighted training conversion tables;\ntrain an enhanced-one-hot encoder using the highlighted and non-highlighted training conversion tables;\nenhanced-one-hot encode the highlighted training conversion tables to generate highlighted training vectors,\nwherein enhanced-one-hot encoding comprises:\ngenerating the new parse tree having a plurality of nodes; and\ngenerating a vector table that includes a first row and a second row, wherein:\nthe first row represents a first traversal through the new parse tree from a trigger node to a first target node, wherein the trigger node includes\na first attribute and a second attribute, and wherein the first target node includes a third attribute and a fourth attribute; and\nthe second row represents a second traversal through the new parse tree from the trigger node to a second target node, wherein the second target node includes a fifth attribute and a sixth attribute;\nwherein the column headings of the vector table comprise a plurality of attributes including the first attribute, the second attribute, the third attribute, the fourth attribute, the fifth attribute, and the sixth attribute;\nwherein each position in the first row of the vector table includes a \u201c1\u201d for each column heading that is true for the first traversal; and\nwherein each position in the first row of the vector table includes a \u201c0\u201d for each column heading that is false for the first traversal;\nenhanced-one-hot encode the non-highlighted conversion tables to generate non-highlighted training vectors,\ntrain a projection model using the highlighted and non-highlighted training vectors;\nprocess the highlighted training vectors using the projection model to generate highlighted processed training vectors; and\ntrain a classifier model using the highlighted processed training vectors,\nwherein the classifier model determines whether a node is in a sought-after class.\n19. The system of claim 18, wherein the sought-after class is members of a hypothetical text span or members of a factual text span.\n20. The system of claim 18, wherein the memory further comprises instructions which, when executed by the computing processor, specifically configures the computing processor and causes the computing processor to:\nconvert the highlighted training text into highlighted parse trees; and\nconvert the non-highlighted training text into non-highlighted parse trees.\n21. The system of claim 18, wherein the memory comprises instructions which, when executed by the computing processor, specifically configures the computing processor and causes the computing processor to:\nprocess the highlighted processed training vectors using the classifier model to determine whether each node is in the sought-after class;\ncompare determinations using the classifier model of whether each node is in the sought-after class with the highlighting of each node; and\nadjust the classifier model to increase the number of determinations that are the same as the highlighting.\n22. The system of claim 18, wherein the memory comprises instructions which, when executed by the computing processor, specifically configures the computing processor and causes the computing processor to:\nmake a feature selection; and\nremove a column from the highlighted and non-highlighted training vectors, based on the feature selection, prior to training the projection model.\n23. A computer program product comprising a computer readable storage medium having a computer readable program stored therein to find nodes in a span, wherein the computer readable program, when executed on a computing device, specifically configures the computing device, and causes the computing device to:\nimport a highlighted training text including a first plurality of training nodes;\nimport a non-highlighted training text including a second plurality of training nodes;\nenhanced-one-hot encode the highlighted and non-highlighted training text, wherein enhanced-one-hot encoding comprises:\ngenerating a parse tree having a plurality of nodes; and\ngenerating a vector table that includes a first row and a second row, wherein:\nthe first row represents a first traversal through the parse tree from a trigger node to a first target node, wherein the trigger node includes a first attribute and a second attribute, and wherein the first target node includes a third attribute and a fourth attribute; and\nthe second row represents a second traversal through the parse tree from the trigger node to a second target node, wherein the second target node includes a fifth attribute and a sixth attribute;\nwherein the column headings of the vector table comprise a plurality of attributes including the first attribute, the second attribute, the third attribute, the fourth attribute, the fifth attribute, and the sixth attribute;\nwherein each position in the first row of the vector table includes a \u201c1\u201d for each column heading that is true for the first traversal; and\nwherein each position in the first row of the vector table includes a \u201c0\u201d for each column heading that is false for the first traversal;\ntrain a projection model using the highlighted and non-highlighted training text;\nprocessing the highlighted training text using the projection model;\ntrain a classifier model using the highlighted processed training text;\nimport new text including a plurality of new nodes;\nenhanced-one-hot encode the new text;\nprocess the new text using the projection model; and\ndetermine, using the classifier model, whether one of the plurality of new nodes is in a sought-after class.\n24. The method of claim 23, wherein the sought-after class is members of a hypothetical text span.\n25. The method of claim 23, wherein the computer readable program further, when executed on a computing device, specifically configures the computing device, and causes the computing device to:\nmake a feature selection; and\nremove a node from the highlighted and non-highlighted training text, based on the feature selection, prior to training the projection model.",
    "status": "Active",
    "citations_own": [
        "US6574633B1",
        "US20140163955A1",
        "US9471559B2",
        "CN106484674A",
        "US9715662B2",
        "US9715495B1",
        "US20170270052A1",
        "US20170286835A1",
        "US20170300632A1",
        "US20170372696A1",
        "US20180075011A1",
        "US20180101598A1",
        "US20180150607A1",
        "CN108304387A",
        "CN109062901A",
        "US20190057191A1"
    ],
    "citations_ftf": [],
    "citedby_own": [],
    "citedby_ftf": [
        "US11087087B1",
        "CN111259112B",
        "US11520972B2",
        "US11755822B2"
    ]
}