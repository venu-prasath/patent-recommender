{
    "patent_link": "https://patents.google.com/patent/US5048097A/en",
    "patent_id": "US5048097A",
    "title": "Optical character recognition neural network system for machine-printed characters",
    "abstract": "Character images which are to be sent to a neural network trained to recognize a predetermined set of symbols are first processed by an optical character recognition pre-processor which normalizes the character images. The output of the neural network is processed by an optical character recognition post-processor. The post-processor corrects erroneous symbol identifications made by the neural network. The post-processor identifies special symbols and symbol cases not identifiable by the neural network following character normalization. For characters identified by the neural network with low scores, the post-processor attempts to find and separate adjacent characters which are kerned and characters which are touching. The touching characters are separated in one of nine successively initiated processes depending upon the geometric parameters of the image. When all else fails, the post-processor selects either the second or third highest scoring symbol identified by the neural network based upon the likelihood of the second or third highest scoring symbol being confused with the highest scoring symbol.",
    "inventors": [
        "Roger S. Gaborski",
        "Louis J. Beato",
        "Lori L. Barski",
        "Hin-Leong Tan",
        "Andrew M. Assad",
        "Dawn L. Dutton"
    ],
    "assignee": "Eastman Kodak Co",
    "classifications": [
        "G06V30/153",
        "G06F18/00",
        "G06V30/10"
    ],
    "claims": "\n1. An optical character recognition system, comprising:\na neural network trained to recognize a character image on the basis of a predetermined set of symbols, said neural network having an input and an output at which each character image transmitted to said input is given an individual score for each one of said symbols in said set;\na pre-processor coupled to said neural network input and comprising means for designating plural contiguous \"on\" pixels in a document image as a separate object and segmenting said object from said document image as an individual character image;\na post-processor coupled to said neural network output and comprising means responsive to the output of said neural network meeting at least one of a predetermined set of neural network output conditions for correcting the output of said neural network, said post processor comprising at least one of:\n(a) means responsive upon an attempt by said neural network to rcognize said character image for modifying said character image whereby, upon receipt of the modified character image at said neural network input, said neural network performs a subsequent attempt to recognize the same character image in its modified form; and\n(b) means responsive upon said neural network choosing one of said symbols for said character image for replacing the symbol chosen by said neural network with a different symbol.\n2. The system of claim 1 wherein said pre-processor further comprises means for normalizing an original version of said character image and transmitting the normalized version of said character image to said neural network input.\n3. An optical character recognition system, comprising:\na neural network trained to recognize a character image on the basis of a predetermined set of symbols, said neural network having an input and an output at which each character image transmitted to said input is given an individual score for each one of said symbols in said set;\na pre-processor coupled to said neural network input and comprising means for designating plural contiguous \"on\" pixels in a document image as a separate object and segmenting said object from said document image as an individual character image and means for normalizing an original version of said character image and transmitting the normalized version of said character image to said neural network input;\na post-processor coupled to said neural network output and comprising means responsive to the output of said neural network meeting at least one of a predetermined set of neural network output conditions for correcting the output of said neural network, wherein said predetermined set of neural network output conditions includes a condition that the highest score at said neural network output corresponds to one of a predetermined set of symbols whose character image upon being normalized by said pre-processor is indistinguishable by said neural network from an other symbol.\n4. The system of claim 3 wherein said other symbol is one of the upper and lower case version of said one symbol and wherein said means for correcting comrpises means for determining from the size of said original version of said character image which one of said upper and lower case version of said symbol is represented by said character image.\n5. An optical character recognition system, comprising:\na neural network trained to recognize a character image on the basis of a predetermined set of symbols, said neural network having an input and an output at which each character image transmitted to said input is given an individual score for each one of said symbols in said set;\na pre-processor coupled to said neural network input and comprising means for designating plural contiguous \"on\" pixels in a document image as a separate object and segmenting said object from said document image as an individual character image and means for normalizing an original version of said character image and transmitting the normalized version of said character image to said neural network input;\na post-processor coupled to said neural network output and comprising means responsive to the output of said neural network meeting at least one of a predetermined set of neural network output conditions for correcting the output of said neural network, wherein said predetermined set of neural network output conditions includes a condition that the highest score at said output is insufficiently high, wherein said means for correcting comprises:\nmeans for detecting whether the original version of said character image is smaller than a predetermined small size corresponding to one of of a set of special symbols not included in said predetermined symbol set whose normalized character image is indistinguishable therefrom; and\nmeans for determining from said character image the identity of one of said special symbols represented by said character image.\n6. The optical character recognition system of claim 1 wherein said pre-processor separates the images of adjacent symbols in said document image which are kerned.\n7. An optical character recognition system, comprising:\na neural network trained to recognize a character image on the basis of a predetermined set of symbols, said neural network having an input and an output at which each character image transmitted to said input is given an individual score for each one of said symbols in said set;\na pre-processor coupled to said neural network input and comprising means for designating plural contiguous \"on\" pixels in a document image as a separate object and segmenting said object from said document image as an individual character image;\na post-processor coupled to said neural network output and comprising means responsive to the output of said neural network meeting at least one of a predetermined set of neural network output conditions for correcting the output of said neural network, wherein said means for designating is responsive whenever two separately designated objects in an earlier-scanned portion of said document image are joined together in another later-scanned portion of said image for designating said two objects as a single larger object, and for remembering the size of each of said two objects, said means for designating further responsive whenever one of a plurality objects designated as a single larger object is of a size greater than a predetermined threshold size for separating said one object from said larger object, whereby to separate touching characters in said document image.\n8. The system of claim 7 wherein said predetermined threshold size is about the average size of the symbols in said document image.\n9. An optical character recognition system, comprising:\nA. a neural network trained to recognize a predetermined set of symbols and having an input and an output at which each image transmitted to said input is given an individual score for each one of said symbols in said set;\nB. a pre-processor connected to said neural network input and comprising segmenting means for segmenting individual character images from a document image and normalizing means for generating a normalized version of said character image from the original version of said character image;\nC. a post-processor connected to said neural network output and to an input of said normalizing means and comprising means responsive whenever the highest score at said neural network output is insufficient for performing a succession of plural progressively more time-consuming attempts to deduce a symbol choice more reliable than that corresponding to said insufficient score; and\nD. wherein said post-processor comprises:\n(1)normalization compensation processor means for performing a first one of said attempts by identifying in said character image a symbol whose normalized character image is ambiguous with respect to that of another symbol,\n(2) dekerning processor means for performing a second one of said attempts by separating the images of two symbols which are kerned together in said character image whenever said normalization ambiguous processor fails to successfully identify said character image,\n(3) touching character processor means for performing a third one of said attempts by separating the images of two symbols which are touching one another in said character image whenever said dekerning processor means fails to successfully separate said character image; and\nE. guess process means for choosing one of several lower scoring symbols identified at the output of said neural network instead of the highest scoring symbol, depending upon one of:\n(1) which one of the lower scoring symbols has a height closest to the height of said original version of said character image;\n(2) whenever all of said several lower scoring symbols are close in height to said character image, which one of the lower scoring symbols identified at said neural network output is likeliest to be confused by said neural network with the highest scoring symbol.\n10. The system of claim 9 wherein said normalization processor means comprises case correction means for identifying the case of said character image from said original character image whenver the highest scoring symbol identified at said neural network output is one whose normalized character image is the same for the upper and lower case versions of said symbol.\n11. The system of claim 9 wherein:\nsaid segmenting means of said pre-processor separates said character image by historgramming \"on\" pixels in said document image and dividing said document image along rows or columns of pixels therein which are devoid of \"on\" pixels; and\nsaid dekerning processor means separates kerned symbols in said character image by performing connected component analysis on said character image.\n12. The system of claim 9 wherein said touching character processor means comprises means for performing a series of character separation trial processes in a predetermined order, each of said trial processes searching for a corresponding set of possible touching symbol pairs which is assumed in the next one of said processes to be absent.\n13. The system of claim 11 wherein said touching character processor means comprises means for:\n(1) attempting to separate said character image at the bottom of two adjacent symbols;\n(2) attempting to separate a symbol having a left-hand arc from an adjacent symbol;\n(3) attempting to separate a symbol having a top horizontal line from an adjacent symbol;\n(4) attempting to separate said character image at the top of two adjacent symbols;\n(5) attempting to separate said character image at both its top and its bottom;\n(6) attempting to separate a symbol comprising oppositely sloping diagonal lines form an adjacent symbol;\n(7) attempting to separate a pair of symbols having adjoining arcs;\n(8) attempting to separate a small letter f from an adjacent symbol; and\n(9) attempting to separate adjacent symbols not attempted in (1) through (8) above.\n14. The system of claim 9 wherein said dekerner processor means and said touching character separation processor means each comprise means for transmitting to said normalizer processor a pair of images formed by separating said character image.\n15. The system of claim 12 wherein said touching character processor further comprises:\nmeans for transmitting to said normalization processor a pair of images formed by separating said character image so as to obtain a second pattern at said neural network output; and\nerror checking means for comparing said second pattern at said output of said neural network with a predetermined output pattern typical of the corresponding one of said series of trial processes splitting a character image of a single known symbol.\n16. The system of claim 15 wherein said predetermined output pattern is one of a set of predetermined output patterns established by transmitting to said neural network input successive images of single symbols which are separated by the corresponding one of said trial processes.\n17. The system of claim 15 wherein said touching character processor further comprises general checking means for comparing with a set of known general error patterns a pattern comprising (a) the highest scoring symbol identified by said neural network for said character image and (b) the symbols identified by said neural network for the pair of images formed by separating said character image.\n18. The system of claim 17 wherein said set of known general error patterns correspond to the splitting of known symbols into two parts.\n19. In an optical character recognition system comprising a neural network trained to recognize a character image on the basis of a predetermined set of symbols, said neural network having an input and an output at which each character image transmitted to said input is given an individual score for each one of said symbols in said set, a method for performing optical character recognition, comprising:\na pre-processing step comprising designating plural contiguous \"on\" pixels in a document image as a separate object and segmenting said object from said document image as an individual character image;\na post-processing step comprising sensing whenever the output of said neural network meets at leas one of a predetermined set of neural network output conditions and correcting the output of said neural network in response to said sensing step, said post processing step comprising at least one of:\n(a) upon an attempt by said neural network to recognize said character image, modifying said character image whereby, upon receipt of the modified character image at said neural network input, said neural network performs a subsequent attempt to recognize the same character image in its modified form; and\n(b) upon said neural network choosing one of said symbols for said character image, replacing the symbol chosen by said neural network with a different symbol.\n20. The method of claim 29 wherein said pre-processing step further comprises normalizing an original version of said character image and transmitting the normalized version of said character image to said neural network input.\n21. In an optical character recognition system comprising a neural network trained to recognize a character image on the basis of a predetermined set of symbols, said neural network having an input and an output at which each character image transmitted to said input is given an individual score for each one of said symbols in said set, a method for performing optical character recognition, comprising:\na pre-processing step comprising designating plural contiguous \"on\" pixels in a document image as a separate object and segmenting said object from said document image as an individual character image and transmitting the normalized version of said character image to said neural network input;\na post-processing step comprising sensing whenever the output of said neural network meets at leas one of a predetermined set of neural network output conditions and correcting the output of said neural network in response to said sensing step, wherein said predetermined set of neural network output conditions includes a condition that the highest score at said neural network output corresponds to one of a predetermined set of symbols whose character image upon being normalized by said pre-processor is indistinguishable by said neural network from an other symbol.\n22. The method of claim 21 wherein said other symbol is one of the upper and lower case version of said one symbol and wherein said correcting step comprises determining from the size of said original version of said character image which one of said upper and lower case version of said symbol is represented by said character image.\n23. In an optical character recognition system comprising a neural network trained to recognize a character image on the basis of a predetermined set of symbols, said neural network having an input and an output at which each character image transmitted to said input is given an individual score for each one of said symbols in said set, a method for performing optical character recognition, comprising:\na pre-processing step comprising designating plural contiguous \"on\" pixels in a document image as a separate object and segmenting said object from said document image as an individual character image and normalizing an original version of said character image and transmitting the normalized version of said character image to said neural network input;\na post-processing step comprising sensing whenever the output of said neural network meets at leas one of a predetermined set of neural network output conditions and correcting the output of said neural network in response to said sensing step, wherein said predetermined set of neural output conditions includes the condition that the highest score at said output is insufficiently high, wherein said correcting step comprises:\ndetecting whether the original version of said character image is smaller than a predetermined small size corresponding to one of a set of special symbols not included in said predetermined symbol set whose normalized character image is indistinguishable therefrom; and\ndetermining from said character image the identity of one of said special symbols represented by said character image.\n24. The method of claim 19 wherein said pre-processing step comprises separating the images of adjacent symbols in said document image which are kerned.\n25. In an optical character recognition system comprising a neural network trained to recognize a character image on the basis of a predetermined set of symbols, said neural network having an input and an output at which each character image transmitted to said input is given an individual score for each one of said symbols in said set, a method for performing optical character recognition, comprising:\na pre-processing step comprising designating plural contiguous \"on\" pixels in a document image as a separate object and segmenting said object from said document image as an individual character image;\na post-processing step comprising sensing whenever the output of said neural network meets at leas one of a predetermined set of neural network output conditions and correcting the output of said neural network in response to said sensing step, wherien said designating step comprises:\nfirst sensing whenever two separately designated objects in an earlier-scanned portion of said document image are joined together in another later-scanned portion fo said image;\ndesignating said two objects as a single larger object in response to said first sensing step;\nremembering the size of each of said two objects;\nsecond sensing whenever one of a plurality objects designated as a single larger object is of a size greater than a predetermined threshold size; and\nseparating said one object from said larger object in response to said second sensing step, whereby to separate touching characterter in said document image.\n26. The method of claim 25 wherein said predetermined threshold size is about the average size of the symbols in said document image.\n27. In an optical character recognition system comprising a neural network trained to recognize a predetermined set of symbols and having an input and an output at which each image transmitted to said input is given an individual score for each one of said symbols in said set, a method for performing optical character recognition, comprising:\nA. a pre-processor step comprising segmenting individual character images form a document image and generating a normalized version of said character image from the original version of said character image and transmitting said normalized version to said input of said neural network;\nB. a post-processing step comprising sensing whenever the highest score at said neural network output is insufficient; and\nC. performing a succession of plural progressively more time-consuming attempts to deduce a symbol choice more reliable than that corresponding to said insufficient score in response to said sensing step; and\nD. wherein said performing step of said post-processing step comprises:\n(1) performing a first one of said attempts by identifying in said character image a symbol whose normalized character image is ambiguous with respect to that of another symbol,\n(2) performing a second one of said attempts by first separating the images of two symbols which are kerned together in said character image whenever said first attempt fails to successfully identify said character image,\n(3) performing a third one of said attempts by second separating the images of two symbols which are touching one another in said character image whenever said first separating step fails to successfully separate said character image; and\nE. a guess processor step, said guess processing step comprising choosing one of several lower scoring symbols identified at the output of said neural network instead of the highest scoring symbol, depending upon one of:\n(1) which one of the lower scoring symbols has a height closest to the height of said original version of said character image;\n(2) if all of said several lower scoring symbols are close in height to said character image, which one of the lower scoring symbols identified at said neural network output is likeliest to be confused by said neural network with the highest scoring symbol.\n28. The method of claim 27 wherein the step of performing the first one of said attempts comprises identifying the case of said character image from said original character image whenever the highest scoring symbol identified at said neural network output is one whose normalized character image is the same for the upper and lower case versions of said symbol.\n29. The method of claim 27 wherein:\nsaid segmenting step comprises histogramming \"on\" pixels in said document image and dividing said document image along rows or columns of pixels therein which are devoid, of \"on\" pixels; and\nsaid first separating step comprises performing connected component analysis on said character image.\n30. The method of claim 27 wherein said second separating step comprises performing a series of character separation trial processes in a predetermined order, each of said trial process comprising searching for a corresponding set of possible touching symbol pairs which is assumed in the next one of said trial processes to be absent.\n31. The method of claim 29 wherein said series of trial processes comprises:\n(1) attempting to separate said character image at the bottom of two adjacent symbols;\n(2) attempting to separate a symbol having a left-hand arc from an adjacent symbol;\n(3) attempting to separate a symbol having a top horizontal line from an adjacent symbol;\n(4) attempting to separate said character image at the top of two adjacent symbols;\n(5) attempting to separate said character image at both its top and its bottom;\n(6) attempting to separate a symbol comprising oppositely sloping diagonal lines from an adjacent symbol;\n(7) attempting to separate a pair of symbols having adjoining arcs;\n(8) attempting to separate a small letter f from an adjacent symbol; and\n(9) attempting to separate adjacent symbols not attempted in steps (1) through (8) above.\n32. The method of claim 27 wherein said first and second separating steps each further comprise normalizing and transmitting to said neural nctwork input a pair of images formed by separating said character image.\n33. The method of claim 30 wherein said second separating step further comprises an error checking process comprising:\nnormalizing and transmitting to said neural network input a pair of images formed by separating said character image so as to obtain a second pattern at said neural network output; and\ncomparing said second pattern at said output of said neural network with a predetermined output pattern typical of the corresponding one of said series of trial processes splitting a character image of a single known symbol.\n34. The method of claim 33 wherein said predetermined output pattern is one of a set of predetermined output patterns established by transmitting to said neural network input successive images of single symbols which are separated by the corresponding one of said trial processes.\n35. The method of claim 33 wherein said second separating step further comprises a general checking step comprising comparing with a set of known general error patterns a pattern comprising (a) the highest scoring symbol identified by said neural network for said character image and (b) the symbols identified by said neural network for the pair of images formed by separating said character image.\n36. The method of claim 35 wherien said set of known general error patterns correspond to the splitting of known symbols into two parts.",
    "status": "Expired - Lifetime",
    "citations_own": [
        "US3192505A",
        "US3267439A",
        "US3275986A",
        "US3275985A",
        "US3967243A",
        "US4479241A",
        "US4635290A",
        "US4876731A",
        "US4926491A"
    ],
    "citations_ftf": [
        "FR2625347B1"
    ],
    "citedby_own": [
        "US5257343A",
        "US5319722A",
        "US5371809A",
        "US5426684A",
        "US5442715A",
        "US5528700A",
        "US5680627A",
        "US5712922A",
        "US5742702A",
        "US5787194A",
        "US5809166A",
        "US5883986A",
        "US6018728A",
        "US6026177A",
        "US6101270A",
        "US6324532B1",
        "US6421461B1",
        "US20030108232A1",
        "US20040252897A1",
        "US20050259866A1",
        "US20070100780A1",
        "US20070154094A1",
        "US20070250532A1",
        "US20100054629A1",
        "DE102008042080A1",
        "US20100182631A1",
        "US20110029504A1",
        "US20110075936A1",
        "US20110096174A1",
        "US20120237118A1",
        "US20130117044A1",
        "US8515816B2",
        "US8619147B2",
        "US8621349B2",
        "US8620083B2",
        "WO2013164849A3",
        "US8713418B2",
        "US20140153838A1",
        "US8781228B2",
        "US8793162B2",
        "US8799099B2",
        "US8799303B2",
        "US8831365B2",
        "US8874504B2",
        "US8903759B2",
        "US8990235B2",
        "US9008447B2",
        "US9075779B2",
        "US9081799B2",
        "US9116890B2",
        "US9143638B2",
        "US20150331832A1",
        "US9268852B2",
        "US9275051B2",
        "US9286526B1",
        "US9323784B2",
        "US9454764B2",
        "US9940551B1",
        "US20200117912A1",
        "CN111385424A",
        "US10769431B2"
    ],
    "citedby_ftf": [
        "US5774586A",
        "SG175282A1"
    ]
}