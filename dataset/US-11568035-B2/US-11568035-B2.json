{
    "patent_id": "US-11568035-B2",
    "title": "Deep neural network for iris identification ",
    "assignee": "Magic Leap, Inc.",
    "publication_date": "2023-01-31",
    "patent_link": "https://patents.google.com/patent/US11568035B2/en",
    "inventors": [
        "Alexey SPIZHEVOY",
        "Adrian Kaehler",
        "Gary Bradski"
    ],
    "classifications": [
        "G06F21/32",
        "G06N3/04",
        "G06N3/045",
        "G06N3/0454",
        "G06N3/08",
        "G06N7/005",
        "G06N7/01",
        "G06V10/82",
        "G06V40/19",
        "G06V40/197",
        "H04L63/0861"
    ],
    "abstract": "Systems and methods for iris authentication are disclosed. In one aspect, a deep neural network (DNN) with a triplet network architecture can be trained to learn an embedding (e.g., another DNN) that maps from the higher dimensional eye image space to a lower dimensional embedding space. The DNN can be trained with segmented iris images or images of the periocular region of the eye (including the eye and portions around the eye such as eyelids, eyebrows, eyelashes, and skin surrounding the eye). With the triplet network architecture, an embedding space representation (ESR) of a person's eye image can be closer to the ESRs of the person's other eye images than it is to the ESR of another person's eye image. In another aspect, to authenticate a user as an authorized user, an ESR of the user's eye image can be sufficiently close to an ESR of the authorized user's eye image.",
    "claims": "\n1. A wearable display system comprising:\na display;\nan image capture device configured to capture eye images of a wearer;\na non-transitory computer readable medium having software instructions stored thereon, the software instructions executable by a hardware computer processor to perform operations comprising:\nreceiving a first eye image from the image capture device;\nreceiving, from an authentication training system, an embedding configured to determine embedding space representations of eye images using a deep neural network and at least one classifier usable to determine a likelihood that respective embedding space representations of images are associated with an authorized user;\nprocessing the first eye image to generate a representation of the first eye image in polar coordinates;\nprocessing the representation of the first eye image using the embedding to generate a first embedding space representation of the first eye image, wherein the first embedding space representation is an n-dimensional vector, and wherein a majority of elements of the first embedding space representation are statistically independent;\nprocessing the first embedding space representation using the at least one classifier to calculate a likelihood score that the first eye image is associated with the authorized user; and\ngranting or denying access to the wearable display system based on the likelihood score.\n2. The system of claim 1,\nwherein the one or more deep neural networks comprise a plurality of layers, and\nwherein the plurality of layers comprises a pooling layer, a brightness normalization layer, a convolutional layer, an inception-like layer, a rectified linear layer, a softsign layer, or any combination thereof.\n3. The system of claim 2, wherein the brightness normalization layer comprises a local contrast normalization layer, a local response normalization layer, or a combination thereof.\n4. The system of claim 1, wherein the first embedding space representation has unit length.\n5. The system of claim 1, wherein the at least one classifier determines the likelihood score based on a Euclidian distance.\n6. The system of claim 1, wherein the at least one classifier is a binary classifier, a logistic regression classifier, a support vector machine classifier, a Bayesian classifier, a softmax classifier, or any combination thereof.\n7. The system of claim 1,\nwherein the wearable display system is configured to: segment the first eye image to generate a second eye image, and\nwherein to process the first eye image, the wearable display system is configured to: process the second eye image using the embedding to generate the first embedding space representation.\n8. The system of claim 1, wherein the deep neural network is trained using a triplet network.\n9. The system of claim 8,\nwherein the triplet network is configured to learn the deep neural network from eye images of a plurality of persons, and\nwherein a distance in an embedding space representation based on eye images from the first eye of an individual person is smaller than a distance in an embedding space representation based on eye images from different persons and smaller than a distance in an embedding space representation based on eye images from the second eye of the individual person.\n10. The system of claim 8, wherein the first eye image comprises mostly of the iris and the retina of the first eye.\n11. The system of claim 8, wherein the first eye image comprises mostly of the retina of the first eye.\n12. The system of claim 1, wherein the deep neural network is configured to learn the embedding from a set of biometric information, wherein the set of biometric information comprises at least one of skin tone, skin texture, fingerprints, or voice.\n13. The system of claim 1, wherein the deep neural network is further configured to learn a co-embedding for secondary biometric information and wherein the wearable display system is further programmed to:\nprocess biometric data using the co-embedding to generate a co-embedding space representation based on the biometric data; and\nprocess the co-embedding space representation using the at least one classifier to calculate the likelihood score that the first eye image of the eye is an image of an eye of an authorized user."
}