{
    "patent_id": "US-11562267-B2",
    "title": "Chatbot for defining a machine learning (ML) solution ",
    "assignee": "Oracle International Corporation",
    "publication_date": "2023-01-24",
    "patent_link": "https://patents.google.com/patent/US11562267B2/en",
    "inventors": [
        "Alberto Polleri",
        "Sergio Aldea Lopez",
        "Marc Michiel Bron",
        "Dan David Golding",
        "Alexander Ioannides",
        "Maria del Rosario Mestre",
        "Hugo Alexandre Pereira Monteiro",
        "Oleg Gennadievich Shevelev",
        "Larissa Cristina Dos Santos Romualdo Suzuki",
        "Xiaoxue Zhao",
        "Matthew Charles Rowe"
    ],
    "classifications": [
        "G06F16/2423",
        "G06N5/04",
        "G06F16/243",
        "G06F16/252",
        "G06F40/40",
        "G06N20/00",
        "G06N20/20",
        "G06N3/006",
        "G06N3/105",
        "G06N5/022",
        "G06N5/046",
        "H04L51/02"
    ],
    "abstract": "The present disclosure relates to systems and methods for an intelligent assistant (e.g., a chatbot) that can be used to enable a user to generate a machine learning system. Techniques can be used to automatically generate a machine learning system to assist a user. In some cases, the user may not be a software developer and may have little or no experience in either machine learning techniques or software programming. In some embodiments, a user can interact with an intelligent assistant. The interaction can be aural, textual, or through a graphical user interface. The chatbot can translate natural language inputs into a structural representation of a machine learning solution using an ontology. In this way, a user can work with artificial intelligence without being a data scientist to develop, train, refine, and compile machine learning models as stand-alone executable code.",
    "claims": "\n1. A computer-implemented method for defining a machine learning solution, the method comprising:\nreceiving a first input describing a problem to be solved by generating the machine learning solution;\ntranscribing the first input into one or more text fragments;\ndetermining an intent of the first input;\ngenerating a machine learning architecture based at least in part on classifying the one or more text fragments;\ncorrelating the one or more text fragments to one or more machine learning frameworks of one of more machine learning models, the correlating comprising analyzing metadata of the one or more machine learning frameworks with the one or more text fragments;\ndisplaying for each of the one or more machine learning models, a representation of the machine learning model via one or more of a display and an audio output;\nreceiving a selection of a particular machine learning model of the one or more machine learning models;\nreceiving a second input identifying a data source for generating the machine learning architecture;\nreceiving a third input identifying one or more constraints for the machine learning architecture;\ngenerating code for the machine learning architecture based at least in part on the one or more selected machine learning models, the second input identifying the data source, and the third input identifying the one or more constraints; and\nstoring metadata specifying the generated code in a memory.\n2. The computer-implemented method of claim 1, further comprising providing one or more services including monitoring, logging, and alerting for the machine learning architecture.\n3. The computer-implemented method of claim 1, further comprising receiving a fourth input identifying how the machine learning solution is presented.\n4. The computer-implemented method of claim 1, further comprising:\nanalyzing the one or more constraints to generate a second plurality of code for the machine learning architecture based at least in part on optimizing the one or more constraints;\ngenerating an optimized solution; and\ndisplaying the optimized solution.\n5. The computer-implemented method of claim 1, further comprising deploying the machine learning architecture via an intelligent assistant interface.\n6. The computer-implemented method of claim 1, wherein the first input comprises at least one of an aural input, a textual input, and a graphical user interface input.\n7. The computer-implemented method of claim 1, wherein the one or more machine learning models comprise at least one of a classifier model, a recommender model, and a reinforcement learning model.\n8. The computer-implemented method of claim 1, wherein the one or more constraints comprises at least one of resources, location, security, and privacy.\n9. A computer-program product tangibly embodied in a non-transitory machine-readable storage medium, including instructions configured to cause a data processing apparatus to perform operations for defining a machine learning solution, the operations comprising:\nreceiving a first input describing a problem to be solved by generating the machine learning solution;\ntranscribing the first input into one or more text fragments;\ndetermining an intent of the first input;\ngenerating a machine learning architecture based at least in part on the one or more text fragments;\ncorrelating the one or more text fragments to one or more machine learning frameworks of one of more machine learning models, the correlating comprising analyzing metadata of the one or more machine learning frameworks with the one or more text fragments;\ndisplaying for each of the one or more machine learning models, a representation of the machine learning model via one or more of a display and an audio output;\nreceiving a selection of a particular machine learning model of the one or more machine learning models;\nreceiving a second input identifying a data source for generating the machine learning architecture;\nreceiving a third input identifying one or more constraints for the machine learning architecture;\ngenerating code for the machine learning architecture based at least in part on the one or more selected machine learning models, the second input identifying the data source, and the third input identifying the one or more constraints; and\nstoring metadata specifying the generated code in a memory.\n10. The computer-program product of claim 9, including instructions configured to cause the data processing apparatus to perform further operations comprising providing one or more services including monitoring, logging, and alerting for the machine learning architecture.\n11. The computer-program product of claim 9, including instructions configured to cause the data processing apparatus to perform further operations comprising receiving a fourth input identifying how the machine learning solution is presented.\n12. The computer-program product of claim 9, including instructions configured to cause the data processing apparatus to perform further operations comprising:\nanalyzing the one or more constraints to generate a second plurality of code for the machine learning architecture based at least in part on optimizing the one or more constraints;\ngenerating an optimized solution; and\ndisplaying the optimized solution generated by the second plurality of code.\n13. The computer-program product of claim 9, including instructions configured to cause the data processing apparatus to perform further operations comprising deploying the machine learning architecture via an intelligent assistant interface.\n14. The computer-program product of claim 9, wherein the first input comprises at least one of an aural input, a textual input, and a graphical user interface input.\n15. The computer-program product of claim 9, wherein the one or more machine learning models comprise at least one of a classifier model, a recommender model and a reinforcement learning model.\n16. A system for defining a machine learning solution, comprising:\none or more data processors; and\na non-transitory computer-readable storage medium containing instructions which, when executed on the one or more data processors, cause the one or more data processors to perform operations comprising:\nreceiving a first input describing a problem to be solved by generating the machine learning solution;\ntranscribing the first input into one or more text fragments;\ndetermining an intent of the first input;\ngenerating a machine learning architecture based at least in part on classifying the one or more text fragments;\ncorrelating the one or more text fragments to one or more machine learning frameworks of a one of more machine learning models, the correlating comprising analyzing metadata of the one or more machine learning frameworks with the one or more text fragments;\ndisplaying for each of the one or more machine learning models, a representation of the machine learning model via one or more of a display and an audio output;\nreceiving a selection of a particular machine learning model of the one or more machine learning models;\nreceiving a second input identifying a data source for generating the machine learning architecture;\nreceiving a third input identifying of one or more constraints for the machine learning architecture;\ngenerating code for the machine learning architecture based at least in part on the one or more selected machine learning models, the second input identifying the data source, and the third input identifying the one or more constraints; and\nstoring metadata specifying the generated code in a memory.\n17. The system of claim 16, wherein the non-transitory computer-readable storage medium includes further instructions which, when executed on the one or more data processors, cause the one or more data processors to perform further operations comprising providing one or more services including monitoring, logging, and alerting for the machine learning architecture.\n18. The system of claim 16, wherein the non-transitory computer-readable storage medium includes further instructions which, when executed on the one or more data processors, cause the one or more data processors to perform further operations comprising receiving a fourth input identifying how the machine learning solution is presented.\n19. The system of claim 16, wherein the non-transitory computer-readable storage medium includes further instructions which, when executed on the one or more data processors, cause the one or more data processors to perform further operations comprising:\nanalyzing the one or more constraints to generate a second plurality of code for the machine learning architecture based optimizing the one or more constraints;\ngenerating an optimized solution; and\ndisplaying the optimized solution generated by the second plurality of code.\n20. The system of claim 16, wherein the non-transitory computer-readable storage medium includes further instructions which, when executed on the one or more data processors, cause the one or more data processors to perform further operations comprising deploying the machine learning architecture via an intelligent assistant interface.",
    "status": "Active",
    "citations_own": [
        "US5343527A",
        "US5699507A",
        "US20040006761A1",
        "US20050102227A1",
        "US20070043734A1",
        "US20070239630A1",
        "US20090144698A1",
        "CN101782976A",
        "US8630961B2",
        "US20140180738A1",
        "US20150170053A1",
        "US20160055426A1",
        "US9306738B2",
        "US20160110657A1",
        "US20160179063A1",
        "US9384450B1",
        "US20160358099A1",
        "US20170061021A1",
        "US20170277693A1",
        "US20180052824A1",
        "US20180089593A1",
        "WO2018111270A1",
        "US20180222776A1",
        "US20180314936A1",
        "US20180314926A1",
        "US20180314250A1",
        "US20180322403A1",
        "US20180322387A1",
        "US20180322365A1",
        "WO2018217635A1",
        "WO2018222776A1",
        "US20180349499A1",
        "US10198399B1",
        "US20190108417A1",
        "US20190163758A1",
        "US20190228261A1",
        "US20190279114A1",
        "US10417577B2",
        "US20190317805A1",
        "US20190334716A1",
        "WO2019236894A1",
        "US20200081899A1",
        "US20200333772A1",
        "US20200410011A1",
        "US20210133670A1",
        "US11238377B2"
    ],
    "citations_ftf": [
        "US7546222B2",
        "US8972329B2"
    ],
    "citedby_own": [
        "US20220237626A1",
        "US20220342952A1",
        "US20230063724A1",
        "US20230132064A1"
    ],
    "citedby_ftf": [
        "GB2569335B",
        "US20200356866A1",
        "US11580131B2",
        "US11475374B2",
        "US11481417B2",
        "US11468238B2",
        "US11455357B2",
        "KR20210085159A",
        "US11462220B2",
        "KR102445519B1",
        "US11694289B2",
        "US11196548B1",
        "US11551674B2",
        "US11336507B2",
        "US11620473B1",
        "WO2022147359A1",
        "US20220222481A1",
        "US11373131B1",
        "US11451496B1",
        "US20220405483A1",
        "US11397808B1",
        "US20230078800A1",
        "US11782964B2",
        "WO2023091624A1",
        "WO2023095078A1",
        "US11711287B2",
        "US20230196248A1",
        "WO2023192017A1"
    ]
}