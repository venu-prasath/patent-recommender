{
    "patent_id": "US-11681925-B2",
    "title": "Techniques for creating, analyzing, and modifying neural networks ",
    "assignee": "Vianai Systems, Inc.",
    "publication_date": "2023-06-20",
    "patent_link": "https://patents.google.com/patent/US11681925B2/en",
    "inventors": [
        "Vishal INDER SIKKA",
        "Yoshiki Ohshima"
    ],
    "classifications": [
        "G06N3/105",
        "G06F18/22",
        "G06N3/048",
        "G06N3/084",
        "G06N5/022",
        "G06N5/04"
    ],
    "abstract": "As described, an artificial intelligence (AI) design application exposes various tools to a user for generating, analyzing, evaluating, and describing neural networks. The AI design application includes a network generator that generates and/or updates program code that defines a neural network based on user interactions with a graphical depiction of the network architecture. The AI design application also includes a network analyzer that analyzes the behavior of the neural network at the layer level, neuron level, and weight level in response to test inputs. The AI design application further includes a network evaluator that performs a comprehensive evaluation of the neural network across a range of sample of training data. Finally, the AI design application includes a network descriptor that articulates the behavior of the neural network in natural language and constrains that behavior according to a set of rules.",
    "claims": "\n1. A computer-implemented method for analyzing one or more functional characteristics of an artificial neural network, the method comprising:\ncausing the artificial neural network to execute an inference operation based on first sample data to generate first activation data;\ngenerating, via one or more processors, a similarity value based on a comparison between the first activation data generated by the artificial neural network and second activation data generated by the artificial neural network, wherein the second activation data is associated with second sample data;\ndetermining, via the one or more processors, that the first sample data corresponds to the second sample data based on the similarity value; and\nin response, generating a graphical user interface that displays the first sample data in conjunction with the second sample data.\n2. The computer-implemented method of claim 1, wherein generating the similarity value comprises evaluating a function based on a first activation level included in the first activation data and a second activation level included in the second activation data.\n3. The computer-implemented method of claim 1, wherein determining that the first sample data corresponds to the second sample data comprises determining that the similarity value exceeds a threshold value.\n4. The computer-implemented method of claim 1, wherein the graphical user interface further displays the first activation data in conjunction with the first sample data and the second sample data.\n5. The computer-implemented method of claim 1, further comprising:\ngenerating a natural language expression that characterizes at least one output of the artificial neural network based on the first activation data; and\nupdating the graphical user interface to display the natural language expression in conjunction with the first sample data and the second sample data.\n6. The computer-implemented method of claim 1, further comprising:\nreceiving a selection of a layer of the artificial neural network via the graphical user interface; and\nin response, updating the graphical user interface to display first data in conjunction with the layer of the artificial neural network.\n7. The computer-implemented method of claim 6, wherein the first data comprises metadata specifying one or more attributes of the layer of the artificial neural network.\n8. The computer-implemented method of claim 6, wherein the first data comprises a set of weight values associated with a set of neurons included in the layer of the artificial neural network.\n9. The computer-implemented method of claim 6, wherein the first data comprises an indication of whether a neuron included in the layer of the artificial neural network promotes an output of the artificial neural network.\n10. The computer-implemented method of claim 6, wherein the first data comprises activation data that is associated with the layer of the artificial neural network and generated during the inference operation.\n11. A non-transitory computer-readable medium storing program instructions that, when executed by a processor, cause the processor to analyze one or more functional characteristics of an artificial neural network by performing the steps of:\ngenerating, via the processor, a similarity value based on a comparison between first activation data and second activation data, wherein the first activation data is generated by the artificial neural network during an inference operation executed by the artificial neural network using first sample data, and the second activation data is generated by the artificial neural network and associated with second sample data;\ndetermining, via the processor, that the first sample data corresponds to the second sample data based on the similarity value; and\nin response, generating a graphical user interface that displays the first sample data in conjunction with the second sample data.\n12. The non-transitory computer-readable medium of claim 11, wherein the step of generating the similarity value comprises evaluating a function based on a first activation level included in the first activation data and a second activation level included in the second activation data.\n13. The non-transitory computer-readable medium of claim 11, wherein the step of determining that the first sample data corresponds to the second sample data comprises determining that the similarity value exceeds a threshold value.\n14. The non-transitory computer-readable medium of claim 11, wherein the graphical user interface further displays the first activation data in conjunction with the first sample data and the second sample data.\n15. The non-transitory computer-readable medium of claim 11, further comprising the steps of:\ngenerating a natural language expression that characterizes at least one output of the artificial neural network based on the first activation data; and\nupdating the graphical user interface to display the natural language expression in conjunction with the first sample data and the second sample data.\n16. The non-transitory computer-readable medium of claim 15, wherein generating the natural language expression comprises populating a template expression with a first lexical term that corresponds to the first activation data.\n17. The non-transitory computer-readable medium of claim 11, further comprising the steps of:\nreceiving a selection of a layer of the artificial neural network via the graphical user interface; and\nin response, updating the graphical user interface to display first data in conjunction with the layer of the artificial neural network.\n18. The non-transitory computer-readable medium of claim 17, wherein the first data characterizes a degree to which a neuron included in the layer of the artificial neural network promotes an output of the artificial neural network.\n19. The non-transitory computer-readable medium of claim 17, wherein the first data comprises a set of input activation levels received by the layer of the artificial neural network and a set of output activation levels generated by the layer of the artificial neural network.\n20. A system, comprising:\na memory storing a software application; and\na processor that, when executing the software application, is configured to perform the steps of:\ncausing an artificial neural network to execute an inference operation based on first sample data to generate first activation data,\ngenerating, via the processor, a similarity value based on a comparison between the first activation data generated by the artificial neural network and second activation data generated by the artificial neural network, wherein the second activation data is associated with second sample data,\ndetermining, via the processor, that the first sample data corresponds to the second sample data based on the similarity value, and\nin response, generating a graphical user interface that displays the first sample data in conjunction with the second sample data.",
    "status": "Active",
    "citations_own": [
        "US5222210A",
        "JPH06314105A",
        "JPH0991430A",
        "JPH09233700A",
        "US20070094168A1",
        "US20130254138A1",
        "WO2013181637A2",
        "US20150032449A1",
        "US20150089399A1",
        "US20150269139A1",
        "US20170017903A1",
        "US20170132817A1",
        "WO2017138220A1",
        "WO2017141517A1",
        "US20170351401A1",
        "US20180018555A1",
        "US20180089592A1",
        "US9934462B1",
        "US20180095632A1",
        "US20180096078A1",
        "US20180136912A1",
        "US20180144244A1",
        "US9990687B1",
        "JP2018142097A",
        "US20180336461A1",
        "US20190188567A1",
        "US20190205728A1",
        "US20190347553A1",
        "US20190370397A1",
        "US20200051252A1",
        "US20200218971A1",
        "US20200293899A1",
        "US20200302330A1",
        "US20210042602A1",
        "US20210063964A1",
        "US20210150359A1",
        "US11120364B1",
        "US20210398360A1",
        "US20220130378A1"
    ],
    "citations_ftf": [],
    "citedby_own": [],
    "citedby_ftf": [
        "US10678244B2",
        "US10671349B2",
        "US11157441B2",
        "US11409692B2",
        "US11561791B2",
        "US11215999B2",
        "US11636333B2",
        "US11562231B2",
        "US11196678B2",
        "US11537811B2",
        "US11610117B2",
        "US10997461B2",
        "US11567514B2",
        "US10956755B2"
    ]
}