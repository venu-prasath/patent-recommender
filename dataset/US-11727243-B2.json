{
    "patent_id": "US-11727243-B2",
    "title": "Knowledge-graph-embedding-based question answering ",
    "assignee": "Baidu Usa Llc",
    "publication_date": "2023-08-15",
    "patent_link": "https://patents.google.com/patent/US11727243B2/en",
    "inventors": [
        "Jingyuan Zhang",
        "Dingcheng Li",
        "Ping Li",
        "Xiao Huang"
    ],
    "classifications": [
        "G06F16/3329",
        "G06N3/006",
        "G06F16/24522",
        "G06F16/35",
        "G06F16/367",
        "G06F16/9024",
        "G06N3/042",
        "G06N3/044",
        "G06N3/08",
        "G06N5/02"
    ],
    "abstract": "Described herein are embodiments for question answering over knowledge graph using a Knowledge Embedding based Question Answering (KEQA) framework. Instead of inferring an input questions' head entity and predicate directly, KEQA embodiments target jointly recovering the question's head entity, predicate, and tail entity representations in the KG embedding spaces. In embodiments, a joint distance metric incorporating various loss terms is used to measure distances of a predicated fact to all candidate facts. In embodiments, the fact with the minimum distance is returned as the answer. Embodiments of a joint training strategy are also disclosed for better performance. Performance evaluation on various datasets demonstrates the effectiveness of the disclosed systems and methods using the KEQA framework.",
    "claims": "\n1. A computer-implemented method for question answering using one or more processors to cause steps to be performed comprising:\ngenerating, using a predicate learning model and information of a knowledge graph (KG), a predicted predicate representation in a KG predicate embedding space for a question comprising one or more tokens;\ngenerating, using a head entity learning model and information of the KG, a predicted head entity representation in a KG entity embedding space for the question;\nobtaining a predicted tail entity representation, based on a relation function that relates, for a fact in KG embedding space, a head entity representation and a predicate representation to a tail entity representation, from the predicted predicate representation and the predicted head entity representation, wherein the predicted predicate representation, the predicted head entity representation, and the predicted tail entity representation forming a predicted fact;\nidentifying, using a head entity detection (HED) model, one or more predicted head entity names for the question, each predicted head entity name comprises one or more tokens from the question;\nsearching, in the KG, head entity synonyms related to the one or more predicted head entity names;\nconstructing a candidate fact set comprising one or more candidate facts, each candidate fact comprises a head entity among the head entity synonyms, a predicate, and a tail entity; and\nchoosing, based on a joint distance metric, one candidate fact in the candidate fact set with a minimum joint distance to the predicted fact as an answer to the question, the joint distance metric comprises:\na first distance term related to a distance between the predicted head entity representation and a head entity embedding representation for the head entity in each candidate fact;\na second distance term related to a distance between the predicted predicate representation and a predicate embedding representation for the predicate in each candidate fact; and\na third distance term related to a distance between the predicted tail entity representation and a tail entity embedding representation for the tail entity in each candidate fact.\n2. The computer-implemented method of claim 1 wherein the predicate learning model has a neural network structure comprising a bidirectional recurrent neural network layer and an attention layer, and wherein the step of generating the predicted predicate representation comprises:\nmapping the one or more tokens in the question into a sequence of word embedding vectors;\ngenerating, using the bidirectional recurrent neural network layer, a forward hidden state sequence and a backward hidden state sequence;\nconcatenating the forward and backward hidden state vectors into a concatenated hidden state vector;\napplying, by the attention layer, an attention weight to the concatenated hidden state vector to obtain a weighted hidden state vector;\nconcatenating the weighted hidden state vector with the word embedding to obtain a hidden state for each token;\napplying a fully connected layer to the hidden state to obtain a target vector for each token; and\nusing a mean of all target vectors as the predicted predicate representation.\n3. The computer-implemented method of claim 2 wherein the head entity learning model has a neural network structure the same as the predicate learning model.\n4. The computer-implemented method of claim 3 wherein the predicate learning model and the head entity learning model are pre-trained using a training data set with ground truth facts via a predicate objective function and a head entity objective function, respectively.\n5. The computer-implemented method of claim 1 wherein the HED model has a neural network structure comprising a bidirectional recurrent neural network layer and a fully connecter layer, and wherein the step of identifying the one or more predicted head entity names for the question comprises:\nmapping the one or more tokens in the question into a sequence of word embedding vectors;\ngenerating, at the bidirectional recurrent neural network layer, a forward hidden state sequence and a backward hidden state sequence;\nconcatenating the forward and backward hidden state vectors to obtain a concatenated hidden state vector;\napplying the fully connected layer and a Softmax function to the concatenated hidden state vector to obtain a target vector for each token, each target vector has two probability values corresponding to probabilities that the token belongs to entity token name and non-entity token name; and\nselecting one or more tokens as the head entity name based on probability value of each token belonging to entity token name.\n6. The computer-implemented method of claim 1 wherein each of the first, second, and third distance terms uses a 2 norm to measure distance.\n7. The computer-implemented method of claim 6 wherein the joint distance metric further comprises string similarity terms representing a string similarity between name of entity in each candidate fact and the tokens classified as entity name by the HED model, and a string similarity between a name of the predicate in each candidate fact and the tokens classified as non-entity name by the HED model.\n8. The computer-implemented method of claim 7 wherein the joint distance metric is a weighted combination of the distance terms and the string similarity terms.\n9. The computer-implemented method of claim 6 wherein in each candidate fact, the tail entity embedding representation is calculated, using a relation function, from the head entity embedding representation and the predicate embedding representation.\n10. The computer-implemented method of claim 1 wherein searching head entity synonyms in the KG related to the one or more predicted head entity names comprises:\ninputting each predicated head entity name into the KG; and\nsearching, in the KG, head entity synonyms for each predicated head entity name, by both embedding comparison and string match, wherein each head entity synonym has a direct or partial string match to the predicated head entity name or has embedding similarity to the predicated head entity name.\n11. The computer-implemented method of claim 10 wherein for a predicated head entity name comprising multiple tokens, an entity representation for the predicated head entity name is formed from a dot product of entity representations of each token.\n12. A computer-implemented method for question answering using one or more processors that cause steps to be performed comprising:\ngenerating, using a predicate learning model stored in one or more memories of one or more computing devices and information of a knowledge graph (KG), a predicted predicate representation for a question comprising one or more tokens in a predicate embedding space, the predicate learning model being pre-trained using training data with ground truth facts and a predicate objective function;\ngenerating, using a head entity learning model stored in one or more memories of one or more computing devices and information of the KG, a predicted head entity representation for the question in an entity embedding space, head entity learning model being pre-trained using training data with ground truth facts and a head entity objective function;\nidentifying, using a relation function based upon KG embedding, a predicted tail entity representation from the predicted predicate representation and the predicted head entity representation, wherein the predicted head entity representation, the predicted predicate representation, and the predicted tail entity representation forming a predicted fact; and\nselecting a candidate fact among at least a subset of facts comprising one or more candidate facts chosen from one or more facts in the KG, based on a joint distance metric, as answer to the question, wherein the selected candidate fact has a minimum joint distance between it and the predicted fact according to the joint distance metric, and wherein each candidate fact comprises a head entity, a predicate, and a tail entity, and wherein the joint distance metric comprises:\na first distance term related to a distance between the predicted head entity representation and a head entity embedding representation for the head entity in each candidate fact;\na second distance term related to a distance between the predicted predicate representation and a predicate embedding representation for the predicate in each candidate fact; and\na third distance term related to a distance between the predicted tail entity representation and a tail entity embedding representation for the tail entity in each candidate fact.\n13. The computer-implemented method of claim 12 wherein the head entity embedding representation in each candidate fact is for a head entity as a synonym for one or more predicted head entity names identified by a head entity detection (HED) model comprising at least a bidirectional recurrent neural network layer and a fully connected layer.\n14. The computer-implemented method of claim 13 wherein the one or more predicted head entity names are identified by the HED model by steps comprising:\ngenerating, using the bidirectional recurrent neural network layer, a forward hidden state sequence and a backward hidden state sequence from a sequence of word embedding vectors of the one or more tokens in the question;\nconcatenating the forward and backward hidden state vectors into a concatenated hidden state vector;\napplying at least the fully connected layer to the concatenated hidden state vector to obtain a target vector for each token, each target vector has two probability values corresponding to probabilities that the token belongs to entity token name and non-entity token name; and\nselecting one or more tokens as the head entity name based on probability value of each token belonging to entity token name.\n15. The computer-implemented method of claim 13 wherein each of the first, second and third distance terms represents a 2 norm of a corresponding distance the joint distance metric further comprises one or more string similarity terms representing:\na string similarity between name of entity in each candidate fact and the tokens classified as entity name by the HED model, and\na string similarity between name of the predicate in each candidate fact and the tokens classified as non-entity name by the HED model.\n16. The computer-implemented method of claim 15 wherein the joint distance metric is a weighted combination of the first distance term, the second distance term, the third distance term, and the string similarity terms with a weight for each term in the joint distance metric.\n17. A non-transitory computer-readable medium or media comprising one or more sequences of instructions which, when executed by one or more processors, causes the steps for question answering to be performed comprising:\ngenerating, using information of a knowledge graph (KG), a vector in a KG predicate embedding space as a predicted predicate representation for a question comprising one or more tokens;\ngenerating, using information of the KG, a vector in a KG entity embedding space as a predicted head entity representation for the question;\nobtaining a predicted tail entity representation, based on a relation function based upon knowledge graph (KG) embedding, from the predicted predicate representation and the predicted head entity representation, wherein the predicted predicate representation, and the predicted tail entity representation forming a predicted fact;\nidentifying one or more predicted head entity names for the question, each predicted head entity name comprises one or more tokens from the question;\nsearching, in the KG, head entity synonyms to the one or more predicted head entity names by both embedding comparison and string match;\nconstructing a candidate fact set comprising one or more candidate facts, each candidate fact comprises a head entity among the head entity synonyms, a predicate, and a tail entity; and\nchoosing one candidate fact in the candidate fact set with a minimum joint distance to the predicted fact based on a joint distance metric as an answer to the question, the joint distance metric comprises:\na first distance term related to a distance between the predicted head entity representation and a head entity embedding representation for the head entity in each candidate fact;\na second distance term related to a distance between the predicted predicate representation and a predicate embedding representation for the predicate in each candidate fact; and\na third distance term related to a distance between the predicted tail entity representation and a tail entity embedding representation for the tail entity in each candidate fact.\n18. The non-transitory computer-readable medium or media of claim 17 wherein each of the first, second, and third distance terms represents a 2 norm of a corresponding distance, the joint distance metric further comprises one or more string similarity terms representing:\na string similarity between an entity name of each candidate fact and entity tokens in the question, and\na string similarity between a predicate name of each candidate fact and non-entity tokens in the question.\n19. The non-transitory computer-readable medium or media of claim 18 wherein the joint distance metric is a weighted combination of the first, second, and third distance terms and the string similarity terms.\n20. The non-transitory computer-readable medium or media of claim 19 wherein in the joint distance metric, the string similarity terms counterweight the distance terms."
}