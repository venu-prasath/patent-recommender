{
    "patent_id": "US-11423337-B2",
    "title": "Training distilled machine learning models ",
    "assignee": "Google Llc",
    "publication_date": "2022-08-23",
    "patent_link": "https://patents.google.com/patent/US11423337B2/en",
    "inventors": [
        "Oriol Vinyals",
        "Jeffrey Adgate Dean",
        "Geoffrey E. Hinton"
    ],
    "classifications": [
        "G06N20/20",
        "G06N20/00",
        "G06N3/045",
        "G06N3/0454",
        "G06N3/084",
        "G06N7/00",
        "G06N7/005",
        "G06N7/01"
    ],
    "abstract": "Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a distilled machine learning model. One of the methods includes training a cumbersome machine learning model, wherein the cumbersome machine learning model is configured to receive an input and generate a respective score for each of a plurality of classes; and training a distilled machine learning model on a plurality of training inputs, wherein the distilled machine learning model is also configured to receive inputs and generate scores for the plurality of classes, comprising: processing each training input using the cumbersome machine learning model to generate a cumbersome target soft output for the training input; and training the distilled machine learning model to, for each of the training inputs, generate a soft output that matches the cumbersome target soft output for the training input.",
    "claims": "\n1. A method performed by one or more data processing apparatus for training a student machine learning model having a plurality of student model parameters on a set of multiple training inputs, wherein the student machine learning model is configured to process an input to generate an output that comprises a respective score for each of a plurality of classes, the method comprising:\nprocessing each training input of the set of multiple training inputs using a teacher machine learning model to generate a target output for the training input, wherein the target output comprises a respective target score for each of the plurality of classes, wherein each target score satisfies:\n2. The method of claim 1, wherein the teacher machine learning model is an ensemble model comprising a plurality of respective baseline machine learning models.\n3. The method of claim 2, wherein processing a training input using the teacher machine learning model to generate a target output for the training input comprises:\nprocessing the training input using each baseline machine learning model to generate a baseline output for the training input; and\ncombining the baseline outputs for the training inputs to generate the target output for the training input.\n4. The method of claim 1, wherein the student machine learning model comprises a neural network model.\n5. The method of claim 1, wherein the student machine learning model has fewer model parameters than the teacher machine learning model.\n6. The method of claim 1, wherein for each training input of the set of multiple training inputs, the output generated by student machine learning model for the training input comprises a respective output score for each of the plurality of classes, wherein each output score satisfies:\n7. The method of claim 1, further comprising training the student machine learning model to, for one or more training inputs of the set of multiple training inputs, process the training input to generate an output that matches a hard output for the training input, wherein the hard output comprises a respective hard score for each of the plurality of classes, wherein the hard score for a target class of the plurality of classes is equal to 1 and the hard score for each remaining class of the plurality of classes is equal to 0.\n8. A system comprising:\none or more computers; and\none or more storage devices communicatively coupled to the one or more computers, wherein the one or more storage devices store instructions that, when executed by the one or more computers, cause the one or more computers to perform operations for training a student machine learning model having a plurality of student model parameters on a set of multiple training inputs, wherein the student machine learning model is configured to process an input to generate an output that comprises a respective score for each of a plurality of classes, the method comprising:\nprocessing each training input of the set of multiple training inputs using a teacher machine learning model to generate a target output for the training input, wherein the target output comprises a respective target score for each of the plurality of classes, wherein each target score satisfies:\n9. The system of claim 8, wherein the teacher machine learning model is an ensemble model comprising a plurality of respective baseline machine learning models.\n10. The system of claim 9, wherein processing a training input using the teacher machine learning model to generate a target output for the training input comprises:\nprocessing the training input using each baseline machine learning model to generate a baseline output for the training input; and\ncombining the baseline outputs for the training inputs to generate the target output for the training input.\n11. The system of claim 8, wherein the student machine learning model comprises a neural network model.\n12. The system of claim 8, wherein the student machine learning model has fewer model parameters than the teacher machine learning model.\n13. The system of claim 8, wherein for each training input of the set of multiple training inputs, the output generated by student machine learning model for the training input comprises a respective output score for each of the plurality of classes, wherein each output score satisfies:\n14. The system of claim 8, wherein the operations further comprise training the student machine learning model to, for one or more training inputs of the set of multiple training inputs, process the training input to generate an output that matches a hard output for the training input, wherein the hard output comprises a respective hard score for each of the plurality of classes, wherein the hard score for a target class of the plurality of classes is equal to 1 and the hard score for each remaining class of the plurality of classes is equal to 0.\n15. One or more non-transitory computer storage media storing instructions that when executed by one or more computers cause the one or more computers to perform operations for training a student machine learning model having a plurality of student model parameters on a set of multiple training inputs, wherein the student machine learning model is configured to process an input to generate an output that comprises a respective score for each of a plurality of classes, the method comprising:\nprocessing each training input of the set of multiple training inputs using a teacher machine learning model to generate a target output for the training input, wherein the target output comprises a respective target score for each of the plurality of classes, wherein each target score satisfies:\n16. The non-transitory computer storage media of claim 15, wherein the teacher machine learning model is an ensemble model comprising a plurality of respective baseline machine learning models.\n17. The non-transitory computer storage media of claim 16, wherein processing a training input using the teacher machine learning model to generate a target output for the training input comprises:\nprocessing the training input using each baseline machine learning model to generate a baseline output for the training input; and\ncombining the baseline outputs for the training inputs to generate the target output for the training input.\n18. The non-transitory computer storage media of claim 15, wherein the student machine learning model comprises a neural network model.\n19. The non-transitory computer storage media of claim 15, wherein the student machine learning model has fewer model parameters than the teacher machine learning model.\n20. The non-transitory computer storage media of claim 15, wherein for each training input of the set of multiple training inputs, the output generated by student machine learning model for the training input comprises a respective output score for each of the plurality of classes, wherein each output score satisfies:",
    "status": "Active",
    "citations_own": [
        "US6192351B1",
        "US20040002931A1",
        "US20140122401A1"
    ],
    "citations_ftf": [],
    "citedby_own": [],
    "citedby_ftf": [
        "CN105912500B",
        "CN109478248B",
        "US20190266487A1",
        "US10839310B2",
        "CN109690576A",
        "US11580380B2",
        "US10713593B2",
        "WO2018093935A1",
        "WO2018142266A1",
        "US11328412B2",
        "EP3563306A1",
        "US10146225B2",
        "TWI719302B",
        "CN107766929B",
        "CN107169513B",
        "CN110892420A",
        "US20180336645A1",
        "JP6911123B2",
        "CN107679625B",
        "US11113604B2",
        "EP3489892B1",
        "JP2021526670A",
        "CN110647996B",
        "US11222288B2",
        "CN109582529A",
        "EP3894965A1",
        "US11514310B2",
        "WO2020161797A1",
        "US11715043B2",
        "WO2020198520A1",
        "US10614345B1",
        "US11537664B2",
        "KR20200144658A",
        "US11113518B2",
        "CN110569874A",
        "CN114303203A",
        "JP2022546430A",
        "CN114341989A",
        "US11604647B2",
        "AU2020353380A1",
        "US10810709B1",
        "US11625934B2",
        "US11631030B2",
        "US11734614B1",
        "FR3109002B1",
        "US20230153632A1",
        "FR3114180A1",
        "JP2023526161A",
        "KR20210151644A",
        "US11775841B2",
        "US11430124B2",
        "WO2022045937A1",
        "DE102021109265A1",
        "JP7041374B2",
        "US11450225B1"
    ]
}