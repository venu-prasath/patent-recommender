{
    "patent_id": "US-10515400-B2",
    "title": "Learning vector-space representations of items for recommendations using word embedding models ",
    "assignee": "Adobe Inc.",
    "publication_date": "2019-12-24",
    "patent_link": "https://patents.google.com/patent/US10515400B2/en",
    "inventors": [
        "Balaji Krishnamurthy",
        "Raghavender Goel",
        "Nikaash Puri"
    ],
    "classifications": [
        "G06Q30/0631",
        "G06F16/31",
        "G06F17/276",
        "G06F40/274",
        "G06N3/042",
        "G06N3/0427",
        "G06N3/08",
        "G06N5/041"
    ],
    "abstract": "Learning vector-space representations of items for recommendations using word embedding models is described. In one or more embodiments, a word embedding model is used to produce item vector representations of items based on considering items interacted with as words and items interacted with during sessions as sentences. The item vectors are used to produce item recommendations similar to currently or recently viewed items.",
    "claims": "\n1. In a digital medium environment to provide recommendations of items of products or services, a method implemented by at least one computing device, the method comprising:\ncollecting, by the at least one computing device, data that describes interaction of a plurality of users with a plurality of items of products or services during a plurality of sessions;\nassociating, by the at least one computing device, each respective item of the plurality of items as a respective word;\nassociating, by the at least one computing device, strings of the words during respective sessions as sentences;\ndetermining, by the at least one computing device, a respective item vector representation for each respective item of the plurality of items by processing the sentences with a word embedding model;\nreceiving, by the at least one computing device, data describing subsequent interaction with at least one of the plurality of items of products or services;\ngenerating, by the at least one computing device, at least one item recommendation by utilizing an item similarity matrix based on the item vector representations and the data describing the subsequent interaction; and\noutputting, by the at least one computing device, the at least one item recommendation.\n2. The method as described in claim 1, wherein the method further comprises building, by the at least one computing device, the item similarity matrix based on the item vector representations.\n3. The method as described in claim 2, wherein building the item similarity matrix comprises computing, by the at least one computing device, dot products between the item vector representations to determine item to item similarities.\n4. The method as described in claim 1, wherein the word embedding model comprises a global log-bilinear regression model that is configured to use a word-word co-occurrence matrix along with local context window methods to generate word embeddings in a low dimensional space.\n5. The method as described in claim 1, wherein the word embedding model utilizes a neural network that is trained to predict a central word given words that occur in a context window around the central word.\n6. The method as described in claim 1, wherein multiple permutations of the words are inputted into the word embedding model.\n7. The method as described in claim 1, wherein the subsequent interaction is with an item that was previously interacted with at a time that the recommendation is generated.\n8. The method as described in claim 1, wherein the subsequent interaction is with a currently viewed item at a time that the recommendation is generated.\n9. The method as described in claim 1, wherein each respective sentence corresponds with a single session of the plurality of sessions.\n10. The method as described in claim 1, wherein each respective item vector representation comprises a word vector.\n11. The method as described in claim 1, wherein the utilizing an item similarity matrix comprises determining an additional item of the plurality of items of products or services based on a similarity to the at least one of the plurality of items of products or services, and wherein the at least one item recommendation is associated with the additional item.\n12. A method, implemented by at least one computing device, of receiving at least one recommended item of a product or service, the method comprising:\nsending, by the at least one computing device, data describing an interaction of a user with at least one item of a product or service;\nreceiving, by the at least one computing device, the at least one recommended item based on the data, the at least one recommended item determined by an item similarity matrix based on item vector representations determined based on words and sentences associated with historical interactions by the user or other users with the at least one item and other items of products or services, the words corresponding to the at least one item and the other items and the sentences corresponding to strings of words corresponding to the at least one item and the other items interacted with during respective sessions; and\noutputting, by the at least one computing device, the at least one recommended item.\n13. The method as described in claim 12, wherein the at least one recommended item is a plurality of recommended items and the method further comprises ranking the plurality of recommended items based upon explicit user ratings.\n14. The method as described in claim 12, wherein the at least one recommended item is further determined by examining the item similarity matrix for the at least one item and the other items built using the item vector representations for the at least one item and the other items, the item vector representations determined by inputting the sentences into a word embedding model.\n15. The method as described in claim 14, wherein the word embedding model comprises a global log-bilinear regression model that is configured to use a word-word co-occurrence matrix along with local context window methods to generate word embeddings in a low dimensional space.\n16. The method as described in claim 14, wherein multiple permutations of the sentences are inputted into the word embedding model.\n17. The method as described in claim 14, wherein the item similarity matrix may associate a plurality of historically interacted with items as being similar and a plurality of other historically interacted with items as being dissimilar.\n18. A system comprising:\nat least one processor; and\nat least one module implemented at least partially in hardware, the at least one module operable to provide at least one item recommendation of a product or service by performing operations comprising:\ncollecting data that describes interaction of a plurality of users with a plurality of items of products or services during a plurality of sessions;\nassociating each respective item of the plurality of items as a respective word;\nassociating strings of the words during respective sessions as sentences;\ndetermining a respective item vector representation for each respective item of the plurality of items by processing the sentences with a word embedding model;\nreceiving data describing subsequent interaction with at least one of the plurality of items of products or services;\ngenerating at least one item recommendation by utilizing an item similarity matrix based on the item vector representations and the data describing the subsequent interaction; and\noutputting the at least one item recommendation.\n19. The system as described in claim 18, the operations further comprising building the item similarity matrix by computing dot products between the item vector representations to determine item to item similarities.\n20. The system as described in claim 18, wherein the subsequent interaction is with an item that was previously interacted with at a time that the recommendation is generated."
}