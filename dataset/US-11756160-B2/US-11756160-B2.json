{
    "patent_id": "US-11756160-B2",
    "title": "ML-based methods for pseudo-CT and HR MR image estimation ",
    "assignee": "Washington University",
    "publication_date": "2023-09-12",
    "patent_link": "https://patents.google.com/patent/US11756160B2/en",
    "inventors": [
        "Chunjoo (Justin) Park",
        "Sasa Mutic",
        "Hao Zhang",
        "Olga Green"
    ],
    "classifications": [
        "G06T3/4053",
        "A61N5/1049",
        "A61B6/5258",
        "A61N5/1067",
        "G06F17/18",
        "G06N20/20",
        "G06N3/045",
        "G06N3/047",
        "G06N3/048",
        "G06N3/08",
        "G06N3/082",
        "G06N3/088",
        "G06T5/002",
        "A61B6/032",
        "A61B6/5247",
        "A61N2005/1055",
        "A61N5/1039",
        "G06N20/10",
        "G06N5/01",
        "G06N5/025",
        "G06N7/01",
        "G06T2207/10088"
    ],
    "abstract": "The present disclosure describes a computer-implemented method of transforming a low-resolution MR image to a high-resolution MR image using a deep CNN-based MRI SR network and a computer-implemented method of transforming an MR image to a pseudo-CT (sCT) image using a deep CNN-based sCT network. The present disclosure further describes a MR image-guided radiation treatment system that includes a computing device to implement the MRI SR and CT networks and to produce a radiation plan based in the resulting high resolution MR images and sCT images.",
    "claims": "\n1. A computer-implemented method of transforming a low-resolution MR image into a super-resolution MR image using an MRI SR deep CNN system comprising a deep CNN-based de-noising auto-encoder (DAE) network and a deep CNN-based super-resolution generative network (SRG), the method comprising:\nreceiving, using a computing device, a low-resolution MR image;\ntransforming, using the computing device, the low-resolution MR image into a de-noised MR image using the DAE network, the DAE network comprising six convolutional encoder layers with 4\u00d74 filters and six de-convolutional decoder layers with 4\u00d74 filters, wherein each convolutional encoder layer comprises a single convolutional filter with stride 2, each de-convolution decoder layer comprises a single deconvolutional filter with stride 2, and each convolutional encoder layer and each de-convolution decoder layer ends with a leaky and standard rectified linear unit (ReLU); and,\ntransforming, using the computing device, the de-noised MR image into the super-resolution MR image using the SRG network.\n2. The computer-implemented method of claim 1, wherein the SRG network comprises:\ntwo up-sampling layers,\neight residual blocks, each residual block comprising two 3\u00d73 convolutional filters separated by a ReLU activation with an elementwise sum operator attached at the end of the layer; and\ntwo output layers, each output layer comprising a 3\u00d73 convolutional filter, ReLU activation, and a subpixel operator up-sampling layer.\n3. The computer-implemented method of claim 2, further comprising training the DAE network by:\nreceiving, using the computing device, a set of noisy low resolution MR images;\ntransforming, using the computing device, each noisy MR image into a de-noised MR image using a noise filter, wherein each noisy MR image and corresponding de-noised MR image together form a noisy/de-noised MR image pair; and\ntraining, using the computing device, the DAE network to minimize a reconstruction error given by \u2225g\u03b8 g (f\u03b8 f ({tilde over (x)}))\u2212x\u2225 for each matched noisy/de-noised low resolution image pair, where x denotes each de-noised MR image, {tilde over (x)} denotes each noisy MR image, and f\u03b8 f and g\u03b8 g denote the encoding and decoding network parameterized by \u03b8f and \u03b8g, respectively.\n4. The computer-implemented method of claim 3, wherein the noise filter comprises a non-local means filter.\n5. The computer-implemented method of claim 2, further comprising training the SRG network by:\nreceiving, using the computing device, a set of matched low resolution/high resolution MR image pairs;\nforming, using the computing device, a generative adversarial network (GAN) including a generative model G parametrized by \u03b8G and comprising the SRG network and a discriminative model D parametrized by \u03b8D, the discriminative model D configured to determine a probability that a high resolution MR image is a high resolution image or an SRG-transformed low resolution MR image from a matched low resolution/high resolution MR image pair; and\ntraining, using the computing device, the GAN to solve the optimization problem given by\n6. The computer-implemented method of claim 5, wherein the set of matched low resolution/high resolution MR image pairs is produced by:\ntransforming, using the computing device, a high resolution MR image to a low resolution MR image training using a deep CNN-based down-sampling network (DSN), the DSN comprising:\ntwo down-sampling layers, each down-sampling layer comprising a 3\u00d73 convolutional filter of stride 2 followed by a ReLU activation;\ntwo residual blocks, each residual block comprising two 3\u00d73 convolutional filters separated by a ReLU activation and followed by an elementwise sum operator; and\nan output layer.",
    "status": "Active",
    "citations_own": [
        "US20110268328A1",
        "US20130266198A1",
        "US20160247263A1",
        "US20170072222A1",
        "US20170337682A1",
        "WO2018048507A1",
        "US20180099152A1",
        "US10032256B1",
        "US20180357537A1"
    ],
    "citations_ftf": [],
    "citedby_own": [],
    "citedby_ftf": [
        "EP3550515A1",
        "US11741580B2",
        "AU2019350918B2",
        "JP7129869B2",
        "WO2020093782A1",
        "CN113168684A",
        "EP3671660A1",
        "CN109697740B",
        "US11042803B2",
        "CN110120024B",
        "KR20200140096A",
        "US20200400769A1",
        "CN110246137B",
        "KR20210001324A",
        "US11540798B2",
        "US10699715B1",
        "US11170543B2",
        "US11507778B2",
        "CN111414988B",
        "US11508037B2",
        "CN111429355A",
        "CN111461983B",
        "CN111402174A",
        "WO2021206687A1",
        "CN111524147B",
        "CN113538225A",
        "CN111583220B",
        "US11301999B2",
        "CN111583303A",
        "CN111627024A",
        "CN111681166B",
        "CN111402143B",
        "CN111696168B",
        "CN111751773B",
        "CN111860233B",
        "CN111932454B",
        "CN112381722A",
        "CN112241966B",
        "CN112330724A",
        "CN112396579A",
        "EP4252193A1",
        "CN112381172B",
        "AU2020281143B1",
        "WO2022120661A1",
        "CN112488976B",
        "WO2022132959A1",
        "CN112561799A",
        "US11715276B2",
        "CN112614052B",
        "CN112669214B",
        "EP4030385A1",
        "CN112907444A",
        "CN112991199A",
        "CN113096207B",
        "CN112862738A",
        "DE102021111086A1",
        "US20220392058A1",
        "US11769033B2",
        "CN113239886A",
        "CN113256609B",
        "CN113506215B",
        "CN113674330B",
        "CN113487657B",
        "CN113763247A",
        "CN113793267B",
        "CN114170089B",
        "CN114638745B",
        "WO2023178527A1",
        "CN115359066B",
        "CN116152807B"
    ]
}