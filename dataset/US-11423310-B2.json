{
    "patent_id": "US-11423310-B2",
    "title": "Deep learning based adaptive arithmetic coding and codelength regularization ",
    "assignee": "WaveOne Inc.",
    "publication_date": "2022-08-23",
    "patent_link": "https://patents.google.com/patent/US11423310B2/en",
    "inventors": [
        "Oren Rippel",
        "Lubomir Bourdev"
    ],
    "classifications": [
        "G06N3/0455",
        "G06N20/00",
        "G06N3/04",
        "G06N3/08",
        "G06V10/82",
        "G06V20/52",
        "G06V30/18057",
        "G06V30/19147",
        "G06V30/19167",
        "G06V30/19173",
        "G06V40/172",
        "G06F18/213",
        "G06F18/214",
        "G06F18/2178",
        "G06F18/24143",
        "G06K9/6232",
        "G06K9/6256",
        "G06K9/6263",
        "G06K9/6274",
        "G06N3/045",
        "G06N3/0454",
        "G06N3/047",
        "G06N3/084",
        "G06T5/002",
        "G06V10/449",
        "G06V10/454",
        "G06V10/758",
        "G06V20/46",
        "G06V30/10",
        "G06V30/194",
        "H04N19/126",
        "H04N19/13",
        "H04N19/149",
        "H04N19/154",
        "H04N19/167",
        "H04N19/172",
        "H04N19/18",
        "H04N19/197",
        "H04N19/33",
        "H04N19/44",
        "H04N19/48",
        "H04N19/91"
    ],
    "abstract": "A deep learning based compression (DLBC) system applies trained models to compress binary code of an input image to a target codelength. For a set of binary codes representing the quantized coefficents of an input image, the DLBC system applies a first model that is trained to predict feature probabilities based on the context of each bit of the binary codes. The DLBC system compresses the binary code via adaptive arithmetic coding based on the determined probability of each bit. The compressed binary code represents a balance between a reconstruction quality of a reconstruction of the input image and a target compression ratio of the compressed binary code.",
    "claims": "\n1. A computer-implemented method comprising:\nreceiving compressed code for an input image that encodes values of one or more processing units for a plurality of bitplanes;\nobtaining a plurality of context features and a plurality of feature probabilities for the plurality of context features, wherein a context feature indicates a context of a processing unit, and a feature probability for a respective context feature indicates a likelihood a processing unit associated with the respective context feature has a non-zero value;\nfor each processing unit in the one or more processing units:\ndetermining a context feature associated with the processing unit based on one or more previously decoded processing units;\ndecoding a value of the processing unit from the compressed code using a feature probability for the context feature associated with the processing unit;\ngenerating a tensor for the input image based on the decoded values of the one or more processing units for the plurality of bitplanes; and\ngenerating a reconstructed version of the input image applying a decoder portion of a neural network autoencoder to the tensor, wherein the decoder portion includes a trained set of parameters.\n2. The computer-implemented method of claim 1, wherein the context of the processing unit comprises values of processing units neighboring the processing unit in the plurality of bitplanes.\n3. The computer-implemented method of claim 1, wherein the context of the processing unit comprises an index of a corresponding channel of the processing unit.\n4. The computer-implemented method of claim 1, wherein each bit in a bitplane of the plurality of bitplanes corresponds to a processing unit.\n5. The computer-implemented method of claim 4, wherein the feature probability for the respective context feature indicates a likelihood the processing unit associated with the respective context feature has a value of 1.\n6. The computer-implemented method of claim 4, wherein the context of the processing unit comprises a bitplane index of the processing unit.\n7. The computer-implemented method of claim 4, wherein the context of the processing unit comprises whether co-located processing units associated with lower bitplane indices have non-zero values.\n8. The computer-implemented method of claim 1, wherein the input image is a residual frame of a video predicted from a plurality of video frames of the video.\n9. The computer-implemented method of claim 1, wherein the compressed code is obtained from an encoded tensor generated by applying an encoder portion of the neural network autoencoder to the input image.\n10. The computer-implemented method of claim 1, wherein decoding the value of the processing unit further comprises performing arithmetic decoding on the compressed code using the feature probability for the context feature associated with the processing unit.\n11. A non-transitory computer-readable storage medium including instructions that, when executed by a processor, cause the processor to perform steps including:\nreceiving compressed code for an input image that encodes values of one or more processing units for a plurality of bitplanes;\nobtaining a plurality of context features and a plurality of feature probabilities for the plurality of context features, wherein a context feature indicates a context of a processing unit, and a feature probability for a respective context feature indicates a likelihood a processing unit associated with the respective context feature has a non-zero value;\nfor each processing unit in the one or more processing units:\ndetermining a context feature associated with the processing unit based on one or more previously decoded processing units;\ndecoding a value of the processing unit from the compressed code using a feature probability for the context feature associated with the processing unit;\ngenerating a tensor for the input image based on the decoded values of the one or more processing units for the plurality of bitplanes; and\ngenerating a reconstructed version of the input image applying a decoder portion of a neural network autoencoder to the tensor, wherein the decoder portion includes a trained set of parameters.\n12. The non-transitory computer-readable storage medium of claim 11, wherein the context of the processing unit comprises values of processing units neighboring the processing unit in the plurality of bitplanes.\n13. The non-transitory computer-readable storage medium of claim 11, wherein the context of the processing unit comprises an index of a corresponding channel of the processing unit.\n14. The non-transitory computer-readable storage medium of claim 11, wherein each bit in a bitplane of the plurality of bitplanes corresponds to a processing unit.\n15. The non-transitory computer-readable storage medium of claim 14, wherein the feature probability for the respective context feature indicates a likelihood the processing unit associated with the respective context feature has a value of 1.\n16. The non-transitory computer-readable storage medium of claim 14, wherein the context of the processing unit comprises a bitplane index of the processing unit.\n17. The non-transitory computer-readable storage medium of claim 14, wherein the context of the processing unit comprises whether co-located processing units associated with lower bitplane indices have non-zero values.\n18. The non-transitory computer-readable storage medium of claim 11, wherein the input image is a residual frame of a video predicted from a plurality of video frames of the video.\n19. The non-transitory computer-readable storage medium of claim 11, wherein the compressed code is obtained from an encoded tensor generated by applying an encoder portion of the neural network autoencoder to the input image.\n20. The non-transitory computer-readable storage medium of claim 11, wherein decoding the value of the processing unit further comprises performing arithmetic decoding on the compressed code using the feature probability for the context feature associated with the processing unit."
}