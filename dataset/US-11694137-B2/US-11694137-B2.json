{
    "patent_id": "US-11694137-B2",
    "title": "Re-training a model for abnormality detection in medical scans based on a re-contrasted training set ",
    "assignee": "Enlitic, Inc.",
    "publication_date": "2023-07-04",
    "patent_link": "https://patents.google.com/patent/US11694137B2/en",
    "inventors": [
        "Li Yao",
        "Jordan Prosky",
        "Eric C. Poblenz",
        "Kevin Lyman",
        "Ben Covington",
        "Anthony Upton"
    ],
    "classifications": [
        "G06Q10/06315",
        "A61B5/7264",
        "A61B6/5205",
        "A61B6/563",
        "G06F16/245",
        "G06F18/2115",
        "G06F18/214",
        "G06F18/217",
        "G06F18/2415",
        "G06F18/24155",
        "G06F18/41",
        "G06F21/6254",
        "G06F3/0482",
        "G06F3/0484",
        "G06F9/542",
        "G06N20/00",
        "G06N20/20",
        "G06N3/045",
        "G06N3/084",
        "G06N5/04",
        "G06N5/045",
        "G06Q20/14",
        "G06Q20/145",
        "G06T11/001",
        "G06T11/006",
        "G06T11/206",
        "G06T3/40",
        "G06T5/002",
        "G06T5/008",
        "G06T5/50",
        "G06T7/0012",
        "G06T7/0014",
        "G06T7/10",
        "G06T7/11",
        "G06T7/187",
        "G06T7/44",
        "G06T7/97",
        "G06V10/225",
        "G06V10/25",
        "G06V10/764",
        "G06V10/82",
        "G06V30/19173",
        "G06V40/171",
        "G16H10/20",
        "G16H10/60",
        "G16H15/00",
        "G16H30/20",
        "G16H30/40",
        "G16H40/20",
        "G16H50/20",
        "G16H50/50",
        "H04L67/01",
        "H04L67/12",
        "A61B5/055",
        "A61B5/7267",
        "A61B6/032",
        "A61B6/5211",
        "A61B6/5217",
        "A61B6/5258",
        "A61B8/4416",
        "A61B8/5207",
        "A61B8/5215",
        "A61B8/5269",
        "G06F18/2111",
        "G06F18/24",
        "G06F40/295",
        "G06N20/10",
        "G06N7/01",
        "G06Q50/22",
        "G06T2200/24",
        "G06T2207/10048",
        "G06T2207/10072",
        "G06T2207/10081",
        "G06T2207/10088",
        "G06T2207/10116",
        "G06T2207/10132",
        "G06T2207/20076",
        "G06T2207/20081",
        "G06T2207/20084",
        "G06T2207/30004",
        "G06T2207/30008",
        "G06T2207/30016",
        "G06T2207/30061",
        "G06T7/70",
        "G06V2201/03",
        "G06V30/194",
        "G16H50/30",
        "G16H50/70",
        "Y02A90/10"
    ],
    "abstract": "A method includes generating first contrast significance data for a first computer vision model generated from a first training set of medical scans. First significant contrast parameters are identified based on the first contrast significance data. A first re-contrasted training set is generated based on performing a first intensity transformation function on the first training set of medical scans, where the first intensity transformation function utilizes the first significant contrast parameters. A first re-trained model is generated from the first re-contrasted training set, which is associated with corresponding output labels based on abnormality data for the first training set of medical scans. Re-contrasted image data of a new medical scan is generated based on performing the first intensity transformation function. Inference data indicating at least one abnormality detected in the new medical scan is generated based on utilizing the first re-trained model on the re-contrasted image data.",
    "claims": "\n1. A method comprising:\ngenerating first contrast significance data for a first computer vision model, wherein the first computer vision model was generated from a first training set of medical scans;\nidentifying first significant contrast parameters based on the first contrast significance data;\ngenerating a first re-contrasted training set based on performing a first intensity transformation function on the first training set of medical scans, wherein the first intensity transformation function utilizes the first significant contrast parameters;\ngenerating a first re-trained model from the first re-contrasted training set, which is associated with corresponding output labels based on abnormality data for the first training set of medical scans;\ngenerating re-contrasted image data of a new medical scan based on performing the first intensity transformation function;\ngenerating inference data indicating at least one abnormality detected in the new medical scan based on utilizing the first re-trained model on the re-contrasted image data; and\ntransmitting the inference data for display.\n2. The method of claim 1, wherein the first training set of medical scans corresponds to a first one of a plurality of medical scan types, further comprising:\ngenerating second contrast significance data for a second computer vision model, wherein the second computer vision model was generated from a second training set of medical scans that correspond to a second one of the plurality of medical scan types that is different from the first one of the plurality of medical scan types;\nidentifying second significant contrast parameters based on the second contrast significance data, wherein the second significant contrast parameters are different from the first significant contrast parameters;\ngenerating a second re-contrasted training set by performing a second intensity transformation function on the second training set of medical scans, wherein the second intensity transformation function utilizes the second significant contrast parameters; and\ngenerating a second re-trained model from the second re-contrasted training set;\nwherein the first intensity transformation function and the first re-trained model is utilized for the new medical scan in response to determining the new medical scan corresponds to the first one of the plurality of medical scan types.\n3. The method of claim 2, wherein at least one of:\nthe first one of the plurality of medical scan types and the second one of the plurality of medical scan types correspond to different anatomical regions; or\nthe first one of the plurality of medical scan types and the second one of the plurality of medical scan types correspond to different modalities.\n4. The method of claim 1, wherein the first intensity transformation function is a non-linear function.\n5. The method of claim 1, wherein the first significant contrast parameters indicate a density window boundary pair.\n6. The method of claim 1, further comprising:\ngenerating a plurality of sets of augmented images, wherein each set of augmented images in the plurality of sets of augmented images is generated by performing a set of intensity transformation functions on one of the first training set of medical scans; and\ngenerating the first computer vision model by performing a training step on the plurality of sets of augmented images, wherein each augmented image of a set of augmented images is assigned same output label data as one of the first training set of medical scans.\n7. The method of claim 6, wherein the first significant contrast parameters utilized to perform the first intensity transformation function correspond to contrast parameters utilized by a corresponding one of the set of intensity transformation functions.\n8. The method of claim 7, wherein the first contrast significance data indicates a ranking of the set of intensity transformation functions, and wherein the first significant contrast parameters are identified to correspond to the contrast parameters utilized by the one of the set of intensity transformation functions in response to the one of the set of intensity transformation functions having a most favorable rank in the ranking.\n9. The method of claim 6, wherein the first contrast significance data indicates a proper subset of the set of intensity transformation functions that includes at least two of the set of intensity transformation functions;\nwherein the first re-contrasted training set is generated by performing the proper subset of the set of intensity transformation functions on the first training set of medical scans to generate a plurality of sets of augmented images; and\nwherein the first re-trained model is generated by performing the training step on the plurality of sets of augmented images.\n10. The method of claim 9, wherein the first contrast significance data is generated by:\ncalculating significance values for each of the set of intensity transformation functions; and\ngenerating a significant subset of the set of intensity transformation functions by including each of the set of intensity transformation functions with a corresponding significance value that compares favorably to a significance threshold, wherein the proper subset corresponds to the significant subset.\n11. The method of claim 9,\nwherein the re-contrasted image data of the new medical scan includes a set of images, generated by performing the proper subset of the set of intensity transformation functions on the new medical scan; and\nwherein generating the inference data includes:\nutilizing the first re-trained model on the set of images of the re-contrasted image data to generate a set of partial inference data; and\nperforming a consensus function on the set of partial inference data to generate the inference data.\n12. The method of claim 6, wherein each of the set of intensity transformation functions are based on density properties of corresponding one of a plurality of different anatomy features present in the first training set of medical scans.\n13. The method of claim 1, further comprising:\ngenerating a plurality of sets of augmented images, wherein each set of augmented images in the plurality of sets of augmented images is generated by performing a set of intensity transformation functions on one of the first training set of medical scans;\ngenerating a set of computer vision models that each correspond to one of the set of intensity transformation functions, wherein each of the set of computer vision models is generated from each of the plurality of sets of augmented images that were generated by utilizing the corresponding one of the set of intensity transformation functions;\ngenerating model accuracy data for each of the set of computer vision models; and\ngenerating model ranking data by ranking the set of computer vision models in accordance with the model accuracy data;\nwherein the first contrast significance data indicates the one of the set of intensity transformation functions that corresponds to a most favorably ranked one of the set of computer vision models in the model ranking data.\n14. The method of claim 1, wherein the first contrast significance data is generated by:\ncalculating significance values for each of a set of contrast parameters that each correspond to contrast settings for at least one medical scan of the first training set of medical scans; and\nindicating each of the set of contrast parameters with a corresponding significance value that compares favorably to a significance threshold.\n15. The method of claim 14, wherein none of the set of contrast parameters have a corresponding significance value that compares favorably to the significance threshold, and wherein the first intensity transformation function corresponds to an identity function in response to the first contrast significance data indicating no significant contrast parameters.\n16. The method of claim 14, wherein the set of contrast parameters correspond to a set of intensity transformation functions applied to medical scans of the first training set of medical scans, wherein none of the set of contrast parameters have a corresponding significance value that compares favorably to the significance threshold, further comprising:\nselecting a new set of contrast parameters;\ngenerating an updated training set of medical scans by performing a new set of intensity transformation functions that utilize the new set of contrast parameters on the first training set of medical scans;\ngenerating an updated first computer vision model from the updated training set of medical scans to; and\ngenerating updated first contrast significance data for the updated first computer vision model, wherein the first significant contrast parameters are identified based on the updated first contrast significance data, and wherein the first significant contrast parameters include contrast parameters of the new set of contrast parameters.\n17. A contrast parameter learning system, comprising:\nat least one processor; and\na memory that stores operational instructions that, when executed by the at least one processor, cause the contrast parameter learning system to:\ngenerate first contrast significance data for a first computer vision model, wherein the first computer vision model was generated from a first training set of medical scans;\nidentify first significant contrast parameters based on the first contrast significance data;\ngenerate a first re-contrasted training set based on performing a first intensity transformation function on the first training set of medical scans, wherein the first intensity transformation function utilizes the first significant contrast parameters;\ngenerate a first re-trained model from the first re-contrasted training set, which is associated with corresponding output labels based on abnormality data for the first training set of medical scans;\ngenerate re-contrasted image data of a new medical scan based on performing the first intensity transformation function;\ngenerate inference data indicating at least one abnormality detected in the new medical scan based on utilizing the first re-trained model on the re-contrasted image data; and\ntransmit the inference data for display.\n18. The contrast parameter learning system of claim 17, further comprising:\nselecting a first set of intensity transformation functions to be applied to a first medical scan in the first training set of medical scans based on density properties of a first abnormality indicated in a corresponding output label of the first medical scan, wherein generating the first re-contrasted training set includes performing the first set of intensity transformation functions upon the first medical scan.\n19. The contrast parameter learning system of claim 18, further comprising:\nselecting a second set of intensity transformation functions to be applied to a second medical scan in the first training set of medical scans based on density properties of a second abnormality indicated in a corresponding output label of the second medical scan, wherein the second abnormality is different from the first abnormality, wherein generating the first re-contrasted training set includes performing the second set of intensity transformation functions upon the second medical scan, and wherein a set difference between the first set of intensity transformation functions and the second set of intensity transformation functions is non-null.\n20. A method comprising:\ngenerating first contrast significance data for a first computer vision model, wherein the first computer vision model was generated from a first training set of medical scans;\nidentifying first significant contrast parameters based on the first contrast significance data;\ngenerating a first re-contrasted training set based on performing a first intensity transformation function on the first training set of medical scans, wherein the first intensity transformation function utilizes the first significant contrast parameters;\ngenerating a first re-trained model from the first re-contrasted training set, which is associated with corresponding output labels based on abnormality data for the first training set of medical scans;\ngenerating re-contrasted image data of a new medical scan based on performing the first intensity transformation function;\ngenerating inference data indicating at least one abnormality detected in the new medical scan based on utilizing the first re-trained model on the re-contrasted image data; and\ntransmitting the inference data for storage via a database storage system."
}