{
    "patent_id": "US-11783199-B2",
    "title": "Image description information generation method and apparatus, and electronic device ",
    "assignee": "Tencent Technology (Shenzhen) Company Limited",
    "publication_date": "2023-10-10",
    "patent_link": "https://patents.google.com/patent/US11783199B2/en",
    "inventors": [
        "Chen Chen",
        "Shuai MOU",
        "Wanpeng XIAO",
        "Qi JU"
    ],
    "classifications": [
        "G06N3/088",
        "G06F18/2132",
        "G06F18/214",
        "G06F18/22",
        "G06F18/24",
        "G06N3/044",
        "G06N3/045",
        "G06N3/08",
        "G06V10/764",
        "G06V10/82",
        "G06N3/006",
        "Y02T10/40"
    ],
    "abstract": "An image description information generation method includes obtaining a to-be-processed target image, and inputting the target image into a target-image description information generation network. The target-image description information generation network is a generation network that is obtained by performing adversarial training using a plurality of sample images and that is configured to generate image description information, the adversarial training is training an initialized image description information generation network and an initialized discriminative network alternately, and the discriminative network is configured to discriminate an output result of the image description information generation network. The method also includes according to the output result of the target-image description information generation network, generating target-image description information used for describing the target image.",
    "claims": "\n1. An image description information generation method, comprising:\nconstructing an initialized image description information generation network and an initialized discriminative network;\nperforming adversarial training of the initialized image description information generation network and the initialized discriminative network, to obtain a target-image description information generation network, comprising: performing the following steps repeatedly until the target-image description information generation network is obtained:\nobtaining a sample image and sample image description information corresponding to the sample image;\ninputting the sample image and the sample image description information into a current image description information generation network, to obtain sample image description generation information of the sample image and sample image reference description information of the sample image, wherein a first matching degree between the sample image description generation information and the sample image is greater than a second matching degree between the sample image reference description information and the sample image, and an initial value of the current image description information generation network is the initialized image description information generation network;\ndetermining to-be-discriminated sample description information in the sample image description information, the sample image description generation information, and the sample image reference description information;\ninputting the sample image and the to-be-discriminated sample description information into a current discriminative network, to obtain a sample discrimination probability value and a sample feedback coefficient, wherein an initial value of the current discriminative network is the initialized discriminative network;\nadjusting the current image description information generation network according to the sample discrimination probability value when the sample feedback coefficient indicates that the sample discrimination probability value does not meet a convergence condition, to obtain a trained image description information generation network; adjusting the current discriminative network according to the trained image description information generation network to obtain a trained discriminative network; returning to the operation of obtaining the sample image and the sample image description information corresponding to the sample image, and continuing to train the trained image description information generation network and the trained discriminative network; and\nusing the current image description information generation network as the target-image description information generation network when the sample feedback coefficient indicates that the sample discrimination probability value meets the convergence condition;\nobtaining a to-be-processed target image;\ninputting the target image into the target-image description information generation network; and\naccording to the output result of the target-image description information generation network, generating target-image description information used for describing the target image.\n2. The method according to claim 1, wherein the constructing the initialized discriminative network comprises:\nconstructing a CNN-related initialized discriminative network based on a convolutional neural network (CNN), a CNN-related multi-layer perception (MLP), and a CNN-related classification network, wherein the CNN-related MLP and the CNN-related classification network are configured to convert an eigenvector outputted by the CNN into a probability value, the CNN comprises M layers of convolution kernels, convolution kernels of the ith layer in the M layers of convolution kernels are configured to perform a convolution operation on a sample image vector of the sample image according to the ith size, i being a positive integer less than or equal to M, and the sample image vector is determined according to image eigenvectors of the sample image and word eigenvectors comprised in sample image description information corresponding to the sample image; or\nconstructing an RNN-related initialized discriminative network based on a recurrent neural network (RNN), an RNN-related MLP, and an RNN-related classification network, wherein the RNN-related MLP and the RNN-related classification network are configured to convert an eigenvector outputted by the RNN into a probability value, the RNN comprises N layers of long-short term memory (LSTM) networks, N being determined according to a sample image vector of the sample image, and the sample image vector is determined according to image eigenvectors of the sample image and word eigenvectors comprised in sample image description information corresponding to the sample image.\n3. The method according to claim 2, wherein the constructing the initialized image description information generation network comprises:\nconstructing the initialized image description information generation network by using a region-based CNN (R-CNN), an attention serialization language model, and a double-layer LSTM network, wherein the R-CNN is configured to extract local eigenvectors and a global eigenvector from the sample image, the attention serialization language model is configured to perform weighted average processing on the local eigenvectors, to obtain an average eigenvector, and the double-layer LSTM network is configured to obtain a to-be-discriminated object vector by using the average eigenvector and the global eigenvector, and input the to-be-discriminated object vector into the initialized discriminative network.\n4. The method according to claim 1, wherein before the adjusting the current image description information generation network according to the sample discrimination probability value, and adjusting the current discriminative network according to the trained image description information generation network, the method further comprises:\ndetermining the sample discrimination probability value outputted by the current discriminative network;\nobtaining the first matching degree between the sample image description generation information and the sample image by using a language model; and\nperforming weighted average processing on the sample discrimination probability value and the first matching degree, to obtain the sample feedback coefficient.\n5. The method according to claim 1, wherein the adjusting the current image description information generation network according to the sample discrimination probability value comprises:\nadjusting a parameter in at least one of the following structures in the current image description information generation network according to the sample discrimination probability value: a current R-CNN, a current attention serialization language model, and a current double-layer LSTM network.\n6. The method according to claim 1, wherein the adjusting the current discriminative network according to the trained image description information generation network to obtain a trained discriminative network comprises:\nobtaining sample image description generation information after training or sample image reference description information after training that is outputted by the trained image description information generation network; and\nadjusting a parameter in a CNN structure in the current discriminative network by using the sample image description information, the sample image description generation information after training, or the sample image reference description information after training, to obtain the trained discriminative network.\n7. The method according to claim 1, wherein the adjusting the current discriminative network according to the trained image description information generation network to obtain a trained discriminative network comprises:\nobtaining sample image description generation information after training or sample image reference description information after training that is outputted by the trained image description information generation network; and\nadjusting a parameter in an RNN structure in the current discriminative network by using the sample image description information, the sample image description generation information after training, or the sample image reference description information after training, to obtain the trained discriminative network.\n8. The method according to claim 1, wherein inputting the sample image and the to-be-discriminated sample description information into the current discriminative network comprises:\nusing a combination of the sample image and the sample image description information as a positive sample of the current discriminative network;\nusing a combination of the sample image and the sample image description generation information as a first negative sample of the current discriminative network; and\nusing a combination of the sample image and the sample image reference description information as a second negative sample of the current discriminative network.\n9. The method according to claim 1, wherein:\nan expression sequence or an expression habit of the sample image reference description information is different from that of the sample image description generation information.\n10. An electronic device, comprising:\nat least one memory storing computer program instructions; and\nat least one processor coupled to the at least one memory and, when executing the computer program instructions, configured to perform:\nconstructing an initialized image description information generation network and an initialized discriminative network;\nperforming adversarial training of the initialized image description information generation network and the initialized discriminative network, to obtain a target-image description information generation network, comprising: performing the following steps repeatedly until the target-image description information generation network is obtained:\nobtaining a sample image and sample image description information corresponding to the sample image;\ninputting the sample image and the sample image description information into a current image description information generation network, to obtain sample image description generation information of the sample image and sample image reference description information of the sample image, wherein a first matching degree between the sample image description generation information and the sample image is greater than a second matching degree between the sample image reference description information and the sample image, and an initial value of the current image description information generation network is the initialized image description information generation network;\ndetermining to-be-discriminated sample description information in the sample image description information, the sample image description generation information, and the sample image reference description information;\ninputting the sample image and the to-be-discriminated sample description information into a current discriminative network, to obtain a sample discrimination probability value and a sample feedback coefficient, wherein an initial value of the current discriminative network is the initialized discriminative network;\nadjusting the current image description information generation network according to the sample discrimination probability value when the sample feedback coefficient indicates that the sample discrimination probability value does not meet a convergence condition, to obtain a trained image description information generation network; adjusting the current discriminative network according to the trained image description information generation network to obtain a trained discriminative network; returning to the operation of obtaining the sample image and the sample image description information corresponding to the sample image, and continuing to train the trained image description information generation network and the trained discriminative network; and\nusing the current image description information generation network as the target-image description information generation network when the sample feedback coefficient indicates that the sample discrimination probability value meets the convergence condition;\nobtaining a to-be-processed target image;\ninputting the target image into the target-image description information generation network; and\naccording to the output result of the target-image description information generation network, generating target-image description information used for describing the target image.\n11. The electronic device according to claim 10, wherein the constructing the initialized discriminative network comprises:\nconstructing a CNN-related initialized discriminative network based on a convolutional neural network (CNN), a CNN-related multi-layer perception (MLP), and a CNN-related classification network, wherein the CNN-related MLP and the CNN-related classification network are configured to convert an eigenvector outputted by the CNN into a probability value, the CNN comprises M layers of convolution kernels, convolution kernels of the ith layer in the M layers of convolution kernels are configured to perform a convolution operation on a sample image vector of the sample image according to the ith size, i being a positive integer less than or equal to M, and the sample image vector is determined according to image eigenvectors of the sample image and word eigenvectors comprised in sample image description information corresponding to the sample image, or\nconstructing an RNN-related initialized discriminative network based on a recurrent neural network (RNN), an RNN-related MLP, and an RNN-related classification network, wherein the RNN-related MLP and the RNN-related classification network are configured to convert an eigenvector outputted by the RNN into a probability value, the RNN comprises N layers of long-short term memory (LSTM) networks, N being determined according to a sample image vector of the sample image, and the sample image vector is determined according to image eigenvectors of the sample image and word eigenvectors comprised in sample image description information corresponding to the sample image.\n12. The electronic device according to claim 11, wherein the constructing the initialized image description information generation network comprises:\nconstructing the initialized image description information generation network by using a region-based CNN (R-CNN), an attention serialization language model, and a double-layer LSTM network, wherein the R-CNN is configured to extract local eigenvectors and a global eigenvector from the sample image, the attention serialization language model is configured to perform weighted average processing on the local eigenvectors, to obtain an average eigenvector, and the double-layer LSTM network is configured to obtain a to-be-discriminated object vector by using the average eigenvector and the global eigenvector, and input the to-be-discriminated object vector into the initialized discriminative network.\n13. The electronic device according to claim 10, wherein before the adjusting the current image description information generation network according to the sample discrimination probability value, and adjusting the current discriminative network according to the trained image description information generation network, the at least one processor is further configured to perform:\ndetermining the sample discrimination probability value outputted by the current discriminative network;\nobtaining the first matching degree between the sample image description generation information and the sample image by using a language model; and\nperforming weighted average processing on the sample discrimination probability value and the first matching degree, to obtain the sample feedback coefficient.\n14. The electronic device according to claim 10, wherein the adjusting the current image description information generation network according to the sample discrimination probability value comprises:\nadjusting a parameter in at least one of the following structures in the current image description information generation network according to the sample discrimination probability value: a current R-CNN, a current attention serialization language model, and a current double-layer LSTM network.\n15. The electronic device according to claim 10, wherein the adjusting the current discriminative network according to the trained image description information generation network to obtain a trained discriminative network comprises:\nobtaining sample image description generation information after training or sample image reference description information after training that is outputted by the trained image description information generation network; and\nadjusting a parameter in a CNN structure in the current discriminative network by using the sample image description information, the sample image description generation information after training, or the sample image reference description information after training, to obtain the trained discriminative network.\n16. The electronic device according to claim 10, wherein the adjusting the current discriminative network according to the trained image description information generation network to obtain a trained discriminative network comprises:\nobtaining sample image description generation information after training or sample image reference description information after training that is outputted by the trained image description information generation network; and\nadjusting a parameter in an RNN structure in the current discriminative network by using the sample image description information, the sample image description generation information after training, or the sample image reference description information after training, to obtain the trained discriminative network.\n17. A non-transitory computer-readable storage medium storing computer program instructions executable by at least one processor to perform:\nconstructing an initialized image description information generation network and an initialized discriminative network;\nperforming adversarial training of the initialized image description information generation network and the initialized discriminative network, to obtain a target-image description information generation network, comprising: performing the following steps repeatedly until the target-image description information generation network is obtained:\nobtaining a sample image and sample image description information corresponding to the sample image;\ninputting the sample image and the sample image description information into a current image description information generation network, to obtain sample image description generation information of the sample image and sample image reference description information of the sample image, wherein a first matching degree between the sample image description generation information and the sample image is greater than a second matching degree between the sample image reference description information and the sample image, and an initial value of the current image description information generation network is the initialized image description information generation network;\ndetermining to-be-discriminated sample description information in the sample image description information, the sample image description generation information, and the sample image reference description information;\ninputting the sample image and the to-be-discriminated sample description information into a current discriminative network, to obtain a sample discrimination probability value and a sample feedback coefficient, wherein an initial value of the current discriminative network is the initialized discriminative network;\nadjusting the current image description information generation network according to the sample discrimination probability value when the sample feedback coefficient indicates that the sample discrimination probability value does not meet a convergence condition, to obtain a trained image description information generation network; adjusting the current discriminative network according to the trained image description information generation network to obtain a trained discriminative network; returning to the operation of obtaining the sample image and the sample image description information corresponding to the sample image, and continuing to train the trained image description information generation network and the trained discriminative network; and\nusing the current image description information generation network as the target-image description information generation network when the sample feedback coefficient indicates that the sample discrimination probability value meets the convergence condition;\nobtaining a to-be-processed target image;\ninputting the target image into the target-image description information generation network; and\naccording to the output result of the target-image description information generation network, generating target-image description information used for describing the target image.",
    "status": "Active",
    "citations_own": [
        "US20160358024A1",
        "CN106844442A",
        "CN107133354A",
        "CN107330444A",
        "CN107451994A",
        "CN108334497A",
        "US20180260698A1",
        "CN108564550A",
        "CN109685116A",
        "US11281938B2"
    ],
    "citations_ftf": [],
    "citedby_own": [],
    "citedby_ftf": [
        "CN109685116B",
        "JP7096361B2",
        "CN110188620B",
        "CN111915339A",
        "CN112150174A",
        "CN110458282B",
        "CN110633655A",
        "US11120268B2",
        "CN110717421A",
        "CN110727868B",
        "CN111105013B",
        "CN111046187B",
        "CN110941945B",
        "CN111126282B",
        "CN111159454A",
        "CN111428091B",
        "CN111639547B",
        "CN112084841B",
        "CN111916050A",
        "CN112102294A",
        "CN112329801B",
        "CN112529857B",
        "CN112529154A",
        "US20220309280A1",
        "CN113378919B",
        "CN113392775B",
        "CN113361628B",
        "CN113673349B",
        "CN113706663A",
        "CN113792853B",
        "CN114006752A",
        "CN113779282B",
        "CN116152690A",
        "CN114117682B",
        "CN114372537B",
        "CN116312861A",
        "CN116543146B",
        "CN116629346B"
    ]
}