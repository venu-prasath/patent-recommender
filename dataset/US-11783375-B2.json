{
    "patent_id": "US-11783375-B2",
    "title": "Customer journey management engine ",
    "assignee": "Cerebri AI Inc.",
    "publication_date": "2023-10-10",
    "patent_link": "https://patents.google.com/patent/US11783375B2/en",
    "inventors": [
        "Alain Charles Briancon",
        "Jean Joseph Belanger",
        "James Cvetan Stojanov",
        "Christopher Michael Coovrey",
        "Pranav Mahesh Makhijani",
        "Gregory Klose",
        "Max Changchun Huang",
        "Mounib Mohamad Ismail",
        "Michael Henry Engeling",
        "Hongshi Li"
    ],
    "classifications": [
        "G06Q30/0269",
        "G06F18/2155",
        "G06F18/24",
        "G06F18/295",
        "G06N20/20",
        "G06N3/006",
        "G06N3/044",
        "G06N3/088",
        "G06N5/01",
        "G06N5/022",
        "G06N7/01"
    ],
    "abstract": "Provided is a process, including: obtaining a first training dataset, training a first machine-learning model on the first training dataset, obtaining a set of candidate question sequences, forming virtual subject-entity records, forming a second training dataset, training a second machine-learning model, and storing the adjusted parameters of the second machine-learning model in memory.",
    "claims": "\n1. A tangible, non-transitory, machine-readable medium storing instructions that when executed by one or more processors effectuate operations comprising:\nobtaining, with one or more processors, a first training dataset, wherein:\nthe first training dataset comprises a plurality of subject-entity records, the subject-entity records each describe a different subject entity;\neach subject entity is a different member of a first population of entities that have interacted over time with an actor entity;\neach subject-entity record describes attributes of a respective subject entity among the first population;\neach subject-entity record describes a time-series of events involving a respective subject entity among the first population;\nthe events are distinct from the attributes;\nat least some of the events are question events that are caused by the actor entity; and\nat least some of the events are subject responses that are caused by a respective subject entity among the first population;\ntraining, with one or more processors, a first machine-learning model on the first training dataset by adjusting parameters of the first machine-learning model to optimize a first objective function that indicates an accuracy of the first machine-learning model in predicting subsequent events in the time-series given prior events in the time-series and given attributes of subject entities among the first population;\nobtaining, with one or more processors, a set of candidate question sequences including candidate question events, the set including a plurality of different candidate question sequences, wherein the actor entity asks at least some of the different candidate question events;\nforming, with one or more processors, virtual subject-entity records by appending the set of candidate question sequences to time-series of at least some of the subject-entity records, wherein:\na given subset of the virtual subject-entity records includes a plurality of virtual-subject entity records that each include at least part of the time-series from the same subject-entity record in the first training dataset, wherein the time-series from the same subject entity record comprises at least some questions and corresponding response events of the subject entity; and\nat least some of the plurality of virtual-subject entity records in the given subset each have a different member of the set of candidate question sequences appended to the at least part of the time-series from the same subject-entity record in the first training dataset;\nforming, with one or more processors, a second training dataset by:\npredicting responses of the subject entities to at least some of the appended set of candidate question sequences with the first machine-learning model based on the virtual subject-entity records; and\nassociating subject entities or attributes thereof with corresponding predicted responses in the second training dataset;\ntraining, with one or more processors, a second machine-learning model on the second training dataset by adjusting parameters of the second machine-learning model to optimize a second objective function that indicates an accuracy of the second machine-learning model in predicting the predicted responses in the second training set given attributes of subject entities corresponding to the predicted responses; and\nstoring, with one or more processors, the adjusted parameters of the second machine-learning model in memory.\n2. The medium of claim 1, wherein:\nat least some of subject-entity records of the plurality of subject-entity records have interacted within a time range with the actor entity.\n3. The medium of claim 2, wherein the time range is a trailing time range.\n4. The medium of claim 1, wherein:\nat least some of subject-entity records of the plurality of subject-entity records have interacted within a geolocation range with the actor entity.\n5. The medium of claim 1, wherein:\nthe first machine-learning model is configured to predict responses of the plurality of subject-entity records given previous time-series of events and attributes of the plurality of subject-entity records.\n6. The medium of claim 1, wherein the operation comprise:\niterating training of a plurality of models to increase the accuracy of the model across each iteration responsive to next questions and responses.\n7. The medium of claim 1, wherein:\nthe first machine learning model comprises a Hidden Markov model.\n8. The medium of claim 1, wherein:\nthe first machine learning model comprises a long short-term memory model.\n9. The medium of claim 1, wherein:\nthe first machine learning model comprises a dynamic Bayesian network.\n10. The medium of claim 1, wherein:\nthe first machine learning model comprises a neural network classifier.\n11. The medium of claim 1, wherein:\nthe second machine learning model is an unsupervised model configured to translate inputs into a vector representation that maps to a candidate action.\n12. The medium of claim 1, wherein:\nthe second machine learning model is a random decision forest model that includes a plurality of weighted trained decision trees.\n13. The medium of claim 1, wherein:\nthe second machine learning model is a gradient-boosted trees model that includes a plurality of weighted trained decision trees.\n14. The medium of claim 1, wherein:\nthe events are stored in an ontology of event types that describes interrelatedness or similarity between the events.\n15. The medium of claim 1, wherein the question events comprise:\nan interactive user interface element for which a response within the interactive user interface element is collected, which may be a selection or other user input;\nan advertisement, for which a response may be the interaction with a particular portion of the advertisement; and\nan article about a product, for which a response may be the interaction with a particular portion of the article.\n16. The medium of claim 1, wherein at least some of the events are subject responses that are caused by a respective subject entity among the first population.\n17. The medium of claim 16, wherein the subject responses comprise:\na canceled response;\na delayed response;\na direct response; and\nan indirect response.\n18. The medium of claim 1, wherein at least some of the plurality of virtual-subject entity records in the given subset each have a different member of the set of candidate question sequences appended to the at least part of the time-series from the same subject-entity record in the first training dataset."
}