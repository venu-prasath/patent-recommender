{
    "patent_id": "US-11679506-B2",
    "title": "Adapting simulation data to real-world conditions encountered by physical processes ",
    "assignee": "Autodesk, Inc.",
    "publication_date": "2023-06-20",
    "patent_link": "https://patents.google.com/patent/US11679506B2/en",
    "inventors": [
        "Hui Li",
        "Evan Patrick Atherton",
        "Erin BRADNER",
        "Nicholas Cote",
        "Heather Kerrick"
    ],
    "classifications": [
        "B25J9/1671",
        "B25J9/1605",
        "B25J9/161",
        "B25J9/163",
        "G05B19/41885",
        "G06F30/20",
        "G06N20/00",
        "G06N3/044",
        "G06N3/08",
        "G06T17/00",
        "G05B2219/32017",
        "G05B2219/35353",
        "Y02P90/02"
    ],
    "abstract": "One embodiment of the present invention sets forth a technique for generating simulated training data for a physical process. The technique includes receiving, as input to at least one machine learning model, a first simulated image of a first object, wherein the at least one machine learning model includes mappings between simulated images generated from models of physical objects and real-world images of the physical objects. The technique also includes performing, by the at least one machine learning model, one or more operations on the first simulated image to generate a first augmented image of the first object. The technique further includes transmitting the first augmented image to a training pipeline for an additional machine learning model that controls a behavior of the physical process.",
    "claims": "\n1. A computer-implemented method for controlling a physical process, the method comprising:\nreceiving a first simulated image of a first object;\nperforming, by at least one machine learning model, one or more operations on the first simulated image to generate a first augmented image of the first object; and\ntransmitting the first augmented image as training data to an additional machine learning model that, once trained, controls a behavior of the physical process.\n2. The computer-implemented method of claim 1, wherein the at least one machine learning model includes mappings between simulated images generated from models of physical objects and real-world images of the physical objects.\n3. The computer-implemented method of claim 2, wherein the at least one machine learning model generates the first augmented image of the first object based on the first simulated image and at least one of the mappings.\n4. The computer-implemented method of claim 1, further comprising training the at least one machine learning model based on simulated training data that includes simulated images of one or more objects and real-world training data that includes real-world images of the one or more objects.\n5. The computer-implemented method of claim 1, further comprising generating the first simulated image from a computer aided design (CAD) model of the first object.\n6. The computer-implemented method of claim 1, further comprising generating labels associated with the first simulated image and transmitting the labels to the additional machine learning model as training data.\n7. The computer-implemented method of claim 6, wherein the labels indicate at least one of a type of the first object, a graspable point on the first object, a position of the first object within the first augmented image, or an orientation of the first object within the first augmented image.\n8. The computer-implemented method of claim 1, wherein the additional machine learning model comprises an artificial neural network.\n9. The computer-implemented method of claim 1, wherein the at least one machine learning model comprises a generator neural network that produces augmented images from simulated images.\n10. The computer-implemented method of claim 1, wherein the at least one machine learning model comprises a discriminator neural network that categorizes augmented images as simulated or real.\n11. The computer-implemented method of claim 1, wherein the physical process comprises a robot-based task.\n12. One or more non-transitory computer-readable media storing instructions that, when executed by one or more processors, cause the one or more processors to perform the steps of:\nreceiving a first simulated image of a first object;\nperforming, by at least one machine learning model, one or more operations on the first simulated image to generate a first augmented image of the first object; and\ntransmitting the first augmented image as training data to an additional machine learning model that, once trained, controls a behavior of a physical process.\n13. The one or more non-transitory computer-readable media of claim 12, wherein the at least one machine learning model includes mappings between simulated images generated from models of physical objects and real-world images of the physical objects.\n14. The one or more non-transitory computer-readable media of claim 13, wherein the at least one machine learning model generates the first augmented image of the first object based on the first simulated image and at least one of the mappings.\n15. The one or more non-transitory computer-readable media of claim 12, further comprising training the at least one machine learning model based on simulated training data that includes simulated images of one or more objects and real-world training data that includes real-world images of the one or more objects.\n16. The one or more non-transitory computer-readable media of claim 12, wherein the first simulated image and the first augmented image comprise at least one of a two-dimensional (2D) representation of the first object or one or more three-dimensional (3D) locations associated with the first object.\n17. The one or more non-transitory computer-readable media of claim 12, further comprising generating labels associated with the first simulated image and transmitting the labels to the additional machine learning model as training data.\n18. The one or more non-transitory computer-readable media of claim 17, wherein the labels indicate at least one of a type of the first object, a graspable point on the first object, a position of the first object within the first augmented image, or an orientation of the first object within the first augmented image.\n19. The one or more non-transitory computer-readable media of claim 12, wherein the additional machine learning model comprises an artificial neural network.\n20. The one or more non-transitory computer-readable media of claim 12, wherein the at least one machine learning model comprises a generator neural network that produces augmented images from simulated images.\n21. The one or more non-transitory computer-readable media of claim 12, wherein the at least one machine learning model comprises a discriminator neural network that categorizes augmented images as simulated or real.\n22. The one or more non-transitory computer-readable media of claim 12, wherein the one or more operations performed by the at least one machine learning model on the first simulated image comprise at least one of one or more shading operations, one or more lighting operations, or one or more operations that increase image noise.\n23. A system, comprising:\none or more memories that store instructions, and one or more processors that are coupled to the one or more memories and, when executing the instructions, are configured to:\nreceive a first simulated image of a first object;\nperform one or more operations on the first simulated image to generate a first augmented image of the first object; and\ntransmitting the first augmented image as training data to a machine learning model that, once trained, controls a behavior of a physical process.",
    "status": "Active",
    "citations_own": [
        "US6675189B2",
        "US20080316205A1",
        "US20080316206A1",
        "US20110020779A1",
        "US20140079314A1",
        "US20140122391A1",
        "US20150106306A1",
        "US9158295B2",
        "US9183676B2",
        "US20150339589A1",
        "US20160034809A1",
        "US20160035093A1",
        "US20160162786A1",
        "US20160284095A1",
        "US9547746B1",
        "US20180012411A1",
        "US20180028294A1",
        "US20180075581A1",
        "US20180117446A1",
        "US20180181802A1",
        "US20180225823A1",
        "US20180314250A1",
        "US20180330511A1",
        "US20180341836A1",
        "US20180349508A1",
        "US20180349527A1",
        "US20190057520A1",
        "US20190114302A1",
        "US10297070B1",
        "US10360515B2",
        "US20190384790A1",
        "US20200118423A1",
        "US20200167161A1",
        "US20200258057A1",
        "US20200265745A1",
        "US20200268349A1",
        "US10867417B2",
        "US20210201078A1"
    ],
    "citations_ftf": [],
    "citedby_own": [],
    "citedby_ftf": [
        "US11537262B1",
        "US10678244B2",
        "US11273553B2",
        "US20180357819A1",
        "US10671349B2",
        "US11157441B2",
        "US11409692B2",
        "CN109426212A",
        "WO2019051492A1",
        "US11341364B2",
        "US11657602B2",
        "KR102565444B1",
        "US10755115B2",
        "US11113887B2",
        "US10726248B2",
        "US11561791B2",
        "US20200334899A1",
        "US20210271968A1",
        "US10867214B2",
        "JP6810087B2",
        "US10565475B2",
        "US11215999B2",
        "US10901416B2",
        "US11636333B2",
        "US11256958B1",
        "US20210260753A1",
        "US11562231B2",
        "US11196678B2",
        "US11501179B2",
        "US10601454B1",
        "US11537811B2",
        "US11610117B2",
        "US10810726B2",
        "US10922584B2",
        "US10997461B2",
        "CN109857487A",
        "US11567514B2",
        "US10956755B2",
        "US10970911B2",
        "GB2581523A",
        "CN113826051A",
        "US11676063B2",
        "US11341367B1",
        "US20200306960A1",
        "US11016496B2",
        "US20200342152A1",
        "EP3736741A1",
        "EP3736740A1",
        "US11345030B2",
        "US11372474B2",
        "CN110297693B",
        "CN110202585B",
        "EP3779686A1",
        "WO2021067234A1",
        "EP3812105B1",
        "WO2021084587A1",
        "US20210133502A1",
        "CN110757464A",
        "CN110899147B",
        "DE102020200165B4",
        "US20210216906A1",
        "CN114945925A",
        "US11758069B2",
        "US11586522B2",
        "CN111429423B",
        "EP4128088A1",
        "EP3960394A1",
        "DE102020211648A1",
        "EP3988255A1",
        "US20220219402A1",
        "US11436793B1",
        "WO2022182345A1",
        "US11651554B2",
        "US20230043409A1",
        "WO2023004802A1",
        "US20230139772A1",
        "TR2021022147A2",
        "WO2023198282A1"
    ]
}