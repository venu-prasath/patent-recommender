{
    "patent_id": "US-11417131-B2",
    "title": "Techniques for sentiment analysis of data using a convolutional neural network and a co-occurrence network ",
    "assignee": "Oracle International Corporation",
    "publication_date": "2022-08-16",
    "patent_link": "https://patents.google.com/patent/US11417131B2/en",
    "inventors": [
        "Michael Malak",
        "Mark L. Kreider"
    ],
    "classifications": [
        "G06F40/205",
        "G06F18/21",
        "G06F18/2413",
        "G06F40/30",
        "G06K9/6217",
        "G06K9/627",
        "G06N3/045",
        "G06N3/0454",
        "G06N5/046",
        "G06V10/454",
        "G06V10/764",
        "G06V30/1985",
        "G06V30/2272",
        "G06V30/274",
        "G06N3/082",
        "G06N3/105"
    ],
    "abstract": "Techniques are provided for performing sentiment analysis on words in a first data set. An example embodiment includes generating a word embedding model including a first plurality of features. A value indicating sentiment for the words in the first data set can be determined using a convolutional neural network (CNN). A second plurality of features are generated based on bigrams identified in the data set. The bigrams can be generated using a co-occurrence graph. The model is updated to include the second plurality of features, and sentiment analysis can be performed on a second data set using the updated model.",
    "claims": "\n1. A method comprising, at a computer system:\ntraining a word embedding model based on training data;\ngenerating the word embedding model comprising a first plurality of features for words based on the trained word embedding model;\ngenerating an initial matrix, wherein the initial matrix comprises a plurality of rows comprising a plurality of words from a first data set, and a first plurality of columns comprising the first plurality of features from the word embedding model;\ndetermining one or more values indicating a measure of sentiment for the plurality of words in the initial matrix in relation to each of the first plurality of features, wherein the one or more values indicating the measure of sentiment for the plurality of words in the initial matrix in relation to each of the first plurality of features are determined using a convolutional neural network;\ngenerating a co-occurrence graph based on the first data set which is used to generate the initial matrix;\nidentifying one or more bigrams in the first data set based on the co-occurrence graph that was generated based on the first data set;\ndetermining a set of bigrams in the co-occurrence graph, that was generated based on the first data set, having a highest frequency of occurrence;\ngenerating an updated matrix to include a second plurality of features corresponding with the set of bigrams having the highest frequency of occurrence;\nfor each of the second plurality of features, generating, in the updated matrix, an indication of an occurrence of a bigram corresponding to each the plurality of words based on the set of bigrams and the co-occurrence graph; and\ndetermining a measure of sentiment for a second data set using the updated matrix.\n2. The method according to claim 1, further comprising, before generating the word embedding model comprising the first plurality of features for words:\nloading the training data for training the word embedding model, wherein the training data comprises a spreadsheet of data; and\nanalyzing the training data in order to generate the word embedding model.\n3. The method according to claim 2, wherein analyzing the training data comprises labeling each of the data in the training data with a numeric value, wherein the numeric value is based on a positive or negative sentiment associated with the data.\n4. The method according to claim 1, wherein the first plurality of features for words comprises attributes associated with the words.\n5. The method according to claim 1, wherein the convolutional neural network is executed based on a plurality of function calls in order to perform sentiment analysis.\n6. The method according to claim 1, wherein the set of bigrams in the co-occurrence graph having the highest frequency of occurrence among the plurality of words from the first data set are assigned a higher weight than bigrams having a lower frequency of occurrence among the plurality of words from the first data set.\n7. The method according to claim 1, wherein the updated matrix comprises a second plurality of columns, and wherein each of the second plurality of columns comprises a feature corresponding with the second plurality of features of the set of bigrams.\n8. The method according to claim 1, wherein the co-occurrence graph identifies relationships between words, and wherein the co-occurrence graph is generated based on bigrams in the first data set.\n9. A system comprising:\none or more processors;\na memory accessible to the one or more processors, the memory comprising instructions that, when executed by the one or more processors, cause the one or more processors to perform a method comprising:\ntraining a word embedding model based on training data;\ngenerating the word embedding model comprising a first plurality of features for words based on the trained word embedding model;\ngenerating an initial matrix, wherein the initial matrix comprises a plurality of rows comprising a plurality of words from a first data set, and a first plurality of columns comprising the first plurality of features from the word embedding model;\ndetermining one or more values indicating a measure of sentiment for the plurality of words in the initial matrix in relation to each of the first plurality of features, wherein the one or more values indicating the measure of sentiment for the plurality of words in the initial matrix in relation to each of the first plurality of features are determined using a convolutional neural network;\ngenerating a co-occurrence graph based on the first data set which is used to generate the initial matrix;\nidentifying one or more bigrams in the first data set based on the co-occurrence graph that was generated based on the first data set;\ndetermining a set of bigrams in the co-occurrence graph, that was generated based on the first data set, having a highest frequency of occurrence;\ngenerating an updated matrix to include a second plurality of features corresponding with the set of bigrams having the highest frequency of occurrence;\nfor each of the second plurality of features, generating, in the updated matrix, an indication of an occurrence of a bigram corresponding to each the plurality of words based on the set of bigrams and the co-occurrence graph; and\ndetermining a measure of sentiment for a second data set using the updated matrix.\n10. The system according to claim 9, further comprising, before generating the word embedding model comprising the first plurality of features for words:\nloading the training data for training the word embedding model, wherein the training data comprises a spreadsheet of data; and\n11. The system according to claim 10, wherein analyzing the training data comprises labeling each of the data in the training data with a numeric value, wherein the numeric value is based on a positive or negative sentiment associated with the data.\n12. The system according to claim 9, wherein the first plurality of features for words comprises attributes associated with the words.\n13. The system according to claim 9, wherein the convolutional neural network is executed based on a plurality of function calls in order to perform sentiment analysis.\n14. The system according to claim 9, wherein the set of bigrams in the co-occurrence graph having the highest frequency of occurrence among the plurality of words from the first data set are assigned a higher weight than bigrams having a lower frequency of occurrence among the plurality of words from the first data set.\n15. The system according to claim 9, wherein the updated matrix comprises a second plurality of columns, and wherein each of the second plurality of columns comprises a feature corresponding with the second plurality of features of the set of bigrams.\n16. The system according to claim 9, wherein the co-occurrence graph identifies relationships between words, and wherein the co-occurrence graph is generated based on bigrams in the first data set.\n17. A non-transitory computer readable medium storing a plurality of instructions for controlling a computer system to perform a method comprising:\ntraining a word embedding model based on training data;\ngenerating the word embedding model comprising a first plurality of features for words based on the trained word embedding model;\ngenerating an initial matrix, wherein the initial matrix comprises a plurality of rows comprising a plurality of words from a first data set, and a first plurality of columns comprising the first plurality of features from the word embedding model;\ndetermining one or more values indicating a measure of sentiment for the plurality of words in the initial matrix in relation to each of the first plurality of features, wherein the one or more values indicating the measure of sentiment for the plurality of words in the initial matrix in relation to each of the first plurality of features are determined using a convolutional neural network;\ngenerating a co-occurrence graph based on the first data set which is used to generate the initial matrix;\nidentifying one or more bigrams in the first data set based on the co-occurrence graph that was generated based on the first data set;\ndetermining a set of bigrams in the co-occurrence graph, that was generated based on the first data set, having a highest frequency of occurrence;\ngenerating an updated matrix to include a second plurality of features corresponding with the set of bigrams having the highest frequency of occurrence;\nfor each of the second plurality of features, generating, in the updated matrix, an indication of an occurrence of a bigram corresponding to each the plurality of words based on the set of bigrams and the co-occurrence graph; and\ndetermining a measure of sentiment for a second data set using the updated matrix.\n18. The computer readable medium according to claim 17, further comprising before generating the word embedding model comprising the first plurality of features for words:\nloading the training data for training the word embedding model, wherein the training data comprises a spreadsheet of data; and\nanalyzing the training data in order to generate the word embedding model.\n19. The computer readable medium according to claim 18, wherein analyzing the training data comprises labeling each of the data in the training data with a numeric value, wherein the numeric value is based on a positive or negative sentiment associated with the data.\n20. The computer readable medium according to claim 17, wherein the updated matrix comprises a second plurality of columns, and wherein each of the second plurality of columns comprises a feature corresponding with the second plurality of features of the set of bigrams.",
    "status": "Active",
    "citations_own": [
        "US6047283A",
        "US20020107861A1",
        "US20020152201A1",
        "US6556983B1",
        "US6807558B1",
        "US20040260695A1",
        "US20050071140A1",
        "US20050278325A1",
        "US20060075021A1",
        "US20070112827A1",
        "US20080027929A1",
        "US20080281820A1",
        "US20090006460A1",
        "US7571177B2",
        "US20100274821A1",
        "US20110106791A1",
        "US20110173000A1",
        "US8155951B2",
        "US20120101975A1",
        "US20120117076A1",
        "US20120166180A1",
        "US8234285B1",
        "US20120253792A1",
        "US20130110792A1",
        "US20130232452A1",
        "US20130268534A1",
        "US20140052688A1",
        "US20140067728A1",
        "US20140074829A1",
        "US20140088944A1",
        "US20140095425A1",
        "US20140115155A1",
        "US20140222181A1",
        "US8874616B1",
        "US20140337331A1",
        "US20150106360A1",
        "US20150106324A1",
        "US20150370775A1",
        "US20160092476A1",
        "WO2016049437A1",
        "WO2016049460A1",
        "US20160188701A1",
        "US20160239581A1",
        "US20160247061A1",
        "US20160286544A1",
        "US20160314200A1",
        "US20170109358A1",
        "US20170270100A1",
        "US20180074786A1",
        "US20180075104A1",
        "US20180075115A1",
        "US20180173699A1",
        "US20180293499A1",
        "US20180336278A1",
        "US10643355B1"
    ],
    "citations_ftf": [],
    "citedby_own": [],
    "citedby_ftf": [
        "US10347017B2",
        "US10748312B2",
        "US10579721B2",
        "US11049190B2",
        "US11222266B2",
        "US11347751B2",
        "CN107463907B",
        "US11138157B2",
        "US10783161B2",
        "USD960177S1",
        "US11256548B2",
        "US11042712B2",
        "US11106979B2",
        "US10721190B2",
        "US11373640B1",
        "US10812486B2",
        "US20220067585A1",
        "CN110162594B",
        "CN109978829B",
        "US10956474B2",
        "US10809913B1",
        "US11227120B2",
        "US11163956B1",
        "US11461590B2",
        "CN110378407A",
        "US11694029B2",
        "CN110750978A",
        "CN110795937A",
        "US11308285B2",
        "CN110852040B",
        "CN110852090A",
        "US11321479B2",
        "CN111191428B",
        "CN111143567B",
        "US11783128B2",
        "US11645523B2",
        "US20210264220A1",
        "EP4115348A1",
        "US20210365443A1",
        "US11687514B2",
        "US11531811B2",
        "CN112100344A",
        "US20220207429A1",
        "US11599842B2",
        "US11537495B2",
        "US11635878B2",
        "CN112948541B",
        "US11669680B2",
        "CN113220873A",
        "CN113378545B",
        "US20230017739A1",
        "WO2023032345A1",
        "US20230121351A1",
        "US11450124B1",
        "CN116150509B",
        "CN116384340B"
    ]
}