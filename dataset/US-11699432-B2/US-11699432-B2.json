{
    "patent_id": "US-11699432-B2",
    "title": "Cross-context natural language model generation ",
    "assignee": "Sorcero, Inc.",
    "publication_date": "2023-07-11",
    "patent_link": "https://patents.google.com/patent/US11699432B2/en",
    "inventors": [
        "Walter Bender",
        "Unai Garay Maestre",
        "Carlos Fernandez Musoles",
        "Adam Tomkins"
    ],
    "classifications": [
        "G10L15/063",
        "G06F16/2237",
        "G06F16/248",
        "G06F16/328",
        "G06F16/3323",
        "G06F16/3329",
        "G06F16/3338",
        "G06F16/3344",
        "G06F16/3347",
        "G06F16/345",
        "G06F16/367",
        "G06F16/90332",
        "G06F40/20",
        "G06F40/289",
        "G06F40/30",
        "G06F40/40",
        "G06F9/451",
        "G06F9/547",
        "G06N20/00",
        "G06N3/04",
        "G06N5/022",
        "G10L15/16",
        "G10L15/197",
        "G16H50/70",
        "G16H70/60",
        "G06F9/453",
        "G06N3/044",
        "G06N3/045",
        "G16B50/10",
        "G16H10/60",
        "G16H40/20",
        "G16H70/20",
        "Y02A90/10"
    ],
    "abstract": "Provided is a method including obtaining a corpus and an associated set of domain indicators. The method includes learning a set of vectors in an embedding space based on n-grams of the corpus. The method includes updating ontology graphs comprising a set of vertices and edges associating the set of vertices with each other. The method also includes determining a vector cluster using hierarchical clustering based on distances of the set of vectors with respect to each other in the embedding space and determining a hierarchy of the ontology graphs based on a set of domain indicators of a respective set of vertices corresponding to vectors of the vector cluster. The method also includes updating an index based on the ontology graphs.",
    "claims": "\n1. A computer-implemented method of using domain-specific ontologies of providing summaries of documents in a corpora of natural-language text documents, the method comprising:\nobtaining, with a computer system, a set of user-specific context parameters and a natural-language text document;\ndetermining, with the computer system, a first domain of knowledge based on the set of user-specific context parameters, wherein the first domain of knowledge maps to a first ontology amongst a plurality of ontologies, and wherein ontologies in the plurality of ontologies map n-grams onto a set of concepts to which the n-grams refer;\nscoring, with the computer system, a first set of n-grams of the natural-language text document using a scoring model based on relations between members of the first set of n-grams;\nselecting, with the computer system, text sections of the natural-language text based on n-gram scores provided by the scoring model;\ndetermining, with the computer system, an initial set of n-grams of the n-grams, wherein each respective n-gram of the initial set of n-grams maps to a respective concept of the set of concepts, and wherein each respective n-gram is identified by an ontology other than the first ontology;\ndetermining, with the computer system, a set of related n-grams mapped to the set of concepts associated with the first domain of knowledge; and\ngenerating, with the computer system, a text summary for the natural-language text document based on the text sections and the set of related n-grams;\npresenting a user interface (UI) to a client computer device, the UI comprising a set of UI elements that, when interacted with, causes the client computer device to send a feedback message;\nreceiving the feedback message based on an interaction with the set of UI elements;\n2. The method of claim 1, comprising:\nobtaining a set of text documents;\nfor each respective document in the set of text documents:\ndetermining whether a pre-existing text summary in the text document is present in the respective document based on a header or whitespace separation between the pre-existing text summary and other text in the respective document;\nadding a respective sequence of n-grams of the respective pre-existing text summary to a set of training summaries; and\nperform a set of supervised learning operations to train a summarization model that represents n-grams of the set of text documents as vectors in an embedding space in which pairwise distances between vectors is indicative of semantic similarity of pairs of n-grams represented by respective pairs of vectors, wherein generating a text summary comprises using the summarization model.\n3. The method of claim 1, further comprising:\nobtaining a corpus of natural-language text documents, wherein the corpus of natural-language text documents comprises a set of training documents and a set of training summaries associated with the set of training documents; and\nconfiguring a first summarization model by performing supervised learning with the summarization model based on the set of training documents and a set of training summaries.\n4. The method of claim 3, wherein the summarization model is a first summarization model of a plurality of summarization models, the method further comprises training a plurality of summarization models corresponding to the different domains of knowledge by using, for each respective summarization model of the plurality of summarization models, a respective set of training documents labeled with a respective domain of knowledge as training inputs.\n5. The method of claim 1, wherein the summary of a document that includes an n-gram that is not present in the document.\n6. The method of claim 1, wherein the UI visually indicates the set of related n-grams by changing a text color, text size, or text background color with respect to other n-grams of the text summary.\n7. The method of claim 1, further comprising steps for generating the text summary.\n8. A tangible, non-transitory, machine-readable medium storing instructions that, when executed by one or more processors, effectuate operations comprising:\nobtaining, with a computer system, a set of ontology graphs comprising a first ontology graph associated with a first domain category value and a second ontology graph associated with a second domain category value, wherein vertices of the first ontology graph are connected to vertices of the second ontology graph via a set of graph edges;\nobtaining, with the computer system, a natural-language text document in response to a query made by a user associated with a set of context parameters;\nobtaining, with the computer system, a set of domain category values identified using the set of context parameters, wherein the set of domain category values comprises the second domain category value;\ndetermining, with the computer system, a first set of embedding vectors in an embedding space based on a first set of n-grams of the natural-language text document, the determining the first set of embedding vectors comprising using a first set of neural network layers to generate the first set of embedding vectors;\ndetermining a set of hidden state values of the first set of neural network layers, the set of hidden state values representing intermediate outputs that are computed by a first layer of the first set of neural network layers and provided to a second layer of the first set of neural network layers as inputs;\nupdate the set of hidden state values by performing a set of SoftMax operations, wherein performing the set of SoftMax operations comprises determining a ratio of exponential values computed from the set of hidden state values provided by the second layer;\nobtaining an attention vector;\ndetermining a weighted sum of the set of hidden state values by multiplying elements of the set of hidden state values by the attention vector;\nretrieving, with the computer system, a first set of vertices of the first ontology graph based on the first set of embedding vectors, wherein each respective vertex of the first set of vertices is identified by a respective embedding vector of the first set of vertices;\nselecting, with the computer system, a second set of vertices of the second ontology graph, wherein the second set of vertices is adjacent to the first set of vertices via the set of graph edges associating the first ontology graph and the second ontology graph;\ngenerating, with the computer system using the updated set of hidden state values, a sequence of n-grams based on a second set of embedding vectors identified by the second set of vertices; and\npresenting, with the computer system, a user interface (UI) comprising a summary to a visual display.\n9. The medium of claim 8, wherein generating the sequence of n-grams comprises:\ngenerating an initial sequence of n-grams based on the first set of embedding vectors;\nselecting a subset of n-grams of the initial sequence of n-grams based on the first ontology graph and the second ontology graph, wherein for each respective n-gram of the subset of n-grams:\nthe respective n-gram is mapped to a respective first vertex in the first ontology graph that is adjacent to a respective second vertex of the second ontology graph; and\nreplacing the respective n-gram of the subset of n-grams of the initial sequence of n-grams with a respective second n-gram of the second ontology graph to generate the sequence of n-grams, wherein the respective second vertex maps to the respective second n-gram.\n10. The medium of claim 8, wherein generating the sequence of n-grams comprises:\ngenerating an initial sequence of n-grams based on the first set of embedding vectors;\nfor each respective n-gram of a subset of n-grams, wherein the respective n-gram is mapped to a respective first vertex of the first ontology graph that is adjacent to a respective second vertex of the second ontology graph:\ngenerating a probability value using a random or pseudorandom operation;\ndetermining whether the probability value satisfies an n-gram generation threshold; and\nin response to a determination that the probability value satisfies an n-gram generation threshold, replace the respective n-gram with a second n-gram mapped to the respective second vertex.\n11. The medium of claim 8, the operations further comprising:\ndetermining a plurality of attention distributions using a set of neural network layers, wherein elements of a respective attention distribution of the plurality of attention distributions map to n-grams of a sequence of the natural-language text document;\ndetermining a sum of the plurality of attention distributions; and\nselecting the set of n-grams to replace with n-grams of the second ontology graph based on the sum of the plurality of attention distributions.\n12. The medium of claim 8, further comprising:\nretrieving a set of neural network parameters based on the second domain category value, wherein the set of neural network parameters comprises a plurality of weights of neurons of the neural network; and\ngenerating the sequence of n-grams based on the second set of embedding vectors of the second set of vertices comprising using generating the sequence of n-grams using a neural network configured with the set of neural network parameters.\n13. The medium of claim 8, the operations further comprising:\nsegmenting the natural-language text document is a sequence of text sections;\ndetermining a respective topic score for each respective text section using a probabilistic model, wherein the respective topic score indicates a probability that the respective text section is associated with a topic; and\nselecting a text section based on a corresponding topic score of the text section satisfying a relevance threshold, wherein generating the sequence of n-grams comprises generating the sequence of n-grams based on the text section.\n14. The medium of claim 8, wherein presenting the UI comprises updating embedded tags surrounding an n-gram in a web document used to render the UI, wherein:\nthe n-gram is mapped to a vertex of the second set of vertices;\nthe embedded tags cause the UI to display the n-gram of the summary as an interactive UI element; and\nan interaction with the interactive UI element displays an n-gram mapped to a vertex of the first ontology graph.\n15. The medium of claim 8, wherein the query is a first query, the operations further comprising generating a second query based on the second set of embedding vectors; and obtaining a second document based on the second query.\n16. The medium of claim 8, wherein the summary is a first text summary, the operations further comprising:\ngenerating a second text summary based on the first set of n-grams, wherein the second text summary does not comprise n-grams mapping to the second set of vertices; and\nwherein presenting the UI comprises presenting a UI element that, when interacted with, causes the first text summary and the second text summary to be concurrently display.\n17. The medium of claim 8, wherein the natural-language text document is a first natural-language text document, the operations further comprising:\nobtaining a second natural-language text document in response to the query made by a user;\ndetermining a third set of embedding vectors in an embedding space based on a third set of n-grams of the second natural-language text document;\nretrieving a third set of vertices of the first ontology graph based on the third set of embedding vectors, wherein each respective vertex of the third set of vertices is identified by a respective embedding vector of the first set of vertices;\nselecting a second set of vertices of the second ontology graph, wherein the second set of vertices is adjacent to the first set of vertices via a set of graph edges associating the first ontology graph and the second ontology graph;\ngenerating a sequence of n-grams of a summary based on a second set of embedding vectors of the second set of vertices; and\npresenting a user interface comprising the summary to a visual display.\n18. A system comprising:\none or more memory devices storing instructions; and\none or more processors configured to execute the instructions that, when executed, cause operations comprising:\nobtaining, with a computer system, a set of ontology graphs comprising a first ontology graph associated with a first domain category value and a second ontology graph associated with a second domain category value, wherein vertices of the first ontology graph are connected to vertices of the second ontology graph via a set of graph edges;\nobtaining, with the computer system, a natural-language text document in response to a query made by a user associated with a set of context parameters;\nobtaining, with the computer system, a set of domain category values identified using the set of context parameters, wherein the set of domain category values comprises the second domain category value;\ndetermining a first set of embedding vectors in an embedding space based on a first set of n-grams of the natural-language text document, the determining the first set of embedding vectors comprising using a first set of neural network layers to generate the first set of embedding vectors;\ndetermining a set of hidden state values of the first set of neural network layers, the set of hidden state values representing intermediate outputs that are computed by a first layer of the first set of neural network layers and provided to a second layer of the first set of neural network layers as inputs;\nupdate the set of hidden state values by performing a set of SoftMax operations, wherein performing the set of SoftMax operations comprises determining a ratio of exponential values computed from the set of hidden state values provided by the second layer;\nobtaining an attention vector;\ndetermining a weighted sum of the set of hidden state values by multiplying elements of the set of hidden state values by the attention vector;\nretrieving a set of associations based on the first domain category value and the second domain category value;\nobtaining a second set of embedding vectors using the set of associations based on the first set of embedding vectors, wherein each respective first embedding vector of the first set of embedding vectors are mapped to a respective second embedding vector of the second set of embedding vectors;\ngenerating, using the updated set of hidden state values, a sequence of n-grams of a summary based on the second set of embedding vectors using an abstractive text summarization model; and\npresenting a user interface comprising the sequence of n-grams to a visual display.\n19. The system of claim 18, wherein:\nretrieving the set of associations comprises retrieving a self-balancing search tree based on the first domain category value and the second domain category value; and\nobtaining the second set of embedding vectors comprises starting at the root of the self-balancing search tree and recursively traversing nodes of the self-balancing search tree using a key based on a first embedding vector of the first set of embedding vectors to retrieve a second embedding vector of the second set of embedding vectors.\n20. The system of claim 18, wherein:\nretrieving the set of associations comprises retrieving a prefix trie based on the first domain category value and the second domain category value; and\nobtaining the second set of embedding vectors comprises traversing nodes of the prefix trie based on the a first embedding vector of the first set of embedding vectors to obtain a second embedding vector of the second set of embedding vectors.",
    "status": "Active",
    "citations_own": [
        "US20020078090A1",
        "US20070162409A1",
        "US20080133509A1",
        "US20080172353A1",
        "US20090012842A1",
        "KR20090033150A",
        "US20110029571A1",
        "US20110040766A1",
        "KR20110078560A",
        "US20110213796A1",
        "US20120278336A1",
        "US20120284261A1",
        "US20140195518A1",
        "KR20140127113A",
        "US20150242387A1",
        "US20150339290A1",
        "US20150347375A1",
        "US20160132487A1",
        "US20160196335A1",
        "KR101647087B1",
        "US20160313868A1",
        "US20170083569A1",
        "US9715495B1",
        "US20170278416A1",
        "US20170337268A1",
        "US20180373844A1",
        "US20190005049A1",
        "WO2019063365A1",
        "US20190163817A1",
        "KR20190059084A",
        "US10402435B2",
        "KR20190107033A",
        "US20190303498A1",
        "US10558759B1",
        "US20200099530A1",
        "US10699062B2",
        "US20200327432A1",
        "US20200349179A1",
        "US20210019339A1",
        "US10929452B2",
        "US20210089860A1",
        "US20210200954A1",
        "US20210263898A1",
        "US11151982B2",
        "US11170158B2",
        "US11494564B2",
        "US11545156B2",
        "US11562144B2"
    ],
    "citations_ftf": [
        "WO1997008604A2",
        "US8346534B2",
        "US8572126B2",
        "US10303999B2",
        "DE112012005177T5",
        "US9372924B2",
        "US9442917B2",
        "US9715488B2",
        "US9665564B2",
        "US10303798B2",
        "US9348920B1",
        "US10108603B2",
        "US10621166B2",
        "CN110766489A",
        "US10789430B2",
        "US11275796B2"
    ],
    "citedby_own": [
        "US20210294970A1"
    ],
    "citedby_ftf": [
        "US10021051B2",
        "US11416129B2",
        "US11243955B2",
        "US11423234B2",
        "JP6975682B2",
        "US20220020454A1",
        "US11748613B2",
        "US11551089B2",
        "US20210319068A1",
        "US11650986B1",
        "US20210349887A1",
        "US20210358601A1",
        "US11734580B2",
        "CN113742288A",
        "US11574128B2",
        "US20220027578A1",
        "US11461539B2",
        "US20220066914A1",
        "US20220075877A1",
        "US11475010B2",
        "US11641665B2",
        "US20220100884A1",
        "US20220100800A1",
        "US20220138185A1",
        "US20220156299A1",
        "CN112102937B",
        "WO2022120585A1",
        "US11755636B2",
        "US20220254505A1",
        "US11756575B2",
        "US20220261406A1",
        "US20220292262A1",
        "US20220292121A1",
        "US20220309106A1",
        "US11521639B1",
        "US20220318522A1",
        "US11675965B2",
        "CN112800287B",
        "US20220374459A1",
        "US11709812B2",
        "US20220374428A1",
        "US20220382902A1",
        "US11630958B2",
        "US20220391576A1",
        "US11443114B1",
        "US20230029420A1",
        "US11763803B1",
        "US11580150B1",
        "US20230052123A1",
        "US11704312B2",
        "US20230066906A1",
        "US11698934B2",
        "US20230117224A1",
        "US20230141853A1",
        "US20230143291A1",
        "US20230169527A1",
        "US11468133B1",
        "US20230196016A1",
        "US11368423B1",
        "US20230259539A1",
        "US11709989B1",
        "CN114663896B",
        "US11546323B1",
        "GR1010503B",
        "CN116186211B",
        "US11769017B1",
        "CN115964471B",
        "US11765207B1",
        "US11763235B1"
    ]
}