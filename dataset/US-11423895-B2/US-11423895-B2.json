{
    "patent_id": "US-11423895-B2",
    "title": "Method and system for providing an interactive interface ",
    "assignee": "Samsung Electronics Co., Ltd.",
    "publication_date": "2022-08-23",
    "patent_link": "https://patents.google.com/patent/US11423895B2/en",
    "inventors": [
        "Inchul Hwang",
        "Hyeonmok KO",
        "Munjo KIM",
        "Hyungtak CHOI"
    ],
    "classifications": [
        "G06F3/16",
        "G10L15/22",
        "G06F3/01",
        "G06F3/011",
        "G06F3/14",
        "G06F3/167",
        "G06F40/30",
        "G06F40/35",
        "G06N3/006",
        "G06N3/08",
        "G06N5/041",
        "G10L15/063",
        "G10L25/63",
        "G10L15/16",
        "G10L2015/223",
        "G10L2015/225"
    ],
    "abstract": "Provided are a method and device for providing an event-emotion-based interactive interface by using an artificial intelligence (AI) system. The method includes identifying an emotional state of a user for at least one event by analyzing a response to a query, learning emotion information of the user for the at least one event, based on the emotional state of the user, determining an interaction type for the at least one event, based on the emotion information of the user, and providing notification information for the at least one event, based on the interaction type.",
    "claims": "\n1. A method, performed by an electronic device, of providing a virtual assistant interface, the method comprising:\nquerying a user about a schedule by using the virtual assistant interface;\nreceiving a response to the query from the user, the response comprising information about at least one event related to the schedule, wherein the receiving of the response to the query comprises receiving voice data of an utterance of the user as the response to the query;\nidentifying, from the voice data, the at least one event related to the schedule and an emotional state of the user for the at least one event related to the schedule by analyzing the response to the query;\nlearning emotion information of the user for the at least one event related to the schedule, based on the emotional state of the user for the at least one event related to the schedule;\ndetermining an interaction type for the at least one event related to the schedule, based on the emotion information of the user for the at least one event related to the schedule; and\nproviding notification information for the at least one event related to the schedule through the virtual assistant interface, based on the interaction type.\n2. The method of claim 1, wherein the receiving of the response to the query comprises:\nextracting information related to the at least one event from the voice data; and\nregistering the at least one event as a new event in the electronic device by using the extracted information.\n3. The method of claim 1, wherein the learning of the emotion information of the user comprises:\nobtaining default emotion information related to the at least one event from information for mapping events to emotion information; and\nlearning the emotion information of the user for the at least one event by modifying the default emotion information, based on the emotional state of the user for the at least one event related to the schedule.\n4. The method of claim 1, wherein the learning of the emotion information of the user comprises:\ndetermining a progress stage of the at least one event based on a relationship between a current time and a scheduled time of the at least one event; and\nrefining the emotion information of the user for the at least one event, based on the progress stage of the at least one event.\n5. The method of claim 1, wherein the learning of the emotion information of the user comprises:\nobtaining feedback information on the at least one event from the user after the at least one event is finished; and\nrefining the emotion information of the user for the at least one event, based on the obtained feedback information.\n6. The method of claim 1, wherein the learning of the emotion information of the user comprises learning the emotion information of the user by using information related to at least one of a person related to the at least one event, a scheduled time of the at least one event, or a place related to the at least one event.\n7. The method of claim 1, wherein the determining of the interaction type comprises determining a tone for providing the notification information for the at least one event, based on the emotion information of the user.\n8. The method of claim 1, wherein the providing of the notification information comprises:\nselecting a color corresponding to the emotion information of the user; and\ndisplaying the notification information for the at least one event by using the selected color.\n9. The method of claim 1, further comprising providing a response to an utterance of the user related to the at least one event, based on the determined interaction type.\n10. The method of claim 1, wherein the providing of the notification information for the at least one event comprises:\ndetermining a notification providing method related to the at least one event, based on a situation of the user; and\nproviding the notification information for the at least one event, based on the determined notification providing method.\n11. The method of claim 1, further comprising providing a diary interface comprising the emotion information of the user related to the at least one event.\n12. An electronic device comprising:\nan output interface configured to provide a virtual assistant interface; and\nat least one processor configured to:\nquery a user about a schedule by using the virtual assistant interface;\nreceive a response to the query from the user, the response comprising information about at least one event related to the schedule, wherein the receiving of the response to the query comprises receiving voice data of an utterance of the user as the response to the query;\nidentify, from the voice data, the at least one event related to the schedule and an emotional state of the user for the at least one event related to the schedule by analyzing the response to the query;\nlearn emotion information of the user for the at least one event related to the schedule, based on the emotional state of the user for the at least one event related to the schedule;\ndetermine an interaction type for the at least one event related to the schedule, based on the emotion information of the user for the at least one event related to the schedule; and\nprovide notification information for the at least one event related to the schedule through the virtual assistant interface, based on the interaction type.\n13. The electronic device of claim 12, wherein the at least one processor is further configured to:\nextract information related to the at least one event from the voice data; and\nregister the at least one event as a new event in the electronic device, using the extracted information.\n14. The electronic device of claim 12, wherein the at least one processor is further configured to:\nobtain default emotion information related to the at least one event from information for mapping events to emotion information; and\nlearn the emotion information of the user for the at least one event by modifying the default emotion information, based on the emotional state of the user for the at least one event related to the schedule.\n15. A non-transitory computer-readable recording medium having recorded thereon a program which, when executed, causes an electronic device to perform operations comprising:\nquerying a user about a schedule by using a virtual assistant interface;\nreceiving a response to the query from the user, the response comprising information about at least one event related to the schedule; wherein the receiving of the response to the query comprises receiving voice data of an utterance of the user as the response to the query,\nidentifying, from the voice data, the at least one event related to the schedule and an emotional state of the user for the at least one event related to the schedule by analyzing the response to the query\nlearning emotion information of the user for the at least one event related to the schedule, based on the emotional state of the user for the at least one event related to the schedule;\ndetermining an interaction type for the at least one event related to the schedule, based on the emotion information of the user for the at least one event related to the schedule; and\nproviding notification information for the at least one event related to the schedule through the virtual assistant interface, based on the interaction type.\n16. The method of claim 1, wherein the emotional information comprises information of an emotional state comprising two or more emotions.",
    "status": "Active",
    "citations_own": [
        "JPH0981632A",
        "US5918222A",
        "JP2005062240A",
        "US20080096533A1",
        "AU2013231030A1",
        "KR20140126485A",
        "BRPI1011670A2",
        "US9336268B1",
        "WO2016089929A1",
        "US20160180722A1",
        "CN105931638A",
        "DE202017105815U1",
        "CN108039988A",
        "US20180150739A1",
        "US20180174020A1",
        "US20180322403A1",
        "US20190012591A1",
        "US20200007380A1",
        "US20210125610A1"
    ],
    "citations_ftf": [],
    "citedby_own": [
        "US20210304787A1"
    ],
    "citedby_ftf": [
        "WO2019200584A1",
        "US11734754B1",
        "JP7248615B2",
        "KR102256383B1",
        "US20220139562A1",
        "US11283751B1",
        "KR20220095973A",
        "WO2023038559A1",
        "CN116521038A",
        "US20230343349A1",
        "KR102493097B1"
    ]
}