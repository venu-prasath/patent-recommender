{
    "patent_id": "US-11606379-B1",
    "title": "Identifying threat indicators by processing multiple anomalies ",
    "assignee": "Splunk Inc.",
    "publication_date": "2023-03-14",
    "patent_link": "https://patents.google.com/patent/US11606379B1/en",
    "inventors": [
        "Robert Winslow Pratt",
        "Ravi Prasad Bulusu"
    ],
    "classifications": [
        "H04L63/1425",
        "G06F21/552",
        "G06F21/554",
        "G06N20/00",
        "H04L63/1416",
        "H04L63/1433",
        "H04L63/20",
        "G06N5/045",
        "H04L2463/121"
    ],
    "abstract": "Techniques are described for processing anomalies detected using user-specified rules with anomalies detected using machine-learning based behavioral analysis models to identify threat indicators and security threats to a computer network. In an embodiment, anomalies are detected based on processing event data at a network security system that used rules-based anomaly detection. These rules-based detected anomalies are acquired by a network security system that uses machine-learning based anomaly detection. The rules-based detected anomalies are processed along with machine learning detected anomalies to detect threat indicators or security threats to the computer network. The threat indicators and security threats are output as alerts to the network security system that used rules-based anomaly detection.",
    "claims": "\n1. A method comprising:\nreceiving first anomaly data indicative of a first anomaly detected in an information technology (IT) environment, the first anomaly having been detected by use of an anomaly detection rule;\nreceiving event data indicative of an event in the IT environment;\napplying the first anomaly data and the received event data, in real time, to a machine learning anomaly detection model to generate second anomaly data indicative of a second anomaly detected in the IT environment;\ninputting the first anomaly data and the second anomaly data into a machine learning threat indicator model; and\nprocessing the first anomaly data and the second anomaly data using the machine learning threat indicator model to identify a threat indicator associated with a potential security threat to the IT environment.\n2. The method of claim 1, wherein the first anomaly or second anomaly are detected by processing events, wherein each of the events includes a timestamped portion of raw machine data, the timestamped portion of raw machine data indicative of activity in the IT environment.\n3. The method of claim 1, further comprising:\nreceiving third anomaly data indicative of a third anomaly detected in the IT environment, the third anomaly data having been detected by use of a machine learning anomaly detection model; and\nprocessing the first anomaly data, the second anomaly data, and the third anomaly data using the machine learning threat indicator model to identify the threat indicator.\n4. The method of claim 1, wherein the first anomaly data is received from a first network security system that uses rule-based anomaly detection, and wherein the method further comprises:\ngenerating threat indicator data indicative of the identified threat indicator; and\noutputting the threat indicator data to the first network security system.\n5. The method of claim 1, wherein the first anomaly data is received from a first network security system that uses rule-based anomaly detection, and wherein the method further comprises:\ncausing display of information associated with the threat indicator via a graphical user interface of the first network security system.\n6. The method of claim 1, wherein the first anomaly data is received from a first network security system that uses rule-based anomaly detection, and wherein the method further comprises:\nreceiving, from a second network security system, third anomaly data indicative of a third anomaly detected in the IT environment, the third anomaly data having been detected by use of a machine learning anomaly detection model;\nprocessing the first anomaly data, the second anomaly data, and the third anomaly data using the machine learning threat indicator model to identify the threat indicator;\ncausing display of first information associated with the first anomaly via a first graphical user interface of the second network security system; and\ncausing display of second information associated with the second anomaly via a second graphical user interface of the first network security system.\n7. The method of claim 1, further comprising:\nreceiving fourth anomaly data indicative of a fourth anomaly detected in the IT environment, the fourth anomaly data having been detected by use of the anomaly detection rule; and\nprocessing the first anomaly data, the second anomaly data, and the fourth anomaly data using the machine learning threat indicator model to identify the threat indicator.\n8. The method of claim 1,\nwherein the first anomaly was detected by processing, using the anomaly detection rule, a first set of events associated with activity in the IT environment;\nwherein the second anomaly was detected by processing, using the machine-learning anomaly detection model, a second set of events associated with activity in the IT environment; and\nwherein the first set of events is different from the second set of events.\n9. The method of claim 1, further comprising:\ncausing display, via a graphical user interface of a network security system, of information associated with any of the first anomaly, the second anomaly, or the threat indicator.\n10. The method of claim 1, further comprising:\ncausing display, via a graphical user interface of a network security system, of information associated with the threat indicator;\nreceiving, via the graphical user interface, a request for raw machine data related to the threat indicator; and\nsearching, in response to receiving the request, a plurality of events associated with the first anomaly and second anomaly for particular events related to the threat indicator; and\ncausing display, via the graphical user interface, of raw machine data included in the particular events.\n11. The method of claim 1, further comprising:\ncausing display, via a graphical user interface of a network security system, of an option for a user to define the anomaly detection rule.\n12. The method of claim 1, further comprising:\nbefore processing the first anomaly data and the second anomaly data using the machine-learning threat indicator model:\ndetermining, based on the first anomaly data, that the first anomaly is associated with a first category of anomalous activity;\ndetermining, based on the second anomaly data, that the second anomaly is associated with a second category of anomalous activity; and\ndetermining that the first category of anomalous activity corresponds to the second category of anomalous activity.\n13. The method of claim 1, further comprising:\ndetermining that the first anomaly corresponds to the second anomaly;\nwherein the first anomaly data and second anomaly data are processed using the machine-learning threat indicator model in response to determining that the first anomaly corresponds to the second anomaly.\n14. The method of claim 1, wherein the machine-learning threat indicator model includes:\nmodel processing logic defining a process for assigning a threat indicator score to the processed first anomaly data and second anomaly data; and\na model state defining a set of parameters for applying the model processing logic;\nwherein identifying the threat indicator includes:\nassigning the threat indicator score based on the processing of the first anomaly data with the second anomaly data using the machine-learning threat indicator model; and\nwherein the threat indicator is identified if the threat indicator score satisfies a specified scoring criterion.\n15. The method of claim 1, wherein processing the first anomaly data and the second anomaly data includes:\naggregating the first anomaly data and the second anomaly data;\ncorrelating the first anomaly data and the second anomaly data; or\nenhancing the first anomaly data and the second anomaly.\n16. The method of claim 1, wherein identifying the threat indicator includes:\ndetermining a measure of anomalies associated with a particular entity in the IT environment over a time period, the particular entity including any of a user, a device, or an application;\nwherein the threat indicator is identified if the measure of anomalies associated with the particular entity satisfies a specified criterion.\n17. The method of claim 1, wherein identifying the threat indicator includes:\ndetermining a number of entities in the IT environment associated with a particular category of anomaly over a time period;\nwherein the threat indicator is identified if the number of entities associated with the particular category of anomaly satisfies a specified criterion.\n18. The method of claim 1, further comprising:\noutputting the threat indicator, in real-time, to an administrator associated with the IT environment.\n19. A computer system comprising:\nprocessor; and\na storage device having instructions stored thereon which, when executed by the processor, cause the computer system to:\nreceive first anomaly data indicative of a first anomaly detected in an information technology (IT) environment, the first anomaly having been detected by use of an anomaly detection rule;\nreceive event data indicative of an event in the IT environment;\napply the first anomaly data and the received event data, in real time, to a machine learning anomaly detection model to generate second anomaly data indicative of a second anomaly detected in the IT environment;\ninput the first anomaly data and the second anomaly data into a machine-learning threat indicator model; and\nprocessing the first anomaly data and the second anomaly data using the machine-learning threat indicator model to identify a threat indicator associated with a potential security threat to the IT environment.\n20. A non-transitory computer readable medium containing instructions, execution of which in a computer system causes the computer system to:\nreceive first anomaly data indicative of a first anomaly detected in an information technology (IT) environment, the first anomaly having been detected by use of an anomaly detection rule;\nreceive event data indicative of an event in the IT environment;\napply the first anomaly data and the received event data, in real time, to a machine learning anomaly detection model to generate second anomaly data indicative of a second anomaly detected in the IT environment;\ninput the first anomaly data and the second anomaly data into a machine-learning threat indicator model; and\nprocessing the first anomaly data and the second anomaly data using the machine-learning threat indicator model to identify a threat indicator associated with a potential security threat to the IT environment.",
    "status": "Active",
    "citations_own": [
        "US20100017870A1",
        "US20100174671A1",
        "US20100223213A1",
        "US20100257217A1",
        "US20120240185A1",
        "US20120290510A1",
        "US20120304007A1",
        "US20140101762A1",
        "US20150310195A1",
        "US20160043827A1",
        "US20160182559A1",
        "US20160226895A1",
        "US20160294773A1",
        "US9516053B1",
        "US20170118240A1",
        "US20180005134A1",
        "US20180013776A1",
        "US20180027006A1",
        "US20180083995A1",
        "US10673880B1"
    ],
    "citations_ftf": [],
    "citedby_own": [
        "US20220029966A1"
    ],
    "citedby_ftf": [
        "US10673880B1",
        "US10607004B2",
        "US11057344B2",
        "US10999296B2",
        "US10984099B2",
        "US20190116193A1",
        "US11271960B2",
        "US10931696B2",
        "US11689557B2",
        "US20190272474A1",
        "US20190317728A1",
        "US10992492B2",
        "US11005678B2",
        "US11436527B2",
        "KR102050230B1",
        "US11157834B2",
        "US11444957B2",
        "US11722470B2",
        "CN110896386B",
        "US20210377289A1",
        "US11269995B2",
        "US11032304B2",
        "US11449712B2",
        "US11700269B2",
        "US20200204572A1",
        "US11050793B2",
        "US11095683B1",
        "US11146581B2",
        "US10990573B2",
        "US11212304B2",
        "US11063907B2",
        "US11308209B2",
        "US11038910B1",
        "US11405413B2",
        "US11425105B2",
        "US20200259847A1",
        "US11429714B2",
        "US11190534B1",
        "US11349857B1",
        "RU2747474C2",
        "US11558408B2",
        "US20200374284A1",
        "US11310250B2",
        "US11368470B2",
        "US11330001B2",
        "US11736498B1",
        "US11770391B1",
        "GB2587355B",
        "US11489860B2",
        "US11165815B2",
        "US11711382B2",
        "JP7241281B2",
        "US11418526B2",
        "WO2021155471A1",
        "US11470042B2",
        "US11477234B2",
        "EP4111343A1",
        "US11790060B2",
        "WO2021183939A1",
        "US11164438B2",
        "US11645397B2",
        "US11616790B2",
        "US11711379B2",
        "US11563756B2",
        "US11470108B2",
        "US20210342901A1",
        "US11663500B2",
        "US20210373914A1",
        "US11620575B2",
        "EP4172878A1",
        "US11588836B2",
        "CN111782477B",
        "US11556636B2",
        "CN112054989B",
        "US11652833B2",
        "US11381604B2",
        "US11425151B2",
        "CN111935137B",
        "US11768933B2",
        "WO2022070278A1",
        "US11336507B2",
        "US20220124110A1",
        "US11528242B2",
        "CN112804336B",
        "US11687648B2",
        "US20220217156A1",
        "WO2022150653A1",
        "CN112769840B",
        "US20220327108A1",
        "CN113114690B",
        "US20220345473A1",
        "US20220342860A1",
        "US11640387B2",
        "US20220417263A1",
        "CN113448555A",
        "CN113806616B",
        "CN113542311B",
        "US11537502B1",
        "CN114326676B",
        "CN114553473A",
        "WO2023154315A1",
        "WO2023184303A1",
        "CN114710354B",
        "CN114844691B",
        "CN115168917B",
        "CN115348109B",
        "CN115695039B",
        "CN116319021B"
    ]
}