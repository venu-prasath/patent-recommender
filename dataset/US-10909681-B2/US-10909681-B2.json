{
    "patent_id": "US-10909681-B2",
    "title": "Automated selection of an optimal image from a series of images ",
    "assignee": "The Regents Of The University Of California",
    "publication_date": "2021-02-02",
    "patent_link": "https://patents.google.com/patent/US10909681B2/en",
    "inventors": [
        "Albert Hsiao",
        "Naeim Bahrami",
        "Tara Retson"
    ],
    "classifications": [
        "G06N20/20",
        "G06F18/241",
        "G06K9/6268",
        "G06N3/044",
        "G06N3/045",
        "G06N3/084",
        "G06T7/0016",
        "G06V10/764",
        "G06V10/82",
        "G06N3/048",
        "G06T2207/10088",
        "G06T2207/20021",
        "G06T2207/20084",
        "G06T2207/30168",
        "G06V2201/031"
    ],
    "abstract": "A method for identification of an optimal image within a sequence of image frames includes inputting the sequence of images into a computer processor configured for executing a plurality of neural networks and applying a sliding window to the image sequence to identify a plurality of image frame windows. The image frame windows are processed using a first neural network trained to classify the image frames according to identified spatial features. The image frame windows are also processed using a second neural network trained to classify the image frames according to identified serial features. The results of each classification are concatenated to separate each of the image frame windows into one of two classes, one class containing the optimal image. An output is generated to display image frame windows classification as including the optimal image.",
    "claims": "\n1. A method for identification of an optimal image within a sequence of image frames, comprising:\ninputting the sequence of image frames into a computer processor configured for executing a plurality of neural networks;\napplying a sliding window to the sequence of image frames to identify a plurality of image frame windows within the sequence;\nprocessing the plurality of image frame windows using a first neural network of the plurality, the first neural network trained for identifying spatial features within the image frames for first classifying the image frame window into spatial classes according to the identified spatial features;\nprocessing the plurality of image frame windows using a second neural network of the plurality, the second neural network trained for identifying serial features among the image frames for second classifying the image frame windows into series classes according to the identified serial features;\nconcatenating the results of the first classifying and second classifying to separate each of the plurality of image frame windows into one of two classes, wherein image frame windows that include the optimal image are classified into one of the classes; and\ngenerating an output displaying image frame windows that include the optimal image.\n2. The method of claim 1, wherein the sequence of image frames is an MRI time sequence and the serial features comprise time.\n3. The method of claim 2, wherein the MRI time sequence comprises a T1 mapping sequence.\n4. The method of claim 1, wherein the sequence of image frames is a stack of MRI slices and the serial features comprise location within the stack.\n5. The method of claim 1, wherein the first neural network is a convolutional neural network (CNN).\n6. The method of claim 5, wherein the CNN is VGG19.\n7. The method of claim 1, wherein the second neural network is a recurrent neural network (RNN).\n8. The method of claim 7, wherein the RNN is formed from layers comprising long short-term memory (LSTM) models.\n9. The method of claim 8, wherein the LSTM models comprise a three serial bidirectional LSTM.\n10. A method for identification of an optimal image within a sequence of image frames, comprising:\ninputting the sequence of image frames into a computer processor configured for executing a plurality of neural networks;\napplying a sliding window to the sequence of image frames to identify a plurality of image frame windows within the sequence;\nprocessing the plurality of image frame windows using a convolutional neural network (CNN), the CNN trained for identifying spatial features within the image frames for first classifying the image frame window into spatial classes according to the identified spatial features;\nprocessing the plurality of image frame windows using a recurrent neural network (RNN), the RNN trained for identifying serial features among the image frames for second classifying the image frame windows into series classes according to the identified serial features;\nconcatenating the outputs of the CNN and the RNN to separate each of the plurality of image frame windows into one of two classes, wherein image frame windows that include the optimal image are classified into one of the classes; and\ngenerating an output displaying image frame windows that include the optimal image.\n11. The method of claim 10, wherein the sequence of image frames is an MRI time sequence and the serial features comprise time.\n12. The method of claim 11, wherein the MRI time sequence comprises a T1 mapping sequence.\n13. The method of claim 10, wherein the sequence of image frames is a stack of MRI slices and the serial features comprise location within the stack.\n14. The method of claim 10, wherein the CNN is VGG19.\n15. The method of claim 10, wherein the RNN is formed from layers comprising long short-term memory (LSTM) models.\n16. The method of claim 15, wherein the LSTM models comprise a three serial bidirectional LSTM.\n17. A system for identifying an optimal image within a sequence of image frames, the system comprising:\nat least one computer processor configured to acquire the sequence of image frames and apply a sliding window to identify a plurality of image frame windows within the sequence;\na spatial classification module configured for identifying spatial features within the image frames for first classifying the image frame windows into spatial classes according to the identified spatial features:\na temporal/sequential classification module configured for identifying serial features among the image frames for second classifying the image frame windows into series classes according to the identified serial features;\na concatenator module configured for combining the results of the first classifying and second classifying to separate each of the plurality of image frame windows into one of two classes, wherein image frame windows that include the optimal image are classified into one of the classes; and\na display module configured for generating an output display of the image frame windows that include the optimal image.\n18. The system of claim 17, wherein the sequence of image frames is an MRI time sequence and the serial features comprise time.\n19. The system of claim 18, wherein the MRI time sequence comprises a T1 mapping sequence.\n20. The system of claim 17, wherein the sequence of image frames is a stack of MRI slices and the serial features comprise location within the stack.\n21. The system of claim 17, wherein the spatial classification module and the temporal/sequential classification module are neural networks.\n22. The system of claim 21, wherein the spatial classification module is a convolutional neural network (CNN).\n23. The system of claim 21, wherein temporal/sequential classification module is a recurrent neural network (RNN).\n24. The system of claim 23, wherein the RNN is formed from layers comprising long short-term memory (LSTM) models.\n25. The system of claim 24, wherein the LSTM models comprise a three serial bidirectional LSTM.",
    "status": "Active",
    "citations_own": [
        "US20120078084A1",
        "US20140112564A1",
        "US20160338613A1",
        "US20180256042A1",
        "US20180285699A1",
        "US20180333104A1",
        "US10628943B2"
    ],
    "citations_ftf": [],
    "citedby_own": [
        "CN113205509A",
        "US20220375562A1"
    ],
    "citedby_ftf": [
        "US11289204B2",
        "WO2019224800A1",
        "CN110491502B",
        "US11354546B2",
        "US20200349668A1",
        "US20200411167A1",
        "CN110246137B",
        "US11232859B2",
        "US11514573B2",
        "JP2021178079A",
        "CN112150449B",
        "US11521323B2",
        "CN112259227B",
        "US11636603B2",
        "US20220207306A1",
        "CN113344773B",
        "EP4154797A1",
        "CN115830020B"
    ]
}