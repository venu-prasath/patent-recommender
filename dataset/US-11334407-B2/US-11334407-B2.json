{
    "patent_id": "US-11334407-B2",
    "title": "Abnormality detection system, abnormality detection method, abnormality detection program, and method for generating learned model ",
    "assignee": "Preferred Networks, Inc.",
    "publication_date": "2022-05-17",
    "patent_link": "https://patents.google.com/patent/US11334407B2/en",
    "inventors": [
        "Daisuke Okanohara",
        "Kenta OONO"
    ],
    "classifications": [
        "G06F11/0703",
        "G06N7/01",
        "G06F11/07",
        "G06N3/045",
        "G06N3/0454",
        "G06N3/08",
        "G06N7/00",
        "G06N7/005",
        "G06K2009/00583",
        "G06N3/04",
        "G06V20/90"
    ],
    "abstract": "A method and system that efficiently selects sensors without requiring advanced expertise or extensive experience even in a case of new machines and unknown failures. An abnormality detection system includes a storage unit for storing a latent variable model and a joint probability model, an acquisition unit for acquiring sensor data that is output by a sensor, a measurement unit for measuring the probability of the sensor data acquired by the acquisition unit based on the latent variable model and the joint probability model stored by the storage unit, a determination unit for determining whether the sensor data is normal or abnormal based on the probability of the sensor data measured by the measurement unit, and a learning unit for learning the latent variable model and the joint probability model based on the sensor data output by the sensor.",
    "claims": "\n1. A system comprising:\none or more memories; and\none or more processors configured to output anomaly information of target data inputted into the system using at least an encoder of a machine learning model,\nwherein, in the encoder of the machine learning model, a probability distribution of a latent variable of normal data is modeled based on a predetermined probability distribution.\n2. The system according to claim 1, further comprising the encoder of the machine learning model, and a decoder of the machine learning model capable of decoding latent variables generated by the encoder of the machine learning model.\n3. The system according to claim 2, wherein the encoder and the decoder of the machine learning model have been learned based on training data that is normal.\n4. The system according to claim 1, wherein the one or more processors are configured to generate a latent variable from the target data based on the encoder of the machine learning model and perform a predetermined process on the generated latent variable to output the anomaly information of the target data.\n5. The system according to claim 4, wherein the predetermined process is a decoding process of decoding the latent variable generated based on the encoder of the machine learning model, using a decoder of the machine learning model.\n6. The system according to claim 1, wherein the encoder of the machine learning model is represented by a multi-layer neural network.\n7. The system according to claim 1, wherein the target data is derived from a sensor.\n8. The system according to claim 1, wherein the anomaly information is at least one of a likelihood of the target data, an anomaly score of the target data, or information indicating whether the target data is anomaly or not.\n9. The system according to claim 1, wherein the machine learning model is a standard VAE or a derivative of the standard VAE.\n10. The system according to claim 1, wherein, in the encoder of the machine learning model, the probability distribution of the latent variable of normal data is modeled based on the predetermined probability distribution so as to correspond to the predetermined probability distribution.\n11. A system comprising:\none or more memories; and\none or more processors configured to:\ninput target data into a predetermined machine learning model for anomaly detection that encodes, by an encoder of the predetermined machine learning model, input data into a latent variable and decodes, by a decoder of the predetermined machine learning model, the latent variable, and acquire output data corresponding to the target data from the predetermined machine learning model; and\noutput anomaly information based on at least the output data corresponding to the target data acquired from the predetermined machine learning model,\nwherein the encoder of the predetermined machine learning model is configured to model a probability distribution of a latent variable of normal data based on a predetermined probability distribution.\n12. The system according to claim 11, wherein the predetermined machine learning model is trained using training data including the normal data so that the probability distribution of the latent variable of the normal data approaches to the predetermined probability distribution.\n13. The system according to claim 11, wherein the encoder and the decoder are each implemented by a multi-layer neural network.\n14. The system according to claim 13, wherein parameters of each of the multi-layer neural network that implements the encoder and the decoder respectively are adjusted by a backpropagation method based on a predetermine function that includes regularization term for the probability distribution of the latent variable.\n15. The system according to claim 14, wherein the regularization term corresponds to a Kullback-Liebler divergence from the probability distribution of the latent variable encoded from the training data including the normal data by the encoder to the predetermined probability distribution.\n16. The system according to claim 11, wherein the predetermined machine learning model is one of a standard VAE (Variational Auto-Encoder), a derivative of the standard VAE, AAE (Adversarial Auto-Encoder), or ADGM (Auxiliary Deep Generative Model).\n17. The system according to claim 11, wherein the predetermined machine learning model has been trained to model the probability distribution of the latent variant of the normal data with the predetermined probability distribution without data to be processed for the anomaly detection.\n18. The system according to claim 11, wherein the inputting and the acquiring include:\ninputting the target data into the predetermined machine learning model;\nperforming the encoding and the decoding on the target data; and\nacquiring the output data corresponding to the target data.\n19. The system according to claim 11, wherein the outputting the anomaly information outputs the anomaly information based on at least the target data in addition to the output data corresponding to the target data.\n20. The system according to claim 11, wherein the outputting the anomaly information includes a calculation process of calculating a likelihood or an anomaly score of the target data.\n21. The system according to claim 11, wherein the output data is restored data of data to be processed, and the outputting the anomaly information includes a calculation process of calculating a deviation between the target data and the restored data.\n22. The system according to claim 11, wherein the one or more processors determines whether or not the target data is anomaly based on at least the output data corresponding to the target data, and outputs the anomaly information indicating the determination.\n23. The system according to claim 11, wherein the target data and the normal data are sensor data.\n24. The system according to claim 23, wherein the target data and the normal data are preprocessed sensor data.\n25. The system according to claim 23, wherein the sensor data is image data or physical quantity data.\n26. The system according to claim 11, wherein the predetermined probability distribution is standard normal distribution.\n27. A data encoding apparatus comprising: an interface acquiring target data to be processed for anomaly detection; and an encoder of a machine learning model encoding the target data to be processed for the anomaly detection acquired by the interface into a latent variable, wherein a probability distribution of a latent variable of normal data of the encoder of the machine learning model is configured to be modeled based on a predetermined probability distribution.\n28. The data encoding apparatus according to claim 27, wherein the predetermined probability distribution is a standard normal distribution.\n29. The data encoding apparatus according to claim 27, wherein the encoder is implemented by a multi-layer neural network.\n30. A data encoding apparatus comprising:\nan interface that acquires target data to be processed for anomaly detection; and\nan encoder that encodes the target data into a latent variable and has parameters of an encoder part of a predetermined machine learning model, wherein the parameters are obtained by at least:\ninputting, by one or more computers, training data including normal data into a predetermined machine learning model that encodes input data into a latent variable and decodes the latent variable to encode the training data into a latent variable and decode the latent variable corresponding to the training data; and\nupdating the parameters, by the one or more computers, to reduce a deviation between (i) data that obtained by inputting the training data into the predetermined machine learning model and performing the encoding and the decoding and (ii) the training data, and so that a probability distribution of a latent variable of normal data approaches to a predetermined probability distribution.\n31. A method comprising:\nacquiring, by one or more computers, target data to be processed for anomaly detection; and\noutputting, by the one or more computers, anomaly information of the acquired target data using at least an encoder of a machine learning model, wherein a probability distribution of a latent variable of normal data is modeled based on a predetermined probability distribution.\n32. A non-transitory computer-readable medium storing a program which executes a method, the method comprising:\nacquiring, by one or more computers, target data to be processed for anomaly detection; and\noutputting, by the one or more computers, anomaly information of the acquired target data using at least an encoder of a machine learning model, wherein a probability distribution of a latent variable of normal data is modeled based on a predetermined probability distribution.\n33. A method for generating anomaly detection model comprising:\ninputting, by one or more computers, training data including normal data into a predetermined machine learning model that encodes input data into a latent variable and decodes the latent variable to encode the training data into a latent variable and decode the latent variable corresponding to the training data; and\nupdating parameters, by the one or more computers, to reduce a deviation between (i) data that obtained by inputting the training data into the predetermined machine learning model and performing the encoding and the decoding and (ii) the training data, and so that a probability distribution of a latent variable of normal data approaches to a predetermined probability distribution in an encoder part of the predetermined machine learning model,\nwherein the one or more computers obtain the predetermined machine learning model as the anomaly detection model into which target data to be processed for anomaly detection is input.",
    "status": "Active",
    "citations_own": [
        "US6577768B1",
        "US20040168100A1",
        "US20070005202A1",
        "JP2007326654A",
        "JP2009276334A",
        "US20100061624A1",
        "US20100274433A1",
        "JP2012098901A",
        "US20130110992A1",
        "US20130325782A1",
        "US20140201570A1",
        "US20150254555A1",
        "US20150317284A1",
        "US20160155136A1",
        "US20160274963A1",
        "US20170063399A1",
        "US10388274B1"
    ],
    "citations_ftf": [
        "US5465321A",
        "EP2369529A1",
        "US9177550B2",
        "US10867597B2",
        "CN103729444B",
        "US20150278441A1",
        "CN104113544B",
        "CN104503420B"
    ],
    "citedby_own": [
        "US20200349470A1"
    ],
    "citedby_ftf": [
        "GB201718756D0",
        "US11291532B2",
        "JP6840953B2",
        "CN110383299A",
        "WO2018173121A1",
        "US11694072B2",
        "JP6767312B2",
        "WO2019004350A1",
        "JP6853148B2",
        "EP3457333A1",
        "CN109521725A",
        "JP7325557B2",
        "WO2019073923A1",
        "JP6881207B2",
        "CN109685087B9",
        "JP2021509187A",
        "JP6835704B2",
        "JP6893483B2",
        "KR101967339B1",
        "JP7006396B2",
        "JP7106902B2",
        "EP3782087A4",
        "JP7002404B2",
        "JP7119631B2",
        "JP6767434B2",
        "JP7056406B2",
        "JP7007243B2",
        "US20210327456A1",
        "JP7106391B2",
        "JP7056465B2",
        "CN109086876B",
        "US10754310B2",
        "CN111124793A",
        "JP6867358B2",
        "EP3888103A4",
        "US11664108B2",
        "CN109635422B",
        "KR102279983B1",
        "RU2739866C2",
        "JP7268367B2",
        "JP6723401B1",
        "JP7308476B2",
        "CN109871002B",
        "US11715016B2",
        "CN109978379B",
        "JP6737487B1",
        "US11604934B2",
        "JP2020201871A",
        "JP2021015573A",
        "CN110473084A",
        "JP6935551B2",
        "US11748626B2",
        "US11586943B2",
        "US11635893B2",
        "US11586194B2",
        "US11775816B2",
        "US11498388B2",
        "US11702086B2",
        "JP7068246B2",
        "WO2021039339A1",
        "US11693562B2",
        "US11650746B2",
        "KR20210033774A",
        "JP2021071908A",
        "US11019087B1",
        "JP2021082126A",
        "CN110992354B",
        "US11224359B2",
        "US20210216876A1",
        "US11531339B2",
        "US11709625B2",
        "JP6979477B2",
        "JP7333284B2",
        "EP4163841A1",
        "JPWO2021250868A1",
        "CN111726350B",
        "CN111865947B",
        "WO2022024245A1",
        "EP3719711A3",
        "CN111654695A",
        "KR20220019560A",
        "CN111898701B",
        "KR102466716B1",
        "TWI747452B",
        "CN112036305B",
        "CN112286169B",
        "WO2022176196A1",
        "WO2022197902A1",
        "WO2022259661A1",
        "WO2023021690A1",
        "KR102539448B1",
        "TWI809622B",
        "CN114553756B"
    ]
}