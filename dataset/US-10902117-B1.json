{
    "patent_id": "US-10902117-B1",
    "title": "Framework for classifying an object as malicious with machine learning for deploying updated predictive models ",
    "assignee": "Fireeye, Inc.",
    "publication_date": "2021-01-26",
    "patent_link": "https://patents.google.com/patent/US10902117B1/en",
    "inventors": [
        "Abhishek Singh",
        "Ali Mesdaq",
        "Anirban Das",
        "Varun Jain"
    ],
    "classifications": [
        "G06F21/56",
        "G06N5/02",
        "G06N5/025",
        "G06N5/045",
        "H04L63/1425"
    ],
    "abstract": "According to one embodiment, a computerized method for acquiring updated predictive model is described. The updated predictive model is achieved through machine learning analyses of information by a training engine, which issues a control message in response to a discrepancy in a determination of the suspect object as malicious or non-malicious by a detection engine and a classification engine. The detection engine analyzes a content of a suspect object to determine whether the suspect object is malicious or non-malicious. Similarly, the classification engine analyses the suspect object based on the predictive model to determine whether the suspect object is malicious or non-malicious. The control message causes the training engine to update the predictive model based on machine learning analyses of information provided via the control message and to return an updated predictive model to the classification engine.",
    "claims": "\n1. An apparatus comprising:\none or more processors; and\na non-transitory storage medium communicatively coupled to the one or more processors, the non-transitory storage medium comprises\na detection engine that, during execution by the one or more processors, analyzes a content of a suspect object to determine whether the suspect object is malicious or non-malicious,\na classification engine that, during execution by the one or more processors and through use of a predictive model, conducts an analysis of the suspect object based on the predictive model to determine whether the suspect object is malicious or non-malicious, and\nlogic configured to transmit a control message, in response to a discrepancy existing in a first determination of the suspect object as malicious or non-malicious by the detection engine and a second determination of the suspect object as malicious or non-malicious by the classification engine, to a training engine, the control message to cause the training engine to update the predictive model based on machine learning analyses in response to information provided via the control message and to return an updated predictive model to the classification engine.\n2. The apparatus of claim 1, wherein the control message comprises (1) an identifier of the suspect object and (2) one or more suspect features of the object used by the predictive model to classify the object as malicious or non-malicious.\n3. The apparatus of claim 2, wherein the control message further comprises (3) results of the classification of the suspect object by the classification engine.\n4. The apparatus of claim 1, wherein the training engine is part of a cloud computing service remotely located from the apparatus.\n5. The apparatus of claim 1, wherein the updated predictive model includes one or more parameters that are modified from parameters associated with the predictive model to achieve better accuracy in prediction or classification of a secondary object that includes features associated with the suspect object that has been determined to be malicious.\n6. The apparatus of claim 5, wherein the one or more parameters associated with the updated predictive model includes a change to a character string value associated with the suspect object or an increase in a confidence score assigned to a certain type of feature.\n7. The apparatus of claim 1, wherein the predictive model includes logic that controls the analyses conducted by the classification engine.\n8. The apparatus of claim 1, wherein the detection engine is configured to determine whether the suspect object is malicious based on one or more analyses of one or more features of the suspect object that indicates at least a prescribed probability that the suspect object is associated with a malicious attack.\n9. The apparatus of claim 1, wherein the detection engine and the classification engine operate within a static analysis engine and, responsive to the discrepancy in the first and second determinations of the suspect object as malicious or non-malicious by the detection engine and the classification engine, the object is provided to one or more virtual machines within a run-time, virtual execution environment for dynamic analysis of behaviors of the object or behaviors of at least one virtual machine of the one or more virtual machines executing the object.\n10. The apparatus of claim 1 being deployed as a cloud computing service.\n11. The apparatus of claim 1, wherein the predictive model includes logic that controls the analysis of the suspect object by the classification engine.\n12. The apparatus of claim 1, wherein the logic to transmit the control message to the training engine in response to a triggering event, the triggering event is based on one or more of a degree of discrepancy, a rate or periodicity of discrepancies, or a number of times that the discrepancy occurs.\n13. The apparatus of claim 1, wherein the logic includes a security agent configured to upload the control message to the training engine in response to the security agent determining the discrepancy between the first determination by the detection engine and the second determination by the classification engine.\n14. The apparatus of claim 13, wherein the classification engine to receive an alert from the training engine that causes the predictive model to be altered into the updated predictive model.\n15. The apparatus of claim 1, wherein the predictive model implements a decision-tree learning algorithm developed using machine learning techniques from prior analysis of (i) labelled and unlabeled data or (ii) experiential knowledge from human analysts.\n16. The apparatus of claim 1 operating with the training engine configured to receive the control message including any one or more of the following: (i) an identifier of the object, (ii) one or more suspicious features of the suspect object for use by model update logic in updating the predictive model, and (iii) results from a preliminary classification of the suspect object by the classification engine.\n17. The apparatus of claim 16, wherein the training engine to determine, based on the identifier of the suspect object, if the suspect object has been evaluated previously, and if not, the training engine to modify one or more parameters associated with the predictive model to generate the updated predictive model that achieves better accuracy in prediction or classification of objects corresponding to the suspect object better than the predictive model.\n18. The apparatus of claim 1, wherein the first determination by the detection engine represents a first score reflecting a probability that the suspect object is malicious, the second determination by the classification engine represents a second score reflecting a probability that the suspect object is malicious, and the predictive model is to be updated with the updated predictive model when a difference between the first score and the second store exceeds a score threshold.\n19. The apparatus of claim 1, wherein the non-transitory storage medium further comprises a reporting engine configured to generate a report to identify at least a presence of malware associated with the suspect object upon classifying the suspect object as malicious.\n20. The apparatus of claim 1, wherein the training engine is configured to evaluate results of the analyses of the suspect object by the classification engine operating in accordance with the predictive model.\n21. The apparatus of claim 20, wherein the training engine is configured to evaluate the results of the analysis of the suspect object by the classification engine and results of the analysis of the suspect object by the detection engine to determine whether the predictive model needs updating to more accurately classify a level of maliciousness for one or more objects subsequently analyzed by the apparatus.\n22. The apparatus of claim 21, wherein the training engine operates as a cloud computing service.\n23. The apparatus of claim 1, wherein the detection engine analyzes the content of the suspect object without execution of the suspect object based on pattern checking operations.\n24. The apparatus of claim 23, wherein the pattern checking operations include (i) signature matching or (ii) heuristics, or (iii) determinative rule-based analysis including blacklist or whitelist checking.\n25. The apparatus of claim 1, wherein the classification engine, operating in accordance with the predictive model, conducts an analysis of at least features or one or more patterns of features associated with the suspect object, where the predictive model has been trained using a data set comprising: one or more of (i) labelled data associated with malware, (ii) unlabeled data associated with malware, (iii) labeled data associated with benign objects and (iv) unlabeled data associated with benign objects.\n26. The apparatus of claim 1, wherein the updated predictive model is generated based on machine learning techniques from prior analyses of labelled and unlabeled data and/or experiential knowledge from human analysts.\n27. A method comprising:\nanalyzing, by a first analysis component, content of a suspect object to determine whether the suspect object is malicious or non-malicious;\nanalyzing, by a second analysis component, content of the suspect object based on a predictive model to determine whether the suspect object is malicious or non-malicious;\ntransmitting a control message, in response to a discrepancy existing in a first determination of the suspect object as malicious or non-malicious by the first analysis component and a second determination of the suspect object as malicious or non-malicious by the second analysis component, to a training engine; and\nreceiving an updated predictive model based on machine learning analyses using information provided as part of the control message, wherein the updated predictive model to control analyses conducted by the second analysis component on objects received subsequent to bth the suspect object and an updating of the predictive model.\n28. The method of claim 27, wherein the control message comprises (1) an identifier of the suspect object and (2) one or more suspect features of the object used by the predictive model to classify the object as malicious or non-malicious.\n29. The method of claim 28, wherein the control message further comprises (3) results of the classification of the suspect object by a classification engine.\n30. The method of claim 28 further comprising:\ndetermining, by the training engine based on the identifier of the suspect object, if the suspect object has been evaluated previously;\nin response to the suspect object not being previously evaluated, modifying one or more parameters associated with the predictive model, to achieve better accuracy in prediction or classification of objects including any of with the one or more suspect suspicious features associated with the suspect object determined to be malicious by the first analysis component, to generate the updated predictive model.\n31. The method of claim 27 being conducted as part of cloud computing services.\n32. The method of claim 27 further comprising:\nanalyzing, by the second analysis component, content of a secondary object by the updated predictive model to determine whether the secondary object is malicious or non-malicious, the updated predictive model includes one or more parameters that are modified from parameters associated with the predictive model to achieve better accuracy in a prediction of whether the secondary object is malicious.\n33. The method of claim 32, wherein the one or more parameters associated with the updated predictive model includes a change to a character string value associated with the suspect object or an increase in a confidence score assigned to a certain type of feature.\n34. The method of claim 27, wherein the predictive model includes logic that controls the analyses conducted by the second analysis component operating as a classification engine.\n35. The method of claim 27, wherein the analyzing, by the first analysis component, of the content of the suspect object comprising determining whether the suspect object is malicious based on one or more analyses of one or more features of the suspect object that indicates at least a prescribed probability that the one or more features are associated with a malicious attack.\n36. The method of claim 27 further comprising:\nperforming additional analyses on the suspect object responsive to detecting the discrepancy in the determination of the suspect object as malicious or non-malicious by the first analysis component and the second analysis component, the additional analyses include a monitor and analysis of behaviors of the suspect object or a virtual machine during execution of the suspect object within the virtual machine.\n37. The method of claim 27, wherein the predictive model includes logic operating within a classification engine that controls the analysis of the suspect object by the classification engine.\n38. The method of claim 27, wherein the transmitting of the control messages in response to a discrepancy is based, at least in part, on a triggering event to transmit the control message to the training engine based on one or more of (i) a degree of the discrepancy, (ii) a rate or periodicity of discrepancies including the discrepancy, or (iii) a number of times that discrepancies including the discrepancy has occurred.\n39. The method of claim 27, wherein the transmitting of the control message is conducted by a security agent deployed within an endpoint including the first analysis component and the second analysis component, the security agent to upload the control message to the training engine in response to the security agent determining the discrepancy between the first determination by the first analysis component operating as a detection engine and the second determination by the second analysis component operating as a classification engine.\n40. The apparatus of claim 39, wherein the security agent to transmit the control message and the classification engine to receive an alert from the training engine that causes the predictive model to be altered into the updated predictive model.\n41. The method of claim 27, wherein the predictive model implements a decision-tree learning algorithm developed using machine learning techniques from prior analysis of (i) labelled and unlabeled data or (ii) experiential knowledge from human analysts.\n42. The method of claim 27, wherein the first determination by the first analysis component, being a detection engine, represents a first score reflecting a probability that the suspect object is malicious, the second determination by the second analysis component, being a classification engine, represents a second score reflecting a probability that the suspect object is malicious, and the predictive model is to be updated with the updated predictive model when a difference between the first score and the second store exceed a score threshold.\n43. The method of claim 27 further comprising:\ngenerating a report to identify at least a presence of malware associated with the suspect object upon classifying the suspect object as malicious.\n44. A method comprising:\nconducting a first analysis of content of a suspect object to determine whether the suspect object is malicious or non-malicious;\nconducting a second analysis of content of the suspect object based on a predictive model to determine whether the suspect object is malicious or non-malicious;\ntransmitting a control message in response to a discrepancy existing in determinations of the suspect object as malicious or non-malicious by the first analysis and the second analysis, to a training engine; and\nreceiving an updated predictive model based on machine learning analyses using information provided as part of the control message, wherein the updated predictive model to control analyses conducted by the second analysis on objects received subsequent to the suspect object and an updating of the predictive model.\n45. The method of claim 44, wherein the determination of the suspect object comprises a first determination of the suspect object as malicious or non-malicious by the first analysis and a second determination of the suspect object as malicious or non-malicious by the second analysis.\n46. The method of claim 45, wherein prior to receiving the updated predictive model, the method further comprising:\ndetermining, by the training engine, whether the suspect object is included in a training data set used to produce the predictive model by at least comparing an identifier associated with the predictive model to a list of identifiers representing objects analyzed to generate the predictive model.\n47. The method of claim 46, wherein prior to receiving the updated predictive model, the method further comprising:\ndetermining, by the training engine, whether there exists one or more features associated with the suspect object that are not present in any prior objects considered in generation of the predictive model; and\nupdating the training data set in response to the suspect object being absent from the training data set and any of the one or more features are different from features associated with the prior objects considered in generation of the predictive model.\n48. The method of claim 45, wherein the discrepancy existing between the first determination of the suspect object and the second determination of the suspect object is based on whether the suspect object is malicious or non-malicious.\n49. The method of claim 45, wherein the discrepancy existing between the first determination of the suspect object and the second determination of the suspect object is based on degrees of maliciousness of the suspect object as determined during the first analysis and the second analysis.\n50. The method of claim 44, wherein the first analysis is conducted by a detection engine and the second analysis is conducted by a classification engine, the classification engine uses the predictive model or the updated predictive model in determining whether the suspect object and the objects are malicious or non-malicious."
}