{
    "patent_id": "US-10896246-B2",
    "title": "Method for concealing data and data obfuscation device using the same ",
    "assignee": "Deeping Source Inc.",
    "publication_date": "2021-01-19",
    "patent_link": "https://patents.google.com/patent/US10896246B2/en",
    "inventors": [
        "Tae Hoon Kim"
    ],
    "classifications": [
        "G06F21/6254",
        "G06F16/35",
        "G06F18/214",
        "G06F18/2148",
        "G06F21/14",
        "G06F21/606",
        "G06F21/6245",
        "G06F40/279",
        "G06K9/6256",
        "G06K9/6257",
        "G06N20/00",
        "G06N20/20",
        "G06N3/04",
        "G06N3/045",
        "G06N3/0454",
        "G06N3/048",
        "G06N3/08",
        "G06N3/084",
        "G06T3/0068",
        "G06V10/7747",
        "G06V10/82",
        "G06V20/52",
        "G06N20/10",
        "G06N3/006",
        "G06N3/047",
        "G06N5/01",
        "H04L2209/16"
    ],
    "abstract": "A method for concealing original data to protect personal information is provided. The method includes steps of: a data obfuscation device (a) if the original data is acquired, inputting the original data or its modified data into a learning network, and allowing the learning network to (i) apply a network operation to the original data or the modified data using learned parameters of the learning network and thus to (ii) output characteristic information on the original data or the modified data; and (b) updating the original data or the modified data via backpropagation using part of (i) 1-st losses calculated by referring to the characteristic information and its corresponding 1-st ground truth, and (ii) 2-nd losses calculated by referring to (ii-1) a task specific output generated by using the characteristic information and (ii-2) a 2-nd ground truth corresponding to the task specific output, to thereby generate obfuscated data.",
    "claims": "\n1. A method for concealing original data to protect personal information, a concealed data being recognized as similar or same as the original data by a computer but different by a human, comprising steps of:\n(a) a data obfuscation device, on condition that the original data is acquired, inputting the original data or its modified data into a learning network, and allowing the learning network to (i) apply a network operation to the original data or the modified data using one or more learned parameters of the learning network and thus to (ii) output characteristic information on the original data or the modified data, the characteristic information being at least one of features and logits of the original data or modified data; and\n(b) the data obfuscation device updating the original data or the modified data via backpropagation using at least part of (i) one or more 1-st losses calculated by referring to the characteristic information and its corresponding at least one 1-st ground truth, and (ii) one or more 2-nd losses calculated by referring to (ii-1) at least one task specific output generated by using the characteristic information and (ii-2) at least one 2-nd ground truth corresponding to the task specific output, to thereby generate obfuscated data corresponding to the original data, wherein\n(b) includes maintaining the learned parameters during the backpropagation regardless of resultant calculated losses,\nwherein the learning network includes a 1-st learning network to an n-th learning network respectively having one or more 1-st learned parameters to one or more n-th learned parameters wherein n is an integer greater than 0,\nwherein, at the step of (a), the data obfuscation device inputs the original data or the modified data into each of the 1-st learning network to the n-th learning network, and allows each of the 1-st learning network to the n-th learning network to (i) apply its corresponding network operation to the original data or the modified data using respectively the 1-st learned parameters to the n-th learned parameters of the 1-st learning network to the n-th learning network, and thus to (ii) output each piece of 1-st characteristic information to n-th characteristic information on the original data or the modified data, and\nwherein, at the step of (b), the data obfuscation device updates the original data or the modified data via backpropagation using at least part of (i) one of the 1-st losses which is an average over (1_1)-st losses to (1_n)-th losses wherein the (1_1)-st losses to the (1_n)-th losses are calculated by referring to the 1-st characteristic information to the n-th characteristic information and at least one (1_1)-st ground truth to at least one (1_n)-th ground truth respectively corresponding to the 1-st characteristic information to the n-th characteristic information, (ii) one of the 2-nd losses which is an average over (2_1)-st losses to (2_n)-th losses wherein the (2_1)-st losses to the (2_n)-th losses are calculated by referring to a 1-st task specific output to an n-th task specific output generated by using each piece of the 1-st characteristic information to the n-th characteristic information and by further referring to at least one (2_1)-st ground truth to at least one (2_n)-th ground truth respectively corresponding to the 1-st task specific output to the n-th task specific output, and (iii) a 3-rd loss which is an average over a 1-st sum loss to an n-th sum loss wherein each of the 1-st sum loss to the n-th sum loss is each piecewise summation of the (1_1)-st losses to the (1_n)-th losses and the (2_1)-st losses to the (2_n)-th losses corresponding to the (1_1)-st losses to the (1_n)-th losses, to thereby generate the obfuscated data corresponding to the original data.\n2. The method of claim 1, wherein, at the step of (b), the data obfuscation device acquires at least one loss gradient for minimizing at least part of the 1-st losses and the 2-nd losses, and backpropagates the loss gradient to the original data or the modified data.\n3. The method of claim 1, wherein, at the step of (a), the data obfuscation device generates the modified data corresponding to the original data by performing at least one of a process of adding a random noise created by a random noise generating network to the original data, a process of blurring the original data and, a process of changing a resolution of the original data.\n4. A method for concealing original data to protect personal information, a concealed data being recognized as similar or same by a computer but different by a human, comprising steps of:\n(a) a data obfuscation device, on condition that the original data is acquired, modifying the original data, to thereby generate modified data;\n(b) the data obfuscation device, (i) inputting the original data into a learning network, and allowing the learning network to (i-1) apply a network operation to the original data using one or more learned parameters of the learning network and thus to (i-2) output 1-st characteristic information on the original data, the 1-st characteristic information being at least one of features and logits of the original data, and (ii) inputting the modified data into the learning network, and allowing the learning network to (ii-1) apply a network operation to the modified data using the learned parameters and thus to (ii-2) output 2-nd characteristic information on the modified data, the 2-nd characteristic information being at least one of features and logits of the modified data; and\n(c) the data obfuscation device updating the original data or the modified data via backpropagation using one or more data losses created by referring to at least part of (i) one or more 1-st losses calculated by referring to the 1-st characteristic information and the 2-nd characteristic information, and (ii) one or more 2-nd losses calculated by referring to (ii-1) at least one task specific output generated by using the 2-nd characteristic information and (ii-2) at least one ground truth corresponding to the task specific output, to thereby generate obfuscated data corresponding to the original data, wherein\n(c) includes maintaining the learned parameters during the backpropagation regardless of resultant calculated losses,\nwherein the learning network includes a 1-st learning network to an n-th learning network respectively having one or more 1-st learned parameters to one or more n-th learned parameters wherein n is an integer greater than 0,\nwherein, at the step of (b), the data obfuscation device (i) inputs the original data and the modified data into each of the 1-st learning network to the n-th learning network, and (ii) allows each of the 1-st learning network to the n-th learning network to (ii-1) apply its corresponding network operation to the original data and the modified data using respectively the 1-st learned parameters to the n-th learned parameters of the 1-st learning network to the n-th learning network, thus to (ii-2) output each piece of (1_1)-st characteristic information to (1_n)-th characteristic information on the original data, and (ii-3) output each piece of (2_1)-st characteristic information to (2_n)-th characteristic information on the modified data, and\nwherein, at the step of (c), the data obfuscation device updates the original data or the modified data via backpropagation using at least part of (i) one of the 1-st losses which is an average over (1_1)-st losses to (1_n)-th losses wherein the (1_1)-st losses to the (1_n)-th losses are calculated by referring to the (1_1)-st characteristic information to the (1_n)-th characteristic information and the (2_1)-st characteristic information to the (2_n)-th characteristic information corresponding to the (1_1)-st characteristic information to the (1_n)-th characteristic information, (ii) one of the 2-nd losses which is an average over (2_1)-st losses to (2_n)-th losses wherein the (2_1)-st losses to the (2_n)-th losses are calculated by referring to a 1-st task specific output to an n-th task specific output generated by using each piece of the (2_1)-st characteristic information to the (2_n)-th characteristic information and by further referring to at least one 1-st ground truth to at least one n-th ground truth respectively corresponding to the 1-st task specific output to the n-th task specific output, and (iii) a 3-rd loss which is an average over a 1-st sum loss to an n-th sum loss wherein each of the 1-st sum loss to the n-th sum loss is each piecewise summation of the (1_1)-st losses to the (1_n)-th losses and the (2_1)-st losses to the (2_n)-th losses corresponding to the (1_1)-st losses to the (1_n)-th losses, to thereby generate the obfuscated data corresponding to the original data.\n5. The method of claim 4, wherein, at the step of (a), the data obfuscation device generates the modified data corresponding to the original data by performing at least one of a process of adding a random noise created by a random noise generating network to the original data, a process of blurring of the original data, and a process of changing a resolution of the original data.\n6. A data obfuscation device for concealing original data to protect personal information, a concealed data being recognized as similar or same as the original data by a computer but different by a human, comprising:\nat least one memory that stores instructions; and\nat least one processor configured to execute the instructions to perform or support another device to perform processes of: (I) on condition that the original data is acquired, inputting the original data or its modified data into a learning network, and allowing the learning network to (i) apply a network operation to the original data or the modified data using one or more learned parameters of the learning network and thus to (ii) output characteristic information on the original data or the modified data, the characteristic information being at least one of features and logits of the original data or modified data, and (II) updating the original data or the modified data via backpropagation using at least part of (i) one or more 1-st losses calculated by referring to the characteristic information and its corresponding at least one 1-st ground truth, and (ii) one or more 2-nd losses calculated by referring to (ii-1) at least one task specific output generated by using the characteristic information and (ii-2) at least one 2-nd ground truth corresponding to the task specific output, to thereby generate obfuscated data corresponding to the original data, wherein\n(b) includes maintaining the learned parameters during the backpropagation regardless of resultant calculated losses,\nwherein the learning network includes a 1-st learning network to an n-th learning network respectively having one or more 1-st learned parameters to one or more n-th learned parameters wherein n is an integer greater than 0,\nwherein, at the process of (I), the processor inputs the original data or the modified data into each of the 1-st learning network to the n-th learning network, and allows each of the 1-st learning network to the n-th learning network to (i) apply its corresponding network operation to the original data or the modified data using respectively the 1-st learned parameters to the n-th learned parameters of the 1-st learning network to the n-th learning network, and thus to (ii) output each piece of 1-st characteristic information to n-th characteristic information on the original data or the modified data, and\nwherein, at the process of (II), the processor updates the original data or the modified data via backpropagation using at least part of (i) one of the 1-st losses which is an average over (1_1)-st losses to (1_n)-th losses wherein the (1_1)-st losses to the (1_n)-th losses are calculated by referring to the 1-st characteristic information to the n-th characteristic information and at least one (1_1)-st ground truth to at least one (1_n)-th ground truth respectively corresponding to the 1-st characteristic information to the n-th characteristic information, (ii) one of the 2-nd losses which is an average over (2_1)-st losses to (2_n)-th losses wherein the (2_1)-st losses to the (2_n)-th losses are calculated by referring to a 1-st task specific output to an n-th task specific output generated by using each piece of the 1-st characteristic information to the n-th characteristic information and by further referring to at least one (2_1)-st ground truth to at least one (2_n)-th ground truth respectively corresponding to the 1-st task specific output to the n-th task specific output, and (iii) a 3-rd loss which is an average over a 1-st sum loss to an n-th sum loss wherein each of the 1-st sum loss to the n-th sum loss is each piecewise summation of the (1_1)-st losses to the (1_n)-th losses and the (2_1)-st losses to the (2_n)-th losses corresponding to the (1_1)-st losses to the (1_n)-th losses, to thereby generate the obfuscated data corresponding to the original data.\n7. The data obfuscation device of claim 6, wherein, at the process of (II), the processor acquires at least one loss gradient for minimizing at least part of the 1-st losses and the 2-nd losses, and backpropagates the loss gradient to the original data or the modified data.\n8. The data obfuscation device of claim 6, wherein, at the process of (I), the processor generates the modified data corresponding to the original data by performing at least one of a process of adding a random noise created by a random noise generating network to the original data, a process of blurring the original data and, a process of changing a resolution of the original data.\n9. A data obfuscation device for concealing original data to protect personal information, a concealed data being recognized as similar or same as the original data by a computer but different by a human, comprising:\nat least one memory that stores instructions; and\nat least one processor configured to execute the instructions to perform or support another device to perform processes of: (I) on condition that the original data is acquired, modifying the original data, to thereby generate modified data, (II) (i) inputting the original data into a learning network, and allowing the learning network to (i-1) apply a network operation to the original data using one or more learned parameters of the learning network and thus to (i-2) output 1-st characteristic information on the original data, the 1-st characteristic information being at least one of features and logits of the original data, and (ii) inputting the modified data into the learning network, and allowing the learning network to (ii-1) apply a network operation to the modified data using the learned parameters and thus to (ii-2) output 2-nd characteristic information on the modified data, the 2-nd characteristic information being at least one of features and logits of the modified data, and (III) updating the original data or the modified data via backpropagation using one or more data losses created by referring to at least part of (i) one or more 1-st losses calculated by referring to the 1-st characteristic information and the 2-nd characteristic information, and (ii) one or more 2-nd losses calculated by referring to (ii-1) at least one task specific output generated by using the 2-nd characteristic information and (ii-2) at least one ground truth corresponding to the task specific output, to thereby generate obfuscated data corresponding to the original data, wherein\n(III) includes maintaining the learned parameters during the backpropagation regardless of resultant calculated losses,\nwherein the learning network includes a 1-st learning network to an n-th learning network respectively having one or more 1-st learned parameters to one or more n-th learned parameters wherein n is an integer greater than 0,\nwherein, at the process of (II), the processor (i) inputs the original data and the modified data into each of the 1-st learning network to the n-th learning network, and (ii) allows each of the 1-st learning network to the n-th learning network to (ii-1) apply its corresponding network operation to the original data and the modified data using respectively the 1-st learned parameters to the n-th learned parameters of the 1-st learning network to the n-th learning network, thus to (ii-2) output each piece of (1_1)-st characteristic information to (1_n)-th characteristic information on the original data, and (ii-3) output each piece of (2_1)-st characteristic information to (2_n)-th characteristic information on the modified data, and\nwherein, at the process of (III), the processor updates the original data or the modified data via backpropagation using at least part of (i) one of the 1-st losses which is an average over (1_1)-st losses to (1_n)-th losses wherein the (1_1)-st losses to the (1_n)-th losses are calculated by referring to the (1_1)-st characteristic information to the (1_n)-th characteristic information and the (2_1)-st characteristic information to the (2_n)-th characteristic information corresponding to the (1_1)-st characteristic information to the (1_n)-th characteristic information, (ii) one of the 2-nd losses which is an average over (2_1)-st losses to (2_n)-th losses wherein the (2_1)-st losses to the (2_n)-th losses are calculated by referring to a 1-st task specific output to an n-th task specific output generated by using each piece of the (2_1)-st characteristic information to the (2_n)-th characteristic information and by further referring to at least one 1-st ground truth to at least one n-th ground truth respectively corresponding to the 1-st task specific output to the n-th task specific output, and (iii) a 3-rd loss which is an average over a 1-st sum loss to an n-th sum loss wherein each of the 1-st sum loss to the n-th sum loss is each piecewise summation of the (1_1)-st losses to the (1_n)-th losses and the (2_1)-st losses to the (2_n)-th losses corresponding to the (1_1)-st losses to the (1_n)-th losses, to thereby generate the obfuscated data corresponding to the original data.\n10. The data obfuscation device of claim 9, wherein, at the process of (I), the processor generates the modified data corresponding to the original data by performing at least one of a process of adding a random noise created by a random noise generating network to the original data, a process of blurring of the original data, and a process of changing a resolution of the original data.",
    "status": "Active",
    "citations_own": [
        "US20060269098A1",
        "US20110246787A1",
        "KR20170092631A",
        "KR101861520B1",
        "JP2018106216A",
        "US20190034483A1",
        "US20190188830A1"
    ],
    "citations_ftf": [
        "US5671335A",
        "JPH07105165A",
        "JP3974763B2",
        "JP4424364B2",
        "US8577387B2",
        "US9105119B2",
        "US9275308B2",
        "US10043035B2",
        "JP6286329B2",
        "WO2016145516A1",
        "US9773196B2",
        "US9847974B2",
        "KR101784265B1",
        "US20180129900A1",
        "US10733530B2",
        "KR101877372B1",
        "US11023593B2",
        "US11481640B2",
        "US10475169B2",
        "US10748247B2",
        "US10475538B2",
        "US10709394B2",
        "US10535141B2"
    ],
    "citedby_own": [],
    "citedby_ftf": [
        "JP7353032B2",
        "WO2020137728A1",
        "JP7268368B2",
        "US11562134B2",
        "KR102260039B1",
        "US10621378B1",
        "CN111078825A",
        "US11321430B2",
        "US11334408B2",
        "US11314874B2",
        "US11379603B2",
        "US11363029B2",
        "EP4100896A1",
        "US20210303662A1",
        "US10956598B1",
        "EP3905087B1",
        "US11709954B2",
        "US11017319B1",
        "US11017320B1",
        "US11334773B2",
        "CN112019502B",
        "US11023777B1",
        "US11200494B1",
        "US11244248B1",
        "US20220129582A1",
        "KR102531368B1",
        "US11164046B1",
        "WO2022154194A1",
        "US11366930B1",
        "US11308359B1",
        "US11669635B1",
        "US11423643B1",
        "CN116049840B"
    ]
}