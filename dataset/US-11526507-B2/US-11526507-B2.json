{
    "patent_id": "US-11526507-B2",
    "title": "Neural network based translation of natural language queries to database queries ",
    "assignee": "Salesforce, Inc.",
    "publication_date": "2022-12-13",
    "patent_link": "https://patents.google.com/patent/US11526507B2/en",
    "inventors": [
        "Victor ZHONG",
        "Caiming Xiong",
        "Richard Socher"
    ],
    "classifications": [
        "G06F16/24522",
        "G06N3/006",
        "G06N3/045",
        "G06N3/0454",
        "G06N3/08",
        "G06N7/005",
        "G06N7/01",
        "G06F16/13",
        "G06F16/24578"
    ],
    "abstract": "A computing system uses neural networks to translate natural language queries to database queries. The computing system uses a plurality of machine learning based models, each machine learning model for generating a portion of the database query. The machine learning models use an input representation generated based on terms of the input natural language query, a set of columns of the database schema, and the vocabulary of a database query language, for example, structured query language SQL. The plurality of machine learning based models may include an aggregation classifier model for determining an aggregation operator in the database query, a result column predictor model for determining the result columns of the database query, and a condition clause predictor model for determining the condition clause of the database query. The condition clause predictor is based on reinforcement learning.",
    "claims": "\n1. A computer implemented method comprising:\nreceiving, from a client device, an input natural language query based on data stored using a database schema;\naccessing a plurality of machine learning based models, each model configured to predict a portion of a database query corresponding to the input natural language query;\nfor each of the plurality of machine learning based models:\nproviding an input describing the input natural language query and the database schema; and\nexecuting the machine learning based model based on the input to generate a portion of the database query;\ncombining the generated portions of the database query to obtain the database query;\nexecuting the database query to obtain a result set; and\nsending the result set to the client device.\n2. The computer implemented method of claim 1, wherein the plurality of machine learning based models comprise an aggregation classifier model for determining an aggregation operator in the database query, wherein the aggregation classifier model comprises a multi-layer perceptron.\n3. The computer implemented method of claim 1, wherein the plurality of machine learning based models comprise a result column predictor model for determining a result column of the result set of the database query, wherein the result column predictor model comprises a multi-layer perceptron.\n4. The computer implemented method of claim 3, wherein the result column generates an input representation form one or more columns corresponding to the input natural language query using a long short term memory network (LSTM).\n5. The computer implemented method of claim 1, wherein the plurality of machine learning based models comprise a condition clause predictor model for determining a condition clause of the database query, wherein the condition clause predictor model is based on reinforcement learning.\n6. The computer implemented method of claim 5, further comprising:\nreceiving a result set based on a ground truth database query;\ndetermining reward values based on a comparison of the result set obtained from the database query and a result set obtained from the ground truth database query; and\nadjusting weights of the condition clause predictor model based on the reward values.\n7. The computer implemented method of claim 1, further comprising:\ngenerating an input representation for providing as input to a machine learning model, the generating comprising:\ndetermining a sequence of tokens corresponding to the input natural language query;\ndetermining column encodings corresponding to one or more tokens of the sequence of tokens; and\ndetermining the input representation based on the column encodings.\n8. The computer implemented method of claim 1, further comprising:\ngenerating an input representation describing the database schema for providing as input to a machine learning model from the plurality of machine learning based models.\n9. The computer implemented method of claim 1, further comprising:\ngenerating an input representation describing a vocabulary of a database query language for providing as input to a machine learning model from the plurality of machine learning based models.\n10. The computer implemented method of claim 1, further comprising:\ntraining the plurality of machine learning based models using gradient descent to minimize an objective function representing a loss based on an output the result of each of the plurality of machine learning based models.\n11. A non-transitory computer readable storage medium storing instructions that when executed by a computer processor cause the computer processor to perform steps comprising:\nreceiving, from a client device, an input natural language query based on data stored using a database schema;\naccessing a plurality of machine learning based models, each model configured to predict a portion of a database query corresponding to the input natural language query;\nfor each of the plurality of machine learning based models:\nproviding an input describing the input natural language query and the database schema; and\nexecuting the machine learning based model based on the input to generate a portion of the database query;\ncombining the generated portions of the database query to obtain the database query;\nexecuting the database query to obtain a result set; and\nsending the result set to the client device.\n12. The non-transitory computer readable storage medium of claim 11, wherein the plurality of machine learning based models comprise an aggregation classifier model for determining an aggregation operator in the database query, wherein the aggregation classifier model comprises a multi-layer perceptron.\n13. The non-transitory computer readable storage medium of claim 11, wherein the plurality of machine learning based models comprise a result column predictor model for determining a result column of the result set of the database query, wherein the result column predictor model comprises a multi-layer perceptron.\n14. The non-transitory computer readable storage medium of claim 13, wherein the result column generates an input representation for one or more columns corresponding to the input natural language query using a long short term memory network (LSTM).\n15. The non-transitory computer readable storage medium of claim 11, wherein the plurality of machine learning based models comprise a condition clause predictor model for determining a condition clause of the database query, wherein the condition clause predictor model is based on reinforcement learning.\n16. The non-transitory computer readable storage medium of claim 15, wherein the instructions cause the computer processor to perform steps further comprising:\nreceiving a result set based on a ground truth database query;\ndetermining reward values based on a comparison of the result set obtained from the database query and a result set obtained from the ground truth database query; and\nadjusting weights of the condition clause predictor model based on the reward values.\n17. The non-transitory computer readable storage medium of claim 11, wherein the instructions cause the computer processor to perform steps further comprising:\ngenerating an input representation for providing as input to a machine learning model, the generating comprising:\ndetermining a sequence of tokens corresponding to the input natural language query;\ndetermining column encodings corresponding to one or more tokens of the sequence of tokens; and\ndetermining the input representation based on the column encodings.\n18. The non-transitory computer readable storage medium of claim 11, wherein the instructions cause the computer processor to perform steps further comprising:\ngenerating an input representation describing the database schema for providing as input to a machine learning model from the plurality of machine learning based models.\n19. The non-transitory computer readable storage medium of claim 11, wherein the instructions cause the computer processor to perform steps further comprising:\ngenerating an input representation describing a vocabulary of a database query language for providing as input to a machine learning model from the plurality of machine learning based models.\n20. A computer system comprising:\na computer processor; and\na non-transitory computer readable storage medium storing instructions that when executed by the computer processor cause the computer processor to perform steps comprising:\nreceiving, from a client device, an input natural language query based on data stored using a database schema;\naccessing a plurality of machine learning based models, each model configured to predict a portion of a database query corresponding to the input natural language query;\nfor each of the plurality of machine learning based models:\nproviding an input describing the input natural language query and the database schema; and\nexecuting the machine learning based model based on the input to generate a portion of the database query;\ncombining the generated portions of the database query to obtain the database query;\nexecuting the database query to obtain a result set; and\nsending the result set to the client device.",
    "status": "Active",
    "citations_own": [
        "US20070027905A1",
        "US20110314010A1",
        "US8156145B2",
        "CN102622342A",
        "CN102693303A",
        "US8380645B2",
        "US20130239006A1",
        "US20160140123A1",
        "US20160171050A1",
        "WO2016151690A1",
        "US20160342597A1",
        "US20170061330A1",
        "US20170109355A1",
        "CN106598948A",
        "CN106663092A",
        "US20170161262A1",
        "US20170249309A1",
        "US9830315B1",
        "US20180052824A1",
        "US20180101791A1",
        "US20180143978A1",
        "US10013416B1",
        "US20180210883A1"
    ],
    "citations_ftf": [],
    "citedby_own": [
        "US20210056149A1"
    ],
    "citedby_ftf": [
        "US10565493B2",
        "US10565305B2",
        "US10565318B2",
        "US11386327B2",
        "US10817650B2",
        "US10885586B2",
        "US11087211B2",
        "US10542270B2",
        "US11276002B2",
        "US10776581B2",
        "US10929607B2",
        "US11227218B2",
        "US10783875B2",
        "US11106182B2",
        "US11501202B1",
        "US11494454B1",
        "US10909157B2",
        "US10777196B2",
        "US11436481B2",
        "US10970486B2",
        "US11029694B2",
        "US11087177B2",
        "US11514915B2",
        "US11645509B2",
        "US20200125664A1",
        "US10963652B2",
        "US20200257679A1",
        "US11568306B2",
        "US11366969B2",
        "US11003867B2",
        "US11087092B2",
        "US11580445B2",
        "CN110059100B",
        "US11232308B2",
        "US11281863B2",
        "US11789945B2",
        "US11550783B2",
        "US11487939B2",
        "US11562251B2",
        "US11620572B2",
        "US11604965B2",
        "US11669712B2",
        "US11775775B2",
        "US11687588B2",
        "US11657269B2",
        "US11615240B2",
        "US20220292087A1",
        "US11475048B2",
        "US11520785B2",
        "US11449796B2",
        "US11568000B2",
        "US11599792B2",
        "US11640527B2",
        "CN112580357A",
        "US11341340B2",
        "US11620515B2",
        "US11347708B2",
        "US11288438B2",
        "US11334766B2",
        "US11537899B2",
        "US11188530B2",
        "US11256754B2",
        "US11487999B2",
        "US11416688B2",
        "US11640505B2",
        "CN111177180A",
        "KR102345568B1",
        "WO2021132760A1",
        "CN111125154B",
        "US11481418B2",
        "US11669745B2",
        "US11562147B2",
        "US20210240917A1",
        "US11521065B2",
        "US11748770B1",
        "US11328731B2",
        "CN111522839B",
        "US11544597B2",
        "US11625543B2",
        "US11720559B2",
        "US11625436B2",
        "CN111813802B",
        "WO2022072844A1",
        "EP4229519A1",
        "US11803541B2",
        "US20220156270A1",
        "CN112380238A",
        "CN112559552B",
        "CN112507098B",
        "KR102498403B1",
        "CN113220881A",
        "US20220284018A1",
        "JP2022147406A",
        "US11500865B1",
        "US11604794B1",
        "US11726994B1",
        "CN113052257A",
        "US11768831B2",
        "CN113486056B",
        "US11726750B1",
        "KR20230079729A",
        "US20230306061A1"
    ]
}