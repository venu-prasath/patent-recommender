{
    "patent_id": "US-11521037-B2",
    "title": "Delayed responses by computational assistant ",
    "assignee": "Google Llc",
    "publication_date": "2022-12-06",
    "patent_link": "https://patents.google.com/patent/US11521037B2/en",
    "inventors": [
        "Yariv ADAN",
        "Vladimir Vuskovic",
        "Behshad Behzadi"
    ],
    "classifications": [
        "G06N3/006",
        "G06F16/3329",
        "G06F3/167",
        "G06Q10/02",
        "G06Q10/063114",
        "G10L15/22",
        "G10L13/00",
        "G10L2015/223",
        "H04M2203/355",
        "H04M3/4936",
        "Y02D10/00"
    ],
    "abstract": "An example method includes receiving, by a computational assistant executing at one or more processors, a representation of an utterance spoken at a computing device; identifying, based on the utterance, a task to be performed by the computational assistant; responsive to determining, by the computational assistant, that complete performance of the task will take more than a threshold amount of time, outputting, for playback by one or more speakers operably connected to the computing device, synthesized voice data that informs a user of the computing device that complete performance of the task will not be immediate; and performing, by the computational assistant, the task.",
    "claims": "\n1. A method implemented by one or more processors, the method comprising:\nreceiving a representation of an utterance spoken at a computing device;\nidentifying, based on the utterance, a task to be performed by a computational assistant;\ndetermining that completing performance of the task requires an occurrence of a future event;\nin response to determining that completing performance requires the occurrence of the future event:\noutputting, for playback by one or more speakers operably connected to the computing device, synthesized voice data that informs a user of the computing device that complete performance of the task will not be immediate,\nwherein the synthesized voice data output for playback is determined based on an estimated time associated with the occurrence of the future event; and\nin response to detecting the occurrence of the future event:\ncausing the computational assistant to perform the task.\n2. The method of claim 1, wherein determining that completing performance of the task requires the occurrence of the future event comprises:\ndetermining that completing performance of the task involves the computational assistant interacting with a person other than the user of the computing device; and\ndetermining that interacting with the person other than the user of the computing device is not eligible for immediate performance.\n3. The method of claim 1, wherein interacting with the person other than the user of the computing device comprises:\noutputting, by the computational assistant and for playback by one or more speakers operably connected to a device associated with the person other than the user of the computing device, synthesized voice data as part of a conversation with the person other than the user of the computing device.\n4. The method of claim 1, wherein the synthesized voice data that informs the user of the computing device that complete performance of the task will not be immediate is output at a first time, and further comprising:\nreceiving, at a second time that is later than the first time, a representation of an additional utterance spoken at the computing device, the additional utterance comprising a request for a status of performance of the task; and\noutputting, for playback by the one or more speakers operably connected to the computing device, additional synthesized voice data that informs the user of the status of performance of the task.\n5. The method of claim 1, further comprising:\nreceiving, before performance of the task is complete, a representation of an additional utterance spoken at the computing device, the additional utterance comprising a request to modify one or more parameters of the task; and\nperforming, by the computational assistant, the task with the modified one or more parameters.\n6. The method of claim 1, wherein the request to modify one or more parameters of the task comprises one or more of:\na request to change a time of a reservation or ticket purchase; and\na request to change a number of people included in a reservation or ticket purchase.\n7. The method of claim 1, further comprising:\ndisplaying, at the computing device and prior to completing performance of the task, a visual indicator that the computational assistant is performing the task.\n8. The method of claim 1, further comprising:\nmonitoring for the occurrence of the future event; and\ndetermining, based on the monitoring, whether the occurrence of the future event is detected.\n9. The method of claim 8, where the future event comprises one of:\nhaving to wait until tickets go on sale, or\nproviding a final score to a sports game currently in progress.\n10. A method implemented by one or more processors, the method comprising:\nreceiving a representation of an utterance spoken at a computing device;\nidentifying, based on the utterance, a task to be performed by a computational assistant;\ndetermining, based on the task, to place a call with an entity, on behalf of a user of the computing device, to perform the task;\noutputting, for playback by one or more speakers operably connected to the computing device, synthesized voice data that informs the user that complete performance of the task will not be immediate;\ninitiating performance of the call with the entity, on behalf of the user, to perform the task; and\nduring performance of the call:\nreceiving a representation of an additional utterance spoken at the computing device;\ndetermining, based on the additional utterance, to modify performance of the task; and\ncausing the computational assistant to complete modified performance of the task.\n11. The method of claim 10, wherein determining to modify performance of the task comprises determining the additional utterance includes a request to modify one or more parameters of the task.\n12. The method of claim 11, wherein causing the computational assistant to complete modified performance of the task comprises causing the computational assistant to complete modified performance of the task with the modified one or more parameters during performance of the call.\n13. The method of claim 12, wherein the task is a restaurant reservation task.\n14. The method of claim 13, wherein the one or more parameters of the task include one or more of: a party size parameter, a date parameter, or a restaurant parameter.\n15. The method of claim 10, wherein initiating performance of the call with the entity, on behalf of the user, to perform the task comprises:\ninteracting the call with a person other than the user of the computing device.\n16. The method of claim 15, wherein interacting with the person other than the user of the computing device comprises:\noutputting, by the computational assistant and for playback by one or more speakers operably connected to a device associated with the person other than the user of the computing device, synthesized voice data as part of the call with the person other than the user of the computing device.\n17. A system comprising:\nat least one processor; and\nmemory storing instructions that, when executed, cause the at least one processor to:\nreceive a representation of an utterance spoken at a computing device;\nidentify, based on the utterance, a task to be performed by a computational assistant;\ndetermine, based on the task, to place a call with an entity, on behalf of a user of the computing device, to perform the task;\noutput, for playback by one or more speakers operably connected to the computing device, synthesized voice data that informs the user that complete performance of the task will not be immediate;\ninitiate performance of the call with the entity, on behalf of the user, to perform the task; and\nduring performance of the call:\nreceive a representation of an additional utterance spoken at the computing device;\ndetermine, based on the additional utterance, to modify performance of the task; and\ncause the computational assistant to complete modified performance of the task.",
    "status": "Active",
    "citations_own": [
        "JP2002351492A",
        "US20100004930A1",
        "US20150121216A1",
        "US20150334346A1",
        "US20150332195A1",
        "US20160118036A1",
        "JP2016090681A",
        "WO2016111881A1",
        "US20160239737A1",
        "JP2016534616A",
        "US20170068550A1",
        "US20170371724A1",
        "US11048995B2"
    ],
    "citations_ftf": [
        "IL142366A0",
        "JP4003544B2",
        "US7606714B2",
        "JP2004318731A",
        "CN103959751A",
        "US9082402B2",
        "US20130235044A1",
        "JP6052610B2",
        "US10134395B2",
        "AU2015266863B2",
        "JP2016076799A",
        "US20160224939A1",
        "US10747498B2"
    ],
    "citedby_own": [],
    "citedby_ftf": [
        "US9318108B2",
        "US8977255B2",
        "US8676904B2",
        "US10706373B2",
        "US10276170B2",
        "US10417037B2",
        "WO2014124332A2",
        "US10652394B2",
        "US10748529B1",
        "US10176167B2",
        "US9633547B2",
        "US10553098B2",
        "AU2015266863B2",
        "US9715875B2",
        "US10170123B2",
        "US9338493B2",
        "US11330100B2",
        "US9886953B2",
        "US9721566B2",
        "US10009286B2",
        "US10460227B2",
        "US10200824B2",
        "US20160378747A1",
        "US10747498B2",
        "US10671428B2",
        "US10691473B2",
        "US10586535B2",
        "DK201670540A1",
        "US11204787B2",
        "DK201770383A1",
        "US10726832B2",
        "DK180048B1",
        "DK201770429A1",
        "DK179496B1",
        "DK179745B1",
        "US11048995B2",
        "US20180336892A1",
        "US10303715B2",
        "US10506088B1",
        "US10818288B2",
        "US10928918B2",
        "US10892996B2",
        "DK179822B1",
        "DK180639B1",
        "US10496705B1",
        "US11475898B2",
        "US11638059B2",
        "US11348573B2",
        "JP6956921B2",
        "US11307752B2",
        "US11423908B2",
        "US11475884B2",
        "US11217251B2",
        "US11140099B2",
        "DK180129B1",
        "US11289073B2",
        "US11496600B2",
        "DK201970511A1",
        "US11360641B2",
        "US11468890B2",
        "WO2021056255A1",
        "US11783256B1",
        "US11636304B2",
        "US11289090B2",
        "US11183193B1",
        "US11755276B2",
        "US11438683B2",
        "US11763813B2",
        "US20230004918A1",
        "US11804215B1"
    ]
}