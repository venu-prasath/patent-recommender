{
    "patent_id": "US-11756693-B2",
    "title": "Medical assessment based on voice ",
    "assignee": "Canary Speech, LLC",
    "publication_date": "2023-09-12",
    "patent_link": "https://patents.google.com/patent/US11756693B2/en",
    "inventors": [
        "Jangwon Kim",
        "Namhee Kwon",
        "Henry O'connell",
        "Phillip Walstad",
        "Kevin Shengbin Yang"
    ],
    "classifications": [
        "G16H80/00",
        "A61B5/1123",
        "A61B5/4088",
        "A61B5/4803",
        "A61B5/7267",
        "G06N20/10",
        "G06N3/08",
        "G06N7/01",
        "G10L25/66",
        "G16H10/20",
        "G16H40/67",
        "G16H50/20",
        "G16H50/50",
        "G06F2111/10",
        "G10L15/02",
        "G10L15/063",
        "G10L15/22"
    ],
    "abstract": "Apparatuses, systems, methods, and computer program products are disclosed for medical assessment based on voice. A query module is configured to audibly question a user from an electronic display screen and/or a speaker of a computing device with one or more open ended questions. A response module is configured to receive a conversational verbal response of a user from a microphone of a computing device in response to one or more open ended questions. A detection module is configured to provide a machine learning assessment for a user of a medical condition based on a machine learning analysis of a received conversational verbal response of the user.",
    "claims": "\n1. An apparatus comprising:\na query module installed on a computing device and configured to query a user from one or more of an electronic display screen and a speaker of the computing device;\na response module installed on the computing device and configured to receive response data for the user from one or more sensors of the computing device in response to querying the user, the response data comprising a recorded verbal response of the user and one or more of text data of a typed response, image data, video data, touch input, and movement information from the one or more sensors of the computing device; and\na detection module installed on the computing device and configured to provide a machine learning assessment for the user of a medical condition based on a machine learning analysis of the received response data for the user, the machine learning assessment based at least partially on one or more biomarkers of the received response data, the one or more biomarkers comprising a measurable indicator of a condition of the user.\n2. The apparatus of claim 1, wherein the detection module is configured to determine the machine learning assessment based on one or more acoustic features of the received response data without regard to language features of the received response data such that the machine learning assessment is independent of one or more of a language and a dialect of the received response data.\n3. The apparatus of claim 1, wherein the user comprises a medical trial participant and the machine learning assessment comprises an assessment of an efficacy of a medical treatment for the medical condition.\n4. The apparatus of claim 3, wherein the detection module comprises one of a plurality of distributed detection modules disposed on mobile computing devices for a plurality of medical trial participants comprising at least a placebo group not receiving the medical treatment and a group receiving the medical treatment, the plurality of distributed detection modules configured to provide blind assessments of the medical condition for both the placebo group and the group receiving the medical treatment.\n5. The apparatus of claim 3, wherein the one or more biomarkers of the received response data indicate a quality of life for the user, wherein the one or more biomarkers indicate one or more of physical fatigue, tiredness, mental fatigue, stress, anxiety, and depression.\n6. The apparatus of claim 1, wherein the user comprises a prospective medical trial participant and the machine learning assessment comprises a suitability of the user for a medical trial for the medical condition.\n7. The apparatus of claim 1, wherein the query module queries the user at a predefined health state to collect baseline response data.\n8. The apparatus of claim 1, wherein the query module queries the user in response to a potential medical event.\n9. The apparatus of claim 1, wherein the one or more sensors of the computing device is selected from the group comprising an image sensor, a microphone, a touchscreen, an accelerometer, and a gyroscope.\n10. The apparatus of claim 1, wherein the received response data comprises received baseline response data and received test case response data that the response module receives separately.\n11. The apparatus of claim 10, wherein the response module receives the baseline response data in response to one or more baseline prompts and the test case response data in response to one or more test case prompts based on a potential medical event and provides the machine learning assessment using the baseline response data and the test case response data.\n12. The apparatus of claim 1, wherein the computing device is a wearable device comprising the one or more sensors and configured to receive the response data from the user.\n13. A system comprising:\na plurality of distributed voice modules disposed and installed on computing devices for a plurality of users, the plurality of distributed voice modules configured to query the plurality of users from one or more of an electronic display screen and a speaker of the computing device and to receive response data for the plurality of users from one or more sensors of the computing device in response to querying the plurality of users, the response data comprising a recorded verbal response of the user and one or more of text data of a typed response, image data, video data, touch input, and movement information from the one or more sensors of the computing device; and\na backend server device configured to store at least baseline response data from the plurality of users, test case response data from the plurality of users, and machine learning assessments of a medical condition for at least the test case response data, the machine learning assessments based at least partially on one or more biomarkers of the received response data, the one or more biomarkers comprising a measurable indicator of a condition of the user, and to provide the stored baseline response data, test case response data, and machine learning assessments to at least a subset of the plurality of users on the computing devices through the plurality of distributed voice modules.\n14. The system of claim 13, wherein the plurality of users comprises participants in a medical trial for the medical condition and the subset of the plurality of users comprises one or more administrators of the medical trial with hierarchical access control permissions to access the stored baseline recorded response data, test case recorded response data, and machine learning assessments.\n15. An apparatus comprising:\nmeans for querying a user from an application installed on a computing device using one or more of an electronic display screen and a speaker of the computing device;\nmeans for receiving response data for the user from one or more sensors of the computing device in response to querying the user, the response data comprising a recorded verbal response of the user and one or more of text data of a typed response, image data, video data, touch input, and movement information from the one or more sensors of the computing device; and\nmeans for assessing the user for a medical condition using machine learning based on the received response data for the user, the machine learning assessment based at least partially on one or more biomarkers of the received response data, the one or more biomarkers comprising a measurable indicator of a condition of the user.\n16. The apparatus of claim 15, further comprising:\nmeans for authenticating different users in a hierarchy of users; and\nmeans for providing access to different recordings and different assessments to the different users based on hierarchical access control permissions for the hierarchy of users.\n17. The apparatus of claim 1, wherein the detection module is configured to extract one or more image features from the image data for the machine learning assessment.\n18. The apparatus of claim 17, wherein the one or more image features are extracted from image data of at least one of the user's face and a body part of the user associated with the medical condition.\n19. The apparatus of claim 17, wherein the image features are from image data extracted from the video data associated with the user.\n20. The apparatus of claim 1, wherein the response data comprises data for a doctor's visit for the user that is received from the one or more sensors of the computing device during the doctor's visit.",
    "status": "Active",
    "citations_own": [
        "JPH11197116A",
        "AU5315699A",
        "JP2012508407A",
        "US20170053665A1",
        "US20190073885A1"
    ],
    "citations_ftf": [
        "US6067516A",
        "US7725307B2",
        "US7062443B2",
        "US20030105638A1",
        "US20030115214A1",
        "US7315821B2",
        "US6804654B2",
        "US7825488B2",
        "US6696339B1",
        "US20040210159A1",
        "US9240188B2",
        "US20120277594A1",
        "TW200735878A",
        "US8478596B2",
        "US20070226012A1",
        "EP2012655A4",
        "US7884727B2",
        "US9390167B2",
        "US8494857B2",
        "WO2010132541A2",
        "WO2011011413A2",
        "US9087320B2",
        "AU2010357179A1",
        "US8784311B2",
        "US20120310670A1",
        "US9055861B2",
        "US9514281B2",
        "US9763617B2",
        "US20130158434A1",
        "ES2947765T3",
        "US9517373B2",
        "US20140073993A1",
        "US9579056B2",
        "US20140113263A1",
        "US9135571B2",
        "US9295423B2",
        "US9495646B2",
        "WO2015107681A1",
        "US9685174B2",
        "US20160004831A1",
        "US9952685B2",
        "US10874340B2",
        "JP2017532082A",
        "US20160140986A1",
        "US20160135737A1",
        "JP2018512202A",
        "US20160335399A1",
        "US20160278633A1",
        "US11638550B2",
        "WO2017021944A2",
        "EP3350806A4",
        "US9899035B2",
        "AU2016352996A1",
        "US11164596B2",
        "US11404170B2",
        "US10796715B1",
        "US10939821B2",
        "EP3619657A4"
    ],
    "citedby_own": [],
    "citedby_ftf": [
        "US10939821B2",
        "EP3619657A4",
        "US10910105B2",
        "US11114097B2",
        "US20190043623A1",
        "US11436549B1",
        "US11508479B2",
        "WO2019246239A1",
        "US20190385711A1",
        "US20200042825A1",
        "US11120226B1",
        "US11633103B1",
        "US20210219893A1",
        "US11631401B1",
        "US11380351B2",
        "US10847177B2",
        "US11036838B2",
        "US11159510B2",
        "US11176230B2",
        "US11120109B2",
        "US11113370B2",
        "US11048793B2",
        "WO2020128542A1",
        "US10943588B2",
        "US11133026B2",
        "US11350885B2",
        "US11651252B2",
        "US11024327B2",
        "US11011188B2",
        "CN113710147A",
        "JP7327987B2",
        "US11547345B2",
        "CN110263641A",
        "EP3745412A1",
        "WO2020243701A1",
        "EP3809411A1",
        "US11114113B2",
        "CN112908317B",
        "JPWO2021111964A1",
        "US11232570B2",
        "US11484211B2",
        "CN112133284B",
        "EP4150617A1",
        "JP2022000744A",
        "US11417342B2",
        "US20230233136A1",
        "US11526796B2",
        "WO2022031725A1",
        "EP3965116A1",
        "US20220076694A1",
        "US11495211B2",
        "GB202019000D0",
        "WO2022212740A2",
        "CN113838450B",
        "US20230072242A1",
        "WO2023095136A1",
        "WO2023094657A1",
        "KR102380376B1",
        "CN116583913A"
    ]
}