{
    "patent_id": "US-11562256-B2",
    "title": "Method and device for presenting prediction model, and method and device for adjusting prediction model ",
    "assignee": "The Fourth Paradigm (Beijing) Tech Co Ltd",
    "publication_date": "2023-01-24",
    "patent_link": "https://patents.google.com/patent/US11562256B2/en",
    "inventors": [
        "Yang Bai",
        "Yuqiang Chen",
        "Wenyuan DAI"
    ],
    "classifications": [
        "G06N5/02",
        "G06N20/00",
        "G06N3/08",
        "G06N5/003",
        "G06N5/01",
        "G06N5/045",
        "G06Q10/04",
        "G06Q10/067",
        "G06Q30/0203",
        "G06N20/10"
    ],
    "abstract": "A method and device for presenting a prediction model, and a method and device for adjusting a prediction model. The method for presenting a prediction model includes: obtaining at least one prediction result of a prediction model for at least one prediction sample; obtaining at least one decision-making tree training sample for training a decision-making tree model according to the at least one prediction sample and the at least one prediction result, the decision-making tree model being used for fitting the prediction model; training the decision-making tree model by using at least one decision-making tree training sample; and visually presenting the trained decision-making tree model. By means of the method, a prediction model hard to understand can be approximated to a decision-making tree model, and the approximated decision-making tree model is presented, so that a user better understands the prediction model according to the presented decision-making tree model.",
    "claims": "\n1. A method for presenting a prediction model, the method comprising:\nacquiring at least one prediction result obtained by the prediction model with respect to at least one prediction sample;\nacquiring at least one decision tree training sample for training a decision tree model based on the at least one prediction sample and the at least one prediction result, wherein the decision tree model is used to fit the prediction model;\ntraining the decision tree model using the at least one decision tree training sample; and\nvisually presenting the trained decision tree model, wherein nodes presented in the trained decision tree model include intermediate nodes and endpoints, each of the intermediate nodes represents judgment for a certain condition, and a path that satisfies the condition of the intermediate node and a path that does not satisfy the condition of the intermediate node are differentially displayed, and each of the endpoints indicates the prediction result,\nwherein in the acquiring at least one decision tree training sample for training a decision tree model based on the at least one prediction sample and the at least one prediction result, transforming the at least one portion of the features of the prediction sample, using the transformed at least one portion of the features as the features of the decision tree training sample, and acquiring the label of the decision tree training sample based on correspondingly obtained prediction result,\nwherein the label of the decision tree training sample corresponds to the obtained prediction result,\nwherein, the at least one portion of the features of the prediction sample are transformed, in consideration of an expected scale of the decision tree model and/or node interpretability of the decision tree model,\nwherein the transforming of the at least one portion of the features of the prediction sample comprises transforming at least one feature subset among the at least one portion of the features of the prediction sample into at least one corresponding transformation feature subset respectively, and\nwherein the feature subset before being transformed indicates attribute information of the prediction sample, and the corresponding transform feature subset indicates weight information of the attribute information.\n2. The method according to claim 1, wherein the at least one portion of the features of the prediction sample comprise a feature that plays a main role of prediction, and/or a feature that is easy to be understood by a user, among the features of the prediction sample.\n3. The method according to claim 1, wherein a number of the features of the transformation feature subset is less than or equal to a number of the features of a corresponding feature subset before being transformed.\n4. The method according to claim 1, wherein the transforming of the at least one portion of the features of the prediction sample comprises transforming at least one discrete feature subset among the at least one portion of the features of the prediction sample into at least one corresponding continuous feature.\n5. The method according to claim 4, wherein the discrete feature subset indicates attribute information of the prediction sample,\nwherein, the corresponding continuous feature indicates statistical information of the attribute information about a prediction target of the prediction model; or, the corresponding continuous feature indicates a prediction weight of the attribute information about the prediction target of the prediction model.\n6. The method according to claim 1, wherein prior to acquiring at least one prediction result obtained by the prediction model with respect to at least one prediction sample, the method further comprises:\nobtaining the at least one prediction sample based on at least one prediction model training sample on a basis of which the prediction model is trained, and inputting the at least one prediction sample into the prediction model.\n7. The method according to claim 1, wherein in training the decision tree model using the at least one decision tree training sample, the training of the decision tree model is performed under a preset regularization term about an expected scale of the decision tree model.\n8. The method according to claim 7, wherein the regularization term is used to limit a number of nodes, a number of layers, and/or a node sample minimum threshold, of the decision tree model.\n9. The method according to claim 1, wherein the visually presenting of the trained decision tree model comprises visually presenting the trained decision tree model through a pruning process, wherein a node which is cut in the pruning process is not presented, or is presented implicitly.\n10. A computing device for presenting a prediction model, comprising a storage component in which a set of computer-executable instructions is stored, and a processor, wherein when the set of the computer-executable instructions is executed by the processor, following steps are performed:\nacquiring at least one prediction result obtained by the prediction model with respect to at least one prediction sample;\nacquiring at least one decision tree training sample for training a decision tree model based on the at least one prediction sample and the at least one prediction result, wherein the decision tree model is used to fit the prediction model;\ntraining the decision tree model using the at least one decision tree training sample; and\nvisually presenting the trained decision tree model, wherein nodes presented in the trained decision tree model include intermediate nodes and endpoints, each of the intermediate nodes represents judgment for a certain condition, and a path that satisfies the condition of the intermediate node and a path that does not satisfy the condition of the intermediate node are differentially displayed, and each of the endpoints indicates the prediction result,\nwherein in the acquiring at least one decision tree training sample for training a decision tree model based on the at least one prediction sample and the at least one prediction result, transforming the at least one portion of the features of the prediction sample, using the transformed at least one portion of the features as the features of the decision tree training sample, and acquiring the label of the decision tree training sample based on correspondingly obtained prediction result,\nwherein the label of the decision tree training sample corresponds to the obtained prediction result,\nwherein, the at least one portion of the features of the prediction sample are transformed, in consideration of an expected scale of the decision tree model and/or node interpretability of the decision tree model,\nwherein the transforming of the at least one portion of the features of the prediction sample comprises transforming at least one feature subset among the at least one portion of the features of the prediction sample into at least one corresponding transformation feature subset respectively, and\nwherein the feature subset before being transformed indicates attribute information of the prediction sample, and the corresponding transform feature subset indicates weight information of the attribute information.\n11. The computing device according to claim 10, wherein the at least one portion of the features of the prediction sample comprise a feature that plays a main role of prediction, and/or a feature that is easy to be understood by a user, among the features of the prediction sample.\n12. The computing device according to claim 10, wherein the transforming of the at least one portion of the features of the prediction sample comprises transforming at least one discrete feature subset among the at least one portion of the features of the prediction sample into at least one corresponding continuous feature.\n13. The computing device according to claim 12, wherein the discrete feature subset indicates attribute information of the prediction sample,\nwherein, the corresponding continuous feature indicates statistical information of the attribute information about a prediction target of the prediction model; or, the corresponding continuous feature indicates a prediction weight of the attribute information about the prediction target of the prediction model.\n14. A non-transitory computer storage medium storing instructions that when executed by a processor causes the processor to perform operations comprising:\nacquiring at least one prediction result obtained by the prediction model with respect to at least one prediction sample;\nacquiring at least one decision tree training sample for training a decision tree model based on the at least one prediction sample and the at least one prediction result, wherein the decision tree model is used to fit the prediction model;\ntraining the decision tree model using the at least one decision tree training sample; and\nvisually presenting the trained decision tree model, wherein nodes presented in the trained decision tree model include intermediate nodes and endpoints, each of the intermediate nodes represents judgment for a certain condition, and a path that satisfies the condition of the intermediate node and a path that does not satisfy the condition of the intermediate node are differentially displayed, and each of the endpoints indicates the prediction result,\nwherein in the acquiring at least one decision tree training sample for training a decision tree model based on the at least one prediction sample and the at least one prediction result, transforming the at least one portion of the features of the prediction sample, using the transformed at least one portion of the features as the features of the decision tree training sample, and acquiring the label of the decision tree training sample based on correspondingly obtained prediction result,\nwherein the label of the decision tree training sample corresponds to the obtained prediction result,\nwherein, the at least one portion of the features of the prediction sample are transformed, in consideration of an expected scale of the decision tree model and/or node interpretability of the decision tree model,\nwherein the transforming of the at least one portion of the features of the prediction sample comprises transforming at least one feature subset among the at least one portion of the features of the prediction sample into at least one corresponding transformation feature subset respectively, and\nwherein the feature subset before being transformed indicates attribute information of the prediction sample, and the corresponding transform feature subset indicates weight information of the attribute information.",
    "status": "Active",
    "citations_own": [
        "US20030069652A1",
        "US20040172347A1",
        "US20090030864A1",
        "US20100312727A1",
        "JP2012053880A",
        "CN102567391A",
        "US20120232902A1",
        "US20120244507A1",
        "WO2013067337A1",
        "US20130226856A1",
        "US20140279760A1",
        "CN104111920A",
        "US20140337096A1",
        "US20150379426A1",
        "US20160071017A1",
        "CN105930934A"
    ],
    "citations_ftf": [
        "JP3897169B2",
        "US9070047B2",
        "CN103257921B",
        "CN104572786A"
    ],
    "citedby_own": [],
    "citedby_ftf": [
        "CN108960514B",
        "US11100421B2",
        "CN107103514A",
        "CN107392085B",
        "US11392827B1",
        "CN107688870B",
        "CN107866072B",
        "CN107832581B",
        "CN108346107B",
        "CN108090032B",
        "CN108304915B",
        "US20190258900A1",
        "US11449762B2",
        "CN108596434B",
        "CN110322334A",
        "CN109426891A",
        "CN108961071B",
        "US20210166181A1",
        "CN108960434B",
        "CN110766164A",
        "CN109091867B",
        "CN111062736A",
        "CN109634828A",
        "JP2022516172A",
        "CN109767269B",
        "CN110196945B",
        "CN112257890A",
        "CN110378739B",
        "CN110675959B",
        "CN110705592A",
        "CN110782128A",
        "US20210110298A1",
        "CN110795603B",
        "CN111242182A",
        "CN111259975B",
        "US11640556B2",
        "CN111309852B",
        "CN111401570B",
        "CN111489037B",
        "CN111814385A",
        "CN111402143B",
        "CN111428008B",
        "CN111722720B",
        "CN111797995A",
        "US11704185B2",
        "CN111967581B",
        "CN112084716B",
        "CN112017777B",
        "CN112329874A",
        "CN112256537A",
        "CN112101574B",
        "CN114757244A",
        "CN112734195B",
        "US11636132B1",
        "CN113298004B",
        "CN113379301A",
        "CN115423148B",
        "CN116522958A"
    ]
}