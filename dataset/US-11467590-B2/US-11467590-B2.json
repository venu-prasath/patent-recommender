{
    "patent_id": "US-11467590-B2",
    "title": "Techniques for considering uncertainty in use of artificial intelligence models ",
    "assignee": "SafeAI, Inc.",
    "publication_date": "2022-10-11",
    "patent_link": "https://patents.google.com/patent/US11467590B2/en",
    "inventors": [
        "Bibhrajit HALDER"
    ],
    "classifications": [
        "B62D15/0255",
        "G05D1/0221",
        "G05D1/0088",
        "G06N3/006",
        "G06N3/08",
        "G06N3/084",
        "G05D1/024",
        "G05D1/0246",
        "G05D1/0255",
        "G05D1/0257",
        "G05D1/027",
        "G05D1/0278",
        "G05D2201/0213",
        "G06N3/045"
    ],
    "abstract": "An infrastructure is provided for improving the safety of autonomous systems. An autonomous vehicle management system (AVMS) controls one or more autonomous functions or operations performed by a vehicle or machine such that the autonomous operations are performed in a safe manner. The AVMS uses various artificial intelligence (AI) based techniques (e.g., neural networks, reinforcement learning (RL) techniques, etc.) and models as part of its processing. For an inferring data point, for which a prediction is made by AVMS using an AI model, the AVMS checks how statistically similar (or dissimilar) the inferring data point is to the distribution of the training dataset. A score (confidence score) is generated indicative of how similar or dissimilar the inferring data point is to the training dataset. The AVMS uses this confidence score to decide how the prediction made by the AI model is to be used.",
    "claims": "\n1. A method comprising:\nreceiving, by a controller system configured to control an autonomous operation of a vehicle, an inferring data point, the inferring data point received from a sensor associated with the vehicle;\ninferencing, by the controller system using a model trained using training data, a prediction based upon the inferring data point, wherein the training data comprises a set of sensor inputs labeled with ground truth information, the sensor inputs represent data points for the training data, each of the data points is represented by a vector comprising \u201cN\u201d attributes or dimensions, where N>=1, each vector is mapped to a point in N-dimensional space, and all the data points taken together and mapped in the N-dimensional space define a distribution of the data points in the training data;\ncomparing, by the controller system, the inferring data point to a distribution of data points in the training data, wherein the comparison comprises mapping or plotting the inferring data point to a data point in the N-dimensional space and determining a distance of the data point to the distribution of the data points in the training data using a distance measuring technique;\ncomputing, by the controller system, a score for the inferring data point based on the comparison between the inferring data points and the distribution of the data points in the training data, wherein the score is indicative of a degree of similarity or difference between the inferring data point and the data points in the training data; and\ndetermining, by the controller system, based upon the score, whether the prediction is used by the controller system for controlling the autonomous operation of the vehicle.\n2. The method of claim 1 wherein the distance measuring technique is a Mahalanobis distance technique, a Generalized Mahalanobis distance technique, or a Cosine Similarity technique.\n3. The method of claim 1 wherein comparison further comprises:\nplotting, in the N-dimensional space, a plurality of points corresponding to the data points in the training data;\nand\nmeasuring the distance, in the N-dimensional space, between the data point corresponding to the inferring data point and the distribution of the plurality of points corresponding to the data points in the training data.\n4. The method of claim 1 wherein the inferring data point is a sensor input from a radar sensor, a LIDAR sensor, a camera, a Global Positioning System (GPS) sensor, a Inertial Measurement Unit sensor, a Vehicle-to-everything sensor, an audio sensor, a proximity sensor, or a SONAR sensor associated with the vehicle.\n5. The method of claim 1 wherein the model is a neural network.\n6. The method of claim 1 wherein controlling the autonomous operation of the vehicle comprises identifying, based upon the inferring data point, an action to be performed by the vehicle, wherein the action is associated with the autonomous operation of the vehicle.\n7. The method of claim 1 wherein the determining comprises:\ndetermining, based upon the score, that the degree of similarity between the inferring data point and the training data is below a threshold degree of similarity; and\ndeciding, by the controller system, not to use the prediction for controlling the autonomous operation of the vehicle.\n8. The method of claim 7 further comprising:\nadding the inferring data point to the training data to create updated training data; and\nretraining the model using the updated training data.\n9. A non-transitory computer-readable medium storing instructions that, when executed by one or more processors, cause the one or more processors to perform processing including:\nreceiving an inferring data point, the inferring data point received from a sensor associated with the vehicle;\ninferencing, by the controller system using a model trained using training data, a prediction based upon the inferring data point, wherein the training data comprises a set of sensor inputs labeled with ground truth information, the sensor inputs represent data points for the training data, each of the data points is represented by a vector comprising \u201cN\u201d attributes or dimensions, where N>=1, each vector is mapped to a point in N-dimensional space, and all the data points taken together and mapped in the N-dimensional space define a distribution of the data points in the training data;\ncomparing, by the controller system, the inferring data point to a distribution of data points in the training data, wherein the comparison comprises mapping or plotting the inferring data point to a data point in the N-dimensional space and determining a distance of the data point to the distribution of the data points in the training data using a distance measuring technique;\ncomputing, by the controller system, a score for the inferring data point based on the comparison between the inferring data points and the distribution of the data points in the training data, wherein the score is indicative of a degree of similarity or difference between the inferring data point and the data points in the training data; and\ndetermining, by the controller system, based upon the score, whether the prediction is used by the controller system for controlling the autonomous operation of the vehicle.\n10. The non-transitory computer-readable medium of claim 9 wherein the distance measuring technique is a Mahalanobis distance technique, a Generalized Mahalanobis distance technique, or a Cosine Similarity technique.\n11. The non-transitory computer-readable medium of claim 9 wherein the inferring data point is an image of an environment of the vehicle and the training data includes a plurality of images.\n12. The non-transitory computer-readable medium of claim 9 wherein the model is a neural network.\n13. The non-transitory computer-readable medium of claim 9 wherein the determining comprises:\nidentifying, by the controller system, based upon the inferring data point, an action to be performed by the vehicle, wherein the action is associated with the autonomous operation of the vehicle; and\ndetermining, by the controller system based upon the score, whether the prediction is used by the controller system for identifying the action to be performed.\n14. The non-transitory computer-readable medium of claim 9 wherein the determining comprises:\ndetermining, based upon the score, that the degree of similarity between the inferring data point and the training data is below a threshold degree of similarity; and\ndeciding, by the controller system, not to use the prediction for controlling the autonomous operation of the vehicle;\nthe processing further comprising:\nadding the inferring data point to the training data to create updated training data; and\nretraining the model using the updated training data.\n15. A system comprising:\na sensor; and\na controller system, the controller system configured to control an autonomous operation of a vehicle; and\nwherein the controller system is configured to perform processing including:\nreceiving an inferring data point from the sensor;\ninferencing, using a model trained using training data, a prediction based upon the inferring data point, wherein the training data comprises a set of sensor inputs labeled with ground truth information, the sensor inputs represent data points for the training data, each of the data points is represented by a vector comprising \u201cN\u201d attributes or dimensions, where N>=1, each vector is mapped to a point in N-dimensional space, and all the data points taken together and mapped in the N-dimensional space define a distribution of the data points in the training data;\ncomparing the inferring data point to a distribution of data points in the training data, wherein the comparison comprises mapping or plotting the inferring data point to a data point in the N-dimensional space and determining a distance of the data point to the distribution of the data points in the training data using a distance measuring technique;\ncomputing a score for the inferring data point based on the comparison between the inferring data points and the distribution of the data points in the training data, wherein the score is indicative of a degree of similarity or difference between the inferring data point and the data points in the training data; and\ndetermining, based upon the score, whether the prediction is used by the controller system for controlling the autonomous operation of the vehicle.\n16. The system of claim 15 wherein the determining comprises:\nidentifying, based upon the inferring data point, an action to be performed by the vehicle, wherein the action is associated with the autonomous operation of the vehicle; and\ndetermining, based upon the score, whether the prediction is used by the controller system for identifying the action to be performed.\n17. The system of claim 15 wherein the determining comprises:\ndetermining, based upon the score, that the degree of similarity between the inferring data point and the training data is below a threshold degree of similarity; and\ndeciding not to use the prediction for controlling the autonomous operation of the vehicle;\nthe processing further comprising:\nadding the inferring data point to the training data to create updated training data; and\nretraining the model using the updated training data.",
    "status": "Active",
    "citations_own": [
        "US20040258360A1",
        "WO2005103848A1",
        "WO2008005659A2",
        "US20080027590A1",
        "US20080144944A1",
        "US20080236275A1",
        "US20090234499A1",
        "US20100106356A1",
        "CN101784774A",
        "DE102009001242A1",
        "US7857760B2",
        "US20110125323A1",
        "US20110141311A1",
        "US20110190972A1",
        "US8133178B2",
        "US20120089291A1",
        "US8233959B2",
        "US20120281907A1",
        "CN102782733A",
        "US20130302758A1",
        "EP2733560A1",
        "CN104380349A",
        "US20150310281A1",
        "US9187088B1",
        "US20150339570A1",
        "US9247900B2",
        "CN105388801A",
        "US20160096270A1",
        "US20160221500A1",
        "US9417637B2",
        "US9446194B2",
        "DE202016004628U1",
        "CN106144861A",
        "CN106456067A",
        "US20170060132A1",
        "US20170147722A1",
        "US20170151910A1",
        "WO2017091629A1",
        "US20170168146A1",
        "US20170248963A1",
        "US20170297576A1",
        "US20170357270A1",
        "US20180032042A1",
        "US20180032040A1",
        "US20180074493A1",
        "US20180089563A1",
        "US20180093676A1",
        "US20180107770A1",
        "US20180136000A1",
        "US20180136644A1",
        "CN108290540A",
        "US10025316B1",
        "CN108292356A",
        "US20180233047A1",
        "CN108725446A",
        "US20190025857A1",
        "US20190047586A1",
        "US20190094858A1",
        "US20190113927A1",
        "US20190291727A1",
        "US20190310636A1",
        "US20190310654A1",
        "US20190310627A1",
        "US20190361672A1",
        "US10809735B2",
        "US10976178B2"
    ],
    "citations_ftf": [],
    "citedby_own": [
        "US20210325892A1",
        "US20220135059A1",
        "US11625036B2"
    ],
    "citedby_ftf": [
        "JP6728495B2",
        "JP6939378B2",
        "WO2019136375A1",
        "US11561541B2",
        "US10809735B2",
        "US11169536B2",
        "US10671077B2",
        "US20190346841A1",
        "US20190384303A1",
        "US10885905B2",
        "US11507099B2",
        "KR20210061461A",
        "US11231717B2",
        "AU2019396213A1",
        "IL270540A",
        "WO2020163390A1",
        "EP3739418B1",
        "WO2021078361A1",
        "CN110764507A",
        "US11531107B2",
        "US11514363B2",
        "US20210191387A1",
        "US11332165B2",
        "US11645456B2",
        "US11367347B2",
        "US11518406B2",
        "US11310349B1",
        "DE102020213027A1",
        "US20220146277A1",
        "EP4001041A1",
        "WO2023287970A1",
        "CN114140723B",
        "TWI809592B",
        "US11640562B1"
    ]
}