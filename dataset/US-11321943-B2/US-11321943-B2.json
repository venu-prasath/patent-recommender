{
    "patent_id": "US-11321943-B2",
    "title": "Crop type classification in images ",
    "assignee": "X Development Llc",
    "publication_date": "2022-05-03",
    "patent_link": "https://patents.google.com/patent/US11321943B2/en",
    "inventors": [
        "Cheng-en Guo",
        "Jie Yang",
        "Elliott Grant"
    ],
    "classifications": [
        "G06N3/08",
        "G06F18/24143",
        "G06K9/6274",
        "G06N20/20",
        "G06N3/045",
        "G06N7/005",
        "G06N7/01",
        "G06T7/174",
        "G06T7/77",
        "G06V10/30",
        "G06V10/454",
        "G06V10/764",
        "G06V10/82",
        "G06V20/13",
        "G06V20/17",
        "G06V20/188",
        "G06Q50/02",
        "G06T2207/10024",
        "G06T2207/10032",
        "G06T2207/10036",
        "G06T2207/10048",
        "G06T2207/20081",
        "G06T2207/20084",
        "G06T2207/30188"
    ],
    "abstract": "In embodiments, obtaining a plurality of image sets associated with a geographical region and a time period, wherein each image set of the plurality of image sets comprises multi-spectral and time series images that depict a respective particular portion of the geographical region during the time period, and predicting one or more crop types growing in each of particular locations within the particular portion of the geographical region associated with an image set of the plurality of image sets. Determining a crop type classification for each of the particular locations based on the predicted one or more crop types for the respective particular locations, and generating a crop indicative image comprising at least one image of the multi-spectral and time series images of the image set overlaid with indications of the crop type classification determined for the respective particular locations.",
    "claims": "\n1. A method comprising:\nreceiving, by a computing device, input containing one or more search parameters, wherein the one or more search parameters include one or more of a latitude, a longitude, a county, a size, a shape, and an identifier; and\npresenting, by the computing device, a crop indicative image depicting a portion of a geographical region, wherein the portion of the geographical region is selected based on the one or more search parameters, and wherein the crop indicative image includes at least one image of an image set associated with the geographical region overlaid with indications of crop type classifications determined for particular locations depicted in the at least one image;\nwherein the crop type classifications determined for the particular locations depicted in the at least one image are determined by:\nobtaining a plurality of image sets associated with the geographical region and a time period, wherein each image set of the plurality of image sets comprises multi-spectral and time series images that depict a respective particular portion of the geographical region during the time period;\npredicting one or more crop types growing in each of particular locations within the particular portion of the geographical region associated with an image set of the plurality of image sets; and\ndetermining a crop type classification for each of the particular locations based on the predicted one or more crop types for the respective particular locations;\nwherein determining the crop type classification for each of the particular locations comprises:\nin response to determining that the crop types predicted for the respective particular location include a dominant majority predicted crop type, selecting the dominant majority predicted crop type as the crop type classification; and\nin response to determining that the crop types predicted for the respective particular location does not include a dominant majority predicted crop type:\nsplitting the respective particular location into a plurality of sub-particular locations; and\nclassifying each respective sub-particular location as a respective crop type of the crop types predicted for the particular location.\n2. The method of claim 1, further comprising providing a user interface through which crop type classifications are capable of being manually modified by a user;\nreceiving crop type classification modifications from the user; and\nupdating a database storing the at least one image and the crop type classifications with the crop type classification modifications.\n3. The method of claim 1, wherein predicting the one or more crop types growing in each of the particular locations comprises:\npredicting presence of a crop at the particular locations;\ndetermining crop boundary locations within the particular portion of the geographical region based on the predicted presence of the crop at the particular locations; and\npredicting the one or more crop types growing within each of the determined crop boundary locations.\n4. The method of claim 1, further comprising presenting, by the computing device, an estimate of a crop yield for each of the particular locations based on the crop type classification determined for the respective particular locations.\n5. The method of claim 1, further comprising presenting, by the computing device, guidance regarding crop management practices for each of the particular locations based on the crop type classification determined for the respective particular locations.\n6. The method of claim 1, wherein determining the crop type classification for each of the particular locations comprises determining the crop type classification to a sub-meter ground resolution for each of the particular locations.\n7. The method of claim 1, wherein predicting the one or more crop types growing in each of the particular locations comprises applying the image set to one or more machine learning systems or a convolutional neural network (CNN).\n8. The method of claim 7, wherein the one or more machine learning systems or CNN is configured to predict the one or more crop types growing in each of the particular locations after supervised training on ground truth data.\n9. The method of claim 8, wherein the ground truth data comprises one or more of government crop data, publicly available crop data, images with crop areas identified at low ground resolution, images with crop types identified at low ground resolution, images with manually identified crop boundaries, images with manually identified crop boundaries and crop types, crop survey data, sampled crop data, and farmer reports.\n10. The method of claim 1, wherein predicting the one or more crop types growing in each of the particular locations comprises, for each of the particular locations, analyzing the time series images for changes over time of pixels associated with the respective particular locations, wherein a particular change pattern of the pixels is associated with at least one crop type.\n11. One or more non-transitory computer-readable storage media comprising a plurality of instructions to cause an apparatus, in response to execution by one or more processors of the apparatus, to:\nreceive input containing one or more search parameters, wherein the one or more search parameters include one or more of a latitude, a longitude, a county, a size, a shape, and an identifier; and\npresent a crop indicative image depicting a portion of a geographical region, wherein the portion of the geographical region is selected based on the one or more search parameters, and wherein the crop indicative image includes at least one image of an image set associated with the geographical region overlaid with indications of crop type classifications determined for particular locations depicted in the at least one image;\nwherein the crop type classifications determined for the particular locations depicted in the at least one image are determined by:\nobtaining a plurality of image sets associated with the geographical region and a time period, wherein each image set of the plurality of image sets comprises multi-spectral and time series images that depict a respective particular portion of the geographical region during the time period;\npredicting one or more crop types growing in each of particular locations within the particular portion of the geographical region associated with an image set of the plurality of image sets; and\ndetermining a crop type classification for each of the particular locations based on the predicted one or more crop types for the respective particular locations;\nwherein predicting the one or more crop types growing in each of the particular locations comprises applying the image set to one or more machine learning systems, wherein the one or more machine learning systems include a convolutional neural network (CNN); and\nwherein the one or more machine learning systems are configured to predict the one or more crop types growing in each of the particular locations after supervised training on ground truth data.\n12. The computer-readable storage medium of claim 11, wherein the instructions further cause the apparatus to:\nprovide a user interface through which crop type classifications are capable of being manually modified by a user;\nreceive crop type classification modifications from the user; and\nupdate a database storing the at least one image and the crop type classifications with the crop type classification modifications.\n13. The computer-readable storage medium of claim 11, wherein predicting the one or more crop types growing in each of the particular locations comprises:\npredicting presence of a crop at the particular locations;\ndetermining crop boundary locations within the particular portion of the geographical region based on the predicted presence of the crop at the particular locations; and\npredicting the one or more crop types growing within each of the determined crop boundary locations.\n14. The computer-readable storage medium of claim 11, wherein determining the crop type classification for each of the particular locations comprises, for each of the particular locations, selecting a dominant majority predicted crop type from among the crop types predicted for the respective particular locations, wherein the dominant majority predicted crop type is the crop type classification.\n15. The computer-readable storage medium of claim 11, wherein determining the crop type classification for each of the particular locations comprises:\nfor each of the particular locations, if the dominant majority predicted crop type is absent, splitting the respective particular location into a plurality of sub-particular locations and classifying each of the respective sub-particular locations of the plurality of sub-particular locations as a respective crop type of the crop types predicted for the particular location.\n16. The computer-readable storage medium of claim 11, wherein determining the crop type classification for each of the particular locations comprises determining the crop type classification to a sub-meter ground resolution for each of the particular locations.\n17. The computer-readable storage medium of claim 11, wherein the ground truth data comprises one or more of government crop data, publicly available crop data, images with crop areas identified at low ground resolution, images with crop types identified at low ground resolution, images with manually identified crop boundaries, images with manually identified crop boundaries and crop types, crop survey data, sampled crop data, and farmer reports.\n18. The computer-readable storage medium of claim 11, wherein a first resolution of a first image of the image set is different from a second resolution of a second image of the image set, the first resolution is lower than a third resolution of the crop indicative image, and a fourth resolution of at least a portion of the ground truth data is lower than the third resolution of the crop indicative image.\n19. The computer-readable storage medium of claim 11, wherein predicting the one or more crop types growing in each of the particular locations comprises, for each of the particular locations, analyzing the time series images for changes over time of pixels associated with the respective particular locations, wherein a particular change pattern of the pixels is associated with at least one crop type.\n20. The computer-readable storage medium of claim 11, wherein the instructions further cause the apparatus to present an estimate of a crop yield for each of the particular locations based on the crop type classification determined for the respective particular locations or present guidance regarding crop management practices for each of the particular locations based on the crop type classification determined for the respective particular locations.",
    "status": "Active",
    "citations_own": [
        "JP2003006612A",
        "US20060287896A1",
        "US20070036467A1",
        "US7916898B2",
        "CN102194127A",
        "JP2014102542A",
        "US20140172754A1",
        "CN104952070A",
        "CN104951754A",
        "US20150278640A1",
        "US9152938B2",
        "CN105005782A",
        "US9256907B2",
        "WO2016035149A1",
        "US20160247082A1",
        "US9619734B2",
        "US20170161560A1",
        "US20170213109A1",
        "CN107358214A",
        "US20180082223A1",
        "US20180330435A1",
        "US10909368B2",
        "US20210397857A1",
        "US20220044146A1"
    ],
    "citations_ftf": [
        "CN1382370A",
        "JP2008148565A",
        "US8055081B2",
        "CN103443820B",
        "US8310361B1",
        "US9946931B2",
        "US9813512B2",
        "US10025983B2",
        "EP3438954A4"
    ],
    "citedby_own": [
        "US11763557B1"
    ],
    "citedby_ftf": [
        "US10445877B2",
        "US10664702B2",
        "US10586105B2",
        "US10678244B2",
        "US11157441B2",
        "US10671349B2",
        "US11409692B2",
        "US11263707B2",
        "US10909368B2",
        "US10621434B2",
        "US11561791B2",
        "US11367093B2",
        "EP3785214A1",
        "US11215999B2",
        "US11636333B2",
        "US11562231B2",
        "US11034357B2",
        "US11195030B2",
        "US11197417B2",
        "US11196678B2",
        "US11589509B2",
        "US11079725B2",
        "US11641800B2",
        "US11467605B2",
        "US11178818B2",
        "US11240961B2",
        "US11653588B2",
        "US11672203B2",
        "US11537811B2",
        "US11610117B2",
        "US10997461B2",
        "US11567514B2",
        "US10956755B2",
        "US11234366B2",
        "TWI760782B",
        "US11238283B2",
        "US11157811B2",
        "US11477940B2",
        "CN111539350A",
        "US11500876B2",
        "US11748984B2",
        "US11393194B2",
        "US11592822B2",
        "US11675354B2",
        "US11635765B2",
        "US11727680B2",
        "US11474523B2",
        "US11711995B2",
        "US11650587B2",
        "CN112287186B",
        "WO2022200547A1",
        "US20220350991A1",
        "US20220391614A1",
        "US11531656B1",
        "CN113435649B",
        "WO2023275086A1",
        "KR102390740B1",
        "CN113591611B",
        "US20230046882A1",
        "WO2023095041A1",
        "EP4246462A1"
    ]
}