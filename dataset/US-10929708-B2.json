{
    "patent_id": "US-10929708-B2",
    "title": "Deep learning network for salient region identification in images ",
    "assignee": "International Business Machines Corporation",
    "publication_date": "2021-02-23",
    "patent_link": "https://patents.google.com/patent/US10929708B2/en",
    "inventors": [
        "Tanveer F. Syeda-Mahmood",
        "Alexandras Karargyris"
    ],
    "classifications": [
        "G06K9/4676",
        "G06N3/088",
        "G06F18/24143",
        "G06K9/4609",
        "G06N3/042",
        "G06N3/045",
        "G06N3/08",
        "G06N5/041",
        "G06T11/003",
        "G06T7/0012",
        "G06V10/26",
        "G06V10/454",
        "G06V10/764",
        "G06V10/82",
        "G06T2207/10081",
        "G06T2207/10088",
        "G06T2207/10104",
        "G06T2207/10132",
        "G06T2207/20081",
        "G06T2207/20084",
        "G06T2207/30016",
        "G06V2201/03"
    ],
    "abstract": "Mechanisms are provided to implement a hybrid deep learning network. The hybrid deep learning network receives, from a imaging system, first input data specifying a non-annotated image. The hybrid deep learning network pre-processes the non-annotated image to generate second input data specifying a hint image and corresponding annotation data specifying salient regions of the hint image. The hybrid deep learning network processes the first input data and second input data to perform training of the hybrid deep learning network by targeting feature detection in the non-annotated image in the salient regions identified in the hint image. The trained hybrid deep learning network is used to process third input data specifying a new non-annotated image to thereby identify an object or structure in the new non-annotated image.",
    "claims": "\n1. A method, in a data processing system comprising at least one processor and at least one memory, wherein the at least one memory comprises instructions that are executed by the at least one processor to cause the at least one processor to implement a hybrid deep learning network, and wherein the method comprises:\nreceiving, by the hybrid deep learning network, from an imaging system, first input data specifying a non-annotated image;\npre-processing, by the hybrid deep learning network, the non-annotated image to generate second input data specifying a hint image and corresponding annotation data specifying salient regions of the hint image;\nprocessing, by the hybrid deep learning network, the first input data and second input data to perform training of the hybrid deep learning network by targeting feature detection in the non-annotated image in the salient regions identified in the hint image; and\nprocessing, using the trained hybrid deep learning network, third input data specifying a new non-annotated image to thereby identify an object or structure in the new non-annotated image, wherein processing the first input data and second input data to perform training of the hybrid deep learning network comprises at least one of:\nperforming an outer fusion operation to combine the first input data with the second input data to generate a combined image input, prior to inputting the combined image input into the deep learning network, wherein the deep learning network utilizes a single set of one or more convolutional filter layers to process the combined image input;\nperforming an inner fusion operation to submit the first input data to a first set of one or more convolutional filter layers of the deep learning network, and to submit the second input data to a second set of one or more convolutional filter layers of the deep learning network, and wherein outputs of the first set of one or more convolutional filter layers and the second set of one or more convolutional filter layers are merged to form a combined feature input to a de-convolution portion of the deep learning network; or\nperforming a substitution operation to substitute the second input data for the first input data as input to the deep learning network to perform training of the hybrid deep learning network.\n2. The method of claim 1, wherein processing the first input data and second input data to perform training of the hybrid deep learning network by targeting feature detection in the non-annotated image in the salient regions identified in the hint image comprises filtering out regions of the non-annotated image that are not specified in the hint image as being salient regions.\n3. The method of claim 1, wherein the pre-processing of the non-annotated image comprises generating the hint image at least by performing, on the non-annotated image, a multi-level thresholding operation with region grouping based on one or more saliency operators.\n4. The method of claim 3, wherein the plurality of saliency operations comprise at least one image characteristic, and wherein the at least one image characteristic comprises at least one of a region size, a region location, color value, or an intensity value.\n5. The method of claim 1, wherein the pre-processing of the non-annotated image comprises applying a region size filter on regions of the non-annotated image having different tissue densities to thereby identify salient regions within the non-annotated image.\n6. The method of claim 5, wherein the pre-processing of the non-annotated image further comprises performing a color connected component grouping that identifies salient regions within the non-annotated image, where anatomical structures in the non-annotated image that have similar characteristics have similar coloring in the non-annotated image.\n7. The method of claim 6, further comprising:\nperforming task specific filtering of salient regions in the pre-processed non-annotated image to identify salient regions of interest to the particular task being performed; and\ngenerating the hint image based on the filtered salient regions, wherein the task specific filtering comprises applying task specific saliency measures indicating either positive or negative saliency for the particular task.\n8. The method of claim 1, wherein the annotation data specifies one or more contours in the non-annotated image, and one or more corresponding labels, identifying anatomical structures present in the non-annotated image.\n9. The method of claim 1, wherein the imaging system is at least one of a x-ray imaging system, a sonogram imaging system, a computed tomography (CT) scan imaging system, a positron emission tomography (PET) scan imaging system, magnetic resonance image (MRI) imaging system, or an echocardiography imaging system.\n10. A computer program product comprising a computer readable storage medium having a computer readable program stored therein, wherein the computer readable program, when executed on a data processing system, causes the data processing system to implement a hybrid deep learning network that operates to:\nreceive, from an imaging system, first input data specifying a non-annotated image;\npre-process the non-annotated image to generate second input data specifying a hint image and corresponding annotation data specifying salient regions of the hint image; and\nprocess the first input data and second input data to perform training of the hybrid deep learning network by targeting feature detection in the non-annotated image in the salient regions identified in the hint image, and wherein the data processing system further processes, using the trained hybrid deep learning network, third input data specifying a new non-annotated image to thereby identify an object or structure in the new non-annotated image, wherein the computer readable program further causes the hybrid deep learning network to process the first input data and second input data to perform training of the hybrid deep learning network at least by one of:\nperforming an outer fusion operation to combine the first input data with the second input data to generate a combined image input, prior to inputting the combined image input into the deep learning network, wherein the deep learning network utilizes a single set of one or more convolutional filter layers to process the combined image input;\nperforming an inner fusion operation to submit the first input data to a first set of one or more convolutional filter layers of the deep learning network, and to submit the second input data to a second set of one or more convolutional filter layers of the deep learning network, and wherein outputs of the first set of one or more convolutional filter layers and the second set of one or more convolutional filter layers are merged to form a combined feature input to a de-convolution portion of the deep learning network; or\nperforming a substitution operation to substitute the second input data for the first input data as input to the deep learning network to perform training of the hybrid deep learning network.\n11. The computer program product of claim 10, wherein the computer readable program further causes the hybrid deep learning network to process the first input data and second input data to perform training of the hybrid deep learning network by targeting feature detection in the non-annotated image in the salient regions identified in the hint image at least by filtering out regions of the non-annotated image that are not specified in the hint image as being salient regions.\n12. The computer program product of claim 10, wherein the computer readable program further causes the hybrid deep learning network to pre-process the non-annotated image at least by generating the hint image at least by performing, on the non-annotated image, a multi-level thresholding operation with region grouping based on one or more saliency operators.\n13. The computer program product of claim 12, wherein the plurality of saliency operations comprise at least one image characteristic, and wherein the at least one image characteristic comprises at least one of a region size, a region location, color value, or an intensity value.\n14. The computer program product of claim 10, wherein the computer readable program further causes the hybrid deep learning network to pre-process the non-annotated image at least by applying a region size filter on regions of the non-annotated image having different tissue densities to thereby identify salient regions within the non-annotated image.\n15. The computer program product of claim 14, wherein the computer readable program further causes the hybrid deep learning network to pre-process the non-annotated image further at least by performing a color connected component grouping that identifies salient regions within the non-annotated image, where anatomical structures in the non-annotated image that have similar characteristics have similar coloring in the non-annotated image.\n16. The computer program product of claim 15, wherein the computer readable program further causes the hybrid deep learning network to:\nperform task specific filtering of salient regions in the pre-processed non-annotated image to identify salient regions of interest to the particular task being performed; and\ngenerate the hint image based on the filtered salient regions, wherein the task specific filtering comprises applying task specific saliency measures indicating either positive or negative saliency for the particular task.\n17. The computer program product of claim 10, wherein the annotation data specifies one or more contours in the non-annotated image, and one or more corresponding labels, identifying anatomical structures present in the non-annotated image.\n18. A data processing system comprising:\nat least one processor; and\nat least one memory coupled to the at least one processor, wherein the at least one memory comprises instructions which, when executed by the at least one processor, cause the at least one processor to implement a hybrid deep learning network that operates to:\nreceive, from an imaging system, first input data specifying a non-annotated image;\npre-process the non-annotated image to generate second input data specifying a hint image and corresponding annotation data specifying salient regions of the hint image; and\nprocess the first input data and second input data to perform training of the hybrid deep learning network by targeting feature detection in the non-annotated image in the salient regions identified in the hint image, and wherein the data processing system further processes, using the trained hybrid deep learning network, third input data specifying a new non-annotated image to thereby identify an object or structure in the new non-annotated image, wherein the instructions further cause the hybrid deep learning network to process the first input data and second input data to perform training of the hybrid deep learning network at least by one of:\nperforming an outer fusion operation to combine the first input data with the second input data to generate a combined image input, prior to inputting the combined image input into the deep learning network, wherein the deep learning network utilizes a single set of one or more convolutional filter layers to process the combined image input;\nperforming an inner fusion operation to submit the first input data to a first set of one or more convolutional filter layers of the deep learning network, and to submit the second input data to a second set of one or more convolutional filter layers of the deep learning network, and wherein outputs of the first set of one or more convolutional filter layers and the second set of one or more convolutional filter layers are merged to form a combined feature input to a de-convolution portion of the deep learning network; or\nperforming a substitution operation to substitute the second input data for the first input data as input to the deep learning network to perform training of the hybrid deep learning network."
}