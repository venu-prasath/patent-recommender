{
    "patent_id": "US-2020082270-A1",
    "title": "Verifiable Deep Learning Training Service ",
    "assignee": "International Business Machines Corporation",
    "publication_date": "2020-03-12",
    "patent_link": "https://patents.google.com/patent/US20200082270A1/en",
    "inventors": [
        "Zhongshu Gu",
        "Heqing Huang",
        "Jialong Zhang",
        "Dong Su",
        "Dimitrios Pendarakis",
        "Ian M. Molloy"
    ],
    "classifications": [
        "G06N3/084",
        "G06F21/606",
        "G06F21/602",
        "G06F21/71",
        "G06N3/042",
        "G06N3/045",
        "G06N5/022",
        "G06N5/041",
        "G06N5/045"
    ],
    "abstract": "Deep learning training service framework mechanisms are provided. The mechanisms receive encrypted training datasets for training a deep learning model, execute a FrontNet subnet model of the deep learning model in a trusted execution environment, and execute a BackNet subnet model of the deep learning model external to the trusted execution environment. The mechanisms decrypt, within the trusted execution environment, the encrypted training datasets and train the FrontNet subnet model and BackNet subnet model of the deep learning model based on the decrypted training datasets. The FrontNet subnet model is trained within the trusted execution environment and provides intermediate representations to the BackNet subnet model which is trained external to the trusted execution environment using the intermediate representations. The mechanisms release a trained deep learning model comprising a trained FrontNet subnet model and a trained BackNet subnet model, to the one or more client computing devices.",
    "claims": "\n1. A method, in a data processing system comprising at least one processor and at least one memory, the at least one memory comprising instructions that are executed by the at least one processor to configure the at least one processor to implement a deep learning training service framework, the method comprising:\nreceiving, by the deep learning training service framework, from one or more client computing devices, one or more encrypted training datasets for training a deep learning model;\nexecuting, by the deep learning training service framework, a FrontNet subnet model of the deep learning model in a trusted execution environment of the deep learning training service framework;\nexecuting, by the deep learning training service framework, a BackNet subnet model of the deep learning model in the deep learning training service framework external to the trusted execution environment;\ndecrypting, by a security module executing within the trusted execution environment, the one or more encrypted training datasets;\ntraining, by training logic of the deep learning training service framework, the FrontNet subnet model and BackNet subnet model of the deep learning model based on the decrypted training datasets, wherein the FrontNet subnet model is trained within the trusted execution environment and provides intermediate representations to the BackNet subnet model which is trained external to the trusted execution environment using the intermediate representations; and\nreleasing, by the deep learning training service framework, a trained deep learning model comprising a trained FrontNet subnet model and a trained BackNet subnet model, to the one or more client computing devices.\n2. The method of claim 1, wherein the one or more client computing devices comprises a plurality of computing devices associated with a plurality of different training dataset providers, and wherein the security module executing within the trusted execution environment prevents training dataset providers from accessing training datasets provided by other training dataset providers.\n3. The method of claim 2, wherein each of the training datasets provided by the different training dataset providers are used during the training of the FrontNet subnet model and the BackNet subnet model of the deep learning model to generate the trained deep learning model, and wherein the same trained deep learning model is released to each of the different training dataset providers.\n4. The method of claim 1, further comprising:\nprior to decrypting the one or more encrypted training datasets, authenticating, by the security module, training dataset providers of the one or more training dataset providers; and\ndiscarding, by the security module, any training datasets from training dataset providers that do not pass the authentication from further use during training of the FrontNet subnet model and BackNet subnet model of the deep learning model.\n5. The method of claim 4, further comprising:\nverifying, by the security module, the integrity of the one or more training datasets; and\ndiscarding, by the security module, any training datasets that do not pass the verification from further use during training of the FrontNet subnet model and BackNet subnet model of the deep learning model.\n6. The method of claim 1, further comprising:\ngenerating, by a fingerprint generation module executing within the trusted execution environment, one or more first fingerprint data structures for the one or more training datasets; and\nstoring, by the fingerprint generation module, the generated one or more first fingerprint data structures in an evidence storage.\n7. The method of claim 6, further comprising:\nprocessing, by the trained deep learning model, new input data to generate an output result and a second fingerprint data structure corresponding to the new input data;\nreceiving, from a client device of the one or more client devices, a query comprising the second fingerprint data structure;\nsearching, by a query module executing in the deep learning training service framework, the evidence storage for a first fingerprint data structure similar to the second fingerprint data structure; and\nidentifying, by the query module, a training dataset, of the one or more training datasets, and a corresponding training dataset provider based on an entry in the evidence storage having a first fingerprint data structure similar to the second fingerprint data structure.\n8. The method of claim 7, further comprising:\nperforming at least one of a debugging operation or a root cause analysis on the trained deep learning model based on the identified training dataset and identified corresponding training dataset provider.\n9. The method of claim 1, wherein the deep learning model is a neural network, the FrontNet subnet model comprises an input layer of the neural network and one or more intermediate layers of the neural network model, and the BackNet subnet model comprises an output layer of the neural network and one or more intermediate layers of the neural network.\n10. The method of claim 1, wherein the trusted execution environment prevents access to the FrontNet subnet model and the one or more decrypted training datasets from outside the trusted execution environment.\n11. A computer program product comprising a computer readable storage medium having a computer readable program stored therein, wherein the computer readable program, when executed on a data processing system, causes the data processing system to implement a deep learning training service framework configured to:\nreceive from one or more client computing devices, one or more encrypted training datasets for training a deep learning model;\nexecute a FrontNet subnet model of the deep learning model in a trusted execution environment of the deep learning training service framework;\nexecute a BackNet subnet model of the deep learning model in the deep learning training service framework external to the trusted execution environment;\ndecrypt, by a security module executing within the trusted execution environment, the one or more encrypted training datasets;\ntrain, by training logic of the deep learning training service framework, the FrontNet subnet model and BackNet subnet model of the deep learning model based on the decrypted training datasets, wherein the FrontNet subnet model is trained within the trusted execution environment and provides intermediate representations to the BackNet subnet model which is trained external to the trusted execution environment using the intermediate representations; and\nrelease a trained deep learning model comprising a trained FrontNet subnet model and a trained BackNet subnet model, to the one or more client computing devices.\n12. The computer program product of claim 11, wherein the one or more client computing devices comprises a plurality of computing devices associated with a plurality of different training dataset providers, and wherein the security module executing within the trusted execution environment prevents training dataset providers from accessing training datasets provided by other training dataset providers.\n13. The computer program product of claim 12, wherein each of the training datasets provided by the different training dataset providers are used during the training of the FrontNet subnet model and the BackNet subnet model of the deep learning model to generate the trained deep learning model, and wherein the same trained deep learning model is released to each of the different training dataset providers.\n14. The computer program product of claim 11, wherein the computer readable program further configures the deep learning training service framework to:\nauthenticate, prior to decrypting the one or more encrypted training datasets, by the security module, training dataset providers of the one or more training dataset providers; and\ndiscard, by the security module, any training datasets from training dataset providers that do not pass the authentication from further use during training of the FrontNet subnet model and BackNet subnet model of the deep learning model.\n15. The computer program product of claim 14, wherein the computer readable program further configures the deep learning training service framework to:\nverify, by the security module, the integrity of the one or more training datasets; and\ndiscard, by the security module, any training datasets that do not pass the verification from further use during training of the FrontNet subnet model and BackNet subnet model of the deep learning model.\n16. The computer program product of claim 11, wherein the computer readable program further configures the deep learning training service framework to:\ngenerate, by a fingerprint generation module executing within the trusted execution environment, one or more first fingerprint data structures for the one or more training datasets; and\nstore, by the fingerprint generation module, the generated one or more first fingerprint data structures in an evidence storage.\n17. The computer program product of claim 16, wherein the computer readable program further configures the deep learning training service framework to:\nprocess, by the trained deep learning model, new input data to generate an output result and a second fingerprint data structure corresponding to the new input data;\nreceive, from a client device of the one or more client devices, a query comprising the second fingerprint data structure;\nsearch, by a query module executing in the deep learning training service framework, the evidence storage for a first fingerprint data structure similar to the second fingerprint data structure; and\nidentify, by the query module, a training dataset, of the one or more training datasets, and a corresponding training dataset provider based on an entry in the evidence storage having a first fingerprint data structure similar to the second fingerprint data structure.\n18. The computer program product of claim 17, wherein the computer readable program further configures the deep learning training service framework to:\nperform at least one of a debugging operation or a root cause analysis on the trained deep learning model based on the identified training dataset and identified corresponding training dataset provider.\n19. The computer program product of claim 11, wherein the deep learning model is a neural network, the FrontNet subnet model comprises an input layer of the neural network and one or more intermediate layers of the neural network model, and the BackNet subnet model comprises an output layer of the neural network and one or more intermediate layers of the neural network.\n20. A system, comprising:\nat least one processor; and\nat least one memory coupled to the at least one processor, wherein the at least one memory comprises instructions which, when executed by the at least one processor, cause the at least one processor to implement a deep learning training service framework configured to:\nreceive from one or more client computing devices, one or more encrypted training datasets for training a deep learning model;\nexecute a FrontNet subnet model of the deep learning model in a trusted execution environment of the deep learning training service framework;\nexecute a BackNet subnet model of the deep learning model in the deep learning training service framework external to the trusted execution environment;\ndecrypt, by a security module executing within the trusted execution environment, the one or more encrypted training datasets;\ntrain, by training logic of the deep learning training service framework, the FrontNet subnet model and BackNet subnet model of the deep learning model based on the decrypted training datasets, wherein the FrontNet subnet model is trained within the trusted execution environment and provides intermediate representations to the BackNet subnet model which is trained external to the trusted execution environment using the intermediate representations; and\nrelease a trained deep learning model comprising a trained FrontNet subnet model and a trained BackNet subnet model, to the one or more client computing devices.",
    "status": "Active",
    "citations_own": [
        "US20140189808A1",
        "US20170372201A1",
        "US20170372226A1",
        "US20190042878A1"
    ],
    "citations_ftf": [],
    "citedby_own": [
        "US20200175341A1",
        "CN111612168A",
        "US20200311300A1",
        "CN111935179A",
        "US20210019151A1",
        "US20210064760A1",
        "US20210073660A1",
        "CN112487460A",
        "US20210083855A1",
        "US20210097444A1",
        "US20210112038A1",
        "US10997542B2",
        "US10997318B2",
        "US10997315B2",
        "US11004125B2",
        "US11023842B2",
        "US11025675B2",
        "US11023616B2",
        "US11030563B2",
        "US11030327B2",
        "US11030274B2",
        "US11036771B2",
        "US11038925B2",
        "US11036674B2",
        "US11036882B2",
        "US11057356B2",
        "US11062051B2",
        "US11068618B2",
        "US11070593B2",
        "US11074367B2",
        "US11087260B2",
        "US11100444B2",
        "US11100445B2",
        "US11113416B2",
        "US11120162B2",
        "US11122011B2",
        "US11120161B2",
        "US11126748B2",
        "US11134086B2",
        "US11138318B2",
        "US11138336B2",
        "US11138299B2",
        "US11138242B2",
        "US11144675B2",
        "US11146566B2",
        "US11144622B2",
        "US11144670B2",
        "CN113505881A",
        "US11153347B2",
        "US11151233B2",
        "US11157654B2",
        "US11157600B2",
        "US11182501B2",
        "US11188862B2",
        "US11188615B2",
        "US11195134B2",
        "US11200341B2",
        "US11210420B2",
        "US11222309B2",
        "US11222139B2",
        "US11222142B2",
        "US11228620B2",
        "US11227247B2",
        "US11227192B1",
        "WO2022015594A1",
        "US11232356B2",
        "US11238390B2",
        "US11240273B2",
        "US11244367B2",
        "US11244071B2",
        "US11277448B2",
        "US11294939B2",
        "US11295316B2",
        "WO2022072894A1",
        "US20220108035A1",
        "US11301589B2",
        "US11301796B2",
        "US11308435B2",
        "KR102392576B1",
        "WO2022093240A1",
        "US11328092B2",
        "US11336697B2",
        "US11341447B2",
        "US11343284B2",
        "WO2022105607A1",
        "US11354435B2",
        "US11354579B2",
        "US11354434B2",
        "US11361057B2",
        "US11366909B2",
        "US11366786B2",
        "US11373007B2",
        "US11392720B2",
        "US11397819B2",
        "US11403377B2",
        "US11409908B2",
        "US11410106B2",
        "US11416109B2",
        "US11416589B2",
        "US11416798B2",
        "US11418492B2",
        "US11416590B2",
        "US11416634B2",
        "WO2022174787A1",
        "US11436019B2",
        "US11438386B2",
        "US11436373B2",
        "US11444976B2",
        "US11442906B2",
        "CN115051816A",
        "US20220292726A1",
        "CN115130140A",
        "US11461500B2",
        "US20220321332A1",
        "US11475136B2",
        "US11475165B2",
        "US11481710B2",
        "US11494515B2",
        "CN115344886A",
        "US11514366B2",
        "US11520928B2",
        "US11526624B2",
        "US11533315B2",
        "US20220405383A1",
        "US20220414223A1",
        "US11544667B2",
        "US11544409B2",
        "US11546661B2",
        "US11562078B2",
        "US11562097B2",
        "US11568199B2",
        "US11573828B2",
        "US11586762B2",
        "US11586700B2",
        "US11599752B2",
        "US11601464B2",
        "CN115797752A",
        "US11604986B2",
        "US11620142B1",
        "US11625502B2",
        "US20230118211A1",
        "US11636171B2",
        "US11651104B2",
        "US11651402B2",
        "US11651106B2",
        "US11675929B2",
        "US11687528B2",
        "US11704573B2",
        "US11727141B2",
        "US11775348B2",
        "US11797528B2",
        "US11811925B2"
    ],
    "citedby_ftf": []
}